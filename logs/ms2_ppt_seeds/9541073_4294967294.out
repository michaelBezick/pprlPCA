Job 9541073 / array task  on gilbreth-e003.rcac.purdue.edu
CUDA_VISIBLE_DEVICES=0
Group name is:  PCA_OCD
Instantiating 8 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
Instantiating 1 environments...
Environments instantiated.
BasicSampler: Resetting all environments.
BasicSampler: Resetting agent.
AuxPcSAC: Given sampler batch size 5120, training batch size 128, and replay ratio 64, there will be 2560 updates per iteration.
AuxPcSAC: Using learnable entropy coefficient with target entropy of -12
RLRunner: Starting training...
RLRunner: Saving log files to /scratch/gilbreth/mbezick/pprlPCA2/wandb/run-20250911_141441-nnqbbhfb/files
RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-11/nnqbbhfb/nominal/policy_step_0.mp4.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
----------------------------------
| eval/               |          |
|    Length           | 200      |
|    Return           | -228     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -228     |
|    Success          | 0        |
|    SuccessLength    | 200      |
|    StageReturn      | -1.4e+03 |
|    EECloseToHandle  | 0        |
|    OpenEnough       | 0        |
| time/               |          |
|    iterations       | 0        |
|    fps              | 0        |
|    elapsed_time     | 220      |
|    elapsed_steps    | 0        |
----------------------------------
For the first 10000 steps, agent will use a fixed std of 0.75 for exploration.
----------------------------------
| rollout/            |          |
|    Length           | 200      |
|    Return           | -217     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -217     |
|    Success          | 0        |
|    SuccessLength    | 200      |
|    StageReturn      | -1.4e+03 |
|    EECloseToHandle  | 0        |
|    OpenEnough       | 0        |
| time/               |          |
|    iterations       | 1        |
|    fps              | 12       |
|    elapsed_time     | 647      |
|    elapsed_steps    | 5120     |
----------------------------------
-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -216     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -216     |
|    Success           | 0        |
|    SuccessLength     | 200      |
|    StageReturn       | -1.4e+03 |
|    EECloseToHandle   | 0        |
|    OpenEnough        | 0        |
| algo/                |          |
|    critic_loss       | 0.00528  |
|    mean_entropy      | 8.05     |
|    mean_ent_bonus    | 0.711    |
|    max_target_q      | -1.36    |
|    min_target_q      | -3.77    |
|    max_reward        | -0.881   |
|    min_reward        | -1.41    |
|    chamfer_loss      | 0.00435  |
|    color_loss        | 0.00272  |
|    encoder_grad_norm | 0.187    |
|    q1_grad_norm      | 0.22     |
|    q2_grad_norm      | 0.22     |
|    actor_loss        | 1.64     |
|    ent_coeff         | 0.0882   |
|    ent_coeff_loss    | -48.7    |
|    pi_grad_norm      | 0.134    |
|    n_updates         | 2560     |
| time/                |          |
|    iterations        | 2        |
|    fps               | 2.67     |
|    elapsed_time      | 2.57e+03 |
|    elapsed_steps     | 10240    |
-----------------------------------
RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
