/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
wandb: Currently logged in as: michael-bezick (michael-bezick-purdue-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: creating run
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-mejuzx0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-energy-988
wandb: â­ï¸ View project at https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: ðŸš€ View run at https://wandb.ai/michael-bezick-purdue-university/pprl/runs/mejuzx0m
Group name is:  PCA_push_chair
Instantiating 8 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
BasicSampler: Resetting all environments.
BasicSampler: Resetting agent.
SAC: Given sampler batch size 2560, training batch size 512, and replay ratio 16, there will be 80 updates per iteration.
SAC: Using learnable entropy coefficient with target entropy of -20
RLRunner: Starting training...
RLRunner: Saving log files to /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-mejuzx0m/files
  0%|          | 0/1000000 [00:00<?, ?steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_0.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
wandb: WARNING Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                0%|          | 0/1000000 [04:24<?, ?steps/s]----------------------------------
| eval/               |          |
|    Length           | 200      |
|    Return           | -207     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -207     |
|    Success          | 0        |
|    SuccessLength    | 200      |
| time/               |          |
|    iterations       | 0        |
|    fps              | 0        |
|    elapsed_time     | 264      |
|    elapsed_steps    | 0        |
----------------------------------
For the first 10000 steps, agent will use a fixed std of 0.75 for exploration.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
  0%|          | 2560/1000000 [05:22<34:51:44,  7.95steps/s]  1%|          | 5120/1000000 [06:20<18:02:35, 15.32steps/s]  1%|          | 5120/1000000 [06:40<18:02:35, 15.32steps/s]  1%|          | 7680/1000000 [07:12<12:18:32, 22.39steps/s]                                                              1%|          | 7680/1000000 [07:12<12:18:32, 22.39steps/s]----------------------------------
| rollout/            |          |
|    Length           | 200      |
|    Return           | -211     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -211     |
|    Success          | 0        |
|    SuccessLength    | 200      |
| time/               |          |
|    iterations       | 3        |
|    fps              | 45.7     |
|    elapsed_time     | 432      |
|    elapsed_steps    | 7680     |
----------------------------------
  1%|          | 7680/1000000 [07:30<12:18:32, 22.39steps/s]  1%|          | 10240/1000000 [08:33<10:51:26, 25.32steps/s]  1%|          | 10240/1000000 [08:50<10:51:26, 25.32steps/s]  1%|â–         | 12800/1000000 [09:53<10:01:24, 27.36steps/s]  1%|â–         | 12800/1000000 [10:10<10:01:24, 27.36steps/s]  2%|â–         | 15360/1000000 [11:12<9:28:04, 28.89steps/s]                                                               2%|â–         | 15360/1000000 [11:12<9:28:04, 28.89steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -213     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -213     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00721  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.68     |
|    max_target_q      | -0.435   |
|    min_target_q      | -0.707   |
|    max_reward        | -0.763   |
|    min_reward        | -1.61    |
|    encoder_grad_norm | 0.0565   |
|    q1_grad_norm      | 0.146    |
|    q2_grad_norm      | 0.14     |
|    actor_loss        | 0.275    |
|    ent_coeff         | 0.0499   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.111    |
|    n_updates         | 240      |
| time/                |          |
|    iterations        | 6        |
|    fps               | 32       |
|    elapsed_time      | 672      |
|    elapsed_steps     | 15360    |
-----------------------------------
  2%|â–         | 15360/1000000 [11:30<9:28:04, 28.89steps/s]  2%|â–         | 17920/1000000 [12:29<9:03:09, 30.13steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  2%|â–         | 17920/1000000 [12:40<9:03:09, 30.13steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_17920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  2%|â–         | 20480/1000000 [18:02<17:24:20, 15.63steps/s]  2%|â–         | 23040/1000000 [19:20<14:31:45, 18.68steps/s]                                                               2%|â–         | 23040/1000000 [19:20<14:31:45, 18.68steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -214     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -214     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00498  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.677    |
|    max_target_q      | -1.11    |
|    min_target_q      | -1.81    |
|    max_reward        | -0.745   |
|    min_reward        | -1.59    |
|    encoder_grad_norm | 0.103    |
|    q1_grad_norm      | 0.144    |
|    q2_grad_norm      | 0.157    |
|    actor_loss        | 1.14     |
|    ent_coeff         | 0.0496   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0853   |
|    n_updates         | 480      |
| eval/                |          |
|    Length            | 200      |
|    Return            | -215     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -215     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 9        |
|    fps               | 15.7     |
|    elapsed_time      | 1.16e+03 |
|    elapsed_steps     | 23040    |
-----------------------------------
  2%|â–         | 23040/1000000 [19:40<14:31:45, 18.68steps/s]  3%|â–Ž         | 25600/1000000 [20:36<12:30:10, 21.65steps/s]  3%|â–Ž         | 25600/1000000 [20:50<12:30:10, 21.65steps/s]  3%|â–Ž         | 28160/1000000 [21:52<11:05:51, 24.33steps/s]  3%|â–Ž         | 28160/1000000 [22:10<11:05:51, 24.33steps/s]  3%|â–Ž         | 30720/1000000 [23:10<10:12:07, 26.39steps/s]                                                               3%|â–Ž         | 30720/1000000 [23:10<10:12:07, 26.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -210     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -210     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00666  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.674    |
|    max_target_q      | -1.69    |
|    min_target_q      | -2.94    |
|    max_reward        | -0.75    |
|    min_reward        | -1.6     |
|    encoder_grad_norm | 0.21     |
|    q1_grad_norm      | 0.272    |
|    q2_grad_norm      | 0.273    |
|    actor_loss        | 2.01     |
|    ent_coeff         | 0.0494   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0753   |
|    n_updates         | 720      |
| time/                |          |
|    iterations        | 12       |
|    fps               | 33.4     |
|    elapsed_time      | 1.39e+03 |
|    elapsed_steps     | 30720    |
-----------------------------------
  3%|â–Ž         | 30720/1000000 [23:30<10:12:07, 26.39steps/s]  3%|â–Ž         | 33280/1000000 [24:25<9:28:46, 28.33steps/s]   3%|â–Ž         | 33280/1000000 [24:40<9:28:46, 28.33steps/s]  4%|â–Ž         | 35840/1000000 [25:44<9:04:30, 29.51steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_35840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  4%|â–Ž         | 35840/1000000 [26:00<9:04:30, 29.51steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  4%|â–         | 38400/1000000 [31:07<16:29:17, 16.20steps/s]                                                               4%|â–         | 38400/1000000 [31:07<16:29:17, 16.20steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -208     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -208     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00902  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.67     |
|    max_target_q      | -2.27    |
|    min_target_q      | -4.06    |
|    max_reward        | -0.726   |
|    min_reward        | -1.6     |
|    encoder_grad_norm | 0.35     |
|    q1_grad_norm      | 0.422    |
|    q2_grad_norm      | 0.416    |
|    actor_loss        | 2.87     |
|    ent_coeff         | 0.0492   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0679   |
|    n_updates         | 960      |
| eval/                |          |
|    Length            | 200      |
|    Return            | -214     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -214     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 15       |
|    fps               | 16.1     |
|    elapsed_time      | 1.87e+03 |
|    elapsed_steps     | 38400    |
-----------------------------------
  4%|â–         | 40960/1000000 [32:14<13:35:58, 19.59steps/s]  4%|â–         | 40960/1000000 [32:30<13:35:58, 19.59steps/s]  4%|â–         | 43520/1000000 [33:20<11:32:26, 23.02steps/s]  4%|â–         | 43520/1000000 [33:40<11:32:26, 23.02steps/s]  5%|â–         | 46080/1000000 [34:25<10:05:01, 26.28steps/s]                                                               5%|â–         | 46080/1000000 [34:25<10:05:01, 26.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -205     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -205     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0108   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.666    |
|    max_target_q      | -2.84    |
|    min_target_q      | -5.16    |
|    max_reward        | -0.736   |
|    min_reward        | -1.57    |
|    encoder_grad_norm | 0.42     |
|    q1_grad_norm      | 0.491    |
|    q2_grad_norm      | 0.483    |
|    actor_loss        | 3.69     |
|    ent_coeff         | 0.0489   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0616   |
|    n_updates         | 1200     |
| time/                |          |
|    iterations        | 18       |
|    fps               | 38.7     |
|    elapsed_time      | 2.07e+03 |
|    elapsed_steps     | 46080    |
-----------------------------------
  5%|â–         | 46080/1000000 [34:40<10:05:01, 26.28steps/s]  5%|â–         | 48640/1000000 [35:33<9:08:06, 28.93steps/s]   5%|â–         | 48640/1000000 [35:50<9:08:06, 28.93steps/s]  5%|â–Œ         | 51200/1000000 [36:37<8:21:20, 31.54steps/s]  5%|â–Œ         | 51200/1000000 [36:50<8:21:20, 31.54steps/s]  5%|â–Œ         | 53760/1000000 [37:41<7:48:39, 33.65steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_53760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  5%|â–Œ         | 53760/1000000 [38:00<7:48:39, 33.65steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              5%|â–Œ         | 53760/1000000 [41:58<7:48:39, 33.65steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -203     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -203     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0128   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.663    |
|    max_target_q      | -3.41    |
|    min_target_q      | -6.25    |
|    max_reward        | -0.716   |
|    min_reward        | -1.56    |
|    encoder_grad_norm | 0.515    |
|    q1_grad_norm      | 0.57     |
|    q2_grad_norm      | 0.56     |
|    actor_loss        | 4.47     |
|    ent_coeff         | 0.0487   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0582   |
|    n_updates         | 1440     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -203     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -203     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 21       |
|    fps               | 16.9     |
|    elapsed_time      | 2.52e+03 |
|    elapsed_steps     | 53760    |
-----------------------------------
  6%|â–Œ         | 56320/1000000 [43:06<15:25:41, 16.99steps/s]  6%|â–Œ         | 58880/1000000 [44:10<12:43:21, 20.55steps/s]  6%|â–Œ         | 58880/1000000 [44:30<12:43:21, 20.55steps/s]  6%|â–Œ         | 61440/1000000 [45:20<11:01:18, 23.65steps/s]                                                               6%|â–Œ         | 61440/1000000 [45:20<11:01:18, 23.65steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -200     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -200     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0157   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.658    |
|    max_target_q      | -3.98    |
|    min_target_q      | -7.3     |
|    max_reward        | -0.72    |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 0.701    |
|    q1_grad_norm      | 0.753    |
|    q2_grad_norm      | 0.738    |
|    actor_loss        | 5.22     |
|    ent_coeff         | 0.0485   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.055    |
|    n_updates         | 1680     |
| time/                |          |
|    iterations        | 24       |
|    fps               | 38.2     |
|    elapsed_time      | 2.72e+03 |
|    elapsed_steps     | 61440    |
-----------------------------------
  6%|â–Œ         | 61440/1000000 [45:40<11:01:18, 23.65steps/s]  6%|â–‹         | 64000/1000000 [46:27<9:44:16, 26.70steps/s]   6%|â–‹         | 64000/1000000 [46:40<9:44:16, 26.70steps/s]  7%|â–‹         | 66560/1000000 [47:36<8:53:43, 29.15steps/s]  7%|â–‹         | 66560/1000000 [47:50<8:53:43, 29.15steps/s]  7%|â–‹         | 69120/1000000 [48:48<8:23:10, 30.83steps/s]                                                              7%|â–‹         | 69120/1000000 [48:48<8:23:10, 30.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -198     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -198     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0162   |
|    mean_entropy      | 13.4     |
|    mean_ent_bonus    | 0.648    |
|    max_target_q      | -4.49    |
|    min_target_q      | -8.36    |
|    max_reward        | -0.71    |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 0.669    |
|    q1_grad_norm      | 0.678    |
|    q2_grad_norm      | 0.664    |
|    actor_loss        | 5.94     |
|    ent_coeff         | 0.0482   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.057    |
|    n_updates         | 1920     |
| time/                |          |
|    iterations        | 27       |
|    fps               | 36.9     |
|    elapsed_time      | 2.93e+03 |
|    elapsed_steps     | 69120    |
-----------------------------------
  7%|â–‹         | 69120/1000000 [49:00<8:23:10, 30.83steps/s]  7%|â–‹         | 71680/1000000 [49:52<7:48:02, 33.06steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_71680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  7%|â–‹         | 71680/1000000 [50:10<7:48:02, 33.06steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  7%|â–‹         | 74240/1000000 [55:18<15:15:41, 16.85steps/s]  8%|â–Š         | 76800/1000000 [56:22<12:34:50, 20.38steps/s]                                                               8%|â–Š         | 76800/1000000 [56:22<12:34:50, 20.38steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -199     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -199     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0188   |
|    mean_entropy      | 13.1     |
|    mean_ent_bonus    | 0.63     |
|    max_target_q      | -4.9     |
|    min_target_q      | -9.38    |
|    max_reward        | -0.702   |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 0.847    |
|    q1_grad_norm      | 0.824    |
|    q2_grad_norm      | 0.802    |
|    actor_loss        | 6.59     |
|    ent_coeff         | 0.048    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0635   |
|    n_updates         | 2160     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -198     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -198     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 30       |
|    fps               | 16.9     |
|    elapsed_time      | 3.38e+03 |
|    elapsed_steps     | 76800    |
-----------------------------------
  8%|â–Š         | 76800/1000000 [56:40<12:34:50, 20.38steps/s]  8%|â–Š         | 79360/1000000 [57:25<10:40:52, 23.94steps/s]  8%|â–Š         | 79360/1000000 [57:40<10:40:52, 23.94steps/s]  8%|â–Š         | 81920/1000000 [58:35<9:32:36, 26.72steps/s]   8%|â–Š         | 81920/1000000 [58:50<9:32:36, 26.72steps/s]  8%|â–Š         | 84480/1000000 [59:40<8:35:28, 29.60steps/s]                                                              8%|â–Š         | 84480/1000000 [59:40<8:35:28, 29.60steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -195     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -195     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0222   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.622    |
|    max_target_q      | -5.32    |
|    min_target_q      | -10.3    |
|    max_reward        | -0.675   |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 1        |
|    q1_grad_norm      | 0.964    |
|    q2_grad_norm      | 0.944    |
|    actor_loss        | 7.21     |
|    ent_coeff         | 0.0478   |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0651   |
|    n_updates         | 2400     |
| time/                |          |
|    iterations        | 33       |
|    fps               | 38.8     |
|    elapsed_time      | 3.58e+03 |
|    elapsed_steps     | 84480    |
-----------------------------------
  8%|â–Š         | 84480/1000000 [1:00:00<8:35:28, 29.60steps/s]  9%|â–Š         | 87040/1000000 [1:00:44<7:54:07, 32.09steps/s]  9%|â–Š         | 87040/1000000 [1:01:00<7:54:07, 32.09steps/s]  9%|â–‰         | 89600/1000000 [1:01:51<7:29:45, 33.74steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_89600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  9%|â–‰         | 89600/1000000 [1:02:10<7:29:45, 33.74steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  9%|â–‰         | 92160/1000000 [1:07:05<14:31:13, 17.37steps/s]                                                                 9%|â–‰         | 92160/1000000 [1:07:05<14:31:13, 17.37steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -191     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -191     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0243   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.617    |
|    max_target_q      | -5.71    |
|    min_target_q      | -11.3    |
|    max_reward        | -0.641   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 1.01     |
|    q1_grad_norm      | 0.92     |
|    q2_grad_norm      | 0.896    |
|    actor_loss        | 7.77     |
|    ent_coeff         | 0.0475   |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0642   |
|    n_updates         | 2640     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -196     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -196     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 36       |
|    fps               | 17.3     |
|    elapsed_time      | 4.03e+03 |
|    elapsed_steps     | 92160    |
-----------------------------------
  9%|â–‰         | 94720/1000000 [1:08:08<11:59:36, 20.97steps/s]  9%|â–‰         | 94720/1000000 [1:08:20<11:59:36, 20.97steps/s] 10%|â–‰         | 97280/1000000 [1:09:11<10:13:36, 24.52steps/s] 10%|â–‰         | 97280/1000000 [1:09:30<10:13:36, 24.52steps/s] 10%|â–‰         | 99840/1000000 [1:10:20<9:09:01, 27.33steps/s]                                                                10%|â–‰         | 99840/1000000 [1:10:20<9:09:01, 27.33steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -192     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -192     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0274   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.615    |
|    max_target_q      | -6.08    |
|    min_target_q      | -12.2    |
|    max_reward        | -0.626   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 1.14     |
|    q1_grad_norm      | 1.02     |
|    q2_grad_norm      | 0.993    |
|    actor_loss        | 8.34     |
|    ent_coeff         | 0.0473   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0643   |
|    n_updates         | 2880     |
| time/                |          |
|    iterations        | 39       |
|    fps               | 39.4     |
|    elapsed_time      | 4.22e+03 |
|    elapsed_steps     | 99840    |
-----------------------------------
 10%|â–‰         | 99840/1000000 [1:10:40<9:09:01, 27.33steps/s] 10%|â–ˆ         | 102400/1000000 [1:11:28<8:23:05, 29.74steps/s] 10%|â–ˆ         | 102400/1000000 [1:11:40<8:23:05, 29.74steps/s] 10%|â–ˆ         | 104960/1000000 [1:12:37<7:51:58, 31.61steps/s] 10%|â–ˆ         | 104960/1000000 [1:12:50<7:51:58, 31.61steps/s] 11%|â–ˆ         | 107520/1000000 [1:13:41<7:21:09, 33.72steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_107520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 11%|â–ˆ         | 107520/1000000 [1:14:00<7:21:09, 33.72steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                11%|â–ˆ         | 107520/1000000 [1:18:05<7:21:09, 33.72steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -191     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -191     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0292   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.61     |
|    max_target_q      | -6.43    |
|    min_target_q      | -13.1    |
|    max_reward        | -0.621   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 1.09     |
|    q1_grad_norm      | 0.94     |
|    q2_grad_norm      | 0.913    |
|    actor_loss        | 8.88     |
|    ent_coeff         | 0.0471   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.066    |
|    n_updates         | 3120     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -190     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -190     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 42       |
|    fps               | 16.5     |
|    elapsed_time      | 4.69e+03 |
|    elapsed_steps     | 107520   |
-----------------------------------
 11%|â–ˆ         | 110080/1000000 [1:19:07<14:33:23, 16.98steps/s] 11%|â–ˆâ–        | 112640/1000000 [1:20:08<11:55:11, 20.68steps/s] 11%|â–ˆâ–        | 112640/1000000 [1:20:20<11:55:11, 20.68steps/s] 12%|â–ˆâ–        | 115200/1000000 [1:21:12<10:11:06, 24.13steps/s]                                                                 12%|â–ˆâ–        | 115200/1000000 [1:21:12<10:11:06, 24.13steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -189     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -189     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0339   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.604    |
|    max_target_q      | -6.74    |
|    min_target_q      | -13.9    |
|    max_reward        | -0.604   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 1.45     |
|    q1_grad_norm      | 1.27     |
|    q2_grad_norm      | 1.24     |
|    actor_loss        | 9.39     |
|    ent_coeff         | 0.0469   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0696   |
|    n_updates         | 3360     |
| time/                |          |
|    iterations        | 45       |
|    fps               | 40.9     |
|    elapsed_time      | 4.87e+03 |
|    elapsed_steps     | 115200   |
-----------------------------------
 12%|â–ˆâ–        | 115200/1000000 [1:21:30<10:11:06, 24.13steps/s] 12%|â–ˆâ–        | 117760/1000000 [1:22:16<8:56:00, 27.43steps/s]  12%|â–ˆâ–        | 117760/1000000 [1:22:30<8:56:00, 27.43steps/s] 12%|â–ˆâ–        | 120320/1000000 [1:23:22<8:07:09, 30.10steps/s] 12%|â–ˆâ–        | 120320/1000000 [1:23:40<8:07:09, 30.10steps/s] 12%|â–ˆâ–        | 122880/1000000 [1:24:28<7:32:52, 32.28steps/s]                                                                12%|â–ˆâ–        | 122880/1000000 [1:24:28<7:32:52, 32.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -189     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -189     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0367   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.601    |
|    max_target_q      | -7.05    |
|    min_target_q      | -14.8    |
|    max_reward        | -0.549   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 1.4      |
|    q1_grad_norm      | 1.21     |
|    q2_grad_norm      | 1.18     |
|    actor_loss        | 9.88     |
|    ent_coeff         | 0.0467   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0705   |
|    n_updates         | 3600     |
| time/                |          |
|    iterations        | 48       |
|    fps               | 39.3     |
|    elapsed_time      | 5.07e+03 |
|    elapsed_steps     | 122880   |
-----------------------------------
 12%|â–ˆâ–        | 122880/1000000 [1:24:40<7:32:52, 32.28steps/s] 13%|â–ˆâ–Ž        | 125440/1000000 [1:25:32<7:06:35, 34.17steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_125440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 13%|â–ˆâ–Ž        | 125440/1000000 [1:25:50<7:06:35, 34.17steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 13%|â–ˆâ–Ž        | 128000/1000000 [1:31:02<14:19:09, 16.92steps/s] 13%|â–ˆâ–Ž        | 130560/1000000 [1:32:10<11:54:52, 20.27steps/s]                                                                 13%|â–ˆâ–Ž        | 130560/1000000 [1:32:10<11:54:52, 20.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -188     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -188     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0423   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.599    |
|    max_target_q      | -7.32    |
|    min_target_q      | -15.6    |
|    max_reward        | -0.547   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 1.8      |
|    q1_grad_norm      | 1.6      |
|    q2_grad_norm      | 1.56     |
|    actor_loss        | 10.4     |
|    ent_coeff         | 0.0464   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0679   |
|    n_updates         | 3840     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -187     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -187     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 51       |
|    fps               | 16.6     |
|    elapsed_time      | 5.53e+03 |
|    elapsed_steps     | 130560   |
-----------------------------------
 13%|â–ˆâ–Ž        | 130560/1000000 [1:32:30<11:54:52, 20.27steps/s] 13%|â–ˆâ–Ž        | 133120/1000000 [1:33:18<10:14:30, 23.51steps/s] 13%|â–ˆâ–Ž        | 133120/1000000 [1:33:30<10:14:30, 23.51steps/s] 14%|â–ˆâ–Ž        | 135680/1000000 [1:34:28<9:07:01, 26.33steps/s]  14%|â–ˆâ–Ž        | 135680/1000000 [1:34:40<9:07:01, 26.33steps/s] 14%|â–ˆâ–        | 138240/1000000 [1:35:36<8:15:53, 28.96steps/s]                                                                14%|â–ˆâ–        | 138240/1000000 [1:35:36<8:15:53, 28.96steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -185     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -185     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0436   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.597    |
|    max_target_q      | -7.65    |
|    min_target_q      | -16.3    |
|    max_reward        | -0.524   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 1.58     |
|    q1_grad_norm      | 1.38     |
|    q2_grad_norm      | 1.35     |
|    actor_loss        | 10.9     |
|    ent_coeff         | 0.0462   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0674   |
|    n_updates         | 4080     |
| time/                |          |
|    iterations        | 54       |
|    fps               | 37.3     |
|    elapsed_time      | 5.74e+03 |
|    elapsed_steps     | 138240   |
-----------------------------------
 14%|â–ˆâ–        | 138240/1000000 [1:35:50<8:15:53, 28.96steps/s] 14%|â–ˆâ–        | 140800/1000000 [1:36:44<7:39:40, 31.15steps/s] 14%|â–ˆâ–        | 140800/1000000 [1:37:00<7:39:40, 31.15steps/s] 14%|â–ˆâ–        | 143360/1000000 [1:37:49<7:09:36, 33.23steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 14%|â–ˆâ–        | 143360/1000000 [1:38:00<7:09:36, 33.23steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_143360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 15%|â–ˆâ–        | 145920/1000000 [1:43:27<14:25:09, 16.45steps/s]                                                                 15%|â–ˆâ–        | 145920/1000000 [1:43:27<14:25:09, 16.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -182     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -182     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0467   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.598    |
|    max_target_q      | -7.95    |
|    min_target_q      | -17.1    |
|    max_reward        | -0.502   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 1.6      |
|    q1_grad_norm      | 1.35     |
|    q2_grad_norm      | 1.32     |
|    actor_loss        | 11.3     |
|    ent_coeff         | 0.046    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0643   |
|    n_updates         | 4320     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -180     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -180     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 57       |
|    fps               | 16.3     |
|    elapsed_time      | 6.21e+03 |
|    elapsed_steps     | 145920   |
-----------------------------------
 15%|â–ˆâ–        | 148480/1000000 [1:44:37<11:59:31, 19.72steps/s] 15%|â–ˆâ–        | 148480/1000000 [1:44:50<11:59:31, 19.72steps/s] 15%|â–ˆâ–Œ        | 151040/1000000 [1:45:50<10:22:33, 22.73steps/s] 15%|â–ˆâ–Œ        | 151040/1000000 [1:46:10<10:22:33, 22.73steps/s] 15%|â–ˆâ–Œ        | 153600/1000000 [1:47:01<9:11:43, 25.57steps/s]                                                                 15%|â–ˆâ–Œ        | 153600/1000000 [1:47:01<9:11:43, 25.57steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -181     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -181     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.0517   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.595    |
|    max_target_q      | -8.25    |
|    min_target_q      | -17.8    |
|    max_reward        | -0.489   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 1.87     |
|    q1_grad_norm      | 1.57     |
|    q2_grad_norm      | 1.53     |
|    actor_loss        | 11.8     |
|    ent_coeff         | 0.0458   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0626   |
|    n_updates         | 4560     |
| time/                |          |
|    iterations        | 60       |
|    fps               | 36       |
|    elapsed_time      | 6.42e+03 |
|    elapsed_steps     | 153600   |
-----------------------------------
 15%|â–ˆâ–Œ        | 153600/1000000 [1:47:20<9:11:43, 25.57steps/s] 16%|â–ˆâ–Œ        | 156160/1000000 [1:48:08<8:16:32, 28.32steps/s] 16%|â–ˆâ–Œ        | 156160/1000000 [1:48:20<8:16:32, 28.32steps/s] 16%|â–ˆâ–Œ        | 158720/1000000 [1:49:17<7:39:45, 30.50steps/s] 16%|â–ˆâ–Œ        | 158720/1000000 [1:49:30<7:39:45, 30.50steps/s] 16%|â–ˆâ–Œ        | 161280/1000000 [1:50:20<7:04:05, 32.96steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_161280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 16%|â–ˆâ–Œ        | 161280/1000000 [1:50:40<7:04:05, 32.96steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                16%|â–ˆâ–Œ        | 161280/1000000 [1:54:52<7:04:05, 32.96steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -179     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -179     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.053    |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.592    |
|    max_target_q      | -8.54    |
|    min_target_q      | -18.5    |
|    max_reward        | -0.467   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 1.73     |
|    q1_grad_norm      | 1.47     |
|    q2_grad_norm      | 1.43     |
|    actor_loss        | 12.3     |
|    ent_coeff         | 0.0455   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0611   |
|    n_updates         | 4800     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -176     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -176     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 63       |
|    fps               | 16.3     |
|    elapsed_time      | 6.89e+03 |
|    elapsed_steps     | 161280   |
-----------------------------------
 16%|â–ˆâ–‹        | 163840/1000000 [1:56:00<14:11:00, 16.38steps/s] 17%|â–ˆâ–‹        | 166400/1000000 [1:57:06<11:41:04, 19.82steps/s] 17%|â–ˆâ–‹        | 166400/1000000 [1:57:20<11:41:04, 19.82steps/s] 17%|â–ˆâ–‹        | 168960/1000000 [1:58:12<9:55:52, 23.24steps/s]                                                                 17%|â–ˆâ–‹        | 168960/1000000 [1:58:12<9:55:52, 23.24steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -178     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -178     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0591   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.589    |
|    max_target_q      | -8.82    |
|    min_target_q      | -19.3    |
|    max_reward        | -0.465   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 2.21     |
|    q1_grad_norm      | 1.91     |
|    q2_grad_norm      | 1.87     |
|    actor_loss        | 12.7     |
|    ent_coeff         | 0.0453   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0602   |
|    n_updates         | 5040     |
| time/                |          |
|    iterations        | 66       |
|    fps               | 38.6     |
|    elapsed_time      | 7.09e+03 |
|    elapsed_steps     | 168960   |
-----------------------------------
 17%|â–ˆâ–‹        | 168960/1000000 [1:58:30<9:55:52, 23.24steps/s] 17%|â–ˆâ–‹        | 171520/1000000 [1:59:14<8:37:32, 26.68steps/s] 17%|â–ˆâ–‹        | 171520/1000000 [1:59:30<8:37:32, 26.68steps/s] 17%|â–ˆâ–‹        | 174080/1000000 [2:00:18<7:44:05, 29.66steps/s] 17%|â–ˆâ–‹        | 174080/1000000 [2:00:30<7:44:05, 29.66steps/s] 18%|â–ˆâ–Š        | 176640/1000000 [2:01:27<7:14:57, 31.55steps/s]                                                                18%|â–ˆâ–Š        | 176640/1000000 [2:01:27<7:14:57, 31.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -174     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -174     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0593   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.587    |
|    max_target_q      | -9.05    |
|    min_target_q      | -20      |
|    max_reward        | -0.45    |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 1.92     |
|    q1_grad_norm      | 1.6      |
|    q2_grad_norm      | 1.56     |
|    actor_loss        | 13.1     |
|    ent_coeff         | 0.0451   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0593   |
|    n_updates         | 5280     |
| time/                |          |
|    iterations        | 69       |
|    fps               | 39.2     |
|    elapsed_time      | 7.29e+03 |
|    elapsed_steps     | 176640   |
-----------------------------------
 18%|â–ˆâ–Š        | 176640/1000000 [2:01:40<7:14:57, 31.55steps/s] 18%|â–ˆâ–Š        | 179200/1000000 [2:02:35<6:51:53, 33.21steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 18%|â–ˆâ–Š        | 179200/1000000 [2:02:50<6:51:53, 33.21steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_179200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 18%|â–ˆâ–Š        | 181760/1000000 [2:08:09<13:41:30, 16.60steps/s] 18%|â–ˆâ–Š        | 184320/1000000 [2:09:15<11:18:44, 20.03steps/s]                                                                 18%|â–ˆâ–Š        | 184320/1000000 [2:09:15<11:18:44, 20.03steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -172     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -172     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0626   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.583    |
|    max_target_q      | -9.23    |
|    min_target_q      | -20.7    |
|    max_reward        | -0.431   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 2.08     |
|    q1_grad_norm      | 1.76     |
|    q2_grad_norm      | 1.72     |
|    actor_loss        | 13.5     |
|    ent_coeff         | 0.0449   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0584   |
|    n_updates         | 5520     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -172     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -172     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 72       |
|    fps               | 16.4     |
|    elapsed_time      | 7.76e+03 |
|    elapsed_steps     | 184320   |
-----------------------------------
 18%|â–ˆâ–Š        | 184320/1000000 [2:09:30<11:18:44, 20.03steps/s] 19%|â–ˆâ–Š        | 186880/1000000 [2:10:20<9:36:39, 23.50steps/s]  19%|â–ˆâ–Š        | 186880/1000000 [2:10:40<9:36:39, 23.50steps/s] 19%|â–ˆâ–‰        | 189440/1000000 [2:11:25<8:24:53, 26.76steps/s] 19%|â–ˆâ–‰        | 189440/1000000 [2:11:40<8:24:53, 26.76steps/s] 19%|â–ˆâ–‰        | 192000/1000000 [2:12:32<7:38:21, 29.38steps/s]                                                                19%|â–ˆâ–‰        | 192000/1000000 [2:12:32<7:38:21, 29.38steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -171     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -171     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.068    |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.578    |
|    max_target_q      | -9.46    |
|    min_target_q      | -21.3    |
|    max_reward        | -0.392   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 2.31     |
|    q1_grad_norm      | 1.95     |
|    q2_grad_norm      | 1.92     |
|    actor_loss        | 13.9     |
|    ent_coeff         | 0.0447   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0594   |
|    n_updates         | 5760     |
| time/                |          |
|    iterations        | 75       |
|    fps               | 39       |
|    elapsed_time      | 7.95e+03 |
|    elapsed_steps     | 192000   |
-----------------------------------
 19%|â–ˆâ–‰        | 192000/1000000 [2:12:50<7:38:21, 29.38steps/s] 19%|â–ˆâ–‰        | 194560/1000000 [2:13:40<7:06:15, 31.49steps/s] 19%|â–ˆâ–‰        | 194560/1000000 [2:14:00<7:06:15, 31.49steps/s] 20%|â–ˆâ–‰        | 197120/1000000 [2:14:45<6:40:11, 33.44steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 20%|â–ˆâ–‰        | 197120/1000000 [2:15:00<6:40:11, 33.44steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_197120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 20%|â–ˆâ–‰        | 199680/1000000 [2:20:24<13:28:56, 16.49steps/s]                                                                 20%|â–ˆâ–‰        | 199680/1000000 [2:20:24<13:28:56, 16.49steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -166     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -166     |
|    Success           | 0.0571   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.0719   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.574    |
|    max_target_q      | -9.71    |
|    min_target_q      | -22      |
|    max_reward        | -0.39    |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 2.29     |
|    q1_grad_norm      | 1.92     |
|    q2_grad_norm      | 1.87     |
|    actor_loss        | 14.3     |
|    ent_coeff         | 0.0445   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0598   |
|    n_updates         | 6000     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -170     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -170     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 78       |
|    fps               | 16.3     |
|    elapsed_time      | 8.42e+03 |
|    elapsed_steps     | 199680   |
-----------------------------------
 20%|â–ˆâ–ˆ        | 202240/1000000 [2:21:35<11:14:25, 19.71steps/s] 20%|â–ˆâ–ˆ        | 202240/1000000 [2:21:50<11:14:25, 19.71steps/s] 20%|â–ˆâ–ˆ        | 204800/1000000 [2:22:46<9:40:48, 22.82steps/s]  20%|â–ˆâ–ˆ        | 204800/1000000 [2:23:00<9:40:48, 22.82steps/s] 21%|â–ˆâ–ˆ        | 207360/1000000 [2:24:01<8:41:08, 25.35steps/s]                                                                21%|â–ˆâ–ˆ        | 207360/1000000 [2:24:01<8:41:08, 25.35steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -168     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -168     |
|    Success           | 0.0263   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.0806   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.57     |
|    max_target_q      | -9.96    |
|    min_target_q      | -22.6    |
|    max_reward        | -0.384   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 2.54     |
|    q1_grad_norm      | 2.14     |
|    q2_grad_norm      | 2.09     |
|    actor_loss        | 14.7     |
|    ent_coeff         | 0.0443   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0601   |
|    n_updates         | 6240     |
| time/                |          |
|    iterations        | 81       |
|    fps               | 35.5     |
|    elapsed_time      | 8.64e+03 |
|    elapsed_steps     | 207360   |
-----------------------------------
 21%|â–ˆâ–ˆ        | 207360/1000000 [2:24:20<8:41:08, 25.35steps/s] 21%|â–ˆâ–ˆ        | 209920/1000000 [2:25:14<7:56:30, 27.63steps/s] 21%|â–ˆâ–ˆ        | 209920/1000000 [2:25:30<7:56:30, 27.63steps/s] 21%|â–ˆâ–ˆ        | 212480/1000000 [2:26:24<7:20:26, 29.80steps/s] 21%|â–ˆâ–ˆ        | 212480/1000000 [2:26:40<7:20:26, 29.80steps/s] 22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:27:30<6:49:04, 31.98steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_215040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:27:50<6:49:04, 31.98steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:32:03<6:49:04, 31.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -167     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -167     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0796   |
|    mean_entropy      | 12.8     |
|    mean_ent_bonus    | 0.563    |
|    max_target_q      | -10.2    |
|    min_target_q      | -23.3    |
|    max_reward        | -0.371   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 2.38     |
|    q1_grad_norm      | 1.97     |
|    q2_grad_norm      | 1.92     |
|    actor_loss        | 15       |
|    ent_coeff         | 0.044    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0604   |
|    n_updates         | 6480     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -172     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -172     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 84       |
|    fps               | 15.9     |
|    elapsed_time      | 9.12e+03 |
|    elapsed_steps     | 215040   |
-----------------------------------
 22%|â–ˆâ–ˆâ–       | 217600/1000000 [2:33:20<13:40:19, 15.90steps/s] 22%|â–ˆâ–ˆâ–       | 220160/1000000 [2:34:36<11:27:35, 18.90steps/s] 22%|â–ˆâ–ˆâ–       | 220160/1000000 [2:34:50<11:27:35, 18.90steps/s] 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:35:50<9:52:19, 21.87steps/s]                                                                 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:35:50<9:52:19, 21.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -166     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -166     |
|    Success           | 0.05     |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.0885   |
|    mean_entropy      | 12.7     |
|    mean_ent_bonus    | 0.555    |
|    max_target_q      | -10.4    |
|    min_target_q      | -23.9    |
|    max_reward        | -0.374   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 2.37     |
|    q1_grad_norm      | 1.9      |
|    q2_grad_norm      | 1.86     |
|    actor_loss        | 15.3     |
|    ent_coeff         | 0.0438   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0621   |
|    n_updates         | 6720     |
| time/                |          |
|    iterations        | 87       |
|    fps               | 33.8     |
|    elapsed_time      | 9.35e+03 |
|    elapsed_steps     | 222720   |
-----------------------------------
 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:36:10<9:52:19, 21.87steps/s] 23%|â–ˆâ–ˆâ–Ž       | 225280/1000000 [2:37:07<8:49:40, 24.38steps/s] 23%|â–ˆâ–ˆâ–Ž       | 225280/1000000 [2:37:20<8:49:40, 24.38steps/s] 23%|â–ˆâ–ˆâ–Ž       | 227840/1000000 [2:38:22<8:02:44, 26.66steps/s] 23%|â–ˆâ–ˆâ–Ž       | 227840/1000000 [2:38:40<8:02:44, 26.66steps/s] 23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:39:33<7:23:29, 28.92steps/s]                                                                23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:39:33<7:23:29, 28.92steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -165     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -165     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0984   |
|    mean_entropy      | 12.6     |
|    mean_ent_bonus    | 0.55     |
|    max_target_q      | -10.5    |
|    min_target_q      | -24.6    |
|    max_reward        | -0.369   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 2.89     |
|    q1_grad_norm      | 2.38     |
|    q2_grad_norm      | 2.33     |
|    actor_loss        | 15.6     |
|    ent_coeff         | 0.0436   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0627   |
|    n_updates         | 6960     |
| time/                |          |
|    iterations        | 90       |
|    fps               | 34.4     |
|    elapsed_time      | 9.57e+03 |
|    elapsed_steps     | 230400   |
-----------------------------------
 23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:39:50<7:23:29, 28.92steps/s] 23%|â–ˆâ–ˆâ–Ž       | 232960/1000000 [2:40:42<6:52:05, 31.02steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_232960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 23%|â–ˆâ–ˆâ–Ž       | 232960/1000000 [2:41:00<6:52:05, 31.02steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 24%|â–ˆâ–ˆâ–Ž       | 235520/1000000 [2:46:32<13:29:59, 15.73steps/s] 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:47:45<11:13:50, 18.85steps/s]                                                                 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:47:45<11:13:50, 18.85steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -161     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -161     |
|    Success           | 0.0526   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.103    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.543    |
|    max_target_q      | -10.8    |
|    min_target_q      | -25.2    |
|    max_reward        | -0.353   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 2.94     |
|    q1_grad_norm      | 2.46     |
|    q2_grad_norm      | 2.4      |
|    actor_loss        | 15.9     |
|    ent_coeff         | 0.0434   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.065    |
|    n_updates         | 7200     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -166     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -166     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 93       |
|    fps               | 15.6     |
|    elapsed_time      | 1.01e+04 |
|    elapsed_steps     | 238080   |
-----------------------------------
 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:48:00<11:13:50, 18.85steps/s] 24%|â–ˆâ–ˆâ–       | 240640/1000000 [2:48:59<9:39:54, 21.82steps/s]  24%|â–ˆâ–ˆâ–       | 240640/1000000 [2:49:10<9:39:54, 21.82steps/s] 24%|â–ˆâ–ˆâ–       | 243200/1000000 [2:50:16<8:38:34, 24.32steps/s] 24%|â–ˆâ–ˆâ–       | 243200/1000000 [2:50:30<8:38:34, 24.32steps/s] 25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:51:32<7:54:25, 26.50steps/s]                                                                25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:51:32<7:54:25, 26.50steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -159     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -159     |
|    Success           | 0.027    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.0992   |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.536    |
|    max_target_q      | -10.9    |
|    min_target_q      | -25.8    |
|    max_reward        | -0.348   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 2.77     |
|    q1_grad_norm      | 2.27     |
|    q2_grad_norm      | 2.22     |
|    actor_loss        | 16.2     |
|    ent_coeff         | 0.0432   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0642   |
|    n_updates         | 7440     |
| time/                |          |
|    iterations        | 96       |
|    fps               | 33.7     |
|    elapsed_time      | 1.03e+04 |
|    elapsed_steps     | 245760   |
-----------------------------------
 25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:51:50<7:54:25, 26.50steps/s] 25%|â–ˆâ–ˆâ–       | 248320/1000000 [2:52:43<7:14:43, 28.82steps/s] 25%|â–ˆâ–ˆâ–       | 248320/1000000 [2:53:00<7:14:43, 28.82steps/s] 25%|â–ˆâ–ˆâ–Œ       | 250880/1000000 [2:53:46<6:34:52, 31.62steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 25%|â–ˆâ–ˆâ–Œ       | 250880/1000000 [2:54:00<6:34:52, 31.62steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_250880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 25%|â–ˆâ–ˆâ–Œ       | 253440/1000000 [2:59:40<13:11:54, 15.71steps/s]                                                                 25%|â–ˆâ–ˆâ–Œ       | 253440/1000000 [2:59:40<13:11:54, 15.71steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -164     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -164     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0951   |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.529    |
|    max_target_q      | -11.1    |
|    min_target_q      | -26.4    |
|    max_reward        | -0.341   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 2.48     |
|    q1_grad_norm      | 1.93     |
|    q2_grad_norm      | 1.89     |
|    actor_loss        | 16.4     |
|    ent_coeff         | 0.043    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0664   |
|    n_updates         | 7680     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0.0556   |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 99       |
|    fps               | 15.8     |
|    elapsed_time      | 1.08e+04 |
|    elapsed_steps     | 253440   |
-----------------------------------
 26%|â–ˆâ–ˆâ–Œ       | 256000/1000000 [3:00:49<10:52:21, 19.01steps/s] 26%|â–ˆâ–ˆâ–Œ       | 256000/1000000 [3:01:00<10:52:21, 19.01steps/s] 26%|â–ˆâ–ˆâ–Œ       | 258560/1000000 [3:01:58<9:15:19, 22.25steps/s]  26%|â–ˆâ–ˆâ–Œ       | 258560/1000000 [3:02:10<9:15:19, 22.25steps/s] 26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:03:07<8:07:52, 25.24steps/s]                                                                26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:03:07<8:07:52, 25.24steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -158     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -158     |
|    Success           | 0.05     |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.109    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.525    |
|    max_target_q      | -11.2    |
|    min_target_q      | -26.9    |
|    max_reward        | -0.33    |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.17     |
|    q1_grad_norm      | 2.59     |
|    q2_grad_norm      | 2.54     |
|    actor_loss        | 16.7     |
|    ent_coeff         | 0.0428   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0672   |
|    n_updates         | 7920     |
| time/                |          |
|    iterations        | 102      |
|    fps               | 37       |
|    elapsed_time      | 1.1e+04  |
|    elapsed_steps     | 261120   |
-----------------------------------
 26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:03:20<8:07:52, 25.24steps/s] 26%|â–ˆâ–ˆâ–‹       | 263680/1000000 [3:04:15<7:18:00, 28.02steps/s] 26%|â–ˆâ–ˆâ–‹       | 263680/1000000 [3:04:30<7:18:00, 28.02steps/s] 27%|â–ˆâ–ˆâ–‹       | 266240/1000000 [3:05:20<6:38:44, 30.67steps/s] 27%|â–ˆâ–ˆâ–‹       | 266240/1000000 [3:05:40<6:38:44, 30.67steps/s] 27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:06:29<6:15:47, 32.43steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:06:40<6:15:47, 32.43steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_268800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:11:00<6:15:47, 32.43steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -161     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -161     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.118    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.521    |
|    max_target_q      | -11.4    |
|    min_target_q      | -27.6    |
|    max_reward        | -0.336   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.39     |
|    q1_grad_norm      | 2.8      |
|    q2_grad_norm      | 2.74     |
|    actor_loss        | 16.9     |
|    ent_coeff         | 0.0426   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0677   |
|    n_updates         | 8160     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -166     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -166     |
|    Success           | 0.0556   |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 105      |
|    fps               | 16.3     |
|    elapsed_time      | 1.15e+04 |
|    elapsed_steps     | 268800   |
-----------------------------------
 27%|â–ˆâ–ˆâ–‹       | 271360/1000000 [3:12:10<12:27:19, 16.25steps/s] 27%|â–ˆâ–ˆâ–‹       | 273920/1000000 [3:13:20<10:21:37, 19.47steps/s] 27%|â–ˆâ–ˆâ–‹       | 273920/1000000 [3:13:40<10:21:37, 19.47steps/s] 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:14:32<8:54:07, 22.58steps/s]                                                                 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:14:32<8:54:07, 22.58steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -155     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0811   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.117    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.515    |
|    max_target_q      | -11.6    |
|    min_target_q      | -28.2    |
|    max_reward        | -0.315   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 2.96     |
|    q1_grad_norm      | 2.31     |
|    q2_grad_norm      | 2.26     |
|    actor_loss        | 17.1     |
|    ent_coeff         | 0.0424   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0681   |
|    n_updates         | 8400     |
| time/                |          |
|    iterations        | 108      |
|    fps               | 36.2     |
|    elapsed_time      | 1.17e+04 |
|    elapsed_steps     | 276480   |
-----------------------------------
 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:14:50<8:54:07, 22.58steps/s] 28%|â–ˆâ–ˆâ–Š       | 279040/1000000 [3:15:44<7:55:09, 25.29steps/s] 28%|â–ˆâ–ˆâ–Š       | 279040/1000000 [3:16:00<7:55:09, 25.29steps/s] 28%|â–ˆâ–ˆâ–Š       | 281600/1000000 [3:16:59<7:16:00, 27.46steps/s] 28%|â–ˆâ–ˆâ–Š       | 281600/1000000 [3:17:10<7:16:00, 27.46steps/s] 28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:18:06<6:37:38, 30.00steps/s]                                                                28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:18:06<6:37:38, 30.00steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -155     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -155     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.117    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.51     |
|    max_target_q      | -11.7    |
|    min_target_q      | -28.7    |
|    max_reward        | -0.318   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 3.31     |
|    q1_grad_norm      | 2.69     |
|    q2_grad_norm      | 2.62     |
|    actor_loss        | 17.3     |
|    ent_coeff         | 0.0422   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0687   |
|    n_updates         | 8640     |
| time/                |          |
|    iterations        | 111      |
|    fps               | 35.8     |
|    elapsed_time      | 1.19e+04 |
|    elapsed_steps     | 284160   |
-----------------------------------
 28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:18:20<6:37:38, 30.00steps/s] 29%|â–ˆâ–ˆâ–Š       | 286720/1000000 [3:19:12<6:09:33, 32.17steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_286720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 29%|â–ˆâ–ˆâ–Š       | 286720/1000000 [3:19:30<6:09:33, 32.17steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 29%|â–ˆâ–ˆâ–‰       | 289280/1000000 [3:25:01<12:21:34, 15.97steps/s] 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:26:16<10:21:27, 18.99steps/s]                                                                 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:26:16<10:21:27, 18.99steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -153     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -153     |
|    Success           | 0.105    |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.123    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.506    |
|    max_target_q      | -11.8    |
|    min_target_q      | -29.2    |
|    max_reward        | -0.319   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.26     |
|    q1_grad_norm      | 2.59     |
|    q2_grad_norm      | 2.53     |
|    actor_loss        | 17.5     |
|    ent_coeff         | 0.042    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.07     |
|    n_updates         | 8880     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 114      |
|    fps               | 15.7     |
|    elapsed_time      | 1.24e+04 |
|    elapsed_steps     | 291840   |
-----------------------------------
 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:26:30<10:21:27, 18.99steps/s] 29%|â–ˆâ–ˆâ–‰       | 294400/1000000 [3:27:33<9:00:04, 21.77steps/s]  29%|â–ˆâ–ˆâ–‰       | 294400/1000000 [3:27:50<9:00:04, 21.77steps/s] 30%|â–ˆâ–ˆâ–‰       | 296960/1000000 [3:28:47<7:57:50, 24.52steps/s] 30%|â–ˆâ–ˆâ–‰       | 296960/1000000 [3:29:00<7:57:50, 24.52steps/s] 30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:30:02<7:16:04, 26.77steps/s]                                                                30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:30:02<7:16:04, 26.77steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -160     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -160     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.134    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.501    |
|    max_target_q      | -11.9    |
|    min_target_q      | -29.8    |
|    max_reward        | -0.308   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 2.93     |
|    q1_grad_norm      | 2.15     |
|    q2_grad_norm      | 2.11     |
|    actor_loss        | 17.7     |
|    ent_coeff         | 0.0418   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0702   |
|    n_updates         | 9120     |
| time/                |          |
|    iterations        | 117      |
|    fps               | 34       |
|    elapsed_time      | 1.26e+04 |
|    elapsed_steps     | 299520   |
-----------------------------------
 30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:30:20<7:16:04, 26.77steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 302080/1000000 [3:31:09<6:34:35, 29.48steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 302080/1000000 [3:31:20<6:34:35, 29.48steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 304640/1000000 [3:32:15<6:05:06, 31.74steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 30%|â–ˆâ–ˆâ–ˆ       | 304640/1000000 [3:32:30<6:05:06, 31.74steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_304640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 31%|â–ˆâ–ˆâ–ˆ       | 307200/1000000 [3:38:12<12:18:37, 15.63steps/s]                                                                 31%|â–ˆâ–ˆâ–ˆ       | 307200/1000000 [3:38:12<12:18:37, 15.63steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -156     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -156     |
|    Success           | 0.05     |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.129    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.499    |
|    max_target_q      | -12.1    |
|    min_target_q      | -30.3    |
|    max_reward        | -0.304   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.37     |
|    q1_grad_norm      | 2.67     |
|    q2_grad_norm      | 2.63     |
|    actor_loss        | 17.9     |
|    ent_coeff         | 0.0416   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0702   |
|    n_updates         | 9360     |
| eval/                |          |
|    Length            | 194      |
|    Return            | -153     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0556   |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 120      |
|    fps               | 15.7     |
|    elapsed_time      | 1.31e+04 |
|    elapsed_steps     | 307200   |
-----------------------------------
 31%|â–ˆâ–ˆâ–ˆ       | 309760/1000000 [3:39:33<10:23:09, 18.46steps/s] 31%|â–ˆâ–ˆâ–ˆ       | 309760/1000000 [3:39:50<10:23:09, 18.46steps/s] 31%|â–ˆâ–ˆâ–ˆ       | 312320/1000000 [3:40:48<8:55:21, 21.41steps/s]  31%|â–ˆâ–ˆâ–ˆ       | 312320/1000000 [3:41:00<8:55:21, 21.41steps/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:42:07<8:00:07, 23.78steps/s]                                                                31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:42:07<8:00:07, 23.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -155     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0526   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.149    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.493    |
|    max_target_q      | -12.2    |
|    min_target_q      | -30.8    |
|    max_reward        | -0.307   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 3.51     |
|    q1_grad_norm      | 2.8      |
|    q2_grad_norm      | 2.74     |
|    actor_loss        | 18.1     |
|    ent_coeff         | 0.0414   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0712   |
|    n_updates         | 9600     |
| time/                |          |
|    iterations        | 123      |
|    fps               | 32.7     |
|    elapsed_time      | 1.33e+04 |
|    elapsed_steps     | 314880   |
-----------------------------------
 31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:42:20<8:00:07, 23.78steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317440/1000000 [3:43:26<7:19:50, 25.86steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317440/1000000 [3:43:40<7:19:50, 25.86steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320000/1000000 [3:44:32<6:34:20, 28.74steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320000/1000000 [3:44:50<6:34:20, 28.74steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:45:36<5:59:48, 31.38steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:45:50<5:59:48, 31.38steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_322560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:50:34<5:59:48, 31.38steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.144    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.489    |
|    max_target_q      | -12.3    |
|    min_target_q      | -31.3    |
|    max_reward        | -0.305   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 3.38     |
|    q1_grad_norm      | 2.61     |
|    q2_grad_norm      | 2.56     |
|    actor_loss        | 18.3     |
|    ent_coeff         | 0.0412   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0724   |
|    n_updates         | 9840     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -155     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -155     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 126      |
|    fps               | 15.2     |
|    elapsed_time      | 1.38e+04 |
|    elapsed_steps     | 322560   |
-----------------------------------
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 325120/1000000 [3:51:43<12:14:11, 15.32steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327680/1000000 [3:52:52<10:02:36, 18.59steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327680/1000000 [3:53:10<10:02:36, 18.59steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:54:00<8:29:34, 21.91steps/s]                                                                 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:54:00<8:29:34, 21.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -151     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -151     |
|    Success           | 0.158    |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.152    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.483    |
|    max_target_q      | -12.3    |
|    min_target_q      | -31.8    |
|    max_reward        | -0.289   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 4.02     |
|    q1_grad_norm      | 3.18     |
|    q2_grad_norm      | 3.12     |
|    actor_loss        | 18.5     |
|    ent_coeff         | 0.041    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0723   |
|    n_updates         | 10080    |
| time/                |          |
|    iterations        | 129      |
|    fps               | 37.2     |
|    elapsed_time      | 1.4e+04  |
|    elapsed_steps     | 330240   |
-----------------------------------
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:54:20<8:29:34, 21.91steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332800/1000000 [3:55:13<7:29:44, 24.73steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332800/1000000 [3:55:30<7:29:44, 24.73steps/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335360/1000000 [3:56:21<6:42:26, 27.52steps/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335360/1000000 [3:56:40<6:42:26, 27.52steps/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:57:24<6:02:21, 30.45steps/s]                                                                34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:57:24<6:02:21, 30.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -154     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -154     |
|    Success           | 0.05     |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.164    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.481    |
|    max_target_q      | -12.3    |
|    min_target_q      | -32.3    |
|    max_reward        | -0.286   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.29     |
|    q1_grad_norm      | 2.4      |
|    q2_grad_norm      | 2.35     |
|    actor_loss        | 18.6     |
|    ent_coeff         | 0.0408   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0725   |
|    n_updates         | 10320    |
| time/                |          |
|    iterations        | 132      |
|    fps               | 37.6     |
|    elapsed_time      | 1.42e+04 |
|    elapsed_steps     | 337920   |
-----------------------------------
 34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:57:40<6:02:21, 30.45steps/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 340480/1000000 [3:58:32<5:39:30, 32.38steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_340480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 34%|â–ˆâ–ˆâ–ˆâ–      | 340480/1000000 [3:58:50<5:39:30, 32.38steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 34%|â–ˆâ–ˆâ–ˆâ–      | 343040/1000000 [4:04:26<11:31:36, 15.83steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:05:35<9:30:39, 19.11steps/s]                                                                 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:05:35<9:30:39, 19.11steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -154     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -154     |
|    Success           | 0.075    |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.161    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.476    |
|    max_target_q      | -12.2    |
|    min_target_q      | -32.7    |
|    max_reward        | -0.265   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.72     |
|    q1_grad_norm      | 2.83     |
|    q2_grad_norm      | 2.79     |
|    actor_loss        | 18.8     |
|    ent_coeff         | 0.0406   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0729   |
|    n_updates         | 10560    |
| eval/                |          |
|    Length            | 198      |
|    Return            | -158     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -158     |
|    Success           | 0.0556   |
|    SuccessLength     | 198      |
| time/                |          |
|    iterations        | 135      |
|    fps               | 15.6     |
|    elapsed_time      | 1.47e+04 |
|    elapsed_steps     | 345600   |
-----------------------------------
 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:05:50<9:30:39, 19.11steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348160/1000000 [4:06:43<8:03:48, 22.45steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348160/1000000 [4:07:00<8:03:48, 22.45steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350720/1000000 [4:07:48<6:59:50, 25.78steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350720/1000000 [4:08:00<6:59:50, 25.78steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:08:54<6:16:24, 28.64steps/s]                                                                35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:08:54<6:16:24, 28.64steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.16     |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.47     |
|    max_target_q      | -12.3    |
|    min_target_q      | -33.2    |
|    max_reward        | -0.27    |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.85     |
|    q1_grad_norm      | 2.96     |
|    q2_grad_norm      | 2.9      |
|    actor_loss        | 19       |
|    ent_coeff         | 0.0404   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0738   |
|    n_updates         | 10800    |
| time/                |          |
|    iterations        | 138      |
|    fps               | 38.6     |
|    elapsed_time      | 1.49e+04 |
|    elapsed_steps     | 353280   |
-----------------------------------
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:09:10<6:16:24, 28.64steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355840/1000000 [4:10:00<5:45:02, 31.11steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355840/1000000 [4:10:10<5:45:02, 31.11steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358400/1000000 [4:11:07<5:24:46, 32.93steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358400/1000000 [4:11:20<5:24:46, 32.93steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_358400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360960/1000000 [4:17:11<11:20:41, 15.65steps/s]                                                                 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360960/1000000 [4:17:11<11:20:41, 15.65steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -151     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0488   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.161    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.464    |
|    max_target_q      | -12.3    |
|    min_target_q      | -33.6    |
|    max_reward        | -0.281   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 3.71     |
|    q1_grad_norm      | 2.78     |
|    q2_grad_norm      | 2.72     |
|    actor_loss        | 19.1     |
|    ent_coeff         | 0.0402   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0747   |
|    n_updates         | 11040    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -155     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -155     |
|    Success           | 0.111    |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 141      |
|    fps               | 15.5     |
|    elapsed_time      | 1.54e+04 |
|    elapsed_steps     | 360960   |
-----------------------------------
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 363520/1000000 [4:18:26<9:27:55, 18.68steps/s]  36%|â–ˆâ–ˆâ–ˆâ–‹      | 363520/1000000 [4:18:40<9:27:55, 18.68steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366080/1000000 [4:19:42<8:09:53, 21.57steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366080/1000000 [4:20:00<8:09:53, 21.57steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:20:56<7:13:16, 24.29steps/s]                                                                37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:20:56<7:13:16, 24.29steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -155     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0811   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.186    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.463    |
|    max_target_q      | -12.3    |
|    min_target_q      | -34.1    |
|    max_reward        | -0.276   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 4.36     |
|    q1_grad_norm      | 3.44     |
|    q2_grad_norm      | 3.38     |
|    actor_loss        | 19.2     |
|    ent_coeff         | 0.04     |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0736   |
|    n_updates         | 11280    |
| time/                |          |
|    iterations        | 144      |
|    fps               | 34.1     |
|    elapsed_time      | 1.57e+04 |
|    elapsed_steps     | 368640   |
-----------------------------------
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:21:10<7:13:16, 24.29steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371200/1000000 [4:22:02<6:23:22, 27.34steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371200/1000000 [4:22:20<6:23:22, 27.34steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373760/1000000 [4:23:09<5:48:13, 29.97steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373760/1000000 [4:23:20<5:48:13, 29.97steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:24:16<5:25:06, 31.97steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:24:30<5:25:06, 31.97steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_376320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:29:03<5:25:06, 31.97steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -151     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0541   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.177    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.459    |
|    max_target_q      | -12.4    |
|    min_target_q      | -34.5    |
|    max_reward        | -0.261   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.92     |
|    q1_grad_norm      | 2.88     |
|    q2_grad_norm      | 2.84     |
|    actor_loss        | 19.4     |
|    ent_coeff         | 0.0399   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0742   |
|    n_updates         | 11520    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -154     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0556   |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 147      |
|    fps               | 15.8     |
|    elapsed_time      | 1.61e+04 |
|    elapsed_steps     | 376320   |
-----------------------------------
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 378880/1000000 [4:30:14<11:01:03, 15.66steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 381440/1000000 [4:31:24<9:04:24, 18.94steps/s]  38%|â–ˆâ–ˆâ–ˆâ–Š      | 381440/1000000 [4:31:40<9:04:24, 18.94steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:32:32<7:41:16, 22.26steps/s]                                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:32:32<7:41:16, 22.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -151     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0476   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.176    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.455    |
|    max_target_q      | -12.5    |
|    min_target_q      | -34.9    |
|    max_reward        | -0.28    |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.77     |
|    q1_grad_norm      | 2.73     |
|    q2_grad_norm      | 2.68     |
|    actor_loss        | 19.5     |
|    ent_coeff         | 0.0397   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0741   |
|    n_updates         | 11760    |
| time/                |          |
|    iterations        | 150      |
|    fps               | 36.8     |
|    elapsed_time      | 1.64e+04 |
|    elapsed_steps     | 384000   |
-----------------------------------
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:32:50<7:41:16, 22.26steps/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386560/1000000 [4:33:38<6:41:22, 25.47steps/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386560/1000000 [4:33:50<6:41:22, 25.47steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389120/1000000 [4:34:41<5:54:31, 28.72steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389120/1000000 [4:35:00<5:54:31, 28.72steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:35:44<5:22:20, 31.45steps/s]                                                                39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:35:44<5:22:20, 31.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -157     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -157     |
|    Success           | 0.025    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.181    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.452    |
|    max_target_q      | -12.5    |
|    min_target_q      | -35.4    |
|    max_reward        | -0.277   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 3.76     |
|    q1_grad_norm      | 2.75     |
|    q2_grad_norm      | 2.69     |
|    actor_loss        | 19.7     |
|    ent_coeff         | 0.0395   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0755   |
|    n_updates         | 12000    |
| time/                |          |
|    iterations        | 153      |
|    fps               | 39.9     |
|    elapsed_time      | 1.65e+04 |
|    elapsed_steps     | 391680   |
-----------------------------------
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:36:00<5:22:20, 31.45steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394240/1000000 [4:36:49<5:01:53, 33.44steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394240/1000000 [4:37:00<5:01:53, 33.44steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_394240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 396800/1000000 [4:42:46<10:30:57, 15.93steps/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:43:55<8:40:16, 19.24steps/s]                                                                 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:43:55<8:40:16, 19.24steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -154     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -154     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.189    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.45     |
|    max_target_q      | -12.5    |
|    min_target_q      | -35.8    |
|    max_reward        | -0.276   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.41     |
|    q1_grad_norm      | 3.58     |
|    q2_grad_norm      | 3.52     |
|    actor_loss        | 19.8     |
|    ent_coeff         | 0.0393   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0742   |
|    n_updates         | 12240    |
| eval/                |          |
|    Length            | 199      |
|    Return            | -155     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0556   |
|    SuccessLength     | 199      |
| time/                |          |
|    iterations        | 156      |
|    fps               | 15.6     |
|    elapsed_time      | 1.7e+04  |
|    elapsed_steps     | 399360   |
-----------------------------------
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:44:10<8:40:16, 19.24steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401920/1000000 [4:45:01<7:20:23, 22.63steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401920/1000000 [4:45:20<7:20:23, 22.63steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404480/1000000 [4:46:09<6:25:14, 25.76steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404480/1000000 [4:46:20<6:25:14, 25.76steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:47:16<5:46:51, 28.49steps/s]                                                                41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:47:16<5:46:51, 28.49steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.206    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.448    |
|    max_target_q      | -12.5    |
|    min_target_q      | -36.1    |
|    max_reward        | -0.283   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 3.96     |
|    q1_grad_norm      | 3        |
|    q2_grad_norm      | 2.95     |
|    actor_loss        | 19.9     |
|    ent_coeff         | 0.0391   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0736   |
|    n_updates         | 12480    |
| time/                |          |
|    iterations        | 159      |
|    fps               | 38.1     |
|    elapsed_time      | 1.72e+04 |
|    elapsed_steps     | 407040   |
-----------------------------------
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:47:30<5:46:51, 28.49steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409600/1000000 [4:48:23<5:18:14, 30.92steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409600/1000000 [4:48:40<5:18:14, 30.92steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412160/1000000 [4:49:34<5:03:51, 32.24steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412160/1000000 [4:49:50<5:03:51, 32.24steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_412160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414720/1000000 [4:55:17<10:03:31, 16.16steps/s]                                                                 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414720/1000000 [4:55:17<10:03:31, 16.16steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -159     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0286   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.191    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.444    |
|    max_target_q      | -12.4    |
|    min_target_q      | -36.5    |
|    max_reward        | -0.258   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 3.83     |
|    q1_grad_norm      | 2.73     |
|    q2_grad_norm      | 2.69     |
|    actor_loss        | 20.1     |
|    ent_coeff         | 0.0389   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0748   |
|    n_updates         | 12720    |
| eval/                |          |
|    Length            | 188      |
|    Return            | -142     |
|    NonzeroRewards    | 188      |
|    DiscountedReturn  | -142     |
|    Success           | 0.105    |
|    SuccessLength     | 188      |
| time/                |          |
|    iterations        | 162      |
|    fps               | 16       |
|    elapsed_time      | 1.77e+04 |
|    elapsed_steps     | 414720   |
-----------------------------------
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417280/1000000 [4:56:28<8:21:52, 19.35steps/s]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417280/1000000 [4:56:40<8:21:52, 19.35steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419840/1000000 [4:57:37<7:07:49, 22.60steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419840/1000000 [4:57:50<7:07:49, 22.60steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:58:43<6:12:18, 25.86steps/s]                                                                42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:58:43<6:12:18, 25.86steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -151     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0244   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.219    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.442    |
|    max_target_q      | -12.4    |
|    min_target_q      | -37      |
|    max_reward        | -0.26    |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 4.08     |
|    q1_grad_norm      | 2.91     |
|    q2_grad_norm      | 2.86     |
|    actor_loss        | 20.2     |
|    ent_coeff         | 0.0387   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0742   |
|    n_updates         | 12960    |
| time/                |          |
|    iterations        | 165      |
|    fps               | 37.3     |
|    elapsed_time      | 1.79e+04 |
|    elapsed_steps     | 422400   |
-----------------------------------
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:59:00<6:12:18, 25.86steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424960/1000000 [4:59:47<5:31:30, 28.91steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424960/1000000 [5:00:00<5:31:30, 28.91steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427520/1000000 [5:00:50<5:01:31, 31.64steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427520/1000000 [5:01:10<5:01:31, 31.64steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [5:01:57<4:44:02, 33.44steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [5:02:10<4:44:02, 33.44steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_430080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [5:06:44<4:44:02, 33.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -155     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -155     |
|    Success           | 0.05     |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.22     |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.44     |
|    max_target_q      | -12.5    |
|    min_target_q      | -37.3    |
|    max_reward        | -0.264   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 4.32     |
|    q1_grad_norm      | 3.18     |
|    q2_grad_norm      | 3.11     |
|    actor_loss        | 20.4     |
|    ent_coeff         | 0.0385   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0747   |
|    n_updates         | 13200    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 168      |
|    fps               | 16       |
|    elapsed_time      | 1.84e+04 |
|    elapsed_steps     | 430080   |
-----------------------------------
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 432640/1000000 [5:07:52<9:51:35, 15.98steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435200/1000000 [5:09:00<8:07:21, 19.31steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435200/1000000 [5:09:10<8:07:21, 19.31steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:10:04<6:50:22, 22.83steps/s]                                                                44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:10:04<6:50:22, 22.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -150     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.219    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.439    |
|    max_target_q      | -12.6    |
|    min_target_q      | -37.7    |
|    max_reward        | -0.27    |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.14     |
|    q1_grad_norm      | 3        |
|    q2_grad_norm      | 2.94     |
|    actor_loss        | 20.5     |
|    ent_coeff         | 0.0384   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0738   |
|    n_updates         | 13440    |
| time/                |          |
|    iterations        | 171      |
|    fps               | 38.4     |
|    elapsed_time      | 1.86e+04 |
|    elapsed_steps     | 437760   |
-----------------------------------
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:10:20<6:50:22, 22.83steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440320/1000000 [5:11:09<5:56:57, 26.13steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440320/1000000 [5:11:20<5:56:57, 26.13steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442880/1000000 [5:12:17<5:22:22, 28.80steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442880/1000000 [5:12:30<5:22:22, 28.80steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:13:21<4:53:58, 31.44steps/s]                                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:13:21<4:53:58, 31.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.231    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.436    |
|    max_target_q      | -12.7    |
|    min_target_q      | -38.1    |
|    max_reward        | -0.256   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 4.52     |
|    q1_grad_norm      | 3.36     |
|    q2_grad_norm      | 3.32     |
|    actor_loss        | 20.6     |
|    ent_coeff         | 0.0382   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0733   |
|    n_updates         | 13680    |
| time/                |          |
|    iterations        | 174      |
|    fps               | 39.1     |
|    elapsed_time      | 1.88e+04 |
|    elapsed_steps     | 445440   |
-----------------------------------
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:13:40<4:53:58, 31.44steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448000/1000000 [5:14:26<4:34:51, 33.47steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448000/1000000 [5:14:40<4:34:51, 33.47steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_448000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 450560/1000000 [5:20:23<9:34:16, 15.95steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:21:31<7:52:49, 19.28steps/s]                                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:21:31<7:52:49, 19.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -149     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0526   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.218    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.435    |
|    max_target_q      | -12.7    |
|    min_target_q      | -38.5    |
|    max_reward        | -0.257   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.41     |
|    q1_grad_norm      | 3.18     |
|    q2_grad_norm      | 3.13     |
|    actor_loss        | 20.8     |
|    ent_coeff         | 0.038    |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0734   |
|    n_updates         | 13920    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 177      |
|    fps               | 15.7     |
|    elapsed_time      | 1.93e+04 |
|    elapsed_steps     | 453120   |
-----------------------------------
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:21:50<7:52:49, 19.28steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455680/1000000 [5:22:40<6:43:18, 22.49steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455680/1000000 [5:23:00<6:43:18, 22.49steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458240/1000000 [5:23:47<5:52:08, 25.64steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458240/1000000 [5:24:00<5:52:08, 25.64steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:24:57<5:18:20, 28.23steps/s]                                                                46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:24:57<5:18:20, 28.23steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -148     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0732   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.244    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.434    |
|    max_target_q      | -12.7    |
|    min_target_q      | -38.9    |
|    max_reward        | -0.259   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 4.57     |
|    q1_grad_norm      | 3.39     |
|    q2_grad_norm      | 3.35     |
|    actor_loss        | 20.9     |
|    ent_coeff         | 0.0378   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0732   |
|    n_updates         | 14160    |
| time/                |          |
|    iterations        | 180      |
|    fps               | 37.3     |
|    elapsed_time      | 1.95e+04 |
|    elapsed_steps     | 460800   |
-----------------------------------
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:25:10<5:18:20, 28.23steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463360/1000000 [5:26:02<4:50:06, 30.83steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463360/1000000 [5:26:20<4:50:06, 30.83steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465920/1000000 [5:27:08<4:30:56, 32.85steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465920/1000000 [5:27:20<4:30:56, 32.85steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_465920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468480/1000000 [5:33:00<9:13:47, 16.00steps/s]                                                                47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468480/1000000 [5:33:00<9:13:47, 16.00steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -149     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0541   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.242    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.433    |
|    max_target_q      | -12.7    |
|    min_target_q      | -39.3    |
|    max_reward        | -0.249   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 4.46     |
|    q1_grad_norm      | 3.07     |
|    q2_grad_norm      | 3.01     |
|    actor_loss        | 21.1     |
|    ent_coeff         | 0.0376   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.073    |
|    n_updates         | 14400    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -150     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 183      |
|    fps               | 15.9     |
|    elapsed_time      | 2e+04    |
|    elapsed_steps     | 468480   |
-----------------------------------
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471040/1000000 [5:34:14<7:42:26, 19.06steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471040/1000000 [5:34:30<7:42:26, 19.06steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473600/1000000 [5:35:26<6:36:37, 22.12steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473600/1000000 [5:35:40<6:36:37, 22.12steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:36:33<5:44:07, 25.37steps/s]                                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:36:33<5:44:07, 25.37steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.234    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.43     |
|    max_target_q      | -12.7    |
|    min_target_q      | -39.5    |
|    max_reward        | -0.266   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.68     |
|    q1_grad_norm      | 3.57     |
|    q2_grad_norm      | 3.51     |
|    actor_loss        | 21.2     |
|    ent_coeff         | 0.0374   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0723   |
|    n_updates         | 14640    |
| time/                |          |
|    iterations        | 186      |
|    fps               | 36.1     |
|    elapsed_time      | 2.02e+04 |
|    elapsed_steps     | 476160   |
-----------------------------------
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:36:50<5:44:07, 25.37steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478720/1000000 [5:37:37<5:05:52, 28.40steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478720/1000000 [5:37:50<5:05:52, 28.40steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481280/1000000 [5:38:41<4:37:37, 31.14steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481280/1000000 [5:39:00<4:37:37, 31.14steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:39:49<4:21:14, 32.93steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:40:00<4:21:14, 32.93steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_483840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:44:45<4:21:14, 32.93steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -154     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -154     |
|    Success           | 0.05     |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.271    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.427    |
|    max_target_q      | -13.2    |
|    min_target_q      | -39.7    |
|    max_reward        | -0.259   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 5.29     |
|    q1_grad_norm      | 3.99     |
|    q2_grad_norm      | 3.92     |
|    actor_loss        | 21.4     |
|    ent_coeff         | 0.0373   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0725   |
|    n_updates         | 14880    |
| eval/                |          |
|    Length            | 190      |
|    Return            | -147     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -147     |
|    Success           | 0.111    |
|    SuccessLength     | 189      |
| time/                |          |
|    iterations        | 189      |
|    fps               | 15.6     |
|    elapsed_time      | 2.07e+04 |
|    elapsed_steps     | 483840   |
-----------------------------------
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 486400/1000000 [5:46:03<9:17:53, 15.34steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488960/1000000 [5:47:18<7:43:22, 18.38steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488960/1000000 [5:47:30<7:43:22, 18.38steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:48:27<6:31:16, 21.66steps/s]                                                                49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:48:27<6:31:16, 21.66steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -151     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -151     |
|    Success           | 0.075    |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.278    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.427    |
|    max_target_q      | -13.1    |
|    min_target_q      | -40.3    |
|    max_reward        | -0.261   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.98     |
|    q1_grad_norm      | 3.36     |
|    q2_grad_norm      | 3.32     |
|    actor_loss        | 21.5     |
|    ent_coeff         | 0.0371   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.072    |
|    n_updates         | 15120    |
| time/                |          |
|    iterations        | 192      |
|    fps               | 34.6     |
|    elapsed_time      | 2.09e+04 |
|    elapsed_steps     | 491520   |
-----------------------------------
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:48:40<6:31:16, 21.66steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494080/1000000 [5:49:39<5:43:40, 24.53steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494080/1000000 [5:49:50<5:43:40, 24.53steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496640/1000000 [5:50:47<5:05:43, 27.44steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496640/1000000 [5:51:00<5:05:43, 27.44steps/s]ReplayBuffer: Replay buffer is now full. cursor=0.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:51:55<4:40:03, 29.80steps/s]                                                                50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:51:55<4:40:03, 29.80steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -155     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -155     |
|    Success           | 0.025    |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.254    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.424    |
|    max_target_q      | -12.8    |
|    min_target_q      | -40.5    |
|    max_reward        | -0.267   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 5.1      |
|    q1_grad_norm      | 3.91     |
|    q2_grad_norm      | 3.87     |
|    actor_loss        | 21.7     |
|    ent_coeff         | 0.0369   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0716   |
|    n_updates         | 15360    |
| time/                |          |
|    iterations        | 195      |
|    fps               | 36.9     |
|    elapsed_time      | 2.11e+04 |
|    elapsed_steps     | 499200   |
-----------------------------------
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:52:10<4:40:03, 29.80steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501760/1000000 [5:53:04<4:21:41, 31.73steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_501760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501760/1000000 [5:53:20<4:21:41, 31.73steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 504320/1000000 [5:58:51<8:37:47, 15.95steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [6:00:06<7:13:04, 18.98steps/s]                                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [6:00:06<7:13:04, 18.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -154     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -154     |
|    Success           | 0.027    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.279    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.425    |
|    max_target_q      | -12.8    |
|    min_target_q      | -40.9    |
|    max_reward        | -0.242   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 5.4      |
|    q1_grad_norm      | 3.95     |
|    q2_grad_norm      | 3.88     |
|    actor_loss        | 21.8     |
|    ent_coeff         | 0.0367   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.071    |
|    n_updates         | 15600    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 198      |
|    fps               | 15.7     |
|    elapsed_time      | 2.16e+04 |
|    elapsed_steps     | 506880   |
-----------------------------------
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [6:00:20<7:13:04, 18.98steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509440/1000000 [6:01:16<6:09:07, 22.15steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509440/1000000 [6:01:30<6:09:07, 22.15steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512000/1000000 [6:02:22<5:19:27, 25.46steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512000/1000000 [6:02:40<5:19:27, 25.46steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [6:03:29<4:46:01, 28.29steps/s]                                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [6:03:29<4:46:01, 28.29steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -157     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.271    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.424    |
|    max_target_q      | -13.4    |
|    min_target_q      | -41.2    |
|    max_reward        | -0.246   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 5.14     |
|    q1_grad_norm      | 3.58     |
|    q2_grad_norm      | 3.53     |
|    actor_loss        | 22       |
|    ent_coeff         | 0.0366   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0703   |
|    n_updates         | 15840    |
| time/                |          |
|    iterations        | 201      |
|    fps               | 37.8     |
|    elapsed_time      | 2.18e+04 |
|    elapsed_steps     | 514560   |
-----------------------------------
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [6:03:40<4:46:01, 28.29steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517120/1000000 [6:04:38<4:24:40, 30.41steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517120/1000000 [6:04:50<4:24:40, 30.41steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519680/1000000 [6:05:47<4:08:34, 32.21steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519680/1000000 [6:06:00<4:08:34, 32.21steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_519680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522240/1000000 [6:11:36<8:19:00, 15.96steps/s]                                                                52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522240/1000000 [6:11:36<8:19:00, 15.96steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.273    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.424    |
|    max_target_q      | -13.5    |
|    min_target_q      | -41.6    |
|    max_reward        | -0.238   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 5.49     |
|    q1_grad_norm      | 4.19     |
|    q2_grad_norm      | 4.13     |
|    actor_loss        | 22.1     |
|    ent_coeff         | 0.0364   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0698   |
|    n_updates         | 16080    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 204      |
|    fps               | 15.8     |
|    elapsed_time      | 2.23e+04 |
|    elapsed_steps     | 522240   |
-----------------------------------
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524800/1000000 [6:12:45<6:51:38, 19.24steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524800/1000000 [6:13:00<6:51:38, 19.24steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527360/1000000 [6:13:53<5:49:28, 22.54steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527360/1000000 [6:14:10<5:49:28, 22.54steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:14:59<5:03:22, 25.82steps/s]                                                                53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:14:59<5:03:22, 25.82steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.281    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.422    |
|    max_target_q      | -13.3    |
|    min_target_q      | -41.8    |
|    max_reward        | -0.255   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 5.11     |
|    q1_grad_norm      | 3.28     |
|    q2_grad_norm      | 3.24     |
|    actor_loss        | 22.2     |
|    ent_coeff         | 0.0362   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0686   |
|    n_updates         | 16320    |
| time/                |          |
|    iterations        | 207      |
|    fps               | 37.9     |
|    elapsed_time      | 2.25e+04 |
|    elapsed_steps     | 529920   |
-----------------------------------
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:15:10<5:03:22, 25.82steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532480/1000000 [6:16:04<4:30:45, 28.78steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532480/1000000 [6:16:20<4:30:45, 28.78steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535040/1000000 [6:17:13<4:10:55, 30.88steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535040/1000000 [6:17:30<4:10:55, 30.88steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:18:20<3:55:11, 32.77steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:18:30<3:55:11, 32.77steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_537600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:23:06<3:55:11, 32.77steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -153     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.329    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.422    |
|    max_target_q      | -12.6    |
|    min_target_q      | -42.2    |
|    max_reward        | -0.253   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 6.6      |
|    q1_grad_norm      | 3.95     |
|    q2_grad_norm      | 3.9      |
|    actor_loss        | 22.2     |
|    ent_coeff         | 0.036    |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.071    |
|    n_updates         | 16560    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -153     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -153     |
|    Success           | 0.222    |
|    SuccessLength     | 193      |
| time/                |          |
|    iterations        | 210      |
|    fps               | 15.8     |
|    elapsed_time      | 2.3e+04  |
|    elapsed_steps     | 537600   |
-----------------------------------
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 540160/1000000 [6:24:17<8:04:54, 15.80steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542720/1000000 [6:25:28<6:40:10, 19.05steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542720/1000000 [6:25:40<6:40:10, 19.05steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:26:32<5:36:03, 22.55steps/s]                                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:26:32<5:36:03, 22.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -146     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -146     |
|    Success           | 0.105    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.293    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.419    |
|    max_target_q      | -12.2    |
|    min_target_q      | -42.6    |
|    max_reward        | -0.239   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 5.94     |
|    q1_grad_norm      | 3.82     |
|    q2_grad_norm      | 3.76     |
|    actor_loss        | 22.3     |
|    ent_coeff         | 0.0359   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0679   |
|    n_updates         | 16800    |
| time/                |          |
|    iterations        | 213      |
|    fps               | 37.2     |
|    elapsed_time      | 2.32e+04 |
|    elapsed_steps     | 545280   |
-----------------------------------
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:26:50<5:36:03, 22.55steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547840/1000000 [6:27:39<4:52:33, 25.76steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547840/1000000 [6:27:50<4:52:33, 25.76steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550400/1000000 [6:28:42<4:19:35, 28.87steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550400/1000000 [6:29:00<4:19:35, 28.87steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:29:47<3:56:54, 31.45steps/s]                                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:29:47<3:56:54, 31.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.289    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.421    |
|    max_target_q      | -13      |
|    min_target_q      | -43.1    |
|    max_reward        | -0.24    |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 5.59     |
|    q1_grad_norm      | 3.4      |
|    q2_grad_norm      | 3.35     |
|    actor_loss        | 22.5     |
|    ent_coeff         | 0.0357   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0675   |
|    n_updates         | 17040    |
| time/                |          |
|    iterations        | 216      |
|    fps               | 39.5     |
|    elapsed_time      | 2.34e+04 |
|    elapsed_steps     | 552960   |
-----------------------------------
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:30:00<3:56:54, 31.45steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555520/1000000 [6:30:52<3:41:33, 33.44steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_555520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555520/1000000 [6:31:10<3:41:33, 33.44steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 558080/1000000 [6:36:48<7:40:58, 15.98steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:37:56<6:19:34, 19.29steps/s]                                                                56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:37:56<6:19:34, 19.29steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.309    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.418    |
|    max_target_q      | -12.9    |
|    min_target_q      | -43.4    |
|    max_reward        | -0.231   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 5.79     |
|    q1_grad_norm      | 3.17     |
|    q2_grad_norm      | 3.15     |
|    actor_loss        | 22.6     |
|    ent_coeff         | 0.0355   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0682   |
|    n_updates         | 17280    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -165     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -165     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 219      |
|    fps               | 15.7     |
|    elapsed_time      | 2.39e+04 |
|    elapsed_steps     | 560640   |
-----------------------------------
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:38:10<6:19:34, 19.29steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563200/1000000 [6:39:01<5:19:43, 22.77steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563200/1000000 [6:39:20<5:19:43, 22.77steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565760/1000000 [6:40:07<4:38:18, 26.01steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565760/1000000 [6:40:20<4:38:18, 26.01steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:41:11<4:07:29, 29.07steps/s]                                                                57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:41:11<4:07:29, 29.07steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -147     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -147     |
|    Success           | 0.075    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.324    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.416    |
|    max_target_q      | -12.6    |
|    min_target_q      | -43.7    |
|    max_reward        | -0.243   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 6.19     |
|    q1_grad_norm      | 3.17     |
|    q2_grad_norm      | 3.14     |
|    actor_loss        | 22.7     |
|    ent_coeff         | 0.0354   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0685   |
|    n_updates         | 17520    |
| time/                |          |
|    iterations        | 222      |
|    fps               | 39.4     |
|    elapsed_time      | 2.41e+04 |
|    elapsed_steps     | 568320   |
-----------------------------------
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:41:30<4:07:29, 29.07steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570880/1000000 [6:42:19<3:49:24, 31.18steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570880/1000000 [6:42:30<3:49:24, 31.18steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573440/1000000 [6:43:24<3:33:59, 33.22steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573440/1000000 [6:43:40<3:33:59, 33.22steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_573440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576000/1000000 [6:49:34<7:34:57, 15.53steps/s]                                                                58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576000/1000000 [6:49:34<7:34:57, 15.53steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0.027    |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.36     |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.416    |
|    max_target_q      | -12.2    |
|    min_target_q      | -43.8    |
|    max_reward        | -0.237   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 7.19     |
|    q1_grad_norm      | 4.33     |
|    q2_grad_norm      | 4.27     |
|    actor_loss        | 22.7     |
|    ent_coeff         | 0.0352   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0701   |
|    n_updates         | 17760    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -157     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0556   |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 225      |
|    fps               | 15.3     |
|    elapsed_time      | 2.46e+04 |
|    elapsed_steps     | 576000   |
-----------------------------------
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578560/1000000 [6:50:39<6:10:10, 18.97steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578560/1000000 [6:50:50<6:10:10, 18.97steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581120/1000000 [6:51:43<5:09:37, 22.55steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581120/1000000 [6:52:00<5:09:37, 22.55steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:52:51<4:31:13, 25.58steps/s]                                                                58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:52:51<4:31:13, 25.58steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -149     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0789   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.329    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.414    |
|    max_target_q      | -12.1    |
|    min_target_q      | -43.8    |
|    max_reward        | -0.242   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 6.02     |
|    q1_grad_norm      | 2.99     |
|    q2_grad_norm      | 2.95     |
|    actor_loss        | 22.8     |
|    ent_coeff         | 0.035    |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0662   |
|    n_updates         | 18000    |
| time/                |          |
|    iterations        | 228      |
|    fps               | 38.9     |
|    elapsed_time      | 2.48e+04 |
|    elapsed_steps     | 583680   |
-----------------------------------
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:53:10<4:31:13, 25.58steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586240/1000000 [6:54:00<4:04:04, 28.25steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586240/1000000 [6:54:10<4:04:04, 28.25steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588800/1000000 [6:55:04<3:41:17, 30.97steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588800/1000000 [6:55:20<3:41:17, 30.97steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:56:10<3:26:57, 32.91steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_591360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:56:30<3:26:57, 32.91steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [7:01:04<3:26:57, 32.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -154     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.358    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.413    |
|    max_target_q      | -12      |
|    min_target_q      | -44.2    |
|    max_reward        | -0.245   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 6.73     |
|    q1_grad_norm      | 3.52     |
|    q2_grad_norm      | 3.47     |
|    actor_loss        | 23       |
|    ent_coeff         | 0.0348   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0677   |
|    n_updates         | 18240    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 231      |
|    fps               | 15.6     |
|    elapsed_time      | 2.53e+04 |
|    elapsed_steps     | 591360   |
-----------------------------------
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 593920/1000000 [7:02:18<7:15:48, 15.53steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596480/1000000 [7:03:25<5:55:39, 18.91steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596480/1000000 [7:03:40<5:55:39, 18.91steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [7:04:36<5:02:53, 22.06steps/s]                                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [7:04:36<5:02:53, 22.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -155     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0244   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.366    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.413    |
|    max_target_q      | -12.1    |
|    min_target_q      | -44.2    |
|    max_reward        | -0.225   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 6.8      |
|    q1_grad_norm      | 3.76     |
|    q2_grad_norm      | 3.72     |
|    actor_loss        | 23.1     |
|    ent_coeff         | 0.0347   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0653   |
|    n_updates         | 18480    |
| time/                |          |
|    iterations        | 234      |
|    fps               | 36.3     |
|    elapsed_time      | 2.55e+04 |
|    elapsed_steps     | 599040   |
-----------------------------------
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [7:04:50<5:02:53, 22.06steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601600/1000000 [7:05:43<4:23:04, 25.24steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601600/1000000 [7:06:00<4:23:04, 25.24steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604160/1000000 [7:06:53<3:56:41, 27.87steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604160/1000000 [7:07:10<3:56:41, 27.87steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:07:58<3:34:57, 30.49steps/s]                                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:07:58<3:34:57, 30.49steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -153     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0513   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.357    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.413    |
|    max_target_q      | -11.5    |
|    min_target_q      | -44.8    |
|    max_reward        | -0.246   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 7.19     |
|    q1_grad_norm      | 4.38     |
|    q2_grad_norm      | 4.32     |
|    actor_loss        | 23.2     |
|    ent_coeff         | 0.0345   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0671   |
|    n_updates         | 18720    |
| time/                |          |
|    iterations        | 237      |
|    fps               | 37.9     |
|    elapsed_time      | 2.57e+04 |
|    elapsed_steps     | 606720   |
-----------------------------------
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:08:10<3:34:57, 30.49steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609280/1000000 [7:09:05<3:20:35, 32.46steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609280/1000000 [7:09:20<3:20:35, 32.46steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_609280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 611840/1000000 [7:15:09<6:55:30, 15.57steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:16:21<5:42:38, 18.76steps/s]                                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:16:21<5:42:38, 18.76steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -151     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -151     |
|    Success           | 0.075    |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.356    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.412    |
|    max_target_q      | -12.1    |
|    min_target_q      | -45.2    |
|    max_reward        | -0.237   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 6.68     |
|    q1_grad_norm      | 3.28     |
|    q2_grad_norm      | 3.23     |
|    actor_loss        | 23.4     |
|    ent_coeff         | 0.0343   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0662   |
|    n_updates         | 18960    |
| eval/                |          |
|    Length            | 190      |
|    Return            | -157     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -157     |
|    Success           | 0.111    |
|    SuccessLength     | 190      |
| time/                |          |
|    iterations        | 240      |
|    fps               | 15.3     |
|    elapsed_time      | 2.62e+04 |
|    elapsed_steps     | 614400   |
-----------------------------------
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:16:40<5:42:38, 18.76steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616960/1000000 [7:17:24<4:45:43, 22.34steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616960/1000000 [7:17:40<4:45:43, 22.34steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619520/1000000 [7:18:29<4:06:55, 25.68steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619520/1000000 [7:18:40<4:06:55, 25.68steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:19:32<3:38:26, 28.83steps/s]                                                                62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:19:32<3:38:26, 28.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -152     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -152     |
|    Success           | 0.027    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.37     |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.41     |
|    max_target_q      | -12.1    |
|    min_target_q      | -45.7    |
|    max_reward        | -0.245   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 7.55     |
|    q1_grad_norm      | 4.09     |
|    q2_grad_norm      | 4.05     |
|    actor_loss        | 23.6     |
|    ent_coeff         | 0.0342   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0674   |
|    n_updates         | 19200    |
| time/                |          |
|    iterations        | 243      |
|    fps               | 40.1     |
|    elapsed_time      | 2.64e+04 |
|    elapsed_steps     | 622080   |
-----------------------------------
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:19:50<3:38:26, 28.83steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624640/1000000 [7:20:39<3:20:56, 31.13steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624640/1000000 [7:20:50<3:20:56, 31.13steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627200/1000000 [7:21:46<3:08:06, 33.03steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_627200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627200/1000000 [7:22:00<3:08:06, 33.03steps/s]EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629760/1000000 [7:27:28<6:18:00, 16.32steps/s]                                                                63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629760/1000000 [7:27:28<6:18:00, 16.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -156     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0513   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.383    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.408    |
|    max_target_q      | -12.5    |
|    min_target_q      | -46.3    |
|    max_reward        | -0.232   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 7.28     |
|    q1_grad_norm      | 4.35     |
|    q2_grad_norm      | 4.29     |
|    actor_loss        | 23.7     |
|    ent_coeff         | 0.034    |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0674   |
|    n_updates         | 19440    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -163     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -163     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 246      |
|    fps               | 16.2     |
|    elapsed_time      | 2.68e+04 |
|    elapsed_steps     | 629760   |
-----------------------------------
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632320/1000000 [7:28:33<5:09:30, 19.80steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632320/1000000 [7:28:50<5:09:30, 19.80steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634880/1000000 [7:29:38<4:21:40, 23.25steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634880/1000000 [7:29:50<4:21:40, 23.25steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:30:41<3:46:17, 26.70steps/s]                                                                64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:30:41<3:46:17, 26.70steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -153     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0263   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.397    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.406    |
|    max_target_q      | -12.8    |
|    min_target_q      | -46.6    |
|    max_reward        | -0.237   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 7.34     |
|    q1_grad_norm      | 3.77     |
|    q2_grad_norm      | 3.73     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0339   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0677   |
|    n_updates         | 19680    |
| time/                |          |
|    iterations        | 249      |
|    fps               | 39.8     |
|    elapsed_time      | 2.7e+04  |
|    elapsed_steps     | 637440   |
-----------------------------------
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:31:00<3:46:17, 26.70steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640000/1000000 [7:31:45<3:22:34, 29.62steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640000/1000000 [7:32:00<3:22:34, 29.62steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642560/1000000 [7:32:52<3:07:27, 31.78steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642560/1000000 [7:33:10<3:07:27, 31.78steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:33:59<2:56:43, 33.47steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:34:10<2:56:43, 33.47steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_645120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:38:44<2:56:43, 33.47steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -153     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0244   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.381    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.404    |
|    max_target_q      | -12      |
|    min_target_q      | -47.2    |
|    max_reward        | -0.239   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 7.26     |
|    q1_grad_norm      | 4.14     |
|    q2_grad_norm      | 4.09     |
|    actor_loss        | 24       |
|    ent_coeff         | 0.0337   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0669   |
|    n_updates         | 19920    |
| eval/                |          |
|    Length            | 186      |
|    Return            | -140     |
|    NonzeroRewards    | 186      |
|    DiscountedReturn  | -140     |
|    Success           | 0.167    |
|    SuccessLength     | 186      |
| time/                |          |
|    iterations        | 252      |
|    fps               | 15.9     |
|    elapsed_time      | 2.75e+04 |
|    elapsed_steps     | 645120   |
-----------------------------------
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 647680/1000000 [7:39:50<6:04:14, 16.12steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650240/1000000 [7:40:55<4:57:25, 19.60steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650240/1000000 [7:41:10<4:57:25, 19.60steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:42:02<4:12:02, 22.96steps/s]                                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:42:02<4:12:02, 22.96steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -147     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -147     |
|    Success           | 0.1      |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.401    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.406    |
|    max_target_q      | -12.3    |
|    min_target_q      | -47.5    |
|    max_reward        | -0.225   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 8.47     |
|    q1_grad_norm      | 4.65     |
|    q2_grad_norm      | 4.6      |
|    actor_loss        | 24.2     |
|    ent_coeff         | 0.0335   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0639   |
|    n_updates         | 20160    |
| time/                |          |
|    iterations        | 255      |
|    fps               | 38.9     |
|    elapsed_time      | 2.77e+04 |
|    elapsed_steps     | 652800   |
-----------------------------------
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:42:20<4:12:02, 22.96steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655360/1000000 [7:43:06<3:38:30, 26.29steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655360/1000000 [7:43:20<3:38:30, 26.29steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657920/1000000 [7:44:11<3:14:56, 29.25steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657920/1000000 [7:44:30<3:14:56, 29.25steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:45:19<3:00:49, 31.29steps/s]                                                                66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:45:19<3:00:49, 31.29steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.423    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.405    |
|    max_target_q      | -12.1    |
|    min_target_q      | -47.9    |
|    max_reward        | -0.233   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 8.59     |
|    q1_grad_norm      | 4.98     |
|    q2_grad_norm      | 4.92     |
|    actor_loss        | 24.3     |
|    ent_coeff         | 0.0334   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0658   |
|    n_updates         | 20400    |
| time/                |          |
|    iterations        | 258      |
|    fps               | 38.9     |
|    elapsed_time      | 2.79e+04 |
|    elapsed_steps     | 660480   |
-----------------------------------
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:45:30<3:00:49, 31.29steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663040/1000000 [7:46:23<2:47:49, 33.46steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663040/1000000 [7:46:40<2:47:49, 33.46steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_663040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 665600/1000000 [7:52:25<5:53:10, 15.78steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:53:34<4:49:48, 19.08steps/s]                                                                67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:53:34<4:49:48, 19.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0263   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.446    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.405    |
|    max_target_q      | -11.1    |
|    min_target_q      | -48.3    |
|    max_reward        | -0.234   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 9.22     |
|    q1_grad_norm      | 4.88     |
|    q2_grad_norm      | 4.84     |
|    actor_loss        | 24.5     |
|    ent_coeff         | 0.0332   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0637   |
|    n_updates         | 20640    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 261      |
|    fps               | 15.5     |
|    elapsed_time      | 2.84e+04 |
|    elapsed_steps     | 668160   |
-----------------------------------
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:53:50<4:49:48, 19.08steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670720/1000000 [7:54:43<4:05:29, 22.35steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670720/1000000 [7:55:00<4:05:29, 22.35steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673280/1000000 [7:55:49<3:32:48, 25.59steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673280/1000000 [7:56:00<3:32:48, 25.59steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:56:54<3:08:57, 28.59steps/s]                                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:56:54<3:08:57, 28.59steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.454    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.406    |
|    max_target_q      | -11      |
|    min_target_q      | -48.4    |
|    max_reward        | -0.218   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 9.44     |
|    q1_grad_norm      | 3.91     |
|    q2_grad_norm      | 3.86     |
|    actor_loss        | 24.6     |
|    ent_coeff         | 0.033    |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0646   |
|    n_updates         | 20880    |
| time/                |          |
|    iterations        | 264      |
|    fps               | 38.4     |
|    elapsed_time      | 2.86e+04 |
|    elapsed_steps     | 675840   |
-----------------------------------
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:57:10<3:08:57, 28.59steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678400/1000000 [7:57:58<2:51:17, 31.29steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678400/1000000 [7:58:10<2:51:17, 31.29steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680960/1000000 [7:59:07<2:41:54, 32.84steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680960/1000000 [7:59:20<2:41:54, 32.84steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_680960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683520/1000000 [8:04:53<5:26:27, 16.16steps/s]                                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683520/1000000 [8:04:53<5:26:27, 16.16steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -164     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -164     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.431    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.404    |
|    max_target_q      | -9.89    |
|    min_target_q      | -48.8    |
|    max_reward        | -0.237   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 8.31     |
|    q1_grad_norm      | 3.8      |
|    q2_grad_norm      | 3.74     |
|    actor_loss        | 24.8     |
|    ent_coeff         | 0.0329   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0624   |
|    n_updates         | 21120    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -168     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -168     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 267      |
|    fps               | 16       |
|    elapsed_time      | 2.91e+04 |
|    elapsed_steps     | 683520   |
-----------------------------------
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686080/1000000 [8:05:58<4:26:43, 19.62steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686080/1000000 [8:06:10<4:26:43, 19.62steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688640/1000000 [8:07:02<3:43:58, 23.17steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688640/1000000 [8:07:20<3:43:58, 23.17steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:08:06<3:14:10, 26.51steps/s]                                                                69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:08:06<3:14:10, 26.51steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -159     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -159     |
|    Success           | 0.025    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.428    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.401    |
|    max_target_q      | -10.9    |
|    min_target_q      | -49.1    |
|    max_reward        | -0.213   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 8.37     |
|    q1_grad_norm      | 4.69     |
|    q2_grad_norm      | 4.62     |
|    actor_loss        | 25       |
|    ent_coeff         | 0.0327   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0606   |
|    n_updates         | 21360    |
| time/                |          |
|    iterations        | 270      |
|    fps               | 39.7     |
|    elapsed_time      | 2.93e+04 |
|    elapsed_steps     | 691200   |
-----------------------------------
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:08:20<3:14:10, 26.51steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693760/1000000 [8:09:10<2:52:44, 29.55steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693760/1000000 [8:09:20<2:52:44, 29.55steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696320/1000000 [8:10:18<2:40:32, 31.53steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696320/1000000 [8:10:30<2:40:32, 31.53steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:11:23<2:29:32, 33.56steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_698880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:11:40<2:29:32, 33.56steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:16:09<2:29:32, 33.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -155     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -155     |
|    Success           | 0.027    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.436    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.402    |
|    max_target_q      | -10.6    |
|    min_target_q      | -49.5    |
|    max_reward        | -0.247   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 8.59     |
|    q1_grad_norm      | 3.78     |
|    q2_grad_norm      | 3.76     |
|    actor_loss        | 25.2     |
|    ent_coeff         | 0.0326   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0608   |
|    n_updates         | 21600    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 273      |
|    fps               | 15.9     |
|    elapsed_time      | 2.98e+04 |
|    elapsed_steps     | 698880   |
-----------------------------------
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 701440/1000000 [8:17:14<5:08:32, 16.13steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704000/1000000 [8:18:22<4:13:17, 19.48steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704000/1000000 [8:18:40<4:13:17, 19.48steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:19:25<3:31:54, 23.08steps/s]                                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:19:25<3:31:54, 23.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.433    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.4      |
|    max_target_q      | -11.2    |
|    min_target_q      | -49.8    |
|    max_reward        | -0.197   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 8.67     |
|    q1_grad_norm      | 4.68     |
|    q2_grad_norm      | 4.59     |
|    actor_loss        | 25.4     |
|    ent_coeff         | 0.0324   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0591   |
|    n_updates         | 21840    |
| time/                |          |
|    iterations        | 276      |
|    fps               | 39.3     |
|    elapsed_time      | 3e+04    |
|    elapsed_steps     | 706560   |
-----------------------------------
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:19:40<3:31:54, 23.08steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709120/1000000 [8:20:28<3:03:10, 26.47steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709120/1000000 [8:20:40<3:03:10, 26.47steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711680/1000000 [8:21:32<2:42:45, 29.52steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711680/1000000 [8:21:50<2:42:45, 29.52steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:22:37<2:29:27, 31.87steps/s]                                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:22:37<2:29:27, 31.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.464    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.399    |
|    max_target_q      | -10.9    |
|    min_target_q      | -50.2    |
|    max_reward        | -0.233   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 8.98     |
|    q1_grad_norm      | 3.68     |
|    q2_grad_norm      | 3.65     |
|    actor_loss        | 25.6     |
|    ent_coeff         | 0.0323   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0594   |
|    n_updates         | 22080    |
| time/                |          |
|    iterations        | 279      |
|    fps               | 39.9     |
|    elapsed_time      | 3.02e+04 |
|    elapsed_steps     | 714240   |
-----------------------------------
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:22:50<2:29:27, 31.87steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716800/1000000 [8:23:44<2:20:51, 33.51steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_716800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716800/1000000 [8:24:00<2:20:51, 33.51steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 719360/1000000 [8:29:44<4:54:44, 15.87steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:30:52<4:01:16, 19.21steps/s]                                                                72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:30:52<4:01:16, 19.21steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -153     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -153     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.481    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.398    |
|    max_target_q      | -11.3    |
|    min_target_q      | -50.6    |
|    max_reward        | -0.241   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 9.23     |
|    q1_grad_norm      | 4.57     |
|    q2_grad_norm      | 4.51     |
|    actor_loss        | 25.8     |
|    ent_coeff         | 0.0321   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0605   |
|    n_updates         | 22320    |
| eval/                |          |
|    Length            | 198      |
|    Return            | -146     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0556   |
|    SuccessLength     | 198      |
| time/                |          |
|    iterations        | 282      |
|    fps               | 15.5     |
|    elapsed_time      | 3.07e+04 |
|    elapsed_steps     | 721920   |
-----------------------------------
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:31:10<4:01:16, 19.21steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724480/1000000 [8:32:02<3:25:09, 22.38steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724480/1000000 [8:32:20<3:25:09, 22.38steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727040/1000000 [8:33:11<2:59:15, 25.38steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727040/1000000 [8:33:30<2:59:15, 25.38steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:34:19<2:40:08, 28.14steps/s]                                                                73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:34:19<2:40:08, 28.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -152     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -152     |
|    Success           | 0.05     |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.456    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.395    |
|    max_target_q      | -10.9    |
|    min_target_q      | -50.9    |
|    max_reward        | -0.246   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 8.92     |
|    q1_grad_norm      | 4.33     |
|    q2_grad_norm      | 4.28     |
|    actor_loss        | 26       |
|    ent_coeff         | 0.032    |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0591   |
|    n_updates         | 22560    |
| time/                |          |
|    iterations        | 285      |
|    fps               | 37       |
|    elapsed_time      | 3.09e+04 |
|    elapsed_steps     | 729600   |
-----------------------------------
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:34:30<2:40:08, 28.14steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732160/1000000 [8:35:22<2:24:02, 30.99steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732160/1000000 [8:35:40<2:24:02, 30.99steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734720/1000000 [8:36:27<2:13:12, 33.19steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734720/1000000 [8:36:40<2:13:12, 33.19steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_734720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737280/1000000 [8:42:17<4:32:12, 16.09steps/s]                                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737280/1000000 [8:42:17<4:32:12, 16.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -153     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -153     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.431    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.395    |
|    max_target_q      | -11.4    |
|    min_target_q      | -51.3    |
|    max_reward        | -0.224   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 8.44     |
|    q1_grad_norm      | 5.02     |
|    q2_grad_norm      | 4.95     |
|    actor_loss        | 26.2     |
|    ent_coeff         | 0.0318   |
|    ent_coeff_loss    | -112     |
|    pi_grad_norm      | 0.06     |
|    n_updates         | 22800    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 288      |
|    fps               | 16.1     |
|    elapsed_time      | 3.13e+04 |
|    elapsed_steps     | 737280   |
-----------------------------------
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739840/1000000 [8:43:22<3:41:34, 19.57steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739840/1000000 [8:43:40<3:41:34, 19.57steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742400/1000000 [8:44:28<3:06:35, 23.01steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742400/1000000 [8:44:40<3:06:35, 23.01steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:45:34<2:42:36, 26.14steps/s]                                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:45:34<2:42:36, 26.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -156     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -156     |
|    Success           | 0.05     |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.434    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.394    |
|    max_target_q      | -11.7    |
|    min_target_q      | -51.8    |
|    max_reward        | -0.23    |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 8.41     |
|    q1_grad_norm      | 4.33     |
|    q2_grad_norm      | 4.28     |
|    actor_loss        | 26.3     |
|    ent_coeff         | 0.0316   |
|    ent_coeff_loss    | -112     |
|    pi_grad_norm      | 0.0602   |
|    n_updates         | 23040    |
| time/                |          |
|    iterations        | 291      |
|    fps               | 39       |
|    elapsed_time      | 3.15e+04 |
|    elapsed_steps     | 744960   |
-----------------------------------
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:45:50<2:42:36, 26.14steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747520/1000000 [8:46:38<2:24:08, 29.19steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747520/1000000 [8:46:50<2:24:08, 29.19steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750080/1000000 [8:47:42<2:11:15, 31.74steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750080/1000000 [8:48:00<2:11:15, 31.74steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:48:51<2:03:57, 33.26steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_752640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:49:10<2:03:57, 33.26steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:53:29<2:03:57, 33.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.451    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.391    |
|    max_target_q      | -11      |
|    min_target_q      | -52      |
|    max_reward        | -0.242   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 8.81     |
|    q1_grad_norm      | 4.35     |
|    q2_grad_norm      | 4.29     |
|    actor_loss        | 26.6     |
|    ent_coeff         | 0.0315   |
|    ent_coeff_loss    | -112     |
|    pi_grad_norm      | 0.0589   |
|    n_updates         | 23280    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -167     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -167     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 294      |
|    fps               | 16.2     |
|    elapsed_time      | 3.2e+04  |
|    elapsed_steps     | 752640   |
-----------------------------------
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 755200/1000000 [8:54:46<4:15:50, 15.95steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757760/1000000 [8:55:53<3:28:57, 19.32steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757760/1000000 [8:56:10<3:28:57, 19.32steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:56:59<2:55:33, 22.75steps/s]                                                                76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:56:59<2:55:33, 22.75steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0.0263   |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.451    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.39     |
|    max_target_q      | -10.3    |
|    min_target_q      | -52.1    |
|    max_reward        | -0.253   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 9.59     |
|    q1_grad_norm      | 4.57     |
|    q2_grad_norm      | 4.54     |
|    actor_loss        | 26.7     |
|    ent_coeff         | 0.0313   |
|    ent_coeff_loss    | -112     |
|    pi_grad_norm      | 0.0579   |
|    n_updates         | 23520    |
| time/                |          |
|    iterations        | 297      |
|    fps               | 36.5     |
|    elapsed_time      | 3.22e+04 |
|    elapsed_steps     | 760320   |
-----------------------------------
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:57:10<2:55:33, 22.75steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 762880/1000000 [8:58:02<2:30:33, 26.25steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 762880/1000000 [8:58:20<2:30:33, 26.25steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765440/1000000 [8:59:10<2:15:25, 28.87steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765440/1000000 [8:59:20<2:15:25, 28.87steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [9:00:17<2:04:04, 31.17steps/s]                                                                77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [9:00:17<2:04:04, 31.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0.05     |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.435    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.389    |
|    max_target_q      | -9.71    |
|    min_target_q      | -52.6    |
|    max_reward        | -0.246   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 8.97     |
|    q1_grad_norm      | 4.43     |
|    q2_grad_norm      | 4.39     |
|    actor_loss        | 26.9     |
|    ent_coeff         | 0.0312   |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0567   |
|    n_updates         | 23760    |
| time/                |          |
|    iterations        | 300      |
|    fps               | 38.9     |
|    elapsed_time      | 3.24e+04 |
|    elapsed_steps     | 768000   |
-----------------------------------
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [9:00:30<2:04:04, 31.17steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770560/1000000 [9:01:24<1:55:48, 33.02steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770560/1000000 [9:01:40<1:55:48, 33.02steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_770560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 773120/1000000 [9:07:17<3:56:59, 15.96steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:08:26<3:14:05, 19.26steps/s]                                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:08:26<3:14:05, 19.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -156     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -156     |
|    Success           | 0.027    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.42     |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.386    |
|    max_target_q      | -10.5    |
|    min_target_q      | -52.9    |
|    max_reward        | -0.23    |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 8.52     |
|    q1_grad_norm      | 4.31     |
|    q2_grad_norm      | 4.25     |
|    actor_loss        | 27.1     |
|    ent_coeff         | 0.031    |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0576   |
|    n_updates         | 24000    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 303      |
|    fps               | 15.7     |
|    elapsed_time      | 3.29e+04 |
|    elapsed_steps     | 775680   |
-----------------------------------
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:08:40<3:14:05, 19.26steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778240/1000000 [9:09:34<2:43:54, 22.55steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778240/1000000 [9:09:50<2:43:54, 22.55steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780800/1000000 [9:10:40<2:21:28, 25.82steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780800/1000000 [9:10:50<2:21:28, 25.82steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:11:44<2:04:55, 28.90steps/s]                                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:11:44<2:04:55, 28.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -153     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -153     |
|    Success           | 0.025    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.435    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.387    |
|    max_target_q      | -10.3    |
|    min_target_q      | -53.3    |
|    max_reward        | -0.245   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 8.73     |
|    q1_grad_norm      | 4.4      |
|    q2_grad_norm      | 4.36     |
|    actor_loss        | 27.3     |
|    ent_coeff         | 0.0309   |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0563   |
|    n_updates         | 24240    |
| time/                |          |
|    iterations        | 306      |
|    fps               | 38.8     |
|    elapsed_time      | 3.31e+04 |
|    elapsed_steps     | 783360   |
-----------------------------------
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:12:00<2:04:55, 28.90steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785920/1000000 [9:12:56<1:56:34, 30.61steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785920/1000000 [9:13:10<1:56:34, 30.61steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788480/1000000 [9:14:02<1:47:53, 32.68steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_788480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788480/1000000 [9:14:20<1:47:53, 32.68steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791040/1000000 [9:19:49<3:36:14, 16.11steps/s]                                                                79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791040/1000000 [9:19:49<3:36:14, 16.11steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -156     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0526   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.449    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.384    |
|    max_target_q      | -10.2    |
|    min_target_q      | -53.4    |
|    max_reward        | -0.239   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 9.12     |
|    q1_grad_norm      | 3.96     |
|    q2_grad_norm      | 3.88     |
|    actor_loss        | 27.5     |
|    ent_coeff         | 0.0307   |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0582   |
|    n_updates         | 24480    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 309      |
|    fps               | 15.8     |
|    elapsed_time      | 3.36e+04 |
|    elapsed_steps     | 791040   |
-----------------------------------
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793600/1000000 [9:20:54<2:55:46, 19.57steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793600/1000000 [9:21:10<2:55:46, 19.57steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796160/1000000 [9:22:01<2:28:08, 22.93steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796160/1000000 [9:22:20<2:28:08, 22.93steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:23:05<2:07:20, 26.34steps/s]                                                                80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:23:05<2:07:20, 26.34steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.448    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.381    |
|    max_target_q      | -9.79    |
|    min_target_q      | -53.6    |
|    max_reward        | -0.252   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 8.98     |
|    q1_grad_norm      | 4.69     |
|    q2_grad_norm      | 4.62     |
|    actor_loss        | 27.7     |
|    ent_coeff         | 0.0306   |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0563   |
|    n_updates         | 24720    |
| time/                |          |
|    iterations        | 312      |
|    fps               | 39.3     |
|    elapsed_time      | 3.38e+04 |
|    elapsed_steps     | 798720   |
-----------------------------------
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:23:20<2:07:20, 26.34steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801280/1000000 [9:24:13<1:54:31, 28.92steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801280/1000000 [9:24:30<1:54:31, 28.92steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803840/1000000 [9:25:21<1:45:07, 31.10steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803840/1000000 [9:25:40<1:45:07, 31.10steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:26:26<1:37:10, 33.21steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:26:40<1:37:10, 33.21steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_806400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:31:08<1:37:10, 33.21steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -153     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -153     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.46     |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.378    |
|    max_target_q      | -10.3    |
|    min_target_q      | -54      |
|    max_reward        | -0.245   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 9.48     |
|    q1_grad_norm      | 4.8      |
|    q2_grad_norm      | 4.76     |
|    actor_loss        | 27.9     |
|    ent_coeff         | 0.0305   |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0567   |
|    n_updates         | 24960    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 315      |
|    fps               | 15.9     |
|    elapsed_time      | 3.43e+04 |
|    elapsed_steps     | 806400   |
-----------------------------------
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 808960/1000000 [9:32:14<3:17:13, 16.14steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811520/1000000 [9:33:19<2:40:01, 19.63steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811520/1000000 [9:33:30<2:40:01, 19.63steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:34:24<2:14:15, 23.08steps/s]                                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:34:24<2:14:15, 23.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -153     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0811   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.466    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.376    |
|    max_target_q      | -11      |
|    min_target_q      | -54.2    |
|    max_reward        | -0.244   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 9.84     |
|    q1_grad_norm      | 4.58     |
|    q2_grad_norm      | 4.52     |
|    actor_loss        | 28       |
|    ent_coeff         | 0.0303   |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0566   |
|    n_updates         | 25200    |
| time/                |          |
|    iterations        | 318      |
|    fps               | 39.1     |
|    elapsed_time      | 3.45e+04 |
|    elapsed_steps     | 814080   |
-----------------------------------
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:34:40<2:14:15, 23.08steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816640/1000000 [9:35:31<1:56:40, 26.19steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816640/1000000 [9:35:50<1:56:40, 26.19steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819200/1000000 [9:36:38<1:43:53, 29.01steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819200/1000000 [9:36:50<1:43:53, 29.01steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:37:47<1:35:53, 30.98steps/s]                                                                82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:37:47<1:35:53, 30.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.481    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.375    |
|    max_target_q      | -10.5    |
|    min_target_q      | -54.5    |
|    max_reward        | -0.235   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 10.6     |
|    q1_grad_norm      | 4.85     |
|    q2_grad_norm      | 4.78     |
|    actor_loss        | 28.2     |
|    ent_coeff         | 0.0302   |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.057    |
|    n_updates         | 25440    |
| time/                |          |
|    iterations        | 321      |
|    fps               | 37.9     |
|    elapsed_time      | 3.47e+04 |
|    elapsed_steps     | 821760   |
-----------------------------------
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:38:00<1:35:53, 30.98steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824320/1000000 [9:38:54<1:29:15, 32.80steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824320/1000000 [9:39:10<1:29:15, 32.80steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_824320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 826880/1000000 [9:44:47<3:00:41, 15.97steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:45:57<2:28:03, 19.20steps/s]                                                                83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:45:57<2:28:03, 19.20steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -156     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.451    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.375    |
|    max_target_q      | -10.7    |
|    min_target_q      | -54.5    |
|    max_reward        | -0.24    |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 9.89     |
|    q1_grad_norm      | 4.98     |
|    q2_grad_norm      | 4.95     |
|    actor_loss        | 28.3     |
|    ent_coeff         | 0.03     |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0561   |
|    n_updates         | 25680    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -152     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -152     |
|    Success           | 0.0556   |
|    SuccessLength     | 197      |
| time/                |          |
|    iterations        | 324      |
|    fps               | 15.7     |
|    elapsed_time      | 3.52e+04 |
|    elapsed_steps     | 829440   |
-----------------------------------
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:46:10<2:28:03, 19.20steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832000/1000000 [9:47:07<2:05:03, 22.39steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832000/1000000 [9:47:20<2:05:03, 22.39steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834560/1000000 [9:48:13<1:47:34, 25.63steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834560/1000000 [9:48:30<1:47:34, 25.63steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:49:21<1:35:46, 28.35steps/s]                                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:49:21<1:35:46, 28.35steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.459    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.374    |
|    max_target_q      | -10.6    |
|    min_target_q      | -54.9    |
|    max_reward        | -0.235   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 10.2     |
|    q1_grad_norm      | 5.62     |
|    q2_grad_norm      | 5.57     |
|    actor_loss        | 28.5     |
|    ent_coeff         | 0.0299   |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0566   |
|    n_updates         | 25920    |
| time/                |          |
|    iterations        | 327      |
|    fps               | 37.6     |
|    elapsed_time      | 3.54e+04 |
|    elapsed_steps     | 837120   |
-----------------------------------
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:49:40<1:35:46, 28.35steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839680/1000000 [9:50:33<1:28:35, 30.16steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839680/1000000 [9:50:50<1:28:35, 30.16steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842240/1000000 [9:51:39<1:21:04, 32.43steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842240/1000000 [9:51:50<1:21:04, 32.43steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_842240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844800/1000000 [9:57:13<2:37:17, 16.44steps/s]                                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844800/1000000 [9:57:13<2:37:17, 16.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -159     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0526   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.466    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.37     |
|    max_target_q      | -10.4    |
|    min_target_q      | -54.7    |
|    max_reward        | -0.259   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 9.54     |
|    q1_grad_norm      | 4.07     |
|    q2_grad_norm      | 4.01     |
|    actor_loss        | 28.6     |
|    ent_coeff         | 0.0297   |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0543   |
|    n_updates         | 26160    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -164     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -164     |
|    Success           | 0.0556   |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 330      |
|    fps               | 16.3     |
|    elapsed_time      | 3.58e+04 |
|    elapsed_steps     | 844800   |
-----------------------------------
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847360/1000000 [9:58:15<2:06:48, 20.06steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847360/1000000 [9:58:31<2:06:48, 20.06steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849920/1000000 [9:59:20<1:46:17, 23.53steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849920/1000000 [9:59:31<1:46:17, 23.53steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [10:00:28<1:32:39, 26.54steps/s]                                                                 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [10:00:28<1:32:39, 26.54steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -162     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -162     |
|    Success           | 0.0263   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.432    |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.369    |
|    max_target_q      | -10.3    |
|    min_target_q      | -55      |
|    max_reward        | -0.253   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 8.82     |
|    q1_grad_norm      | 4.11     |
|    q2_grad_norm      | 4.07     |
|    actor_loss        | 28.8     |
|    ent_coeff         | 0.0296   |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0549   |
|    n_updates         | 26400    |
| time/                |          |
|    iterations        | 333      |
|    fps               | 39.4     |
|    elapsed_time      | 3.6e+04  |
|    elapsed_steps     | 852480   |
-----------------------------------
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [10:00:41<1:32:39, 26.54steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855040/1000000 [10:01:32<1:21:46, 29.54steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855040/1000000 [10:01:51<1:21:46, 29.54steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857600/1000000 [10:02:39<1:14:50, 31.71steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857600/1000000 [10:02:51<1:14:50, 31.71steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:03:42<1:08:52, 33.84steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_860160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:04:01<1:08:52, 33.84steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:08:26<1:08:52, 33.84steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.442    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.366    |
|    max_target_q      | -11.1    |
|    min_target_q      | -55.3    |
|    max_reward        | -0.247   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 8.98     |
|    q1_grad_norm      | 4.29     |
|    q2_grad_norm      | 4.24     |
|    actor_loss        | 29       |
|    ent_coeff         | 0.0294   |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0556   |
|    n_updates         | 26640    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 336      |
|    fps               | 16.1     |
|    elapsed_time      | 3.65e+04 |
|    elapsed_steps     | 860160   |
-----------------------------------
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 862720/1000000 [10:09:44<2:24:24, 15.84steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865280/1000000 [10:10:53<1:57:20, 19.13steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865280/1000000 [10:11:11<1:57:20, 19.13steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:12:02<1:38:22, 22.39steps/s]                                                                 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:12:02<1:38:22, 22.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -157     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0526   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.411    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.362    |
|    max_target_q      | -11.2    |
|    min_target_q      | -55.4    |
|    max_reward        | -0.26    |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 8.58     |
|    q1_grad_norm      | 4.58     |
|    q2_grad_norm      | 4.54     |
|    actor_loss        | 29.2     |
|    ent_coeff         | 0.0293   |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0555   |
|    n_updates         | 26880    |
| time/                |          |
|    iterations        | 339      |
|    fps               | 35.5     |
|    elapsed_time      | 3.67e+04 |
|    elapsed_steps     | 867840   |
-----------------------------------
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:12:21<1:38:22, 22.39steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870400/1000000 [10:13:13<1:25:24, 25.29steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870400/1000000 [10:13:31<1:25:24, 25.29steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872960/1000000 [10:14:21<1:15:34, 28.02steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872960/1000000 [10:14:41<1:15:34, 28.02steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:15:32<1:09:03, 30.04steps/s]                                                                 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:15:32<1:09:03, 30.04steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.45     |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.36     |
|    max_target_q      | -10.9    |
|    min_target_q      | -55.8    |
|    max_reward        | -0.255   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 9.88     |
|    q1_grad_norm      | 5        |
|    q2_grad_norm      | 4.96     |
|    actor_loss        | 29.4     |
|    ent_coeff         | 0.0292   |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0556   |
|    n_updates         | 27120    |
| time/                |          |
|    iterations        | 342      |
|    fps               | 36.6     |
|    elapsed_time      | 3.69e+04 |
|    elapsed_steps     | 875520   |
-----------------------------------
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:15:51<1:09:03, 30.04steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878080/1000000 [10:16:43<1:04:18, 31.60steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_878080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878080/1000000 [10:17:01<1:04:18, 31.60steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 880640/1000000 [10:22:10<2:00:07, 16.56steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:23:19<1:38:11, 19.83steps/s]                                                                 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:23:19<1:38:11, 19.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.45     |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.358    |
|    max_target_q      | -9.57    |
|    min_target_q      | -55.8    |
|    max_reward        | -0.254   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 9.77     |
|    q1_grad_norm      | 4.49     |
|    q2_grad_norm      | 4.44     |
|    actor_loss        | 29.5     |
|    ent_coeff         | 0.029    |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0557   |
|    n_updates         | 27360    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -166     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -166     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 345      |
|    fps               | 16.4     |
|    elapsed_time      | 3.74e+04 |
|    elapsed_steps     | 883200   |
-----------------------------------
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:23:31<1:38:11, 19.83steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885760/1000000 [10:24:26<1:22:09, 23.18steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885760/1000000 [10:24:41<1:22:09, 23.18steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888320/1000000 [10:25:29<1:09:53, 26.63steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888320/1000000 [10:25:41<1:09:53, 26.63steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:26:36<1:01:59, 29.34steps/s]                                                                 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:26:36<1:01:59, 29.34steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -158     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -158     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.461    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.355    |
|    max_target_q      | -9.34    |
|    min_target_q      | -56      |
|    max_reward        | -0.263   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 10.1     |
|    q1_grad_norm      | 4.67     |
|    q2_grad_norm      | 4.61     |
|    actor_loss        | 29.7     |
|    ent_coeff         | 0.0289   |
|    ent_coeff_loss    | -114     |
|    pi_grad_norm      | 0.0559   |
|    n_updates         | 27600    |
| time/                |          |
|    iterations        | 348      |
|    fps               | 39.2     |
|    elapsed_time      | 3.76e+04 |
|    elapsed_steps     | 890880   |
-----------------------------------
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:26:51<1:01:59, 29.34steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893440/1000000 [10:27:40<55:52, 31.79steps/s]   89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893440/1000000 [10:27:51<55:52, 31.79steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896000/1000000 [10:28:51<52:27, 33.04steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_896000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896000/1000000 [10:29:11<52:27, 33.04steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898560/1000000 [10:34:38<1:44:32, 16.17steps/s]                                                                 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898560/1000000 [10:34:38<1:44:32, 16.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -151     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0513   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.412    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.355    |
|    max_target_q      | -9.25    |
|    min_target_q      | -56.3    |
|    max_reward        | -0.258   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 9.09     |
|    q1_grad_norm      | 5.46     |
|    q2_grad_norm      | 5.38     |
|    actor_loss        | 29.8     |
|    ent_coeff         | 0.0287   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0546   |
|    n_updates         | 27840    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 351      |
|    fps               | 15.9     |
|    elapsed_time      | 3.81e+04 |
|    elapsed_steps     | 898560   |
-----------------------------------
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901120/1000000 [10:35:46<1:24:33, 19.49steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901120/1000000 [10:36:01<1:24:33, 19.49steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903680/1000000 [10:36:54<1:10:25, 22.80steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903680/1000000 [10:37:11<1:10:25, 22.80steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:38:00<1:00:09, 25.98steps/s]                                                                 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:38:00<1:00:09, 25.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -145     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -145     |
|    Success           | 0.103    |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.463    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.351    |
|    max_target_q      | -9.04    |
|    min_target_q      | -56      |
|    max_reward        | -0.268   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 10.7     |
|    q1_grad_norm      | 4.83     |
|    q2_grad_norm      | 4.78     |
|    actor_loss        | 30       |
|    ent_coeff         | 0.0286   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0569   |
|    n_updates         | 28080    |
| time/                |          |
|    iterations        | 354      |
|    fps               | 37.9     |
|    elapsed_time      | 3.83e+04 |
|    elapsed_steps     | 906240   |
-----------------------------------
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:38:11<1:00:09, 25.98steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908800/1000000 [10:39:10<53:20, 28.50steps/s]   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908800/1000000 [10:39:21<53:20, 28.50steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911360/1000000 [10:40:14<47:26, 31.14steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911360/1000000 [10:40:31<47:26, 31.14steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:41:24<43:58, 32.63steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_913920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:41:41<43:58, 32.63steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:45:52<43:58, 32.63steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -155     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -155     |
|    Success           | 0.05     |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.521    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.35     |
|    max_target_q      | -9.07    |
|    min_target_q      | -56.2    |
|    max_reward        | -0.255   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 12.1     |
|    q1_grad_norm      | 6.16     |
|    q2_grad_norm      | 6.1      |
|    actor_loss        | 30.2     |
|    ent_coeff         | 0.0285   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0564   |
|    n_updates         | 28320    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -164     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -164     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 357      |
|    fps               | 16.3     |
|    elapsed_time      | 3.88e+04 |
|    elapsed_steps     | 913920   |
-----------------------------------
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 916480/1000000 [10:47:03<1:25:06, 16.35steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919040/1000000 [10:48:15<1:09:12, 19.50steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919040/1000000 [10:48:31<1:09:12, 19.50steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:49:22<57:04, 22.89steps/s]                                                                 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:49:22<57:04, 22.89steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -165     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -165     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.524    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.347    |
|    max_target_q      | -9.65    |
|    min_target_q      | -56.6    |
|    max_reward        | -0.264   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 11.6     |
|    q1_grad_norm      | 4.83     |
|    q2_grad_norm      | 4.79     |
|    actor_loss        | 30.3     |
|    ent_coeff         | 0.0283   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0581   |
|    n_updates         | 28560    |
| time/                |          |
|    iterations        | 360      |
|    fps               | 36.7     |
|    elapsed_time      | 3.9e+04  |
|    elapsed_steps     | 921600   |
-----------------------------------
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:49:41<57:04, 22.89steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924160/1000000 [10:50:29<48:36, 26.01steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924160/1000000 [10:50:41<48:36, 26.01steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926720/1000000 [10:51:39<42:55, 28.45steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926720/1000000 [10:51:51<42:55, 28.45steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:52:45<38:03, 30.97steps/s]                                                               93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:52:45<38:03, 30.97steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -153     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0526   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.461    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.345    |
|    max_target_q      | -10.2    |
|    min_target_q      | -56.5    |
|    max_reward        | -0.26    |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 9.25     |
|    q1_grad_norm      | 5.07     |
|    q2_grad_norm      | 5.03     |
|    actor_loss        | 30.5     |
|    ent_coeff         | 0.0282   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0576   |
|    n_updates         | 28800    |
| time/                |          |
|    iterations        | 363      |
|    fps               | 37.8     |
|    elapsed_time      | 3.92e+04 |
|    elapsed_steps     | 929280   |
-----------------------------------
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:53:01<38:03, 30.97steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931840/1000000 [10:53:56<35:11, 32.29steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931840/1000000 [10:54:11<35:11, 32.29steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_931840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 934400/1000000 [10:59:40<1:07:50, 16.12steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:00:52<54:28, 19.29steps/s]                                                                 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:00:52<54:28, 19.29steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -151     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0526   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.436    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.342    |
|    max_target_q      | -9.28    |
|    min_target_q      | -56.7    |
|    max_reward        | -0.263   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 9.68     |
|    q1_grad_norm      | 5.43     |
|    q2_grad_norm      | 5.38     |
|    actor_loss        | 30.7     |
|    ent_coeff         | 0.0281   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0566   |
|    n_updates         | 29040    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 366      |
|    fps               | 15.7     |
|    elapsed_time      | 3.97e+04 |
|    elapsed_steps     | 936960   |
-----------------------------------
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:01:11<54:28, 19.29steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939520/1000000 [11:02:00<44:37, 22.59steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939520/1000000 [11:02:11<44:37, 22.59steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942080/1000000 [11:03:06<37:20, 25.85steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942080/1000000 [11:03:21<37:20, 25.85steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:04:13<32:17, 28.57steps/s]                                                               94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:04:13<32:17, 28.57steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -152     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -152     |
|    Success           | 0.05     |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.474    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.341    |
|    max_target_q      | -9.74    |
|    min_target_q      | -56.7    |
|    max_reward        | -0.287   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 10.7     |
|    q1_grad_norm      | 5.46     |
|    q2_grad_norm      | 5.4      |
|    actor_loss        | 30.9     |
|    ent_coeff         | 0.0279   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0566   |
|    n_updates         | 29280    |
| time/                |          |
|    iterations        | 369      |
|    fps               | 38.1     |
|    elapsed_time      | 3.99e+04 |
|    elapsed_steps     | 944640   |
-----------------------------------
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:04:31<32:17, 28.57steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947200/1000000 [11:05:24<28:49, 30.52steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947200/1000000 [11:05:41<28:49, 30.52steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949760/1000000 [11:06:31<25:46, 32.49steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_949760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949760/1000000 [11:06:51<25:46, 32.49steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952320/1000000 [11:12:04<48:10, 16.49steps/s]                                                               95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952320/1000000 [11:12:04<48:10, 16.49steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -153     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -153     |
|    Success           | 0.1      |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.443    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.338    |
|    max_target_q      | -9.87    |
|    min_target_q      | -56.8    |
|    max_reward        | -0.267   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 9.19     |
|    q1_grad_norm      | 4.59     |
|    q2_grad_norm      | 4.55     |
|    actor_loss        | 31       |
|    ent_coeff         | 0.0278   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0564   |
|    n_updates         | 29520    |
| eval/                |          |
|    Length            | 198      |
|    Return            | -157     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0556   |
|    SuccessLength     | 198      |
| time/                |          |
|    iterations        | 372      |
|    fps               | 16.3     |
|    elapsed_time      | 4.03e+04 |
|    elapsed_steps     | 952320   |
-----------------------------------
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954880/1000000 [11:13:11<37:48, 19.89steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954880/1000000 [11:13:31<37:48, 19.89steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957440/1000000 [11:14:17<30:23, 23.34steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957440/1000000 [11:14:31<30:23, 23.34steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:15:22<25:07, 26.53steps/s]                                                               96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:15:22<25:07, 26.53steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.529    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.335    |
|    max_target_q      | -9.85    |
|    min_target_q      | -57.3    |
|    max_reward        | -0.28    |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 12.1     |
|    q1_grad_norm      | 5.6      |
|    q2_grad_norm      | 5.54     |
|    actor_loss        | 31.2     |
|    ent_coeff         | 0.0277   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0587   |
|    n_updates         | 29760    |
| time/                |          |
|    iterations        | 375      |
|    fps               | 38.8     |
|    elapsed_time      | 4.05e+04 |
|    elapsed_steps     | 960000   |
-----------------------------------
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:15:41<25:07, 26.53steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 962560/1000000 [11:16:27<21:13, 29.40steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 962560/1000000 [11:16:41<21:13, 29.40steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965120/1000000 [11:17:30<18:07, 32.09steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965120/1000000 [11:17:41<18:07, 32.09steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:18:34<15:46, 34.14steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_967680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:18:51<15:46, 34.14steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:23:00<15:46, 34.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.462    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.332    |
|    max_target_q      | -10.6    |
|    min_target_q      | -57.5    |
|    max_reward        | -0.273   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.96     |
|    q1_grad_norm      | 5.33     |
|    q2_grad_norm      | 5.31     |
|    actor_loss        | 31.4     |
|    ent_coeff         | 0.0275   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0572   |
|    n_updates         | 30000    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -150     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0556   |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 378      |
|    fps               | 16.8     |
|    elapsed_time      | 4.1e+04  |
|    elapsed_steps     | 967680   |
-----------------------------------
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 970240/1000000 [11:24:10<29:42, 16.69steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972800/1000000 [11:25:21<22:45, 19.93steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972800/1000000 [11:25:31<22:45, 19.93steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:26:31<17:48, 23.05steps/s]                                                               98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:26:31<17:48, 23.05steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -146     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0976   |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.502    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.331    |
|    max_target_q      | -10.1    |
|    min_target_q      | -57.7    |
|    max_reward        | -0.268   |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 11       |
|    q1_grad_norm      | 4.24     |
|    q2_grad_norm      | 4.21     |
|    actor_loss        | 31.6     |
|    ent_coeff         | 0.0274   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0576   |
|    n_updates         | 30240    |
| time/                |          |
|    iterations        | 381      |
|    fps               | 36.5     |
|    elapsed_time      | 4.12e+04 |
|    elapsed_steps     | 975360   |
-----------------------------------
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:26:51<17:48, 23.05steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977920/1000000 [11:27:42<14:13, 25.87steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977920/1000000 [11:28:01<14:13, 25.87steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980480/1000000 [11:28:52<11:28, 28.34steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980480/1000000 [11:29:11<11:28, 28.34steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:30:00<09:14, 30.57steps/s]                                                               98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:30:00<09:14, 30.57steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -146     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -146     |
|    Success           | 0.103    |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.475    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.324    |
|    max_target_q      | -9.48    |
|    min_target_q      | -58      |
|    max_reward        | -0.271   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 10.6     |
|    q1_grad_norm      | 4.71     |
|    q2_grad_norm      | 4.68     |
|    actor_loss        | 31.8     |
|    ent_coeff         | 0.0273   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0587   |
|    n_updates         | 30480    |
| time/                |          |
|    iterations        | 384      |
|    fps               | 36.7     |
|    elapsed_time      | 4.14e+04 |
|    elapsed_steps     | 983040   |
-----------------------------------
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:30:11<09:14, 30.57steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985600/1000000 [11:31:12<07:30, 31.98steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_985600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985600/1000000 [11:31:31<07:30, 31.98steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 988160/1000000 [11:36:38<11:51, 16.65steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:37:42<07:40, 20.14steps/s]                                                               99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:37:42<07:40, 20.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -155     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0488   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.478    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.324    |
|    max_target_q      | -9.45    |
|    min_target_q      | -58.1    |
|    max_reward        | -0.277   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 9.27     |
|    q1_grad_norm      | 4.53     |
|    q2_grad_norm      | 4.49     |
|    actor_loss        | 31.8     |
|    ent_coeff         | 0.0271   |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0593   |
|    n_updates         | 30720    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -156     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 387      |
|    fps               | 16.6     |
|    elapsed_time      | 4.19e+04 |
|    elapsed_steps     | 990720   |
-----------------------------------
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:38:01<07:40, 20.14steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993280/1000000 [11:38:51<04:47, 23.34steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993280/1000000 [11:39:11<04:47, 23.34steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995840/1000000 [11:40:00<02:37, 26.33steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995840/1000000 [11:40:11<02:37, 26.33steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:41:08<00:55, 28.89steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:41:21<00:55, 28.89steps/s]Saved video of policy to videos/2025-09-08/mejuzx0m/nominal/policy_step_998400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:45:23<00:55, 28.89steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -151     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0513   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.525    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.321    |
|    max_target_q      | -9.62    |
|    min_target_q      | -58      |
|    max_reward        | -0.274   |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 11.7     |
|    q1_grad_norm      | 5.52     |
|    q2_grad_norm      | 5.49     |
|    actor_loss        | 32       |
|    ent_coeff         | 0.027    |
|    ent_coeff_loss    | -115     |
|    pi_grad_norm      | 0.0627   |
|    n_updates         | 30960    |
| eval/                |          |
|    Length            | 192      |
|    Return            | -151     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -151     |
|    Success           | 0.111    |
|    SuccessLength     | 192      |
| time/                |          |
|    iterations        | 390      |
|    fps               | 16.7     |
|    elapsed_time      | 4.23e+04 |
|    elapsed_steps     | 998400   |
-----------------------------------
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:45:23<01:07, 23.59steps/s]
RLRunner: Finished training.
RLRunner: Log files saved to /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-mejuzx0m/files
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/along_view+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         eval/fov30/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:         eval/fov70/success_rate â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       eval/nominal/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–
wandb:    eval/roll+15deg/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:    eval/roll+30deg/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ˆâ–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:    eval/shift+x+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    eval/shift+y+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–
wandb:    eval/shift+z+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb: eval/along_view+50/success_rate 0
wandb:         eval/fov30/success_rate 0.5
wandb:         eval/fov70/success_rate 0
wandb:       eval/nominal/success_rate 0
wandb:    eval/roll+15deg/success_rate 0.5
wandb:    eval/roll+30deg/success_rate 0
wandb:    eval/shift+x+50/success_rate 0
wandb:    eval/shift+y+50/success_rate 0
wandb:    eval/shift+z+50/success_rate 0
wandb: 
wandb: ðŸš€ View run jolly-energy-988 at: https://wandb.ai/michael-bezick-purdue-university/pprl/runs/mejuzx0m
wandb: â­ï¸ View project at: https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: Synced 7 W&B file(s), 57 media file(s), 0 artifact file(s) and 42 other file(s)
wandb: Find logs at: ./wandb/run-20250908_150535-mejuzx0m/logs
