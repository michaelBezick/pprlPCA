/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
wandb: Currently logged in as: michael-bezick (michael-bezick-purdue-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: creating run
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-r9fm25ag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-armadillo-988
wandb: â­ï¸ View project at https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: ðŸš€ View run at https://wandb.ai/michael-bezick-purdue-university/pprl/runs/r9fm25ag
Group name is:  PCA_push_chair
Instantiating 8 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
BasicSampler: Resetting all environments.
BasicSampler: Resetting agent.
SAC: Given sampler batch size 2560, training batch size 512, and replay ratio 16, there will be 80 updates per iteration.
SAC: Using learnable entropy coefficient with target entropy of -20
RLRunner: Starting training...
RLRunner: Saving log files to /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-r9fm25ag/files
  0%|          | 0/1000000 [00:00<?, ?steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_0.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
wandb: WARNING Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                0%|          | 0/1000000 [04:27<?, ?steps/s]----------------------------------
| eval/               |          |
|    Length           | 196      |
|    Return           | -205     |
|    NonzeroRewards   | 196      |
|    DiscountedReturn | -205     |
|    Success          | 0.0556   |
|    SuccessLength    | 196      |
| time/               |          |
|    iterations       | 0        |
|    fps              | 0        |
|    elapsed_time     | 268      |
|    elapsed_steps    | 0        |
----------------------------------
For the first 10000 steps, agent will use a fixed std of 0.75 for exploration.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
  0%|          | 2560/1000000 [05:25<35:13:40,  7.86steps/s]  1%|          | 5120/1000000 [06:23<18:08:29, 15.23steps/s]  1%|          | 5120/1000000 [06:40<18:08:29, 15.23steps/s]  1%|          | 7680/1000000 [07:12<12:15:24, 22.49steps/s]                                                              1%|          | 7680/1000000 [07:12<12:15:24, 22.49steps/s]----------------------------------
| rollout/            |          |
|    Length           | 200      |
|    Return           | -209     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -209     |
|    Success          | 0        |
|    SuccessLength    | 200      |
| time/               |          |
|    iterations       | 3        |
|    fps              | 46.5     |
|    elapsed_time     | 433      |
|    elapsed_steps    | 7680     |
----------------------------------
  1%|          | 7680/1000000 [07:30<12:15:24, 22.49steps/s]  1%|          | 10240/1000000 [08:31<10:43:51, 25.62steps/s]  1%|          | 10240/1000000 [08:50<10:43:51, 25.62steps/s]  1%|â–         | 12800/1000000 [09:50<9:54:32, 27.67steps/s]   1%|â–         | 12800/1000000 [10:10<9:54:32, 27.67steps/s]  2%|â–         | 15360/1000000 [11:08<9:20:55, 29.26steps/s]                                                              2%|â–         | 15360/1000000 [11:08<9:20:55, 29.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -211     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -211     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00647  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.68     |
|    max_target_q      | -0.511   |
|    min_target_q      | -0.81    |
|    max_reward        | -0.794   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 0.0582   |
|    q1_grad_norm      | 0.16     |
|    q2_grad_norm      | 0.134    |
|    actor_loss        | 0.345    |
|    ent_coeff         | 0.0499   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.109    |
|    n_updates         | 240      |
| time/                |          |
|    iterations        | 6        |
|    fps               | 32.6     |
|    elapsed_time      | 668      |
|    elapsed_steps     | 15360    |
-----------------------------------
  2%|â–         | 15360/1000000 [11:20<9:20:55, 29.26steps/s]  2%|â–         | 17920/1000000 [12:25<8:57:32, 30.45steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  2%|â–         | 17920/1000000 [12:40<8:57:32, 30.45steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_17920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  2%|â–         | 20480/1000000 [17:59<17:24:19, 15.63steps/s]  2%|â–         | 23040/1000000 [19:19<14:35:06, 18.61steps/s]                                                               2%|â–         | 23040/1000000 [19:19<14:35:06, 18.61steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -210     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -210     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00393  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.677    |
|    max_target_q      | -1.15    |
|    min_target_q      | -1.86    |
|    max_reward        | -0.781   |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 0.101    |
|    q1_grad_norm      | 0.123    |
|    q2_grad_norm      | 0.145    |
|    actor_loss        | 1.16     |
|    ent_coeff         | 0.0496   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0834   |
|    n_updates         | 480      |
| eval/                |          |
|    Length            | 200      |
|    Return            | -210     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -210     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 9        |
|    fps               | 15.6     |
|    elapsed_time      | 1.16e+03 |
|    elapsed_steps     | 23040    |
-----------------------------------
  2%|â–         | 23040/1000000 [19:30<14:35:06, 18.61steps/s]  3%|â–Ž         | 25600/1000000 [20:38<12:37:42, 21.43steps/s]  3%|â–Ž         | 25600/1000000 [20:50<12:37:42, 21.43steps/s]  3%|â–Ž         | 28160/1000000 [21:52<11:08:09, 24.24steps/s]  3%|â–Ž         | 28160/1000000 [22:10<11:08:09, 24.24steps/s]  3%|â–Ž         | 30720/1000000 [23:11<10:14:14, 26.30steps/s]                                                               3%|â–Ž         | 30720/1000000 [23:11<10:14:14, 26.30steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -208     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -208     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00572  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.674    |
|    max_target_q      | -1.72    |
|    min_target_q      | -2.9     |
|    max_reward        | -0.786   |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 0.223    |
|    q1_grad_norm      | 0.27     |
|    q2_grad_norm      | 0.27     |
|    actor_loss        | 1.98     |
|    ent_coeff         | 0.0494   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0728   |
|    n_updates         | 720      |
| time/                |          |
|    iterations        | 12       |
|    fps               | 33.2     |
|    elapsed_time      | 1.39e+03 |
|    elapsed_steps     | 30720    |
-----------------------------------
  3%|â–Ž         | 30720/1000000 [23:30<10:14:14, 26.30steps/s]  3%|â–Ž         | 33280/1000000 [24:29<9:35:21, 28.00steps/s]   3%|â–Ž         | 33280/1000000 [24:40<9:35:21, 28.00steps/s]  4%|â–Ž         | 35840/1000000 [25:46<9:07:33, 29.35steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  4%|â–Ž         | 35840/1000000 [26:00<9:07:33, 29.35steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_35840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  4%|â–         | 38400/1000000 [31:04<16:20:23, 16.35steps/s]                                                               4%|â–         | 38400/1000000 [31:04<16:20:23, 16.35steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -210     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -210     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00743  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.67     |
|    max_target_q      | -2.26    |
|    min_target_q      | -3.98    |
|    max_reward        | -0.763   |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 0.326    |
|    q1_grad_norm      | 0.369    |
|    q2_grad_norm      | 0.357    |
|    actor_loss        | 2.81     |
|    ent_coeff         | 0.0492   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0656   |
|    n_updates         | 960      |
| eval/                |          |
|    Length            | 200      |
|    Return            | -204     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -204     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 15       |
|    fps               | 16.2     |
|    elapsed_time      | 1.86e+03 |
|    elapsed_steps     | 38400    |
-----------------------------------
  4%|â–         | 40960/1000000 [32:07<13:22:20, 19.92steps/s]  4%|â–         | 40960/1000000 [32:20<13:22:20, 19.92steps/s]  4%|â–         | 43520/1000000 [33:10<11:17:13, 23.54steps/s]  4%|â–         | 43520/1000000 [33:30<11:17:13, 23.54steps/s]  5%|â–         | 46080/1000000 [34:09<9:43:30, 27.25steps/s]                                                               5%|â–         | 46080/1000000 [34:09<9:43:30, 27.25steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -205     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -205     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00894  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.666    |
|    max_target_q      | -2.8     |
|    min_target_q      | -5.05    |
|    max_reward        | -0.767   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 0.386    |
|    q1_grad_norm      | 0.408    |
|    q2_grad_norm      | 0.395    |
|    actor_loss        | 3.63     |
|    ent_coeff         | 0.0489   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0608   |
|    n_updates         | 1200     |
| time/                |          |
|    iterations        | 18       |
|    fps               | 41.4     |
|    elapsed_time      | 2.05e+03 |
|    elapsed_steps     | 46080    |
-----------------------------------
  5%|â–         | 46080/1000000 [34:20<9:43:30, 27.25steps/s]  5%|â–         | 48640/1000000 [35:14<8:47:51, 30.04steps/s]  5%|â–         | 48640/1000000 [35:30<8:47:51, 30.04steps/s]  5%|â–Œ         | 51200/1000000 [36:14<7:59:20, 32.99steps/s]  5%|â–Œ         | 51200/1000000 [36:30<7:59:20, 32.99steps/s]  5%|â–Œ         | 53760/1000000 [37:17<7:30:41, 34.99steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  5%|â–Œ         | 53760/1000000 [37:30<7:30:41, 34.99steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_53760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              5%|â–Œ         | 53760/1000000 [41:39<7:30:41, 34.99steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -202     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -202     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0118   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.662    |
|    max_target_q      | -3.33    |
|    min_target_q      | -6.11    |
|    max_reward        | -0.768   |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 0.575    |
|    q1_grad_norm      | 0.588    |
|    q2_grad_norm      | 0.565    |
|    actor_loss        | 4.4      |
|    ent_coeff         | 0.0487   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0572   |
|    n_updates         | 1440     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -199     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -199     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 21       |
|    fps               | 17.1     |
|    elapsed_time      | 2.5e+03  |
|    elapsed_steps     | 53760    |
-----------------------------------
  6%|â–Œ         | 56320/1000000 [42:39<15:09:17, 17.30steps/s]  6%|â–Œ         | 58880/1000000 [43:37<12:21:49, 21.14steps/s]  6%|â–Œ         | 58880/1000000 [43:50<12:21:49, 21.14steps/s]  6%|â–Œ         | 61440/1000000 [44:40<10:32:25, 24.73steps/s]                                                               6%|â–Œ         | 61440/1000000 [44:40<10:32:25, 24.73steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -199     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -199     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0135   |
|    mean_entropy      | 13.5     |
|    mean_ent_bonus    | 0.654    |
|    max_target_q      | -3.84    |
|    min_target_q      | -7.16    |
|    max_reward        | -0.737   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 0.641    |
|    q1_grad_norm      | 0.609    |
|    q2_grad_norm      | 0.59     |
|    actor_loss        | 5.13     |
|    ent_coeff         | 0.0485   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0569   |
|    n_updates         | 1680     |
| time/                |          |
|    iterations        | 24       |
|    fps               | 42.5     |
|    elapsed_time      | 2.68e+03 |
|    elapsed_steps     | 61440    |
-----------------------------------
  6%|â–Œ         | 61440/1000000 [45:00<10:32:25, 24.73steps/s]  6%|â–‹         | 64000/1000000 [45:44<9:18:24, 27.94steps/s]   6%|â–‹         | 64000/1000000 [46:00<9:18:24, 27.94steps/s]  7%|â–‹         | 66560/1000000 [46:49<8:28:14, 30.61steps/s]  7%|â–‹         | 66560/1000000 [47:00<8:28:14, 30.61steps/s]  7%|â–‹         | 69120/1000000 [47:55<7:55:35, 32.62steps/s]                                                              7%|â–‹         | 69120/1000000 [47:55<7:55:35, 32.62steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -199     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -199     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0174   |
|    mean_entropy      | 13.3     |
|    mean_ent_bonus    | 0.642    |
|    max_target_q      | -4.24    |
|    min_target_q      | -8.17    |
|    max_reward        | -0.629   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 0.915    |
|    q1_grad_norm      | 0.858    |
|    q2_grad_norm      | 0.82     |
|    actor_loss        | 5.82     |
|    ent_coeff         | 0.0482   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0594   |
|    n_updates         | 1920     |
| time/                |          |
|    iterations        | 27       |
|    fps               | 39.3     |
|    elapsed_time      | 2.88e+03 |
|    elapsed_steps     | 69120    |
-----------------------------------
  7%|â–‹         | 69120/1000000 [48:10<7:55:35, 32.62steps/s]  7%|â–‹         | 71680/1000000 [49:06<7:39:32, 33.67steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  7%|â–‹         | 71680/1000000 [49:20<7:39:32, 33.67steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_71680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  7%|â–‹         | 74240/1000000 [54:18<14:45:14, 17.43steps/s]  8%|â–Š         | 76800/1000000 [55:25<12:19:14, 20.81steps/s]                                                               8%|â–Š         | 76800/1000000 [55:25<12:19:14, 20.81steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -196     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -196     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0179   |
|    mean_entropy      | 13.2     |
|    mean_ent_bonus    | 0.631    |
|    max_target_q      | -4.55    |
|    min_target_q      | -9.15    |
|    max_reward        | -0.597   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 0.81     |
|    q1_grad_norm      | 0.74     |
|    q2_grad_norm      | 0.709    |
|    actor_loss        | 6.48     |
|    ent_coeff         | 0.048    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0623   |
|    n_updates         | 2160     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -197     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -197     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 30       |
|    fps               | 17.1     |
|    elapsed_time      | 3.33e+03 |
|    elapsed_steps     | 76800    |
-----------------------------------
  8%|â–Š         | 76800/1000000 [55:40<12:19:14, 20.81steps/s]  8%|â–Š         | 79360/1000000 [56:30<10:32:49, 24.25steps/s]  8%|â–Š         | 79360/1000000 [56:50<10:32:49, 24.25steps/s]  8%|â–Š         | 81920/1000000 [57:38<9:22:47, 27.19steps/s]   8%|â–Š         | 81920/1000000 [57:50<9:22:47, 27.19steps/s]  8%|â–Š         | 84480/1000000 [58:45<8:33:42, 29.70steps/s]                                                              8%|â–Š         | 84480/1000000 [58:45<8:33:42, 29.70steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -198     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -198     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0217   |
|    mean_entropy      | 13.1     |
|    mean_ent_bonus    | 0.625    |
|    max_target_q      | -4.84    |
|    min_target_q      | -10.1    |
|    max_reward        | -0.589   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 1.07     |
|    q1_grad_norm      | 0.939    |
|    q2_grad_norm      | 0.9      |
|    actor_loss        | 7.09     |
|    ent_coeff         | 0.0478   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0629   |
|    n_updates         | 2400     |
| time/                |          |
|    iterations        | 33       |
|    fps               | 38.4     |
|    elapsed_time      | 3.53e+03 |
|    elapsed_steps     | 84480    |
-----------------------------------
  8%|â–Š         | 84480/1000000 [59:00<8:33:42, 29.70steps/s]  9%|â–Š         | 87040/1000000 [59:53<8:00:24, 31.67steps/s]  9%|â–Š         | 87040/1000000 [1:00:10<8:00:24, 31.67steps/s]  9%|â–‰         | 89600/1000000 [1:01:00<7:33:14, 33.48steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_89600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  9%|â–‰         | 89600/1000000 [1:01:20<7:33:14, 33.48steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  9%|â–‰         | 92160/1000000 [1:06:22<14:47:09, 17.06steps/s]                                                                 9%|â–‰         | 92160/1000000 [1:06:22<14:47:09, 17.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -197     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -197     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0246   |
|    mean_entropy      | 13.1     |
|    mean_ent_bonus    | 0.622    |
|    max_target_q      | -5.17    |
|    min_target_q      | -11      |
|    max_reward        | -0.573   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 1.2      |
|    q1_grad_norm      | 1.07     |
|    q2_grad_norm      | 1.02     |
|    actor_loss        | 7.72     |
|    ent_coeff         | 0.0475   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0608   |
|    n_updates         | 2640     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -195     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -195     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 36       |
|    fps               | 16.8     |
|    elapsed_time      | 3.98e+03 |
|    elapsed_steps     | 92160    |
-----------------------------------
  9%|â–‰         | 94720/1000000 [1:07:27<12:14:04, 20.55steps/s]  9%|â–‰         | 94720/1000000 [1:07:40<12:14:04, 20.55steps/s] 10%|â–‰         | 97280/1000000 [1:08:28<10:19:55, 24.27steps/s] 10%|â–‰         | 97280/1000000 [1:08:40<10:19:55, 24.27steps/s] 10%|â–‰         | 99840/1000000 [1:09:28<8:59:47, 27.79steps/s]                                                                10%|â–‰         | 99840/1000000 [1:09:28<8:59:47, 27.79steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -192     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -192     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0264   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.617    |
|    max_target_q      | -5.39    |
|    min_target_q      | -11.9    |
|    max_reward        | -0.536   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 1.11     |
|    q1_grad_norm      | 0.929    |
|    q2_grad_norm      | 0.894    |
|    actor_loss        | 8.32     |
|    ent_coeff         | 0.0473   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0606   |
|    n_updates         | 2880     |
| time/                |          |
|    iterations        | 39       |
|    fps               | 41.1     |
|    elapsed_time      | 4.17e+03 |
|    elapsed_steps     | 99840    |
-----------------------------------
 10%|â–‰         | 99840/1000000 [1:09:40<8:59:47, 27.79steps/s] 10%|â–ˆ         | 102400/1000000 [1:10:32<8:07:40, 30.68steps/s] 10%|â–ˆ         | 102400/1000000 [1:10:50<8:07:40, 30.68steps/s] 10%|â–ˆ         | 104960/1000000 [1:11:37<7:33:52, 32.87steps/s] 10%|â–ˆ         | 104960/1000000 [1:11:50<7:33:52, 32.87steps/s] 11%|â–ˆ         | 107520/1000000 [1:12:46<7:17:38, 33.99steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 11%|â–ˆ         | 107520/1000000 [1:13:00<7:17:38, 33.99steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_107520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                11%|â–ˆ         | 107520/1000000 [1:17:14<7:17:38, 33.99steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -193     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -193     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0297   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.613    |
|    max_target_q      | -5.65    |
|    min_target_q      | -12.8    |
|    max_reward        | -0.532   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 1.16     |
|    q1_grad_norm      | 0.94     |
|    q2_grad_norm      | 0.903    |
|    actor_loss        | 8.87     |
|    ent_coeff         | 0.0471   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0618   |
|    n_updates         | 3120     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -192     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -192     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 42       |
|    fps               | 16.5     |
|    elapsed_time      | 4.63e+03 |
|    elapsed_steps     | 107520   |
-----------------------------------
 11%|â–ˆ         | 110080/1000000 [1:18:22<14:50:20, 16.66steps/s] 11%|â–ˆâ–        | 112640/1000000 [1:19:30<12:19:05, 20.01steps/s] 11%|â–ˆâ–        | 112640/1000000 [1:19:50<12:19:05, 20.01steps/s] 12%|â–ˆâ–        | 115200/1000000 [1:20:35<10:27:04, 23.52steps/s]                                                                 12%|â–ˆâ–        | 115200/1000000 [1:20:35<10:27:04, 23.52steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -191     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -191     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0348   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.608    |
|    max_target_q      | -5.91    |
|    min_target_q      | -13.6    |
|    max_reward        | -0.506   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 1.47     |
|    q1_grad_norm      | 1.2      |
|    q2_grad_norm      | 1.16     |
|    actor_loss        | 9.42     |
|    ent_coeff         | 0.0469   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0643   |
|    n_updates         | 3360     |
| time/                |          |
|    iterations        | 45       |
|    fps               | 38.2     |
|    elapsed_time      | 4.84e+03 |
|    elapsed_steps     | 115200   |
-----------------------------------
 12%|â–ˆâ–        | 115200/1000000 [1:20:50<10:27:04, 23.52steps/s] 12%|â–ˆâ–        | 117760/1000000 [1:21:39<9:08:16, 26.82steps/s]  12%|â–ˆâ–        | 117760/1000000 [1:21:50<9:08:16, 26.82steps/s] 12%|â–ˆâ–        | 120320/1000000 [1:22:43<8:13:26, 29.71steps/s] 12%|â–ˆâ–        | 120320/1000000 [1:23:00<8:13:26, 29.71steps/s] 12%|â–ˆâ–        | 122880/1000000 [1:23:48<7:35:40, 32.08steps/s]                                                                12%|â–ˆâ–        | 122880/1000000 [1:23:48<7:35:40, 32.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -191     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -191     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0373   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.605    |
|    max_target_q      | -6.21    |
|    min_target_q      | -14.4    |
|    max_reward        | -0.524   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 1.55     |
|    q1_grad_norm      | 1.29     |
|    q2_grad_norm      | 1.23     |
|    actor_loss        | 9.95     |
|    ent_coeff         | 0.0467   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0648   |
|    n_updates         | 3600     |
| time/                |          |
|    iterations        | 48       |
|    fps               | 39.7     |
|    elapsed_time      | 5.03e+03 |
|    elapsed_steps     | 122880   |
-----------------------------------
 12%|â–ˆâ–        | 122880/1000000 [1:24:00<7:35:40, 32.08steps/s] 13%|â–ˆâ–Ž        | 125440/1000000 [1:24:52<7:07:22, 34.11steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 13%|â–ˆâ–Ž        | 125440/1000000 [1:25:10<7:07:22, 34.11steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_125440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 13%|â–ˆâ–Ž        | 128000/1000000 [1:30:26<14:27:05, 16.76steps/s] 13%|â–ˆâ–Ž        | 130560/1000000 [1:31:27<11:49:03, 20.44steps/s]                                                                 13%|â–ˆâ–Ž        | 130560/1000000 [1:31:27<11:49:03, 20.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -190     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -190     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0417   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.602    |
|    max_target_q      | -6.47    |
|    min_target_q      | -15.1    |
|    max_reward        | -0.49    |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 1.71     |
|    q1_grad_norm      | 1.39     |
|    q2_grad_norm      | 1.34     |
|    actor_loss        | 10.5     |
|    ent_coeff         | 0.0464   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.064    |
|    n_updates         | 3840     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -191     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -191     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 51       |
|    fps               | 16.7     |
|    elapsed_time      | 5.49e+03 |
|    elapsed_steps     | 130560   |
-----------------------------------
 13%|â–ˆâ–Ž        | 130560/1000000 [1:31:40<11:49:03, 20.44steps/s] 13%|â–ˆâ–Ž        | 133120/1000000 [1:32:31<10:03:01, 23.96steps/s] 13%|â–ˆâ–Ž        | 133120/1000000 [1:32:50<10:03:01, 23.96steps/s] 14%|â–ˆâ–Ž        | 135680/1000000 [1:33:34<8:47:21, 27.32steps/s]  14%|â–ˆâ–Ž        | 135680/1000000 [1:33:50<8:47:21, 27.32steps/s] 14%|â–ˆâ–        | 138240/1000000 [1:34:43<8:03:50, 29.68steps/s]                                                                14%|â–ˆâ–        | 138240/1000000 [1:34:43<8:03:50, 29.68steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -187     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -187     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0441   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.599    |
|    max_target_q      | -6.72    |
|    min_target_q      | -15.8    |
|    max_reward        | -0.505   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 1.7      |
|    q1_grad_norm      | 1.37     |
|    q2_grad_norm      | 1.32     |
|    actor_loss        | 11       |
|    ent_coeff         | 0.0462   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0646   |
|    n_updates         | 4080     |
| time/                |          |
|    iterations        | 54       |
|    fps               | 39.2     |
|    elapsed_time      | 5.68e+03 |
|    elapsed_steps     | 138240   |
-----------------------------------
 14%|â–ˆâ–        | 138240/1000000 [1:35:00<8:03:50, 29.68steps/s] 14%|â–ˆâ–        | 140800/1000000 [1:35:50<7:30:18, 31.80steps/s] 14%|â–ˆâ–        | 140800/1000000 [1:36:10<7:30:18, 31.80steps/s] 14%|â–ˆâ–        | 143360/1000000 [1:36:56<7:03:35, 33.71steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 14%|â–ˆâ–        | 143360/1000000 [1:37:10<7:03:35, 33.71steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_143360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 15%|â–ˆâ–        | 145920/1000000 [1:42:16<13:49:49, 17.15steps/s]                                                                 15%|â–ˆâ–        | 145920/1000000 [1:42:16<13:49:49, 17.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -185     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -185     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0492   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.596    |
|    max_target_q      | -7.03    |
|    min_target_q      | -16.6    |
|    max_reward        | -0.489   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 1.92     |
|    q1_grad_norm      | 1.55     |
|    q2_grad_norm      | 1.48     |
|    actor_loss        | 11.5     |
|    ent_coeff         | 0.046    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0636   |
|    n_updates         | 4320     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -188     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -188     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 57       |
|    fps               | 17       |
|    elapsed_time      | 6.14e+03 |
|    elapsed_steps     | 145920   |
-----------------------------------
 15%|â–ˆâ–        | 148480/1000000 [1:43:25<11:34:44, 20.43steps/s] 15%|â–ˆâ–        | 148480/1000000 [1:43:40<11:34:44, 20.43steps/s] 15%|â–ˆâ–Œ        | 151040/1000000 [1:44:32<9:55:31, 23.76steps/s]  15%|â–ˆâ–Œ        | 151040/1000000 [1:44:50<9:55:31, 23.76steps/s] 15%|â–ˆâ–Œ        | 153600/1000000 [1:45:41<8:49:13, 26.66steps/s]                                                                15%|â–ˆâ–Œ        | 153600/1000000 [1:45:41<8:49:13, 26.66steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -180     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -180     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0546   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.594    |
|    max_target_q      | -7.21    |
|    min_target_q      | -17.3    |
|    max_reward        | -0.47    |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 2.12     |
|    q1_grad_norm      | 1.75     |
|    q2_grad_norm      | 1.68     |
|    actor_loss        | 11.9     |
|    ent_coeff         | 0.0458   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0622   |
|    n_updates         | 4560     |
| time/                |          |
|    iterations        | 60       |
|    fps               | 37.5     |
|    elapsed_time      | 6.34e+03 |
|    elapsed_steps     | 153600   |
-----------------------------------
 15%|â–ˆâ–Œ        | 153600/1000000 [1:46:00<8:49:13, 26.66steps/s] 16%|â–ˆâ–Œ        | 156160/1000000 [1:46:47<7:58:50, 29.37steps/s] 16%|â–ˆâ–Œ        | 156160/1000000 [1:47:00<7:58:50, 29.37steps/s] 16%|â–ˆâ–Œ        | 158720/1000000 [1:47:54<7:23:52, 31.59steps/s] 16%|â–ˆâ–Œ        | 158720/1000000 [1:48:10<7:23:52, 31.59steps/s] 16%|â–ˆâ–Œ        | 161280/1000000 [1:49:00<6:57:35, 33.47steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_161280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 16%|â–ˆâ–Œ        | 161280/1000000 [1:49:20<6:57:35, 33.47steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                16%|â–ˆâ–Œ        | 161280/1000000 [1:53:19<6:57:35, 33.47steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -181     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -181     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0587   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.591    |
|    max_target_q      | -7.62    |
|    min_target_q      | -18      |
|    max_reward        | -0.464   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 2.22     |
|    q1_grad_norm      | 1.78     |
|    q2_grad_norm      | 1.71     |
|    actor_loss        | 12.4     |
|    ent_coeff         | 0.0455   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0614   |
|    n_updates         | 4800     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -181     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -181     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 63       |
|    fps               | 16.7     |
|    elapsed_time      | 6.8e+03  |
|    elapsed_steps     | 161280   |
-----------------------------------
 16%|â–ˆâ–‹        | 163840/1000000 [1:54:20<13:34:57, 17.10steps/s] 17%|â–ˆâ–‹        | 166400/1000000 [1:55:26<11:15:28, 20.57steps/s] 17%|â–ˆâ–‹        | 166400/1000000 [1:55:40<11:15:28, 20.57steps/s] 17%|â–ˆâ–‹        | 168960/1000000 [1:56:36<9:45:03, 23.67steps/s]                                                                 17%|â–ˆâ–‹        | 168960/1000000 [1:56:36<9:45:03, 23.67steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -179     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -179     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0617   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.586    |
|    max_target_q      | -7.94    |
|    min_target_q      | -18.7    |
|    max_reward        | -0.46    |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 2.21     |
|    q1_grad_norm      | 1.78     |
|    q2_grad_norm      | 1.7      |
|    actor_loss        | 12.9     |
|    ent_coeff         | 0.0453   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0614   |
|    n_updates         | 5040     |
| time/                |          |
|    iterations        | 66       |
|    fps               | 39.1     |
|    elapsed_time      | 7e+03    |
|    elapsed_steps     | 168960   |
-----------------------------------
 17%|â–ˆâ–‹        | 168960/1000000 [1:56:50<9:45:03, 23.67steps/s] 17%|â–ˆâ–‹        | 171520/1000000 [1:57:46<8:41:08, 26.50steps/s] 17%|â–ˆâ–‹        | 171520/1000000 [1:58:00<8:41:08, 26.50steps/s] 17%|â–ˆâ–‹        | 174080/1000000 [1:58:51<7:48:43, 29.37steps/s] 17%|â–ˆâ–‹        | 174080/1000000 [1:59:10<7:48:43, 29.37steps/s] 18%|â–ˆâ–Š        | 176640/1000000 [2:00:01<7:19:52, 31.20steps/s]                                                                18%|â–ˆâ–Š        | 176640/1000000 [2:00:01<7:19:52, 31.20steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -178     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -178     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0649   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.58     |
|    max_target_q      | -8.29    |
|    min_target_q      | -19.4    |
|    max_reward        | -0.456   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 2.15     |
|    q1_grad_norm      | 1.67     |
|    q2_grad_norm      | 1.6      |
|    actor_loss        | 13.3     |
|    ent_coeff         | 0.0451   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0613   |
|    n_updates         | 5280     |
| time/                |          |
|    iterations        | 69       |
|    fps               | 37.5     |
|    elapsed_time      | 7.2e+03  |
|    elapsed_steps     | 176640   |
-----------------------------------
 18%|â–ˆâ–Š        | 176640/1000000 [2:00:20<7:19:52, 31.20steps/s] 18%|â–ˆâ–Š        | 179200/1000000 [2:01:12<7:01:28, 32.46steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_179200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 18%|â–ˆâ–Š        | 179200/1000000 [2:01:30<7:01:28, 32.46steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 18%|â–ˆâ–Š        | 181760/1000000 [2:06:44<13:43:55, 16.55steps/s] 18%|â–ˆâ–Š        | 184320/1000000 [2:07:50<11:20:42, 19.97steps/s]                                                                 18%|â–ˆâ–Š        | 184320/1000000 [2:07:50<11:20:42, 19.97steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -171     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -171     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.071    |
|    mean_entropy      | 12.8     |
|    mean_ent_bonus    | 0.574    |
|    max_target_q      | -8.35    |
|    min_target_q      | -20.1    |
|    max_reward        | -0.436   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 2.43     |
|    q1_grad_norm      | 1.9      |
|    q2_grad_norm      | 1.83     |
|    actor_loss        | 13.7     |
|    ent_coeff         | 0.0449   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0625   |
|    n_updates         | 5520     |
| eval/                |          |
|    Length            | 199      |
|    Return            | -172     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -172     |
|    Success           | 0.0556   |
|    SuccessLength     | 199      |
| time/                |          |
|    iterations        | 72       |
|    fps               | 16.4     |
|    elapsed_time      | 7.67e+03 |
|    elapsed_steps     | 184320   |
-----------------------------------
 18%|â–ˆâ–Š        | 184320/1000000 [2:08:10<11:20:42, 19.97steps/s] 19%|â–ˆâ–Š        | 186880/1000000 [2:08:58<9:41:55, 23.29steps/s]  19%|â–ˆâ–Š        | 186880/1000000 [2:09:10<9:41:55, 23.29steps/s] 19%|â–ˆâ–‰        | 189440/1000000 [2:10:02<8:27:25, 26.62steps/s] 19%|â–ˆâ–‰        | 189440/1000000 [2:10:20<8:27:25, 26.62steps/s] 19%|â–ˆâ–‰        | 192000/1000000 [2:11:08<7:38:37, 29.36steps/s]                                                                19%|â–ˆâ–‰        | 192000/1000000 [2:11:08<7:38:37, 29.36steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -171     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -171     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0756   |
|    mean_entropy      | 12.7     |
|    mean_ent_bonus    | 0.568    |
|    max_target_q      | -8.75    |
|    min_target_q      | -20.8    |
|    max_reward        | -0.436   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 2.4      |
|    q1_grad_norm      | 1.87     |
|    q2_grad_norm      | 1.79     |
|    actor_loss        | 14       |
|    ent_coeff         | 0.0447   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0627   |
|    n_updates         | 5760     |
| time/                |          |
|    iterations        | 75       |
|    fps               | 38.9     |
|    elapsed_time      | 7.87e+03 |
|    elapsed_steps     | 192000   |
-----------------------------------
 19%|â–ˆâ–‰        | 192000/1000000 [2:11:20<7:38:37, 29.36steps/s] 19%|â–ˆâ–‰        | 194560/1000000 [2:12:15<7:05:45, 31.53steps/s] 19%|â–ˆâ–‰        | 194560/1000000 [2:12:30<7:05:45, 31.53steps/s] 20%|â–ˆâ–‰        | 197120/1000000 [2:13:21<6:40:08, 33.44steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_197120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 20%|â–ˆâ–‰        | 197120/1000000 [2:13:40<6:40:08, 33.44steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 20%|â–ˆâ–‰        | 199680/1000000 [2:18:51<13:15:24, 16.77steps/s]                                                                 20%|â–ˆâ–‰        | 199680/1000000 [2:18:51<13:15:24, 16.77steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -167     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -167     |
|    Success           | 0.0625   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.0811   |
|    mean_entropy      | 12.6     |
|    mean_ent_bonus    | 0.561    |
|    max_target_q      | -8.88    |
|    min_target_q      | -21.5    |
|    max_reward        | -0.4     |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 2.56     |
|    q1_grad_norm      | 1.95     |
|    q2_grad_norm      | 1.87     |
|    actor_loss        | 14.4     |
|    ent_coeff         | 0.0445   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0643   |
|    n_updates         | 6000     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -164     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -164     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 78       |
|    fps               | 16.6     |
|    elapsed_time      | 8.33e+03 |
|    elapsed_steps     | 199680   |
-----------------------------------
 20%|â–ˆâ–ˆ        | 202240/1000000 [2:19:58<10:59:28, 20.16steps/s] 20%|â–ˆâ–ˆ        | 202240/1000000 [2:20:10<10:59:28, 20.16steps/s] 20%|â–ˆâ–ˆ        | 204800/1000000 [2:21:04<9:22:29, 23.56steps/s]  20%|â–ˆâ–ˆ        | 204800/1000000 [2:21:20<9:22:29, 23.56steps/s] 21%|â–ˆâ–ˆ        | 207360/1000000 [2:22:11<8:16:36, 26.60steps/s]                                                                21%|â–ˆâ–ˆ        | 207360/1000000 [2:22:11<8:16:36, 26.60steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -173     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -173     |
|    Success           | 0.05     |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.0864   |
|    mean_entropy      | 12.6     |
|    mean_ent_bonus    | 0.556    |
|    max_target_q      | -9.11    |
|    min_target_q      | -22.2    |
|    max_reward        | -0.389   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 2.84     |
|    q1_grad_norm      | 2.26     |
|    q2_grad_norm      | 2.17     |
|    actor_loss        | 14.7     |
|    ent_coeff         | 0.0443   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0648   |
|    n_updates         | 6240     |
| time/                |          |
|    iterations        | 81       |
|    fps               | 38.4     |
|    elapsed_time      | 8.53e+03 |
|    elapsed_steps     | 207360   |
-----------------------------------
 21%|â–ˆâ–ˆ        | 207360/1000000 [2:22:30<8:16:36, 26.60steps/s] 21%|â–ˆâ–ˆ        | 209920/1000000 [2:23:19<7:31:02, 29.19steps/s] 21%|â–ˆâ–ˆ        | 209920/1000000 [2:23:30<7:31:02, 29.19steps/s] 21%|â–ˆâ–ˆ        | 212480/1000000 [2:24:29<7:01:31, 31.14steps/s] 21%|â–ˆâ–ˆ        | 212480/1000000 [2:24:40<7:01:31, 31.14steps/s] 22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:25:41<6:44:46, 32.32steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:26:00<6:44:46, 32.32steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_215040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:30:09<6:44:46, 32.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -170     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -170     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.0899   |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.55     |
|    max_target_q      | -9.26    |
|    min_target_q      | -22.8    |
|    max_reward        | -0.371   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 2.77     |
|    q1_grad_norm      | 2.17     |
|    q2_grad_norm      | 2.09     |
|    actor_loss        | 15.1     |
|    ent_coeff         | 0.0441   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0657   |
|    n_updates         | 6480     |
| eval/                |          |
|    Length            | 195      |
|    Return            | -158     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -158     |
|    Success           | 0.0556   |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 84       |
|    fps               | 16.1     |
|    elapsed_time      | 9.01e+03 |
|    elapsed_steps     | 215040   |
-----------------------------------
 22%|â–ˆâ–ˆâ–       | 217600/1000000 [2:31:12<13:09:07, 16.52steps/s] 22%|â–ˆâ–ˆâ–       | 220160/1000000 [2:32:21<10:55:53, 19.82steps/s] 22%|â–ˆâ–ˆâ–       | 220160/1000000 [2:32:40<10:55:53, 19.82steps/s] 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:33:38<9:33:04, 22.61steps/s]                                                                 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:33:38<9:33:04, 22.61steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -170     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -170     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0978   |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.544    |
|    max_target_q      | -9.41    |
|    min_target_q      | -23.5    |
|    max_reward        | -0.375   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 3.28     |
|    q1_grad_norm      | 2.58     |
|    q2_grad_norm      | 2.47     |
|    actor_loss        | 15.4     |
|    ent_coeff         | 0.0438   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0657   |
|    n_updates         | 6720     |
| time/                |          |
|    iterations        | 87       |
|    fps               | 36.9     |
|    elapsed_time      | 9.22e+03 |
|    elapsed_steps     | 222720   |
-----------------------------------
 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:33:50<9:33:04, 22.61steps/s] 23%|â–ˆâ–ˆâ–Ž       | 225280/1000000 [2:34:53<8:34:13, 25.11steps/s] 23%|â–ˆâ–ˆâ–Ž       | 225280/1000000 [2:35:10<8:34:13, 25.11steps/s] 23%|â–ˆâ–ˆâ–Ž       | 227840/1000000 [2:36:06<7:49:03, 27.44steps/s] 23%|â–ˆâ–ˆâ–Ž       | 227840/1000000 [2:36:20<7:49:03, 27.44steps/s] 23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:37:24<7:23:21, 28.93steps/s]                                                                23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:37:24<7:23:21, 28.93steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -167     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -167     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.103    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.54     |
|    max_target_q      | -9.65    |
|    min_target_q      | -24.3    |
|    max_reward        | -0.362   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 3.1      |
|    q1_grad_norm      | 2.4      |
|    q2_grad_norm      | 2.3      |
|    actor_loss        | 15.7     |
|    ent_coeff         | 0.0436   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.067    |
|    n_updates         | 6960     |
| time/                |          |
|    iterations        | 90       |
|    fps               | 34       |
|    elapsed_time      | 9.44e+03 |
|    elapsed_steps     | 230400   |
-----------------------------------
 23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:37:40<7:23:21, 28.93steps/s] 23%|â–ˆâ–ˆâ–Ž       | 232960/1000000 [2:38:38<7:01:32, 30.33steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 23%|â–ˆâ–ˆâ–Ž       | 232960/1000000 [2:38:50<7:01:32, 30.33steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_232960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 24%|â–ˆâ–ˆâ–Ž       | 235520/1000000 [2:44:30<13:39:12, 15.55steps/s] 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:45:37<11:11:47, 18.90steps/s]                                                                 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:45:37<11:11:47, 18.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -169     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -169     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.107    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.535    |
|    max_target_q      | -9.86    |
|    min_target_q      | -24.9    |
|    max_reward        | -0.374   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 2.86     |
|    q1_grad_norm      | 2.13     |
|    q2_grad_norm      | 2.04     |
|    actor_loss        | 16       |
|    ent_coeff         | 0.0434   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.067    |
|    n_updates         | 7200     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -171     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -171     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 93       |
|    fps               | 15.5     |
|    elapsed_time      | 9.94e+03 |
|    elapsed_steps     | 238080   |
-----------------------------------
 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:45:50<11:11:47, 18.90steps/s] 24%|â–ˆâ–ˆâ–       | 240640/1000000 [2:46:50<9:35:39, 21.99steps/s]  24%|â–ˆâ–ˆâ–       | 240640/1000000 [2:47:00<9:35:39, 21.99steps/s] 24%|â–ˆâ–ˆâ–       | 243200/1000000 [2:48:00<8:24:59, 24.98steps/s] 24%|â–ˆâ–ˆâ–       | 243200/1000000 [2:48:10<8:24:59, 24.98steps/s] 25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:49:09<7:34:28, 27.66steps/s]                                                                25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:49:09<7:34:28, 27.66steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -163     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -163     |
|    Success           | 0.122    |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.118    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.532    |
|    max_target_q      | -10      |
|    min_target_q      | -25.6    |
|    max_reward        | -0.35    |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 3.28     |
|    q1_grad_norm      | 2.47     |
|    q2_grad_norm      | 2.38     |
|    actor_loss        | 16.3     |
|    ent_coeff         | 0.0432   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0676   |
|    n_updates         | 7440     |
| time/                |          |
|    iterations        | 96       |
|    fps               | 36.3     |
|    elapsed_time      | 1.01e+04 |
|    elapsed_steps     | 245760   |
-----------------------------------
 25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:49:20<7:34:28, 27.66steps/s] 25%|â–ˆâ–ˆâ–       | 248320/1000000 [2:50:22<7:03:41, 29.57steps/s] 25%|â–ˆâ–ˆâ–       | 248320/1000000 [2:50:40<7:03:41, 29.57steps/s] 25%|â–ˆâ–ˆâ–Œ       | 250880/1000000 [2:51:35<6:42:29, 31.02steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 25%|â–ˆâ–ˆâ–Œ       | 250880/1000000 [2:51:50<6:42:29, 31.02steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_250880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 25%|â–ˆâ–ˆâ–Œ       | 253440/1000000 [2:57:18<13:01:50, 15.91steps/s]                                                                 25%|â–ˆâ–ˆâ–Œ       | 253440/1000000 [2:57:18<13:01:50, 15.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -166     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -166     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.118    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.528    |
|    max_target_q      | -10.2    |
|    min_target_q      | -26.2    |
|    max_reward        | -0.351   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 3.44     |
|    q1_grad_norm      | 2.67     |
|    q2_grad_norm      | 2.56     |
|    actor_loss        | 16.5     |
|    ent_coeff         | 0.043    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0674   |
|    n_updates         | 7680     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -169     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -169     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 99       |
|    fps               | 15.7     |
|    elapsed_time      | 1.06e+04 |
|    elapsed_steps     | 253440   |
-----------------------------------
 26%|â–ˆâ–ˆâ–Œ       | 256000/1000000 [2:58:25<10:42:19, 19.31steps/s] 26%|â–ˆâ–ˆâ–Œ       | 256000/1000000 [2:58:40<10:42:19, 19.31steps/s] 26%|â–ˆâ–ˆâ–Œ       | 258560/1000000 [2:59:36<9:10:45, 22.44steps/s]  26%|â–ˆâ–ˆâ–Œ       | 258560/1000000 [2:59:50<9:10:45, 22.44steps/s] 26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:00:45<8:03:39, 25.46steps/s]                                                                26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:00:45<8:03:39, 25.46steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -161     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -161     |
|    Success           | 0.0263   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.126    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.523    |
|    max_target_q      | -10.3    |
|    min_target_q      | -26.9    |
|    max_reward        | -0.336   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 3.54     |
|    q1_grad_norm      | 2.73     |
|    q2_grad_norm      | 2.62     |
|    actor_loss        | 16.8     |
|    ent_coeff         | 0.0428   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0685   |
|    n_updates         | 7920     |
| time/                |          |
|    iterations        | 102      |
|    fps               | 37.2     |
|    elapsed_time      | 1.08e+04 |
|    elapsed_steps     | 261120   |
-----------------------------------
 26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:01:00<8:03:39, 25.46steps/s] 26%|â–ˆâ–ˆâ–‹       | 263680/1000000 [3:01:49<7:09:39, 28.56steps/s] 26%|â–ˆâ–ˆâ–‹       | 263680/1000000 [3:02:00<7:09:39, 28.56steps/s] 27%|â–ˆâ–ˆâ–‹       | 266240/1000000 [3:02:57<6:37:17, 30.78steps/s] 27%|â–ˆâ–ˆâ–‹       | 266240/1000000 [3:03:10<6:37:17, 30.78steps/s] 27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:04:09<6:20:05, 32.06steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:04:20<6:20:05, 32.06steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_268800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:08:49<6:20:05, 32.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -163     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -163     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.13     |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.519    |
|    max_target_q      | -10.5    |
|    min_target_q      | -27.5    |
|    max_reward        | -0.315   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 3.09     |
|    q1_grad_norm      | 2.14     |
|    q2_grad_norm      | 2.08     |
|    actor_loss        | 17.1     |
|    ent_coeff         | 0.0426   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0683   |
|    n_updates         | 8160     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0.0556   |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 105      |
|    fps               | 15.9     |
|    elapsed_time      | 1.13e+04 |
|    elapsed_steps     | 268800   |
-----------------------------------
 27%|â–ˆâ–ˆâ–‹       | 271360/1000000 [3:09:55<12:37:07, 16.04steps/s] 27%|â–ˆâ–ˆâ–‹       | 273920/1000000 [3:11:02<10:23:26, 19.41steps/s] 27%|â–ˆâ–ˆâ–‹       | 273920/1000000 [3:11:20<10:23:26, 19.41steps/s] 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:12:13<8:54:29, 22.56steps/s]                                                                 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:12:13<8:54:29, 22.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.134    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.514    |
|    max_target_q      | -10.6    |
|    min_target_q      | -28.1    |
|    max_reward        | -0.329   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 3.89     |
|    q1_grad_norm      | 3.05     |
|    q2_grad_norm      | 2.92     |
|    actor_loss        | 17.4     |
|    ent_coeff         | 0.0424   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0681   |
|    n_updates         | 8400     |
| time/                |          |
|    iterations        | 108      |
|    fps               | 37.7     |
|    elapsed_time      | 1.15e+04 |
|    elapsed_steps     | 276480   |
-----------------------------------
 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:12:30<8:54:29, 22.56steps/s] 28%|â–ˆâ–ˆâ–Š       | 279040/1000000 [3:13:23<7:52:05, 25.45steps/s] 28%|â–ˆâ–ˆâ–Š       | 279040/1000000 [3:13:40<7:52:05, 25.45steps/s] 28%|â–ˆâ–ˆâ–Š       | 281600/1000000 [3:14:36<7:11:18, 27.76steps/s] 28%|â–ˆâ–ˆâ–Š       | 281600/1000000 [3:14:50<7:11:18, 27.76steps/s] 28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:15:49<6:43:50, 29.54steps/s]                                                                28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:15:49<6:43:50, 29.54steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -159     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -159     |
|    Success           | 0.05     |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.143    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.508    |
|    max_target_q      | -10.8    |
|    min_target_q      | -28.7    |
|    max_reward        | -0.319   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 3.58     |
|    q1_grad_norm      | 2.67     |
|    q2_grad_norm      | 2.56     |
|    actor_loss        | 17.6     |
|    ent_coeff         | 0.0422   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.069    |
|    n_updates         | 8640     |
| time/                |          |
|    iterations        | 111      |
|    fps               | 35.4     |
|    elapsed_time      | 1.17e+04 |
|    elapsed_steps     | 284160   |
-----------------------------------
 28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:16:00<6:43:50, 29.54steps/s] 29%|â–ˆâ–ˆâ–Š       | 286720/1000000 [3:16:59<6:17:59, 31.45steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 29%|â–ˆâ–ˆâ–Š       | 286720/1000000 [3:17:10<6:17:59, 31.45steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_286720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 29%|â–ˆâ–ˆâ–‰       | 289280/1000000 [3:22:40<12:17:47, 16.06steps/s] 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:23:47<10:07:32, 19.43steps/s]                                                                 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:23:47<10:07:32, 19.43steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -163     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -163     |
|    Success           | 0.027    |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.14     |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.505    |
|    max_target_q      | -10.8    |
|    min_target_q      | -29.4    |
|    max_reward        | -0.308   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 3.55     |
|    q1_grad_norm      | 2.66     |
|    q2_grad_norm      | 2.56     |
|    actor_loss        | 17.8     |
|    ent_coeff         | 0.042    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.069    |
|    n_updates         | 8880     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -167     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -167     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 114      |
|    fps               | 16.1     |
|    elapsed_time      | 1.22e+04 |
|    elapsed_steps     | 291840   |
-----------------------------------
 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:24:00<10:07:32, 19.43steps/s] 29%|â–ˆâ–ˆâ–‰       | 294400/1000000 [3:25:03<8:47:42, 22.29steps/s]  29%|â–ˆâ–ˆâ–‰       | 294400/1000000 [3:25:20<8:47:42, 22.29steps/s] 30%|â–ˆâ–ˆâ–‰       | 296960/1000000 [3:26:17<7:50:32, 24.90steps/s] 30%|â–ˆâ–ˆâ–‰       | 296960/1000000 [3:26:30<7:50:32, 24.90steps/s] 30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:27:35<7:13:59, 26.90steps/s]                                                                30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:27:35<7:13:59, 26.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -164     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -164     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.142    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.5      |
|    max_target_q      | -10.9    |
|    min_target_q      | -29.9    |
|    max_reward        | -0.316   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 3.66     |
|    q1_grad_norm      | 2.69     |
|    q2_grad_norm      | 2.58     |
|    actor_loss        | 18.1     |
|    ent_coeff         | 0.0418   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0712   |
|    n_updates         | 9120     |
| time/                |          |
|    iterations        | 117      |
|    fps               | 33.8     |
|    elapsed_time      | 1.25e+04 |
|    elapsed_steps     | 299520   |
-----------------------------------
 30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:27:50<7:13:59, 26.90steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 302080/1000000 [3:28:47<6:41:44, 28.95steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 302080/1000000 [3:29:00<6:41:44, 28.95steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 304640/1000000 [3:29:57<6:14:41, 30.93steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 30%|â–ˆâ–ˆâ–ˆ       | 304640/1000000 [3:30:10<6:14:41, 30.93steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_304640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 31%|â–ˆâ–ˆâ–ˆ       | 307200/1000000 [3:35:51<12:20:23, 15.60steps/s]                                                                 31%|â–ˆâ–ˆâ–ˆ       | 307200/1000000 [3:35:51<12:20:23, 15.60steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -157     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -157     |
|    Success           | 0.1      |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.153    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.496    |
|    max_target_q      | -11      |
|    min_target_q      | -30.6    |
|    max_reward        | -0.315   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 3.24     |
|    q1_grad_norm      | 2.24     |
|    q2_grad_norm      | 2.16     |
|    actor_loss        | 18.3     |
|    ent_coeff         | 0.0416   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0712   |
|    n_updates         | 9360     |
| eval/                |          |
|    Length            | 189      |
|    Return            | -150     |
|    NonzeroRewards    | 189      |
|    DiscountedReturn  | -150     |
|    Success           | 0.167    |
|    SuccessLength     | 189      |
| time/                |          |
|    iterations        | 120      |
|    fps               | 15.5     |
|    elapsed_time      | 1.3e+04  |
|    elapsed_steps     | 307200   |
-----------------------------------
 31%|â–ˆâ–ˆâ–ˆ       | 309760/1000000 [3:37:03<10:13:41, 18.75steps/s] 31%|â–ˆâ–ˆâ–ˆ       | 309760/1000000 [3:37:20<10:13:41, 18.75steps/s] 31%|â–ˆâ–ˆâ–ˆ       | 312320/1000000 [3:38:20<8:51:33, 21.56steps/s]  31%|â–ˆâ–ˆâ–ˆ       | 312320/1000000 [3:38:40<8:51:33, 21.56steps/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:40<7:56:41, 23.95steps/s]                                                                31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:40<7:56:41, 23.95steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -151     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -151     |
|    Success           | 0.146    |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.17     |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.49     |
|    max_target_q      | -11.1    |
|    min_target_q      | -31.1    |
|    max_reward        | -0.311   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 4.1      |
|    q1_grad_norm      | 3.01     |
|    q2_grad_norm      | 2.91     |
|    actor_loss        | 18.5     |
|    ent_coeff         | 0.0414   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0717   |
|    n_updates         | 9600     |
| time/                |          |
|    iterations        | 123      |
|    fps               | 33.6     |
|    elapsed_time      | 1.32e+04 |
|    elapsed_steps     | 314880   |
-----------------------------------
 31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:50<7:56:41, 23.95steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317440/1000000 [3:40:55<7:12:29, 26.30steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317440/1000000 [3:41:10<7:12:29, 26.30steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320000/1000000 [3:42:13<6:45:15, 27.97steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320000/1000000 [3:42:30<6:45:15, 27.97steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:43:27<6:20:25, 29.68steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:43:40<6:20:25, 29.68steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_322560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:48:01<6:20:25, 29.68steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.171    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.485    |
|    max_target_q      | -11.1    |
|    min_target_q      | -31.7    |
|    max_reward        | -0.305   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 4.21     |
|    q1_grad_norm      | 3.15     |
|    q2_grad_norm      | 3.03     |
|    actor_loss        | 18.7     |
|    ent_coeff         | 0.0412   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0723   |
|    n_updates         | 9840     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 126      |
|    fps               | 15.3     |
|    elapsed_time      | 1.37e+04 |
|    elapsed_steps     | 322560   |
-----------------------------------
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 325120/1000000 [3:49:07<11:54:19, 15.75steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327680/1000000 [3:50:18<9:51:03, 18.96steps/s]  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327680/1000000 [3:50:30<9:51:03, 18.96steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:31<8:27:19, 22.00steps/s]                                                                33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:31<8:27:19, 22.00steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -155     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0526   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.189    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.48     |
|    max_target_q      | -11.3    |
|    min_target_q      | -32.2    |
|    max_reward        | -0.303   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 4.41     |
|    q1_grad_norm      | 3.25     |
|    q2_grad_norm      | 3.13     |
|    actor_loss        | 18.9     |
|    ent_coeff         | 0.041    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0725   |
|    n_updates         | 10080    |
| time/                |          |
|    iterations        | 129      |
|    fps               | 36.7     |
|    elapsed_time      | 1.39e+04 |
|    elapsed_steps     | 330240   |
-----------------------------------
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:50<8:27:19, 22.00steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332800/1000000 [3:52:42<7:27:08, 24.87steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332800/1000000 [3:53:00<7:27:08, 24.87steps/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335360/1000000 [3:53:53<6:43:41, 27.44steps/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335360/1000000 [3:54:10<6:43:41, 27.44steps/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:55:01<6:08:46, 29.92steps/s]                                                                34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:55:01<6:08:46, 29.92steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -164     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -164     |
|    Success           | 0.0263   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.189    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.475    |
|    max_target_q      | -11.4    |
|    min_target_q      | -32.7    |
|    max_reward        | -0.302   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 4.08     |
|    q1_grad_norm      | 2.93     |
|    q2_grad_norm      | 2.82     |
|    actor_loss        | 19.1     |
|    ent_coeff         | 0.0408   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0741   |
|    n_updates         | 10320    |
| time/                |          |
|    iterations        | 132      |
|    fps               | 36.6     |
|    elapsed_time      | 1.41e+04 |
|    elapsed_steps     | 337920   |
-----------------------------------
 34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:55:20<6:08:46, 29.92steps/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 340480/1000000 [3:56:13<5:50:49, 31.33steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_340480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 34%|â–ˆâ–ˆâ–ˆâ–      | 340480/1000000 [3:56:30<5:50:49, 31.33steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 34%|â–ˆâ–ˆâ–ˆâ–      | 343040/1000000 [4:02:04<11:34:44, 15.76steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:03:15<9:35:24, 18.95steps/s]                                                                 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:03:15<9:35:24, 18.95steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -161     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -161     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.19     |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.468    |
|    max_target_q      | -11.5    |
|    min_target_q      | -33.3    |
|    max_reward        | -0.306   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 3.81     |
|    q1_grad_norm      | 2.62     |
|    q2_grad_norm      | 2.53     |
|    actor_loss        | 19.3     |
|    ent_coeff         | 0.0406   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0746   |
|    n_updates         | 10560    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -153     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 135      |
|    fps               | 15.5     |
|    elapsed_time      | 1.46e+04 |
|    elapsed_steps     | 345600   |
-----------------------------------
 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:03:30<9:35:24, 18.95steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348160/1000000 [4:04:34<8:21:24, 21.67steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348160/1000000 [4:04:50<8:21:24, 21.67steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350720/1000000 [4:05:48<7:22:53, 24.43steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350720/1000000 [4:06:00<7:22:53, 24.43steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:06:59<6:38:30, 27.05steps/s]                                                                35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:06:59<6:38:30, 27.05steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -152     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -152     |
|    Success           | 0.0976   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.201    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.465    |
|    max_target_q      | -11.5    |
|    min_target_q      | -33.7    |
|    max_reward        | -0.293   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 4.32     |
|    q1_grad_norm      | 3.03     |
|    q2_grad_norm      | 2.92     |
|    actor_loss        | 19.5     |
|    ent_coeff         | 0.0404   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0756   |
|    n_updates         | 10800    |
| time/                |          |
|    iterations        | 138      |
|    fps               | 34.4     |
|    elapsed_time      | 1.48e+04 |
|    elapsed_steps     | 353280   |
-----------------------------------
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:07:10<6:38:30, 27.05steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355840/1000000 [4:08:06<6:03:06, 29.57steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355840/1000000 [4:08:20<6:03:06, 29.57steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358400/1000000 [4:09:12<5:35:29, 31.87steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_358400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358400/1000000 [4:09:30<5:35:29, 31.87steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360960/1000000 [4:14:41<10:44:29, 16.53steps/s]                                                                 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360960/1000000 [4:14:41<10:44:29, 16.53steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -153     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.196    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.462    |
|    max_target_q      | -11.4    |
|    min_target_q      | -34.2    |
|    max_reward        | -0.28    |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 4.6      |
|    q1_grad_norm      | 3.27     |
|    q2_grad_norm      | 3.16     |
|    actor_loss        | 19.6     |
|    ent_coeff         | 0.0402   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0765   |
|    n_updates         | 11040    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -153     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0556   |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 141      |
|    fps               | 16.6     |
|    elapsed_time      | 1.53e+04 |
|    elapsed_steps     | 360960   |
-----------------------------------
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 363520/1000000 [4:15:52<8:58:04, 19.71steps/s]  36%|â–ˆâ–ˆâ–ˆâ–‹      | 363520/1000000 [4:16:10<8:58:04, 19.71steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366080/1000000 [4:17:07<7:47:55, 22.58steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366080/1000000 [4:17:20<7:47:55, 22.58steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:18:23<6:59:44, 25.07steps/s]                                                                37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:18:23<6:59:44, 25.07steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -158     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -158     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.217    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.458    |
|    max_target_q      | -11.5    |
|    min_target_q      | -34.7    |
|    max_reward        | -0.298   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 4.65     |
|    q1_grad_norm      | 3.3      |
|    q2_grad_norm      | 3.18     |
|    actor_loss        | 19.8     |
|    ent_coeff         | 0.0401   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0773   |
|    n_updates         | 11280    |
| time/                |          |
|    iterations        | 144      |
|    fps               | 34.6     |
|    elapsed_time      | 1.55e+04 |
|    elapsed_steps     | 368640   |
-----------------------------------
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:18:40<6:59:44, 25.07steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371200/1000000 [4:19:37<6:22:58, 27.36steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371200/1000000 [4:19:50<6:22:58, 27.36steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373760/1000000 [4:20:51<5:58:03, 29.15steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373760/1000000 [4:21:10<5:58:03, 29.15steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:21:56<5:28:22, 31.65steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:22:10<5:28:22, 31.65steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_376320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:26:23<5:28:22, 31.65steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.222    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.456    |
|    max_target_q      | -11.4    |
|    min_target_q      | -35.2    |
|    max_reward        | -0.294   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 5.41     |
|    q1_grad_norm      | 4.29     |
|    q2_grad_norm      | 4.12     |
|    actor_loss        | 20       |
|    ent_coeff         | 0.0399   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0765   |
|    n_updates         | 11520    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0556   |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 147      |
|    fps               | 16       |
|    elapsed_time      | 1.6e+04  |
|    elapsed_steps     | 376320   |
-----------------------------------
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 378880/1000000 [4:27:31<10:34:47, 16.31steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 381440/1000000 [4:28:41<8:47:44, 19.53steps/s]  38%|â–ˆâ–ˆâ–ˆâ–Š      | 381440/1000000 [4:29:00<8:47:44, 19.53steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:29:52<7:32:50, 22.67steps/s]                                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:29:52<7:32:50, 22.67steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0.027    |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.231    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.453    |
|    max_target_q      | -11.5    |
|    min_target_q      | -35.6    |
|    max_reward        | -0.286   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.33     |
|    q1_grad_norm      | 2.84     |
|    q2_grad_norm      | 2.74     |
|    actor_loss        | 20.1     |
|    ent_coeff         | 0.0397   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0776   |
|    n_updates         | 11760    |
| time/                |          |
|    iterations        | 150      |
|    fps               | 36.8     |
|    elapsed_time      | 1.62e+04 |
|    elapsed_steps     | 384000   |
-----------------------------------
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:30:10<7:32:50, 22.67steps/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386560/1000000 [4:30:59<6:35:45, 25.83steps/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386560/1000000 [4:31:10<6:35:45, 25.83steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389120/1000000 [4:32:06<5:56:10, 28.58steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389120/1000000 [4:32:20<5:56:10, 28.58steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:33:14<5:28:59, 30.82steps/s]                                                                39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:33:14<5:28:59, 30.82steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -155     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0732   |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.226    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.452    |
|    max_target_q      | -11.6    |
|    min_target_q      | -36      |
|    max_reward        | -0.283   |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 4.58     |
|    q1_grad_norm      | 3.16     |
|    q2_grad_norm      | 3.04     |
|    actor_loss        | 20.3     |
|    ent_coeff         | 0.0395   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0773   |
|    n_updates         | 12000    |
| time/                |          |
|    iterations        | 153      |
|    fps               | 38       |
|    elapsed_time      | 1.64e+04 |
|    elapsed_steps     | 391680   |
-----------------------------------
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:33:30<5:28:59, 30.82steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394240/1000000 [4:34:23<5:11:48, 32.38steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_394240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394240/1000000 [4:34:40<5:11:48, 32.38steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 396800/1000000 [4:40:10<10:25:45, 16.07steps/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:41:16<8:33:07, 19.51steps/s]                                                                 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:41:16<8:33:07, 19.51steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.239    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.446    |
|    max_target_q      | -11.5    |
|    min_target_q      | -36.5    |
|    max_reward        | -0.276   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 4.43     |
|    q1_grad_norm      | 2.94     |
|    q2_grad_norm      | 2.84     |
|    actor_loss        | 20.4     |
|    ent_coeff         | 0.0393   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0788   |
|    n_updates         | 12240    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -151     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0556   |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 156      |
|    fps               | 15.9     |
|    elapsed_time      | 1.69e+04 |
|    elapsed_steps     | 399360   |
-----------------------------------
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:41:30<8:33:07, 19.51steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401920/1000000 [4:42:32<7:26:41, 22.31steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401920/1000000 [4:42:50<7:26:41, 22.31steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404480/1000000 [4:43:43<6:34:03, 25.19steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404480/1000000 [4:44:00<6:34:03, 25.19steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:44:55<5:58:11, 27.59steps/s]                                                                41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:44:55<5:58:11, 27.59steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -158     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -158     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.247    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.443    |
|    max_target_q      | -11.6    |
|    min_target_q      | -37      |
|    max_reward        | -0.278   |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 5.23     |
|    q1_grad_norm      | 3.44     |
|    q2_grad_norm      | 3.32     |
|    actor_loss        | 20.6     |
|    ent_coeff         | 0.0391   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0784   |
|    n_updates         | 12480    |
| time/                |          |
|    iterations        | 159      |
|    fps               | 35       |
|    elapsed_time      | 1.71e+04 |
|    elapsed_steps     | 407040   |
-----------------------------------
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:45:10<5:58:11, 27.59steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409600/1000000 [4:46:04<5:28:37, 29.94steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409600/1000000 [4:46:20<5:28:37, 29.94steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412160/1000000 [4:47:10<5:04:42, 32.15steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412160/1000000 [4:47:20<5:04:42, 32.15steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_412160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414720/1000000 [4:52:51<10:03:10, 16.17steps/s]                                                                 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414720/1000000 [4:52:51<10:03:10, 16.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -155     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -155     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.247    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.44     |
|    max_target_q      | -11.5    |
|    min_target_q      | -37.3    |
|    max_reward        | -0.275   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 4.93     |
|    q1_grad_norm      | 3.29     |
|    q2_grad_norm      | 3.16     |
|    actor_loss        | 20.7     |
|    ent_coeff         | 0.0389   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0788   |
|    n_updates         | 12720    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -153     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -153     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 162      |
|    fps               | 16.1     |
|    elapsed_time      | 1.76e+04 |
|    elapsed_steps     | 414720   |
-----------------------------------
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417280/1000000 [4:53:57<8:14:32, 19.64steps/s]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417280/1000000 [4:54:10<8:14:32, 19.64steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419840/1000000 [4:55:04<7:01:03, 22.96steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419840/1000000 [4:55:20<7:01:03, 22.96steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:56:07<6:04:42, 26.40steps/s]                                                                42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:56:07<6:04:42, 26.40steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.247    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.438    |
|    max_target_q      | -11.5    |
|    min_target_q      | -37.8    |
|    max_reward        | -0.279   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 5.52     |
|    q1_grad_norm      | 4.17     |
|    q2_grad_norm      | 4.02     |
|    actor_loss        | 20.9     |
|    ent_coeff         | 0.0387   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0774   |
|    n_updates         | 12960    |
| time/                |          |
|    iterations        | 165      |
|    fps               | 39.2     |
|    elapsed_time      | 1.78e+04 |
|    elapsed_steps     | 422400   |
-----------------------------------
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:56:20<6:04:42, 26.40steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424960/1000000 [4:57:13<5:28:20, 29.19steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424960/1000000 [4:57:30<5:28:20, 29.19steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427520/1000000 [4:58:20<5:03:36, 31.43steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427520/1000000 [4:58:40<5:03:36, 31.43steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [4:59:27<4:45:26, 33.28steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [4:59:40<4:45:26, 33.28steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_430080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [5:04:14<4:45:26, 33.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -152     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -152     |
|    Success           | 0.05     |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.26     |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.435    |
|    max_target_q      | -11.8    |
|    min_target_q      | -38.2    |
|    max_reward        | -0.273   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 5.35     |
|    q1_grad_norm      | 3.84     |
|    q2_grad_norm      | 3.71     |
|    actor_loss        | 21.1     |
|    ent_coeff         | 0.0386   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0776   |
|    n_updates         | 13200    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 168      |
|    fps               | 15.8     |
|    elapsed_time      | 1.83e+04 |
|    elapsed_steps     | 430080   |
-----------------------------------
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 432640/1000000 [5:05:19<9:49:04, 16.05steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435200/1000000 [5:06:25<8:03:40, 19.46steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435200/1000000 [5:06:40<8:03:40, 19.46steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:07:30<6:48:15, 22.95steps/s]                                                                44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:07:30<6:48:15, 22.95steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.265    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.435    |
|    max_target_q      | -11.7    |
|    min_target_q      | -38.6    |
|    max_reward        | -0.276   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 5.46     |
|    q1_grad_norm      | 3.89     |
|    q2_grad_norm      | 3.75     |
|    actor_loss        | 21.2     |
|    ent_coeff         | 0.0384   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0781   |
|    n_updates         | 13440    |
| time/                |          |
|    iterations        | 171      |
|    fps               | 39.3     |
|    elapsed_time      | 1.85e+04 |
|    elapsed_steps     | 437760   |
-----------------------------------
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:07:40<6:48:15, 22.95steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440320/1000000 [5:08:41<6:01:54, 25.77steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440320/1000000 [5:09:00<6:01:54, 25.77steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442880/1000000 [5:09:49<5:26:35, 28.43steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442880/1000000 [5:10:00<5:26:35, 28.43steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:10:56<4:59:45, 30.83steps/s]                                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:10:56<4:59:45, 30.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -148     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0976   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.3      |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.432    |
|    max_target_q      | -11.8    |
|    min_target_q      | -39      |
|    max_reward        | -0.277   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 5.66     |
|    q1_grad_norm      | 3.67     |
|    q2_grad_norm      | 3.54     |
|    actor_loss        | 21.4     |
|    ent_coeff         | 0.0382   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0793   |
|    n_updates         | 13680    |
| time/                |          |
|    iterations        | 174      |
|    fps               | 37.3     |
|    elapsed_time      | 1.87e+04 |
|    elapsed_steps     | 445440   |
-----------------------------------
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:11:10<4:59:45, 30.83steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448000/1000000 [5:11:58<4:36:34, 33.26steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448000/1000000 [5:12:10<4:36:34, 33.26steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_448000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 450560/1000000 [5:17:37<9:15:33, 16.48steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:18:43<7:38:15, 19.89steps/s]                                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:18:43<7:38:15, 19.89steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.28     |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.429    |
|    max_target_q      | -11.3    |
|    min_target_q      | -39.5    |
|    max_reward        | -0.268   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 5.52     |
|    q1_grad_norm      | 3.61     |
|    q2_grad_norm      | 3.49     |
|    actor_loss        | 21.5     |
|    ent_coeff         | 0.038    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0782   |
|    n_updates         | 13920    |
| eval/                |          |
|    Length            | 188      |
|    Return            | -149     |
|    NonzeroRewards    | 188      |
|    DiscountedReturn  | -149     |
|    Success           | 0.105    |
|    SuccessLength     | 188      |
| time/                |          |
|    iterations        | 177      |
|    fps               | 16.4     |
|    elapsed_time      | 1.91e+04 |
|    elapsed_steps     | 453120   |
-----------------------------------
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:19:00<7:38:15, 19.89steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455680/1000000 [5:19:52<6:31:53, 23.15steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455680/1000000 [5:20:10<6:31:53, 23.15steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458240/1000000 [5:21:02<5:47:30, 25.98steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458240/1000000 [5:21:20<5:47:30, 25.98steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:22:10<5:14:00, 28.62steps/s]                                                                46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:22:10<5:14:00, 28.62steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 189      |
|    Return            | -150     |
|    NonzeroRewards    | 189      |
|    DiscountedReturn  | -150     |
|    Success           | 0.128    |
|    SuccessLength     | 189      |
| algo/                |          |
|    critic_loss       | 0.3      |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.43     |
|    max_target_q      | -11.2    |
|    min_target_q      | -39.9    |
|    max_reward        | -0.284   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 5.89     |
|    q1_grad_norm      | 3.84     |
|    q2_grad_norm      | 3.7      |
|    actor_loss        | 21.7     |
|    ent_coeff         | 0.0378   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0781   |
|    n_updates         | 14160    |
| time/                |          |
|    iterations        | 180      |
|    fps               | 37.1     |
|    elapsed_time      | 1.93e+04 |
|    elapsed_steps     | 460800   |
-----------------------------------
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:22:30<5:14:00, 28.62steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463360/1000000 [5:23:14<4:45:52, 31.29steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463360/1000000 [5:23:30<4:45:52, 31.29steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465920/1000000 [5:24:20<4:27:15, 33.31steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465920/1000000 [5:24:30<4:27:15, 33.31steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_465920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468480/1000000 [5:29:58<8:57:51, 16.47steps/s]                                                                47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468480/1000000 [5:29:58<8:57:51, 16.47steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -149     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0488   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.303    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.425    |
|    max_target_q      | -11.2    |
|    min_target_q      | -40.3    |
|    max_reward        | -0.278   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 6.26     |
|    q1_grad_norm      | 3.92     |
|    q2_grad_norm      | 3.77     |
|    actor_loss        | 21.8     |
|    ent_coeff         | 0.0376   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0785   |
|    n_updates         | 14400    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 183      |
|    fps               | 16.4     |
|    elapsed_time      | 1.98e+04 |
|    elapsed_steps     | 468480   |
-----------------------------------
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471040/1000000 [5:31:02<7:20:01, 20.04steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471040/1000000 [5:31:20<7:20:01, 20.04steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473600/1000000 [5:32:06<6:12:22, 23.56steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473600/1000000 [5:32:20<6:12:22, 23.56steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:33:13<5:28:20, 26.59steps/s]                                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:33:13<5:28:20, 26.59steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -150     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.326    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.424    |
|    max_target_q      | -11.3    |
|    min_target_q      | -40.6    |
|    max_reward        | -0.27    |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 7.33     |
|    q1_grad_norm      | 4.99     |
|    q2_grad_norm      | 4.82     |
|    actor_loss        | 22       |
|    ent_coeff         | 0.0375   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0796   |
|    n_updates         | 14640    |
| time/                |          |
|    iterations        | 186      |
|    fps               | 39.5     |
|    elapsed_time      | 2e+04    |
|    elapsed_steps     | 476160   |
-----------------------------------
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:33:30<5:28:20, 26.59steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478720/1000000 [5:34:22<4:58:55, 29.06steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478720/1000000 [5:34:40<4:58:55, 29.06steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481280/1000000 [5:35:37<4:44:04, 30.43steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481280/1000000 [5:35:50<4:44:04, 30.43steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:36:40<4:21:20, 32.92steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:36:50<4:21:20, 32.92steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_483840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:41:24<4:21:20, 32.92steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -148     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0811   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.311    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.421    |
|    max_target_q      | -11.3    |
|    min_target_q      | -41      |
|    max_reward        | -0.263   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 6.4      |
|    q1_grad_norm      | 4.26     |
|    q2_grad_norm      | 4.11     |
|    actor_loss        | 22.1     |
|    ent_coeff         | 0.0373   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0789   |
|    n_updates         | 14880    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -145     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -145     |
|    Success           | 0.111    |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 189      |
|    fps               | 15.6     |
|    elapsed_time      | 2.05e+04 |
|    elapsed_steps     | 483840   |
-----------------------------------
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 486400/1000000 [5:42:28<8:51:49, 16.10steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488960/1000000 [5:43:36<7:18:09, 19.44steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488960/1000000 [5:43:50<7:18:09, 19.44steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:44:46<6:14:41, 22.62steps/s]                                                                49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:44:46<6:14:41, 22.62steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -151     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0769   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.322    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.417    |
|    max_target_q      | -11.2    |
|    min_target_q      | -41.3    |
|    max_reward        | -0.273   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 6.2      |
|    q1_grad_norm      | 3.87     |
|    q2_grad_norm      | 3.73     |
|    actor_loss        | 22.2     |
|    ent_coeff         | 0.0371   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0779   |
|    n_updates         | 15120    |
| time/                |          |
|    iterations        | 192      |
|    fps               | 38       |
|    elapsed_time      | 2.07e+04 |
|    elapsed_steps     | 491520   |
-----------------------------------
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:45:00<6:14:41, 22.62steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494080/1000000 [5:46:03<5:36:26, 25.06steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494080/1000000 [5:46:20<5:36:26, 25.06steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496640/1000000 [5:47:19<5:09:34, 27.10steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496640/1000000 [5:47:30<5:09:34, 27.10steps/s]ReplayBuffer: Replay buffer is now full. cursor=0.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:48:29<4:44:04, 29.38steps/s]                                                                50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:48:29<4:44:04, 29.38steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -154     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.337    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.413    |
|    max_target_q      | -11.4    |
|    min_target_q      | -41.8    |
|    max_reward        | -0.269   |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 6.88     |
|    q1_grad_norm      | 4.33     |
|    q2_grad_norm      | 4.17     |
|    actor_loss        | 22.4     |
|    ent_coeff         | 0.0369   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0785   |
|    n_updates         | 15360    |
| time/                |          |
|    iterations        | 195      |
|    fps               | 34.4     |
|    elapsed_time      | 2.09e+04 |
|    elapsed_steps     | 499200   |
-----------------------------------
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:48:40<4:44:04, 29.38steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501760/1000000 [5:49:36<4:22:48, 31.60steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_501760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501760/1000000 [5:49:50<4:22:48, 31.60steps/s]EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 504320/1000000 [5:55:19<8:35:14, 16.03steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:56:27<7:04:09, 19.38steps/s]                                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:56:27<7:04:09, 19.38steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -148     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0732   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.325    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.412    |
|    max_target_q      | -11      |
|    min_target_q      | -42.2    |
|    max_reward        | -0.275   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 6.52     |
|    q1_grad_norm      | 3.96     |
|    q2_grad_norm      | 3.83     |
|    actor_loss        | 22.5     |
|    ent_coeff         | 0.0367   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0784   |
|    n_updates         | 15600    |
| eval/                |          |
|    Length            | 198      |
|    Return            | -159     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0556   |
|    SuccessLength     | 198      |
| time/                |          |
|    iterations        | 198      |
|    fps               | 16.1     |
|    elapsed_time      | 2.14e+04 |
|    elapsed_steps     | 506880   |
-----------------------------------
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:56:40<7:04:09, 19.38steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509440/1000000 [5:57:33<5:58:24, 22.81steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509440/1000000 [5:57:50<5:58:24, 22.81steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512000/1000000 [5:58:48<5:21:13, 25.32steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512000/1000000 [5:59:00<5:21:13, 25.32steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [6:00:03<4:54:22, 27.48steps/s]                                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [6:00:03<4:54:22, 27.48steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.345    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.41     |
|    max_target_q      | -10.9    |
|    min_target_q      | -42.5    |
|    max_reward        | -0.263   |
|    min_reward        | -1.55    |
|    encoder_grad_norm | 6.85     |
|    q1_grad_norm      | 4.06     |
|    q2_grad_norm      | 3.92     |
|    actor_loss        | 22.7     |
|    ent_coeff         | 0.0366   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0794   |
|    n_updates         | 15840    |
| time/                |          |
|    iterations        | 201      |
|    fps               | 35.6     |
|    elapsed_time      | 2.16e+04 |
|    elapsed_steps     | 514560   |
-----------------------------------
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [6:00:20<4:54:22, 27.48steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517120/1000000 [6:01:09<4:28:01, 30.03steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517120/1000000 [6:01:20<4:28:01, 30.03steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519680/1000000 [6:02:21<4:13:55, 31.53steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_519680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519680/1000000 [6:02:40<4:13:55, 31.53steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522240/1000000 [6:08:02<8:14:26, 16.10steps/s]                                                                52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522240/1000000 [6:08:02<8:14:26, 16.10steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -149     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -149     |
|    Success           | 0.125    |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.368    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.408    |
|    max_target_q      | -9.88    |
|    min_target_q      | -43      |
|    max_reward        | -0.264   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 7        |
|    q1_grad_norm      | 4.18     |
|    q2_grad_norm      | 4.04     |
|    actor_loss        | 22.7     |
|    ent_coeff         | 0.0364   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0782   |
|    n_updates         | 16080    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 204      |
|    fps               | 16       |
|    elapsed_time      | 2.21e+04 |
|    elapsed_steps     | 522240   |
-----------------------------------
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524800/1000000 [6:09:08<6:45:30, 19.53steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524800/1000000 [6:09:20<6:45:30, 19.53steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527360/1000000 [6:10:16<5:45:42, 22.79steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527360/1000000 [6:10:30<5:45:42, 22.79steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:11:26<5:04:50, 25.70steps/s]                                                                53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:11:26<5:04:50, 25.70steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -149     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -149     |
|    Success           | 0.027    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.344    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.41     |
|    max_target_q      | -10.2    |
|    min_target_q      | -43.3    |
|    max_reward        | -0.269   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 7.58     |
|    q1_grad_norm      | 4.89     |
|    q2_grad_norm      | 4.73     |
|    actor_loss        | 22.8     |
|    ent_coeff         | 0.0362   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0773   |
|    n_updates         | 16320    |
| time/                |          |
|    iterations        | 207      |
|    fps               | 37.5     |
|    elapsed_time      | 2.23e+04 |
|    elapsed_steps     | 529920   |
-----------------------------------
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:11:40<5:04:50, 25.70steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532480/1000000 [6:12:38<4:37:35, 28.07steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532480/1000000 [6:12:50<4:37:35, 28.07steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535040/1000000 [6:13:44<4:13:24, 30.58steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535040/1000000 [6:14:00<4:13:24, 30.58steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:14:51<3:57:05, 32.51steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_537600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:15:10<3:57:05, 32.51steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:19:26<3:57:05, 32.51steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -153     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -153     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.351    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.408    |
|    max_target_q      | -10      |
|    min_target_q      | -43.6    |
|    max_reward        | -0.264   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 7.3      |
|    q1_grad_norm      | 4.44     |
|    q2_grad_norm      | 4.28     |
|    actor_loss        | 22.8     |
|    ent_coeff         | 0.036    |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0769   |
|    n_updates         | 16560    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 210      |
|    fps               | 16       |
|    elapsed_time      | 2.28e+04 |
|    elapsed_steps     | 537600   |
-----------------------------------
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 540160/1000000 [6:20:31<7:50:09, 16.30steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542720/1000000 [6:21:38<6:27:24, 19.67steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542720/1000000 [6:21:50<6:27:24, 19.67steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:22:42<5:26:28, 23.21steps/s]                                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:22:42<5:26:28, 23.21steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -154     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -154     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.367    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.407    |
|    max_target_q      | -9.5     |
|    min_target_q      | -44.1    |
|    max_reward        | -0.256   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 8.01     |
|    q1_grad_norm      | 4.81     |
|    q2_grad_norm      | 4.66     |
|    actor_loss        | 22.9     |
|    ent_coeff         | 0.0359   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0772   |
|    n_updates         | 16800    |
| time/                |          |
|    iterations        | 213      |
|    fps               | 39.1     |
|    elapsed_time      | 2.3e+04  |
|    elapsed_steps     | 545280   |
-----------------------------------
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:23:00<5:26:28, 23.21steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547840/1000000 [6:23:56<4:52:24, 25.77steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547840/1000000 [6:24:10<4:52:24, 25.77steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550400/1000000 [6:25:07<4:25:58, 28.17steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550400/1000000 [6:25:20<4:25:58, 28.17steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:26:15<4:04:44, 30.44steps/s]                                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:26:15<4:04:44, 30.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -151     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0488   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.395    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.401    |
|    max_target_q      | -9.61    |
|    min_target_q      | -44.4    |
|    max_reward        | -0.253   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 8.42     |
|    q1_grad_norm      | 5.07     |
|    q2_grad_norm      | 4.9      |
|    actor_loss        | 23       |
|    ent_coeff         | 0.0357   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0778   |
|    n_updates         | 17040    |
| time/                |          |
|    iterations        | 216      |
|    fps               | 36       |
|    elapsed_time      | 2.32e+04 |
|    elapsed_steps     | 552960   |
-----------------------------------
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:26:30<4:04:44, 30.44steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555520/1000000 [6:27:20<3:46:13, 32.75steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555520/1000000 [6:27:30<3:46:13, 32.75steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_555520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 558080/1000000 [6:32:45<7:18:35, 16.79steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:33:51<6:01:27, 20.26steps/s]                                                                56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:33:51<6:01:27, 20.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -152     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -152     |
|    Success           | 0.05     |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.374    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.398    |
|    max_target_q      | -9.61    |
|    min_target_q      | -44.7    |
|    max_reward        | -0.255   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 7.92     |
|    q1_grad_norm      | 4.56     |
|    q2_grad_norm      | 4.4      |
|    actor_loss        | 23.1     |
|    ent_coeff         | 0.0355   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0789   |
|    n_updates         | 17280    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -150     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0556   |
|    SuccessLength     | 197      |
| time/                |          |
|    iterations        | 219      |
|    fps               | 16.9     |
|    elapsed_time      | 2.36e+04 |
|    elapsed_steps     | 560640   |
-----------------------------------
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:34:10<6:01:27, 20.26steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563200/1000000 [6:34:58<5:08:49, 23.57steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563200/1000000 [6:35:10<5:08:49, 23.57steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565760/1000000 [6:36:06<4:32:31, 26.56steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565760/1000000 [6:36:20<4:32:31, 26.56steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:37:14<4:07:18, 29.09steps/s]                                                                57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:37:14<4:07:18, 29.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -149     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0278   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.429    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.395    |
|    max_target_q      | -8.98    |
|    min_target_q      | -44.8    |
|    max_reward        | -0.255   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 9.07     |
|    q1_grad_norm      | 4.97     |
|    q2_grad_norm      | 4.8      |
|    actor_loss        | 23.1     |
|    ent_coeff         | 0.0354   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0788   |
|    n_updates         | 17520    |
| time/                |          |
|    iterations        | 222      |
|    fps               | 37.7     |
|    elapsed_time      | 2.38e+04 |
|    elapsed_steps     | 568320   |
-----------------------------------
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:37:30<4:07:18, 29.09steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570880/1000000 [6:38:21<3:48:15, 31.33steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570880/1000000 [6:38:40<3:48:15, 31.33steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573440/1000000 [6:39:30<3:36:11, 32.88steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_573440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573440/1000000 [6:39:50<3:36:11, 32.88steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576000/1000000 [6:45:15<7:15:40, 16.22steps/s]                                                                58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576000/1000000 [6:45:15<7:15:40, 16.22steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -149     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0526   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.43     |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.391    |
|    max_target_q      | -9.51    |
|    min_target_q      | -45.1    |
|    max_reward        | -0.258   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 8.21     |
|    q1_grad_norm      | 4.11     |
|    q2_grad_norm      | 3.97     |
|    actor_loss        | 23.1     |
|    ent_coeff         | 0.0352   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0791   |
|    n_updates         | 17760    |
| eval/                |          |
|    Length            | 190      |
|    Return            | -152     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -152     |
|    Success           | 0.111    |
|    SuccessLength     | 190      |
| time/                |          |
|    iterations        | 225      |
|    fps               | 16       |
|    elapsed_time      | 2.43e+04 |
|    elapsed_steps     | 576000   |
-----------------------------------
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578560/1000000 [6:46:21<5:57:57, 19.62steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578560/1000000 [6:46:40<5:57:57, 19.62steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581120/1000000 [6:47:29<5:04:25, 22.93steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581120/1000000 [6:47:40<5:04:25, 22.93steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:48:36<4:26:23, 26.05steps/s]                                                                58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:48:36<4:26:23, 26.05steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -155     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -155     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.42     |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.386    |
|    max_target_q      | -8.03    |
|    min_target_q      | -45.1    |
|    max_reward        | -0.261   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 8.47     |
|    q1_grad_norm      | 4.69     |
|    q2_grad_norm      | 4.53     |
|    actor_loss        | 23.2     |
|    ent_coeff         | 0.035    |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.08     |
|    n_updates         | 18000    |
| time/                |          |
|    iterations        | 228      |
|    fps               | 38.1     |
|    elapsed_time      | 2.45e+04 |
|    elapsed_steps     | 583680   |
-----------------------------------
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:48:50<4:26:23, 26.05steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586240/1000000 [6:49:49<4:03:55, 28.27steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586240/1000000 [6:50:00<4:03:55, 28.27steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588800/1000000 [6:50:54<3:42:22, 30.82steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588800/1000000 [6:51:10<3:42:22, 30.82steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:52:02<3:29:00, 32.59steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_591360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:52:20<3:29:00, 32.59steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:56:21<3:29:00, 32.59steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -148     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0976   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.432    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.384    |
|    max_target_q      | -8.37    |
|    min_target_q      | -44.6    |
|    max_reward        | -0.255   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 8.15     |
|    q1_grad_norm      | 3.83     |
|    q2_grad_norm      | 3.71     |
|    actor_loss        | 23.2     |
|    ent_coeff         | 0.0349   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0796   |
|    n_updates         | 18240    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -153     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -153     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 231      |
|    fps               | 16.5     |
|    elapsed_time      | 2.5e+04  |
|    elapsed_steps     | 591360   |
-----------------------------------
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 593920/1000000 [6:57:29<6:44:35, 16.73steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596480/1000000 [6:58:41<5:38:18, 19.88steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596480/1000000 [6:59:00<5:38:18, 19.88steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [6:59:50<4:49:01, 23.12steps/s]                                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [6:59:50<4:49:01, 23.12steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -145     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -145     |
|    Success           | 0.128    |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.45     |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.382    |
|    max_target_q      | -7.77    |
|    min_target_q      | -45.1    |
|    max_reward        | -0.253   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 9.36     |
|    q1_grad_norm      | 4.71     |
|    q2_grad_norm      | 4.55     |
|    actor_loss        | 23.3     |
|    ent_coeff         | 0.0347   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0812   |
|    n_updates         | 18480    |
| time/                |          |
|    iterations        | 234      |
|    fps               | 36.7     |
|    elapsed_time      | 2.52e+04 |
|    elapsed_steps     | 599040   |
-----------------------------------
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [7:00:00<4:49:01, 23.12steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601600/1000000 [7:00:59<4:14:59, 26.04steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601600/1000000 [7:01:10<4:14:59, 26.04steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604160/1000000 [7:02:12<3:53:13, 28.29steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604160/1000000 [7:02:30<3:53:13, 28.29steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:03:20<3:34:29, 30.56steps/s]                                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:03:20<3:34:29, 30.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.471    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.381    |
|    max_target_q      | -6.85    |
|    min_target_q      | -45.6    |
|    max_reward        | -0.255   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 10.1     |
|    q1_grad_norm      | 5.58     |
|    q2_grad_norm      | 5.41     |
|    actor_loss        | 23.4     |
|    ent_coeff         | 0.0345   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0809   |
|    n_updates         | 18720    |
| time/                |          |
|    iterations        | 237      |
|    fps               | 36.6     |
|    elapsed_time      | 2.54e+04 |
|    elapsed_steps     | 606720   |
-----------------------------------
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:03:30<3:34:29, 30.56steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609280/1000000 [7:04:26<3:19:43, 32.61steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609280/1000000 [7:04:40<3:19:43, 32.61steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_609280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 611840/1000000 [7:10:11<6:40:15, 16.16steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:11:24<5:33:24, 19.28steps/s]                                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:11:24<5:33:24, 19.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -146     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0488   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.508    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.377    |
|    max_target_q      | -6.29    |
|    min_target_q      | -45.6    |
|    max_reward        | -0.247   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 10.3     |
|    q1_grad_norm      | 5.29     |
|    q2_grad_norm      | 5.1      |
|    actor_loss        | 23.4     |
|    ent_coeff         | 0.0344   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0832   |
|    n_updates         | 18960    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -154     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0556   |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 240      |
|    fps               | 15.9     |
|    elapsed_time      | 2.59e+04 |
|    elapsed_steps     | 614400   |
-----------------------------------
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:11:40<5:33:24, 19.28steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616960/1000000 [7:12:31<4:41:48, 22.65steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616960/1000000 [7:12:50<4:41:48, 22.65steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619520/1000000 [7:13:36<4:04:47, 25.91steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619520/1000000 [7:13:50<4:04:47, 25.91steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:14:46<3:41:50, 28.39steps/s]                                                                62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:14:46<3:41:50, 28.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -147     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0811   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.505    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.377    |
|    max_target_q      | -5.96    |
|    min_target_q      | -46.3    |
|    max_reward        | -0.249   |
|    min_reward        | -1.53    |
|    encoder_grad_norm | 10.7     |
|    q1_grad_norm      | 5.95     |
|    q2_grad_norm      | 5.75     |
|    actor_loss        | 23.5     |
|    ent_coeff         | 0.0342   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0813   |
|    n_updates         | 19200    |
| time/                |          |
|    iterations        | 243      |
|    fps               | 37.9     |
|    elapsed_time      | 2.61e+04 |
|    elapsed_steps     | 622080   |
-----------------------------------
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:15:00<3:41:50, 28.39steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624640/1000000 [7:15:51<3:21:59, 30.97steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624640/1000000 [7:16:10<3:21:59, 30.97steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627200/1000000 [7:17:03<3:12:24, 32.29steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_627200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627200/1000000 [7:17:20<3:12:24, 32.29steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629760/1000000 [7:22:33<6:12:47, 16.55steps/s]                                                                63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629760/1000000 [7:22:33<6:12:47, 16.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -151     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -151     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.514    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.376    |
|    max_target_q      | -4.15    |
|    min_target_q      | -46.5    |
|    max_reward        | -0.247   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 10.8     |
|    q1_grad_norm      | 5.68     |
|    q2_grad_norm      | 5.5      |
|    actor_loss        | 23.5     |
|    ent_coeff         | 0.034    |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0806   |
|    n_updates         | 19440    |
| eval/                |          |
|    Length            | 198      |
|    Return            | -156     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0556   |
|    SuccessLength     | 198      |
| time/                |          |
|    iterations        | 246      |
|    fps               | 16.4     |
|    elapsed_time      | 2.66e+04 |
|    elapsed_steps     | 629760   |
-----------------------------------
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632320/1000000 [7:23:39<5:06:35, 19.99steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632320/1000000 [7:23:50<5:06:35, 19.99steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634880/1000000 [7:24:50<4:23:37, 23.08steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634880/1000000 [7:25:00<4:23:37, 23.08steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:25:58<3:51:22, 26.12steps/s]                                                                64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:25:58<3:51:22, 26.12steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -148     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0513   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.54     |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.373    |
|    max_target_q      | -4.14    |
|    min_target_q      | -46.8    |
|    max_reward        | -0.246   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 10.3     |
|    q1_grad_norm      | 4.33     |
|    q2_grad_norm      | 4.18     |
|    actor_loss        | 23.6     |
|    ent_coeff         | 0.0339   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0818   |
|    n_updates         | 19680    |
| time/                |          |
|    iterations        | 249      |
|    fps               | 37.5     |
|    elapsed_time      | 2.68e+04 |
|    elapsed_steps     | 637440   |
-----------------------------------
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:26:10<3:51:22, 26.12steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640000/1000000 [7:27:12<3:32:51, 28.19steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640000/1000000 [7:27:30<3:32:51, 28.19steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642560/1000000 [7:28:21<3:15:56, 30.40steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642560/1000000 [7:28:40<3:15:56, 30.40steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:29:28<3:02:51, 32.35steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:29:40<3:02:51, 32.35steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_645120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:34:16<3:02:51, 32.35steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -143     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -143     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.585    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.373    |
|    max_target_q      | -3.81    |
|    min_target_q      | -47.6    |
|    max_reward        | -0.244   |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 12.6     |
|    q1_grad_norm      | 6.51     |
|    q2_grad_norm      | 6.29     |
|    actor_loss        | 23.7     |
|    ent_coeff         | 0.0337   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0796   |
|    n_updates         | 19920    |
| eval/                |          |
|    Length            | 190      |
|    Return            | -138     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -138     |
|    Success           | 0.111    |
|    SuccessLength     | 190      |
| time/                |          |
|    iterations        | 252      |
|    fps               | 15.4     |
|    elapsed_time      | 2.73e+04 |
|    elapsed_steps     | 645120   |
-----------------------------------
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 647680/1000000 [7:35:22<6:10:20, 15.86steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650240/1000000 [7:36:31<5:04:34, 19.14steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650240/1000000 [7:36:50<5:04:34, 19.14steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:37:37<4:16:41, 22.54steps/s]                                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:37:37<4:16:41, 22.54steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -143     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -143     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.589    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.371    |
|    max_target_q      | -3.11    |
|    min_target_q      | -48.1    |
|    max_reward        | -0.249   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 10.9     |
|    q1_grad_norm      | 3.87     |
|    q2_grad_norm      | 3.75     |
|    actor_loss        | 23.7     |
|    ent_coeff         | 0.0335   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0809   |
|    n_updates         | 20160    |
| time/                |          |
|    iterations        | 255      |
|    fps               | 38.2     |
|    elapsed_time      | 2.75e+04 |
|    elapsed_steps     | 652800   |
-----------------------------------
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:37:50<4:16:41, 22.54steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655360/1000000 [7:38:43<3:42:48, 25.78steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655360/1000000 [7:39:00<3:42:48, 25.78steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657920/1000000 [7:39:52<3:20:19, 28.46steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657920/1000000 [7:40:10<3:20:19, 28.46steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:41:00<3:04:35, 30.65steps/s]                                                                66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:41:00<3:04:35, 30.65steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 188      |
|    Return            | -143     |
|    NonzeroRewards    | 188      |
|    DiscountedReturn  | -143     |
|    Success           | 0.146    |
|    SuccessLength     | 188      |
| algo/                |          |
|    critic_loss       | 0.617    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.366    |
|    max_target_q      | -1.98    |
|    min_target_q      | -48.4    |
|    max_reward        | -0.235   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 12.6     |
|    q1_grad_norm      | 5.8      |
|    q2_grad_norm      | 5.59     |
|    actor_loss        | 23.7     |
|    ent_coeff         | 0.0334   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0808   |
|    n_updates         | 20400    |
| time/                |          |
|    iterations        | 258      |
|    fps               | 37.9     |
|    elapsed_time      | 2.77e+04 |
|    elapsed_steps     | 660480   |
-----------------------------------
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:41:10<3:04:35, 30.65steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663040/1000000 [7:42:05<2:51:19, 32.78steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663040/1000000 [7:42:20<2:51:19, 32.78steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_663040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 665600/1000000 [7:47:38<5:35:58, 16.59steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:48:46<4:37:45, 19.91steps/s]                                                                67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:48:46<4:37:45, 19.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -151     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -151     |
|    Success           | 0.122    |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.647    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.365    |
|    max_target_q      | -0.858   |
|    min_target_q      | -48.9    |
|    max_reward        | -0.24    |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 12.9     |
|    q1_grad_norm      | 5.84     |
|    q2_grad_norm      | 5.64     |
|    actor_loss        | 23.8     |
|    ent_coeff         | 0.0332   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0811   |
|    n_updates         | 20640    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -149     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 261      |
|    fps               | 16.5     |
|    elapsed_time      | 2.81e+04 |
|    elapsed_steps     | 668160   |
-----------------------------------
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:49:00<4:37:45, 19.91steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670720/1000000 [7:49:53<3:55:53, 23.26steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670720/1000000 [7:50:10<3:55:53, 23.26steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673280/1000000 [7:51:01<3:27:07, 26.29steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673280/1000000 [7:51:20<3:27:07, 26.29steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:52:16<3:11:39, 28.19steps/s]                                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:52:16<3:11:39, 28.19steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0263   |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.696    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.363    |
|    max_target_q      | -0.988   |
|    min_target_q      | -49.4    |
|    max_reward        | -0.236   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 14.6     |
|    q1_grad_norm      | 6.89     |
|    q2_grad_norm      | 6.65     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0331   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0814   |
|    n_updates         | 20880    |
| time/                |          |
|    iterations        | 264      |
|    fps               | 36.5     |
|    elapsed_time      | 2.83e+04 |
|    elapsed_steps     | 675840   |
-----------------------------------
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:52:30<3:11:39, 28.19steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678400/1000000 [7:53:24<2:55:41, 30.51steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678400/1000000 [7:53:40<2:55:41, 30.51steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680960/1000000 [7:54:35<2:46:16, 31.98steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680960/1000000 [7:54:50<2:46:16, 31.98steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_680960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683520/1000000 [8:00:09<5:21:53, 16.39steps/s]                                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683520/1000000 [8:00:09<5:21:53, 16.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -153     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0263   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.675    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.362    |
|    max_target_q      | -0.453   |
|    min_target_q      | -49.7    |
|    max_reward        | -0.238   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 13       |
|    q1_grad_norm      | 5.07     |
|    q2_grad_norm      | 4.91     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0329   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0794   |
|    n_updates         | 21120    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -150     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 267      |
|    fps               | 16.2     |
|    elapsed_time      | 2.88e+04 |
|    elapsed_steps     | 683520   |
-----------------------------------
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686080/1000000 [8:01:14<4:23:14, 19.88steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686080/1000000 [8:01:30<4:23:14, 19.88steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688640/1000000 [8:02:19<3:42:13, 23.35steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688640/1000000 [8:02:30<3:42:13, 23.35steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:03:25<3:14:15, 26.49steps/s]                                                                69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:03:25<3:14:15, 26.49steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -148     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0526   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.706    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.36     |
|    max_target_q      | -0.642   |
|    min_target_q      | -50      |
|    max_reward        | -0.242   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 14.3     |
|    q1_grad_norm      | 6.33     |
|    q2_grad_norm      | 6.1      |
|    actor_loss        | 24       |
|    ent_coeff         | 0.0327   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0796   |
|    n_updates         | 21360    |
| time/                |          |
|    iterations        | 270      |
|    fps               | 39.2     |
|    elapsed_time      | 2.9e+04  |
|    elapsed_steps     | 691200   |
-----------------------------------
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:03:40<3:14:15, 26.49steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693760/1000000 [8:04:32<2:54:46, 29.20steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693760/1000000 [8:04:50<2:54:46, 29.20steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696320/1000000 [8:05:39<2:41:06, 31.42steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696320/1000000 [8:05:50<2:41:06, 31.42steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:06:48<2:32:11, 32.98steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:07:00<2:32:11, 32.98steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_698880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:11:11<2:32:11, 32.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -149     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0732   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.746    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.362    |
|    max_target_q      | -0.427   |
|    min_target_q      | -50.7    |
|    max_reward        | -0.233   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 14.3     |
|    q1_grad_norm      | 5.57     |
|    q2_grad_norm      | 5.38     |
|    actor_loss        | 24.1     |
|    ent_coeff         | 0.0326   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.079    |
|    n_updates         | 21600    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -153     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0556   |
|    SuccessLength     | 197      |
| time/                |          |
|    iterations        | 273      |
|    fps               | 16.5     |
|    elapsed_time      | 2.95e+04 |
|    elapsed_steps     | 698880   |
-----------------------------------
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 701440/1000000 [8:12:17<4:57:32, 16.72steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704000/1000000 [8:13:24<4:05:13, 20.12steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704000/1000000 [8:13:40<4:05:13, 20.12steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:14:31<3:28:40, 23.44steps/s]                                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:14:31<3:28:40, 23.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -156     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.726    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.362    |
|    max_target_q      | -0.548   |
|    min_target_q      | -50.9    |
|    max_reward        | -0.231   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 13.8     |
|    q1_grad_norm      | 5.32     |
|    q2_grad_norm      | 5.13     |
|    actor_loss        | 24.3     |
|    ent_coeff         | 0.0324   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0774   |
|    n_updates         | 21840    |
| time/                |          |
|    iterations        | 276      |
|    fps               | 38.5     |
|    elapsed_time      | 2.97e+04 |
|    elapsed_steps     | 706560   |
-----------------------------------
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:14:50<3:28:40, 23.44steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709120/1000000 [8:15:43<3:05:40, 26.11steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709120/1000000 [8:16:00<3:05:40, 26.11steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711680/1000000 [8:16:52<2:47:55, 28.61steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711680/1000000 [8:17:10<2:47:55, 28.61steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:17:58<2:33:29, 31.03steps/s]                                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:17:58<2:33:29, 31.03steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -148     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0769   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.692    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.361    |
|    max_target_q      | -0.492   |
|    min_target_q      | -51.1    |
|    max_reward        | -0.238   |
|    min_reward        | -1.59    |
|    encoder_grad_norm | 13       |
|    q1_grad_norm      | 5.56     |
|    q2_grad_norm      | 5.37     |
|    actor_loss        | 24.4     |
|    ent_coeff         | 0.0323   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0771   |
|    n_updates         | 22080    |
| time/                |          |
|    iterations        | 279      |
|    fps               | 37       |
|    elapsed_time      | 2.99e+04 |
|    elapsed_steps     | 714240   |
-----------------------------------
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:18:10<2:33:29, 31.03steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716800/1000000 [8:19:05<2:23:19, 32.93steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716800/1000000 [8:19:20<2:23:19, 32.93steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_716800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 719360/1000000 [8:24:50<4:48:20, 16.22steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:26:01<3:58:25, 19.44steps/s]                                                                72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:26:01<3:58:25, 19.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -146     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -146     |
|    Success           | 0.1      |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.66     |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.359    |
|    max_target_q      | -1.16    |
|    min_target_q      | -51.7    |
|    max_reward        | -0.227   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 12.1     |
|    q1_grad_norm      | 4.44     |
|    q2_grad_norm      | 4.27     |
|    actor_loss        | 24.5     |
|    ent_coeff         | 0.0321   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0778   |
|    n_updates         | 22320    |
| eval/                |          |
|    Length            | 188      |
|    Return            | -144     |
|    NonzeroRewards    | 188      |
|    DiscountedReturn  | -144     |
|    Success           | 0.111    |
|    SuccessLength     | 188      |
| time/                |          |
|    iterations        | 282      |
|    fps               | 15.9     |
|    elapsed_time      | 3.04e+04 |
|    elapsed_steps     | 721920   |
-----------------------------------
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:26:20<3:58:25, 19.44steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724480/1000000 [8:27:09<3:22:20, 22.69steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724480/1000000 [8:27:20<3:22:20, 22.69steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727040/1000000 [8:28:20<2:57:50, 25.58steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727040/1000000 [8:28:30<2:57:50, 25.58steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:29:38<2:44:27, 27.40steps/s]                                                                73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:29:38<2:44:27, 27.40steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -152     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -152     |
|    Success           | 0.0513   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.698    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.36     |
|    max_target_q      | -1.81    |
|    min_target_q      | -51.8    |
|    max_reward        | -0.251   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 14.1     |
|    q1_grad_norm      | 6.29     |
|    q2_grad_norm      | 6.08     |
|    actor_loss        | 24.6     |
|    ent_coeff         | 0.032    |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0771   |
|    n_updates         | 22560    |
| time/                |          |
|    iterations        | 285      |
|    fps               | 35.4     |
|    elapsed_time      | 3.06e+04 |
|    elapsed_steps     | 729600   |
-----------------------------------
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:29:50<2:44:27, 27.40steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732160/1000000 [8:30:47<2:30:18, 29.70steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732160/1000000 [8:31:00<2:30:18, 29.70steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734720/1000000 [8:31:57<2:20:20, 31.50steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734720/1000000 [8:32:10<2:20:20, 31.50steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_734720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737280/1000000 [8:37:28<4:27:11, 16.39steps/s]                                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737280/1000000 [8:37:28<4:27:11, 16.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -149     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0732   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.685    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.358    |
|    max_target_q      | -2.45    |
|    min_target_q      | -52.4    |
|    max_reward        | -0.233   |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 13       |
|    q1_grad_norm      | 5.25     |
|    q2_grad_norm      | 5.05     |
|    actor_loss        | 24.7     |
|    ent_coeff         | 0.0318   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0763   |
|    n_updates         | 22800    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -148     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -148     |
|    Success           | 0.111    |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 288      |
|    fps               | 16.3     |
|    elapsed_time      | 3.1e+04  |
|    elapsed_steps     | 737280   |
-----------------------------------
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739840/1000000 [8:38:39<3:41:14, 19.60steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739840/1000000 [8:38:50<3:41:14, 19.60steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742400/1000000 [8:39:49<3:08:34, 22.77steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742400/1000000 [8:40:00<3:08:34, 22.77steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:40:57<2:44:52, 25.78steps/s]                                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:40:57<2:44:52, 25.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -149     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0513   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.69     |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.355    |
|    max_target_q      | -3.04    |
|    min_target_q      | -52.8    |
|    max_reward        | -0.24    |
|    min_reward        | -1.53    |
|    encoder_grad_norm | 13.7     |
|    q1_grad_norm      | 6.07     |
|    q2_grad_norm      | 5.87     |
|    actor_loss        | 24.9     |
|    ent_coeff         | 0.0317   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0779   |
|    n_updates         | 23040    |
| time/                |          |
|    iterations        | 291      |
|    fps               | 36.6     |
|    elapsed_time      | 3.13e+04 |
|    elapsed_steps     | 744960   |
-----------------------------------
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:41:10<2:44:52, 25.78steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747520/1000000 [8:42:15<2:32:46, 27.54steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747520/1000000 [8:42:30<2:32:46, 27.54steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750080/1000000 [8:43:24<2:19:31, 29.85steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750080/1000000 [8:43:40<2:19:31, 29.85steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:44:34<2:10:31, 31.59steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:44:50<2:10:31, 31.59steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_752640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:49:03<2:10:31, 31.59steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 189      |
|    Return            | -140     |
|    NonzeroRewards    | 189      |
|    DiscountedReturn  | -140     |
|    Success           | 0.105    |
|    SuccessLength     | 189      |
| algo/                |          |
|    critic_loss       | 0.737    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.351    |
|    max_target_q      | -2.56    |
|    min_target_q      | -53.2    |
|    max_reward        | -0.243   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 14.2     |
|    q1_grad_norm      | 5.13     |
|    q2_grad_norm      | 4.96     |
|    actor_loss        | 25       |
|    ent_coeff         | 0.0315   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0777   |
|    n_updates         | 23280    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -150     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -150     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 294      |
|    fps               | 15.8     |
|    elapsed_time      | 3.17e+04 |
|    elapsed_steps     | 752640   |
-----------------------------------
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 755200/1000000 [8:50:11<4:11:33, 16.22steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757760/1000000 [8:51:21<3:27:10, 19.49steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757760/1000000 [8:51:40<3:27:10, 19.49steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:52:27<2:54:25, 22.90steps/s]                                                                76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:52:27<2:54:25, 22.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 181      |
|    Return            | -139     |
|    NonzeroRewards    | 181      |
|    DiscountedReturn  | -139     |
|    Success           | 0.163    |
|    SuccessLength     | 181      |
| algo/                |          |
|    critic_loss       | 0.751    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.345    |
|    max_target_q      | -2.46    |
|    min_target_q      | -53.7    |
|    max_reward        | -0.236   |
|    min_reward        | -1.56    |
|    encoder_grad_norm | 15.5     |
|    q1_grad_norm      | 6.87     |
|    q2_grad_norm      | 6.61     |
|    actor_loss        | 25       |
|    ent_coeff         | 0.0314   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0804   |
|    n_updates         | 23520    |
| time/                |          |
|    iterations        | 297      |
|    fps               | 37.5     |
|    elapsed_time      | 3.19e+04 |
|    elapsed_steps     | 760320   |
-----------------------------------
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:52:40<2:54:25, 22.90steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 762880/1000000 [8:53:38<2:33:31, 25.74steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 762880/1000000 [8:53:50<2:33:31, 25.74steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765440/1000000 [8:54:57<2:22:30, 27.43steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765440/1000000 [8:55:10<2:22:30, 27.43steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:56:07<2:10:40, 29.59steps/s]                                                                77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:56:07<2:10:40, 29.59steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -144     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -144     |
|    Success           | 0.122    |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.749    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.342    |
|    max_target_q      | -2.77    |
|    min_target_q      | -54.8    |
|    max_reward        | -0.23    |
|    min_reward        | -1.59    |
|    encoder_grad_norm | 14.5     |
|    q1_grad_norm      | 5.86     |
|    q2_grad_norm      | 5.66     |
|    actor_loss        | 25.1     |
|    ent_coeff         | 0.0312   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0812   |
|    n_updates         | 23760    |
| time/                |          |
|    iterations        | 300      |
|    fps               | 34.9     |
|    elapsed_time      | 3.22e+04 |
|    elapsed_steps     | 768000   |
-----------------------------------
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:56:20<2:10:40, 29.59steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770560/1000000 [8:57:18<2:01:55, 31.36steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770560/1000000 [8:57:30<2:01:55, 31.36steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_770560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 773120/1000000 [9:02:48<3:50:51, 16.38steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:03:58<3:10:14, 19.65steps/s]                                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:03:58<3:10:14, 19.65steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -146     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0513   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.754    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.343    |
|    max_target_q      | -2.72    |
|    min_target_q      | -54.7    |
|    max_reward        | -0.236   |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 14.9     |
|    q1_grad_norm      | 6.61     |
|    q2_grad_norm      | 6.4      |
|    actor_loss        | 25.3     |
|    ent_coeff         | 0.0311   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.08     |
|    n_updates         | 24000    |
| eval/                |          |
|    Length            | 174      |
|    Return            | -128     |
|    NonzeroRewards    | 174      |
|    DiscountedReturn  | -128     |
|    Success           | 0.211    |
|    SuccessLength     | 174      |
| time/                |          |
|    iterations        | 303      |
|    fps               | 16.3     |
|    elapsed_time      | 3.26e+04 |
|    elapsed_steps     | 775680   |
-----------------------------------
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:04:10<3:10:14, 19.65steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778240/1000000 [9:05:03<2:40:01, 23.10steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778240/1000000 [9:05:20<2:40:01, 23.10steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780800/1000000 [9:06:12<2:20:19, 26.03steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780800/1000000 [9:06:30<2:20:19, 26.03steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:07:26<2:08:12, 28.16steps/s]                                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:07:26<2:08:12, 28.16steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -152     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -152     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.751    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.337    |
|    max_target_q      | -2.74    |
|    min_target_q      | -55.2    |
|    max_reward        | -0.235   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 14.5     |
|    q1_grad_norm      | 5.84     |
|    q2_grad_norm      | 5.63     |
|    actor_loss        | 25.4     |
|    ent_coeff         | 0.0309   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.081    |
|    n_updates         | 24240    |
| time/                |          |
|    iterations        | 306      |
|    fps               | 36.9     |
|    elapsed_time      | 3.28e+04 |
|    elapsed_steps     | 783360   |
-----------------------------------
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:07:40<2:08:12, 28.16steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785920/1000000 [9:08:39<1:59:19, 29.90steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785920/1000000 [9:08:50<1:59:19, 29.90steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788480/1000000 [9:09:52<1:52:28, 31.34steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_788480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788480/1000000 [9:10:10<1:52:28, 31.34steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791040/1000000 [9:15:30<3:35:47, 16.14steps/s]                                                                79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791040/1000000 [9:15:30<3:35:47, 16.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -146     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0769   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.743    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.337    |
|    max_target_q      | -2.56    |
|    min_target_q      | -55.8    |
|    max_reward        | -0.238   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 13.9     |
|    q1_grad_norm      | 5.65     |
|    q2_grad_norm      | 5.47     |
|    actor_loss        | 25.5     |
|    ent_coeff         | 0.0308   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0804   |
|    n_updates         | 24480    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -151     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -151     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 309      |
|    fps               | 15.9     |
|    elapsed_time      | 3.33e+04 |
|    elapsed_steps     | 791040   |
-----------------------------------
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793600/1000000 [9:16:39<2:56:59, 19.44steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793600/1000000 [9:16:50<2:56:59, 19.44steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796160/1000000 [9:17:50<2:30:45, 22.54steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796160/1000000 [9:18:00<2:30:45, 22.54steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:18:59<2:11:07, 25.58steps/s]                                                                80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:18:59<2:11:07, 25.58steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -140     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -140     |
|    Success           | 0.0976   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.753    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.331    |
|    max_target_q      | -3.68    |
|    min_target_q      | -56.6    |
|    max_reward        | -0.229   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 13.1     |
|    q1_grad_norm      | 4.53     |
|    q2_grad_norm      | 4.39     |
|    actor_loss        | 25.6     |
|    ent_coeff         | 0.0306   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0818   |
|    n_updates         | 24720    |
| time/                |          |
|    iterations        | 312      |
|    fps               | 36.8     |
|    elapsed_time      | 3.35e+04 |
|    elapsed_steps     | 798720   |
-----------------------------------
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:19:10<2:11:07, 25.58steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801280/1000000 [9:20:10<1:58:19, 27.99steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801280/1000000 [9:20:20<1:58:19, 27.99steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803840/1000000 [9:21:19<1:48:22, 30.17steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803840/1000000 [9:21:30<1:48:22, 30.17steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:22:30<1:41:30, 31.79steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:22:40<1:41:30, 31.79steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_806400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:26:52<1:41:30, 31.79steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -141     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -141     |
|    Success           | 0.119    |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.8      |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.329    |
|    max_target_q      | -4.36    |
|    min_target_q      | -57.2    |
|    max_reward        | -0.227   |
|    min_reward        | -1.57    |
|    encoder_grad_norm | 16.9     |
|    q1_grad_norm      | 7.59     |
|    q2_grad_norm      | 7.33     |
|    actor_loss        | 25.8     |
|    ent_coeff         | 0.0305   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0825   |
|    n_updates         | 24960    |
| eval/                |          |
|    Length            | 180      |
|    Return            | -137     |
|    NonzeroRewards    | 180      |
|    DiscountedReturn  | -137     |
|    Success           | 0.167    |
|    SuccessLength     | 180      |
| time/                |          |
|    iterations        | 315      |
|    fps               | 16.2     |
|    elapsed_time      | 3.4e+04  |
|    elapsed_steps     | 806400   |
-----------------------------------
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 808960/1000000 [9:27:57<3:12:13, 16.56steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811520/1000000 [9:29:08<2:38:56, 19.76steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811520/1000000 [9:29:20<2:38:56, 19.76steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:30:13<2:13:10, 23.27steps/s]                                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:30:13<2:13:10, 23.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -139     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -139     |
|    Success           | 0.0789   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.768    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.326    |
|    max_target_q      | -5.14    |
|    min_target_q      | -57.3    |
|    max_reward        | -0.233   |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 14.5     |
|    q1_grad_norm      | 6.46     |
|    q2_grad_norm      | 6.24     |
|    actor_loss        | 25.8     |
|    ent_coeff         | 0.0303   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0817   |
|    n_updates         | 25200    |
| time/                |          |
|    iterations        | 318      |
|    fps               | 38.2     |
|    elapsed_time      | 3.42e+04 |
|    elapsed_steps     | 814080   |
-----------------------------------
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:30:30<2:13:10, 23.27steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816640/1000000 [9:31:23<1:56:55, 26.14steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816640/1000000 [9:31:40<1:56:55, 26.14steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819200/1000000 [9:32:33<1:45:39, 28.52steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819200/1000000 [9:32:50<1:45:39, 28.52steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:33:42<1:36:44, 30.71steps/s]                                                                82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:33:42<1:36:44, 30.71steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -147     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0526   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.747    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.325    |
|    max_target_q      | -5.28    |
|    min_target_q      | -58.2    |
|    max_reward        | -0.225   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 14.1     |
|    q1_grad_norm      | 5.46     |
|    q2_grad_norm      | 5.28     |
|    actor_loss        | 26       |
|    ent_coeff         | 0.0302   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0817   |
|    n_updates         | 25440    |
| time/                |          |
|    iterations        | 321      |
|    fps               | 36.8     |
|    elapsed_time      | 3.44e+04 |
|    elapsed_steps     | 821760   |
-----------------------------------
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:34:00<1:36:44, 30.71steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824320/1000000 [9:34:48<1:29:22, 32.76steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824320/1000000 [9:35:00<1:29:22, 32.76steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_824320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 826880/1000000 [9:40:25<2:55:40, 16.42steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:41:33<2:23:55, 19.75steps/s]                                                                83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:41:33<2:23:55, 19.75steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -148     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0714   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.749    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.32     |
|    max_target_q      | -6.09    |
|    min_target_q      | -58.3    |
|    max_reward        | -0.23    |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 13.5     |
|    q1_grad_norm      | 5.18     |
|    q2_grad_norm      | 5.01     |
|    actor_loss        | 26.1     |
|    ent_coeff         | 0.03     |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0836   |
|    n_updates         | 25680    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -149     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -149     |
|    Success           | 0.111    |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 324      |
|    fps               | 16.3     |
|    elapsed_time      | 3.49e+04 |
|    elapsed_steps     | 829440   |
-----------------------------------
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:41:50<2:23:55, 19.75steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832000/1000000 [9:42:39<2:00:45, 23.19steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832000/1000000 [9:42:50<2:00:45, 23.19steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834560/1000000 [9:43:47<1:45:17, 26.19steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834560/1000000 [9:44:00<1:45:17, 26.19steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:45:07<1:37:51, 27.74steps/s]                                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:45:07<1:37:51, 27.74steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 189      |
|    Return            | -142     |
|    NonzeroRewards    | 189      |
|    DiscountedReturn  | -142     |
|    Success           | 0.122    |
|    SuccessLength     | 189      |
| algo/                |          |
|    critic_loss       | 0.809    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.315    |
|    max_target_q      | -6.18    |
|    min_target_q      | -58.7    |
|    max_reward        | -0.222   |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 14.3     |
|    q1_grad_norm      | 4.47     |
|    q2_grad_norm      | 4.33     |
|    actor_loss        | 26.1     |
|    ent_coeff         | 0.0299   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0853   |
|    n_updates         | 25920    |
| time/                |          |
|    iterations        | 327      |
|    fps               | 36       |
|    elapsed_time      | 3.51e+04 |
|    elapsed_steps     | 837120   |
-----------------------------------
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:45:20<1:37:51, 27.74steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839680/1000000 [9:46:20<1:30:32, 29.51steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839680/1000000 [9:46:30<1:30:32, 29.51steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842240/1000000 [9:47:32<1:24:20, 31.18steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_842240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842240/1000000 [9:47:50<1:24:20, 31.18steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844800/1000000 [9:53:14<2:41:46, 15.99steps/s]                                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844800/1000000 [9:53:14<2:41:46, 15.99steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -143     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -143     |
|    Success           | 0.0263   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.811    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.313    |
|    max_target_q      | -5.97    |
|    min_target_q      | -59.2    |
|    max_reward        | -0.213   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 15.3     |
|    q1_grad_norm      | 6.54     |
|    q2_grad_norm      | 6.29     |
|    actor_loss        | 26.2     |
|    ent_coeff         | 0.0298   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0843   |
|    n_updates         | 26160    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -143     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -143     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 330      |
|    fps               | 15.8     |
|    elapsed_time      | 3.56e+04 |
|    elapsed_steps     | 844800   |
-----------------------------------
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847360/1000000 [9:54:21<2:11:28, 19.35steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847360/1000000 [9:54:40<2:11:28, 19.35steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849920/1000000 [9:55:29<1:50:28, 22.64steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849920/1000000 [9:55:40<1:50:28, 22.64steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [9:56:40<1:36:24, 25.50steps/s]                                                                85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [9:56:40<1:36:24, 25.50steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -149     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -149     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.776    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.312    |
|    max_target_q      | -6.53    |
|    min_target_q      | -59.6    |
|    max_reward        | -0.23    |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 13.4     |
|    q1_grad_norm      | 5.06     |
|    q2_grad_norm      | 4.88     |
|    actor_loss        | 26.4     |
|    ent_coeff         | 0.0296   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0845   |
|    n_updates         | 26400    |
| time/                |          |
|    iterations        | 333      |
|    fps               | 37.2     |
|    elapsed_time      | 3.58e+04 |
|    elapsed_steps     | 852480   |
-----------------------------------
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [9:56:50<1:36:24, 25.50steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855040/1000000 [9:57:50<1:26:04, 28.07steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855040/1000000 [9:58:00<1:26:04, 28.07steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857600/1000000 [9:59:05<1:20:01, 29.66steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857600/1000000 [9:59:21<1:20:01, 29.66steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:00:18<1:15:03, 31.05steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:00:31<1:15:03, 31.05steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_860160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:05:06<1:15:03, 31.05steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -137     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -137     |
|    Success           | 0.0513   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.757    |
|    mean_entropy      | 10.3     |
|    mean_ent_bonus    | 0.303    |
|    max_target_q      | -6.63    |
|    min_target_q      | -60.1    |
|    max_reward        | -0.225   |
|    min_reward        | -1.56    |
|    encoder_grad_norm | 13.7     |
|    q1_grad_norm      | 5.06     |
|    q2_grad_norm      | 4.87     |
|    actor_loss        | 26.5     |
|    ent_coeff         | 0.0295   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0859   |
|    n_updates         | 26640    |
| eval/                |          |
|    Length            | 186      |
|    Return            | -143     |
|    NonzeroRewards    | 186      |
|    DiscountedReturn  | -143     |
|    Success           | 0.111    |
|    SuccessLength     | 186      |
| time/                |          |
|    iterations        | 336      |
|    fps               | 15.2     |
|    elapsed_time      | 3.63e+04 |
|    elapsed_steps     | 860160   |
-----------------------------------
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 862720/1000000 [10:06:13<2:26:39, 15.60steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865280/1000000 [10:07:18<1:57:58, 19.03steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865280/1000000 [10:07:31<1:57:58, 19.03steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:08:27<1:38:38, 22.33steps/s]                                                                 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:08:27<1:38:38, 22.33steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -146     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -146     |
|    Success           | 0.075    |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.787    |
|    mean_entropy      | 10.4     |
|    mean_ent_bonus    | 0.304    |
|    max_target_q      | -6.67    |
|    min_target_q      | -60.8    |
|    max_reward        | -0.221   |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 14.7     |
|    q1_grad_norm      | 5.41     |
|    q2_grad_norm      | 5.2      |
|    actor_loss        | 26.6     |
|    ent_coeff         | 0.0293   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0853   |
|    n_updates         | 26880    |
| time/                |          |
|    iterations        | 339      |
|    fps               | 38.3     |
|    elapsed_time      | 3.65e+04 |
|    elapsed_steps     | 867840   |
-----------------------------------
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:08:41<1:38:38, 22.33steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870400/1000000 [10:09:46<1:27:52, 24.58steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870400/1000000 [10:10:01<1:27:52, 24.58steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872960/1000000 [10:10:59<1:18:15, 27.06steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872960/1000000 [10:11:11<1:18:15, 27.06steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:12:13<1:11:47, 28.90steps/s]                                                                 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:12:13<1:11:47, 28.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -148     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0769   |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.781    |
|    mean_entropy      | 10.4     |
|    mean_ent_bonus    | 0.302    |
|    max_target_q      | -6.75    |
|    min_target_q      | -60.8    |
|    max_reward        | -0.226   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 14.1     |
|    q1_grad_norm      | 5.24     |
|    q2_grad_norm      | 5.05     |
|    actor_loss        | 26.7     |
|    ent_coeff         | 0.0292   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0856   |
|    n_updates         | 27120    |
| time/                |          |
|    iterations        | 342      |
|    fps               | 33.9     |
|    elapsed_time      | 3.67e+04 |
|    elapsed_steps     | 875520   |
-----------------------------------
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:12:31<1:11:47, 28.90steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878080/1000000 [10:13:25<1:06:18, 30.64steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878080/1000000 [10:13:41<1:06:18, 30.64steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_878080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 880640/1000000 [10:19:42<2:13:22, 14.92steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:20:51<1:46:59, 18.20steps/s]                                                                 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:20:51<1:46:59, 18.20steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 188      |
|    Return            | -136     |
|    NonzeroRewards    | 188      |
|    DiscountedReturn  | -136     |
|    Success           | 0.119    |
|    SuccessLength     | 187      |
| algo/                |          |
|    critic_loss       | 0.784    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.305    |
|    max_target_q      | -6.89    |
|    min_target_q      | -61.2    |
|    max_reward        | -0.23    |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 14.7     |
|    q1_grad_norm      | 6.21     |
|    q2_grad_norm      | 6        |
|    actor_loss        | 26.9     |
|    ent_coeff         | 0.0291   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0832   |
|    n_updates         | 27360    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -143     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -143     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 345      |
|    fps               | 14.8     |
|    elapsed_time      | 3.73e+04 |
|    elapsed_steps     | 883200   |
-----------------------------------
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:21:11<1:46:59, 18.20steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885760/1000000 [10:22:01<1:29:02, 21.38steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885760/1000000 [10:22:21<1:29:02, 21.38steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888320/1000000 [10:23:11<1:16:06, 24.46steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888320/1000000 [10:23:31<1:16:06, 24.46steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:24:19<1:06:37, 27.30steps/s]                                                                 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:24:19<1:06:37, 27.30steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -150     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.843    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.304    |
|    max_target_q      | -7       |
|    min_target_q      | -61.6    |
|    max_reward        | -0.222   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 15.3     |
|    q1_grad_norm      | 6.47     |
|    q2_grad_norm      | 6.24     |
|    actor_loss        | 27.1     |
|    ent_coeff         | 0.0289   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0815   |
|    n_updates         | 27600    |
| time/                |          |
|    iterations        | 348      |
|    fps               | 36.8     |
|    elapsed_time      | 3.75e+04 |
|    elapsed_steps     | 890880   |
-----------------------------------
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:24:31<1:06:37, 27.30steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893440/1000000 [10:25:32<1:00:34, 29.32steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893440/1000000 [10:25:51<1:00:34, 29.32steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896000/1000000 [10:26:41<55:33, 31.20steps/s]  RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_896000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896000/1000000 [10:27:01<55:33, 31.20steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898560/1000000 [10:32:30<1:46:59, 15.80steps/s]                                                                 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898560/1000000 [10:32:30<1:46:59, 15.80steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -141     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -141     |
|    Success           | 0.0789   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.802    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.303    |
|    max_target_q      | -7.44    |
|    min_target_q      | -61.4    |
|    max_reward        | -0.218   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 14.3     |
|    q1_grad_norm      | 5.47     |
|    q2_grad_norm      | 5.3      |
|    actor_loss        | 27.2     |
|    ent_coeff         | 0.0288   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0809   |
|    n_updates         | 27840    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 351      |
|    fps               | 15.7     |
|    elapsed_time      | 3.8e+04  |
|    elapsed_steps     | 898560   |
-----------------------------------
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901120/1000000 [10:33:38<1:26:06, 19.14steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901120/1000000 [10:33:51<1:26:06, 19.14steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903680/1000000 [10:34:45<1:11:20, 22.50steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903680/1000000 [10:35:01<1:11:20, 22.50steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:35:59<1:02:11, 25.13steps/s]                                                                 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:35:59<1:02:11, 25.13steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -144     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -144     |
|    Success           | 0.0976   |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.823    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.304    |
|    max_target_q      | -7.44    |
|    min_target_q      | -62.4    |
|    max_reward        | -0.216   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 14.3     |
|    q1_grad_norm      | 5.96     |
|    q2_grad_norm      | 5.73     |
|    actor_loss        | 27.4     |
|    ent_coeff         | 0.0286   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0794   |
|    n_updates         | 28080    |
| time/                |          |
|    iterations        | 354      |
|    fps               | 36.7     |
|    elapsed_time      | 3.82e+04 |
|    elapsed_steps     | 906240   |
-----------------------------------
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:36:11<1:02:11, 25.13steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908800/1000000 [10:37:11<55:14, 27.51steps/s]   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908800/1000000 [10:37:31<55:14, 27.51steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911360/1000000 [10:38:24<50:11, 29.43steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911360/1000000 [10:38:41<50:11, 29.43steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:39:35<45:57, 31.22steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:39:51<45:57, 31.22steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_913920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:44:26<45:57, 31.22steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -143     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -143     |
|    Success           | 0.119    |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.857    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.301    |
|    max_target_q      | -7.07    |
|    min_target_q      | -62.3    |
|    max_reward        | -0.229   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 15.2     |
|    q1_grad_norm      | 5.71     |
|    q2_grad_norm      | 5.48     |
|    actor_loss        | 27.5     |
|    ent_coeff         | 0.0285   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0803   |
|    n_updates         | 28320    |
| eval/                |          |
|    Length            | 157      |
|    Return            | -108     |
|    NonzeroRewards    | 157      |
|    DiscountedReturn  | -108     |
|    Success           | 0.389    |
|    SuccessLength     | 157      |
| time/                |          |
|    iterations        | 357      |
|    fps               | 15.2     |
|    elapsed_time      | 3.87e+04 |
|    elapsed_steps     | 913920   |
-----------------------------------
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 916480/1000000 [10:45:36<1:30:10, 15.44steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919040/1000000 [10:46:53<1:13:17, 18.41steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919040/1000000 [10:47:11<1:13:17, 18.41steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:48:12<1:01:47, 21.15steps/s]                                                                 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:48:12<1:01:47, 21.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -137     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -137     |
|    Success           | 0.1      |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.84     |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.301    |
|    max_target_q      | -7.32    |
|    min_target_q      | -62.6    |
|    max_reward        | -0.223   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 14       |
|    q1_grad_norm      | 5.23     |
|    q2_grad_norm      | 5.04     |
|    actor_loss        | 27.7     |
|    ent_coeff         | 0.0284   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0789   |
|    n_updates         | 28560    |
| time/                |          |
|    iterations        | 360      |
|    fps               | 34       |
|    elapsed_time      | 3.89e+04 |
|    elapsed_steps     | 921600   |
-----------------------------------
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:48:31<1:01:47, 21.15steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924160/1000000 [10:49:24<52:35, 24.04steps/s]   92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924160/1000000 [10:49:41<52:35, 24.04steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926720/1000000 [10:50:35<45:43, 26.71steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926720/1000000 [10:50:51<45:43, 26.71steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:51:47<40:44, 28.94steps/s]                                                               93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:51:47<40:44, 28.94steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -150     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -150     |
|    Success           | 0.05     |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.802    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.3      |
|    max_target_q      | -6.95    |
|    min_target_q      | -62.7    |
|    max_reward        | -0.219   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 14.2     |
|    q1_grad_norm      | 5.04     |
|    q2_grad_norm      | 4.88     |
|    actor_loss        | 27.9     |
|    ent_coeff         | 0.0282   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.078    |
|    n_updates         | 28800    |
| time/                |          |
|    iterations        | 363      |
|    fps               | 35.8     |
|    elapsed_time      | 3.91e+04 |
|    elapsed_steps     | 929280   |
-----------------------------------
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:52:01<40:44, 28.94steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931840/1000000 [10:52:53<36:21, 31.24steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_931840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931840/1000000 [10:53:11<36:21, 31.24steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 934400/1000000 [10:58:49<1:10:01, 15.61steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:00:01<56:02, 18.75steps/s]                                                                 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:00:01<56:02, 18.75steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -142     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -142     |
|    Success           | 0.105    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.874    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.302    |
|    max_target_q      | -7.03    |
|    min_target_q      | -62.4    |
|    max_reward        | -0.229   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 15.2     |
|    q1_grad_norm      | 5.41     |
|    q2_grad_norm      | 5.24     |
|    actor_loss        | 28.1     |
|    ent_coeff         | 0.0281   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0788   |
|    n_updates         | 29040    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -148     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0556   |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 366      |
|    fps               | 15.5     |
|    elapsed_time      | 3.96e+04 |
|    elapsed_steps     | 936960   |
-----------------------------------
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:00:21<56:02, 18.75steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939520/1000000 [11:01:11<45:53, 21.96steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939520/1000000 [11:01:31<45:53, 21.96steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942080/1000000 [11:02:18<38:20, 25.18steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942080/1000000 [11:02:31<38:20, 25.18steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:03:27<33:03, 27.91steps/s]                                                               94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:03:27<33:03, 27.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -146     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -146     |
|    Success           | 0.075    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.851    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.306    |
|    max_target_q      | -7.19    |
|    min_target_q      | -62.3    |
|    max_reward        | -0.216   |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 15.5     |
|    q1_grad_norm      | 6.68     |
|    q2_grad_norm      | 6.48     |
|    actor_loss        | 28.3     |
|    ent_coeff         | 0.028    |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0768   |
|    n_updates         | 29280    |
| time/                |          |
|    iterations        | 369      |
|    fps               | 37.4     |
|    elapsed_time      | 3.98e+04 |
|    elapsed_steps     | 944640   |
-----------------------------------
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:03:41<33:03, 27.91steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947200/1000000 [11:04:33<28:56, 30.41steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947200/1000000 [11:04:51<28:56, 30.41steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949760/1000000 [11:05:42<26:01, 32.18steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949760/1000000 [11:06:01<26:01, 32.18steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_949760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952320/1000000 [11:11:21<48:50, 16.27steps/s]                                                               95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952320/1000000 [11:11:21<48:50, 16.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -151     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -151     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.885    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.306    |
|    max_target_q      | -7.2     |
|    min_target_q      | -62.4    |
|    max_reward        | -0.218   |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 15.6     |
|    q1_grad_norm      | 5.97     |
|    q2_grad_norm      | 5.75     |
|    actor_loss        | 28.5     |
|    ent_coeff         | 0.0278   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0747   |
|    n_updates         | 29520    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -150     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -150     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 372      |
|    fps               | 16.2     |
|    elapsed_time      | 4.03e+04 |
|    elapsed_steps     | 952320   |
-----------------------------------
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954880/1000000 [11:12:31<38:30, 19.53steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954880/1000000 [11:12:51<38:30, 19.53steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957440/1000000 [11:13:39<31:08, 22.78steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957440/1000000 [11:13:51<31:08, 22.78steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:14:52<26:08, 25.49steps/s]                                                               96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:14:52<26:08, 25.49steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -144     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -144     |
|    Success           | 0.0952   |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.893    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.304    |
|    max_target_q      | -7.58    |
|    min_target_q      | -62.6    |
|    max_reward        | -0.226   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 16.1     |
|    q1_grad_norm      | 7.38     |
|    q2_grad_norm      | 7.11     |
|    actor_loss        | 28.6     |
|    ent_coeff         | 0.0277   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0757   |
|    n_updates         | 29760    |
| time/                |          |
|    iterations        | 375      |
|    fps               | 36.4     |
|    elapsed_time      | 4.05e+04 |
|    elapsed_steps     | 960000   |
-----------------------------------
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:15:11<26:08, 25.49steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 962560/1000000 [11:16:02<22:13, 28.07steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 962560/1000000 [11:16:21<22:13, 28.07steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965120/1000000 [11:17:11<19:14, 30.21steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965120/1000000 [11:17:31<19:14, 30.21steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:18:17<16:39, 32.33steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:18:31<16:39, 32.33steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_967680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:22:50<16:39, 32.33steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -150     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -150     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.948    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.299    |
|    max_target_q      | -7.15    |
|    min_target_q      | -63.3    |
|    max_reward        | -0.228   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 16.3     |
|    q1_grad_norm      | 6.2      |
|    q2_grad_norm      | 5.96     |
|    actor_loss        | 28.9     |
|    ent_coeff         | 0.0276   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0745   |
|    n_updates         | 30000    |
| eval/                |          |
|    Length            | 192      |
|    Return            | -141     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -141     |
|    Success           | 0.111    |
|    SuccessLength     | 192      |
| time/                |          |
|    iterations        | 378      |
|    fps               | 16.1     |
|    elapsed_time      | 4.1e+04  |
|    elapsed_steps     | 967680   |
-----------------------------------
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 970240/1000000 [11:24:02<30:45, 16.12steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972800/1000000 [11:25:12<23:24, 19.36steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972800/1000000 [11:25:31<23:24, 19.36steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:26:25<18:22, 22.36steps/s]                                                               98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:26:25<18:22, 22.36steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -138     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -138     |
|    Success           | 0.0488   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.853    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.298    |
|    max_target_q      | -7.13    |
|    min_target_q      | -64.4    |
|    max_reward        | -0.224   |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 15       |
|    q1_grad_norm      | 5.22     |
|    q2_grad_norm      | 5.04     |
|    actor_loss        | 29.1     |
|    ent_coeff         | 0.0274   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0727   |
|    n_updates         | 30240    |
| time/                |          |
|    iterations        | 381      |
|    fps               | 35.6     |
|    elapsed_time      | 4.12e+04 |
|    elapsed_steps     | 975360   |
-----------------------------------
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:26:41<18:22, 22.36steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977920/1000000 [11:27:37<14:35, 25.21steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977920/1000000 [11:27:51<14:35, 25.21steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980480/1000000 [11:28:52<11:55, 27.29steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980480/1000000 [11:29:11<11:55, 27.29steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:30:06<09:41, 29.18steps/s]                                                               98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:30:06<09:41, 29.18steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -146     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.932    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.299    |
|    max_target_q      | -6.7     |
|    min_target_q      | -64      |
|    max_reward        | -0.21    |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 16.5     |
|    q1_grad_norm      | 5.7      |
|    q2_grad_norm      | 5.49     |
|    actor_loss        | 29.3     |
|    ent_coeff         | 0.0273   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0727   |
|    n_updates         | 30480    |
| time/                |          |
|    iterations        | 384      |
|    fps               | 34.8     |
|    elapsed_time      | 4.14e+04 |
|    elapsed_steps     | 983040   |
-----------------------------------
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:30:21<09:41, 29.18steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985600/1000000 [11:31:21<07:51, 30.55steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985600/1000000 [11:31:31<07:51, 30.55steps/s]Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_985600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 988160/1000000 [11:37:16<12:44, 15.49steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:38:24<08:13, 18.81steps/s]                                                               99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:38:24<08:13, 18.81steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -146     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -146     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.849    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.297    |
|    max_target_q      | -6.54    |
|    min_target_q      | -64.2    |
|    max_reward        | -0.217   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 15.4     |
|    q1_grad_norm      | 6.18     |
|    q2_grad_norm      | 5.93     |
|    actor_loss        | 29.5     |
|    ent_coeff         | 0.0272   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0714   |
|    n_updates         | 30720    |
| eval/                |          |
|    Length            | 187      |
|    Return            | -134     |
|    NonzeroRewards    | 187      |
|    DiscountedReturn  | -134     |
|    Success           | 0.278    |
|    SuccessLength     | 187      |
| time/                |          |
|    iterations        | 387      |
|    fps               | 15.4     |
|    elapsed_time      | 4.19e+04 |
|    elapsed_steps     | 990720   |
-----------------------------------
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:38:41<08:13, 18.81steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993280/1000000 [11:39:31<05:02, 22.18steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993280/1000000 [11:39:51<05:02, 22.18steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995840/1000000 [11:40:38<02:43, 25.41steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995840/1000000 [11:40:51<02:43, 25.41steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:41:44<00:56, 28.29steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/r9fm25ag/nominal/policy_step_998400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:42:01<00:56, 28.29steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:46:19<00:56, 28.29steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -141     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -141     |
|    Success           | 0.0976   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.932    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.296    |
|    max_target_q      | -6.3     |
|    min_target_q      | -64.7    |
|    max_reward        | -0.214   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 17.4     |
|    q1_grad_norm      | 6.64     |
|    q2_grad_norm      | 6.38     |
|    actor_loss        | 29.7     |
|    ent_coeff         | 0.027    |
|    ent_coeff_loss    | -112     |
|    pi_grad_norm      | 0.0715   |
|    n_updates         | 30960    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -144     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -144     |
|    Success           | 0.111    |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 390      |
|    fps               | 16.2     |
|    elapsed_time      | 4.24e+04 |
|    elapsed_steps     | 998400   |
-----------------------------------
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:46:19<01:07, 23.56steps/s]
RLRunner: Finished training.
RLRunner: Log files saved to /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-r9fm25ag/files
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/along_view+50/success_rate â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:         eval/fov30/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ˆâ–
wandb:         eval/fov70/success_rate â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:       eval/nominal/success_rate â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ˆâ–â–â–ˆ
wandb:    eval/roll+15deg/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–ˆâ–â–
wandb:    eval/roll+30deg/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–ˆâ–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–
wandb:    eval/shift+x+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–…â–â–ˆâ–â–â–
wandb:    eval/shift+y+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–â–
wandb:    eval/shift+z+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–
wandb: 
wandb: Run summary:
wandb: eval/along_view+50/success_rate 0
wandb:         eval/fov30/success_rate 0
wandb:         eval/fov70/success_rate 0
wandb:       eval/nominal/success_rate 1
wandb:    eval/roll+15deg/success_rate 0
wandb:    eval/roll+30deg/success_rate 0
wandb:    eval/shift+x+50/success_rate 0
wandb:    eval/shift+y+50/success_rate 0
wandb:    eval/shift+z+50/success_rate 0
wandb: 
wandb: ðŸš€ View run vocal-armadillo-988 at: https://wandb.ai/michael-bezick-purdue-university/pprl/runs/r9fm25ag
wandb: â­ï¸ View project at: https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: Synced 7 W&B file(s), 57 media file(s), 0 artifact file(s) and 42 other file(s)
wandb: Find logs at: ./wandb/run-20250908_150535-r9fm25ag/logs
