/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
wandb: Currently logged in as: michael-bezick (michael-bezick-purdue-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: creating run
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-0ny84k5k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-darkness-987
wandb: â­ï¸ View project at https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: ðŸš€ View run at https://wandb.ai/michael-bezick-purdue-university/pprl/runs/0ny84k5k
Group name is:  PCA_push_chair
Instantiating 8 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
BasicSampler: Resetting all environments.
BasicSampler: Resetting agent.
SAC: Given sampler batch size 2560, training batch size 512, and replay ratio 16, there will be 80 updates per iteration.
SAC: Using learnable entropy coefficient with target entropy of -20
RLRunner: Starting training...
RLRunner: Saving log files to /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-0ny84k5k/files
  0%|          | 0/1000000 [00:00<?, ?steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_0.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
wandb: WARNING Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                0%|          | 0/1000000 [04:13<?, ?steps/s]----------------------------------
| eval/               |          |
|    Length           | 200      |
|    Return           | -219     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -219     |
|    Success          | 0        |
|    SuccessLength    | 200      |
| time/               |          |
|    iterations       | 0        |
|    fps              | 0        |
|    elapsed_time     | 254      |
|    elapsed_steps    | 0        |
----------------------------------
For the first 10000 steps, agent will use a fixed std of 0.75 for exploration.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
  0%|          | 2560/1000000 [05:06<33:10:04,  8.35steps/s]  1%|          | 5120/1000000 [06:06<17:27:32, 15.83steps/s]  1%|          | 5120/1000000 [06:20<17:27:32, 15.83steps/s]  1%|          | 7680/1000000 [07:03<12:14:28, 22.52steps/s]                                                              1%|          | 7680/1000000 [07:03<12:14:28, 22.52steps/s]----------------------------------
| rollout/            |          |
|    Length           | 200      |
|    Return           | -216     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -216     |
|    Success          | 0        |
|    SuccessLength    | 200      |
| time/               |          |
|    iterations       | 3        |
|    fps              | 45.3     |
|    elapsed_time     | 423      |
|    elapsed_steps    | 7680     |
----------------------------------
  1%|          | 7680/1000000 [07:20<12:14:28, 22.52steps/s]  1%|          | 10240/1000000 [08:25<10:52:43, 25.27steps/s]  1%|          | 10240/1000000 [08:40<10:52:43, 25.27steps/s]  1%|â–         | 12800/1000000 [09:44<9:59:09, 27.46steps/s]   1%|â–         | 12800/1000000 [10:00<9:59:09, 27.46steps/s]  2%|â–         | 15360/1000000 [11:02<9:23:12, 29.14steps/s]                                                              2%|â–         | 15360/1000000 [11:02<9:23:12, 29.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -214     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -214     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0077   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.68     |
|    max_target_q      | -0.479   |
|    min_target_q      | -0.808   |
|    max_reward        | -0.793   |
|    min_reward        | -1.61    |
|    encoder_grad_norm | 0.0637   |
|    q1_grad_norm      | 0.147    |
|    q2_grad_norm      | 0.172    |
|    actor_loss        | 0.392    |
|    ent_coeff         | 0.0499   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.109    |
|    n_updates         | 240      |
| time/                |          |
|    iterations        | 6        |
|    fps               | 32.2     |
|    elapsed_time      | 662      |
|    elapsed_steps     | 15360    |
-----------------------------------
  2%|â–         | 15360/1000000 [11:20<9:23:12, 29.14steps/s]  2%|â–         | 17920/1000000 [12:17<8:55:25, 30.57steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  2%|â–         | 17920/1000000 [12:30<8:55:25, 30.57steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_17920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  2%|â–         | 20480/1000000 [18:03<17:47:01, 15.30steps/s]  2%|â–         | 23040/1000000 [19:23<14:50:10, 18.29steps/s]                                                               2%|â–         | 23040/1000000 [19:23<14:50:10, 18.29steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -217     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -217     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0046   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.677    |
|    max_target_q      | -1.21    |
|    min_target_q      | -1.91    |
|    max_reward        | -0.802   |
|    min_reward        | -1.59    |
|    encoder_grad_norm | 0.103    |
|    q1_grad_norm      | 0.196    |
|    q2_grad_norm      | 0.151    |
|    actor_loss        | 1.3      |
|    ent_coeff         | 0.0496   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0853   |
|    n_updates         | 480      |
| eval/                |          |
|    Length            | 200      |
|    Return            | -213     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -213     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 9        |
|    fps               | 15.3     |
|    elapsed_time      | 1.16e+03 |
|    elapsed_steps     | 23040    |
-----------------------------------
  2%|â–         | 23040/1000000 [19:40<14:50:10, 18.29steps/s]  3%|â–Ž         | 25600/1000000 [20:41<12:46:07, 21.20steps/s]  3%|â–Ž         | 25600/1000000 [21:00<12:46:07, 21.20steps/s]  3%|â–Ž         | 28160/1000000 [21:53<11:10:19, 24.16steps/s]  3%|â–Ž         | 28160/1000000 [22:10<11:10:19, 24.16steps/s]  3%|â–Ž         | 30720/1000000 [23:08<10:09:17, 26.51steps/s]                                                               3%|â–Ž         | 30720/1000000 [23:08<10:09:17, 26.51steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -210     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -210     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00607  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.674    |
|    max_target_q      | -1.89    |
|    min_target_q      | -2.99    |
|    max_reward        | -0.781   |
|    min_reward        | -1.56    |
|    encoder_grad_norm | 0.2      |
|    q1_grad_norm      | 0.307    |
|    q2_grad_norm      | 0.298    |
|    actor_loss        | 2.18     |
|    ent_coeff         | 0.0494   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0738   |
|    n_updates         | 720      |
| time/                |          |
|    iterations        | 12       |
|    fps               | 34.1     |
|    elapsed_time      | 1.39e+03 |
|    elapsed_steps     | 30720    |
-----------------------------------
  3%|â–Ž         | 30720/1000000 [23:20<10:09:17, 26.51steps/s]  3%|â–Ž         | 33280/1000000 [24:25<9:30:29, 28.24steps/s]   3%|â–Ž         | 33280/1000000 [24:40<9:30:29, 28.24steps/s]  4%|â–Ž         | 35840/1000000 [25:43<9:05:41, 29.45steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_35840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
  4%|â–Ž         | 35840/1000000 [26:00<9:05:41, 29.45steps/s]EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  4%|â–         | 38400/1000000 [31:12<16:40:00, 16.03steps/s]                                                               4%|â–         | 38400/1000000 [31:12<16:40:00, 16.03steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -207     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -207     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00774  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.671    |
|    max_target_q      | -2.48    |
|    min_target_q      | -4.09    |
|    max_reward        | -0.774   |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 0.28     |
|    q1_grad_norm      | 0.39     |
|    q2_grad_norm      | 0.391    |
|    actor_loss        | 3.02     |
|    ent_coeff         | 0.0492   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0659   |
|    n_updates         | 960      |
| eval/                |          |
|    Length            | 200      |
|    Return            | -211     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -211     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 15       |
|    fps               | 15.9     |
|    elapsed_time      | 1.87e+03 |
|    elapsed_steps     | 38400    |
-----------------------------------
  4%|â–         | 40960/1000000 [32:19<13:42:41, 19.43steps/s]  4%|â–         | 40960/1000000 [32:30<13:42:41, 19.43steps/s]  4%|â–         | 43520/1000000 [33:25<11:37:03, 22.87steps/s]  4%|â–         | 43520/1000000 [33:40<11:37:03, 22.87steps/s]  5%|â–         | 46080/1000000 [34:29<10:06:06, 26.23steps/s]                                                               5%|â–         | 46080/1000000 [34:29<10:06:06, 26.23steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -207     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -207     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0104   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.667    |
|    max_target_q      | -3.05    |
|    min_target_q      | -5.17    |
|    max_reward        | -0.736   |
|    min_reward        | -1.58    |
|    encoder_grad_norm | 0.427    |
|    q1_grad_norm      | 0.567    |
|    q2_grad_norm      | 0.572    |
|    actor_loss        | 3.85     |
|    ent_coeff         | 0.0489   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.061    |
|    n_updates         | 1200     |
| time/                |          |
|    iterations        | 18       |
|    fps               | 39       |
|    elapsed_time      | 2.07e+03 |
|    elapsed_steps     | 46080    |
-----------------------------------
  5%|â–         | 46080/1000000 [34:40<10:06:06, 26.23steps/s]  5%|â–         | 48640/1000000 [35:32<9:00:11, 29.35steps/s]   5%|â–         | 48640/1000000 [35:50<9:00:11, 29.35steps/s]  5%|â–Œ         | 51200/1000000 [36:37<8:17:28, 31.79steps/s]  5%|â–Œ         | 51200/1000000 [36:50<8:17:28, 31.79steps/s]  5%|â–Œ         | 53760/1000000 [37:38<7:39:44, 34.30steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  5%|â–Œ         | 53760/1000000 [37:50<7:39:44, 34.30steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_53760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              5%|â–Œ         | 53760/1000000 [41:59<7:39:44, 34.30steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -203     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -203     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0112   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.663    |
|    max_target_q      | -3.59    |
|    min_target_q      | -6.23    |
|    max_reward        | -0.726   |
|    min_reward        | -1.57    |
|    encoder_grad_norm | 0.431    |
|    q1_grad_norm      | 0.518    |
|    q2_grad_norm      | 0.524    |
|    actor_loss        | 4.64     |
|    ent_coeff         | 0.0487   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.057    |
|    n_updates         | 1440     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -207     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -207     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 21       |
|    fps               | 17.1     |
|    elapsed_time      | 2.52e+03 |
|    elapsed_steps     | 53760    |
-----------------------------------
  6%|â–Œ         | 56320/1000000 [43:04<15:22:47, 17.04steps/s]  6%|â–Œ         | 58880/1000000 [44:11<12:46:34, 20.46steps/s]  6%|â–Œ         | 58880/1000000 [44:30<12:46:34, 20.46steps/s]  6%|â–Œ         | 61440/1000000 [45:16<10:54:39, 23.89steps/s]                                                               6%|â–Œ         | 61440/1000000 [45:16<10:54:39, 23.89steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -199     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -199     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0134   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.658    |
|    max_target_q      | -4.09    |
|    min_target_q      | -7.28    |
|    max_reward        | -0.713   |
|    min_reward        | -1.55    |
|    encoder_grad_norm | 0.527    |
|    q1_grad_norm      | 0.585    |
|    q2_grad_norm      | 0.589    |
|    actor_loss        | 5.4      |
|    ent_coeff         | 0.0485   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0544   |
|    n_updates         | 1680     |
| time/                |          |
|    iterations        | 24       |
|    fps               | 39       |
|    elapsed_time      | 2.72e+03 |
|    elapsed_steps     | 61440    |
-----------------------------------
  6%|â–Œ         | 61440/1000000 [45:30<10:54:39, 23.89steps/s]  6%|â–‹         | 64000/1000000 [46:22<9:37:45, 27.00steps/s]   6%|â–‹         | 64000/1000000 [46:40<9:37:45, 27.00steps/s]  7%|â–‹         | 66560/1000000 [47:27<8:42:21, 29.78steps/s]  7%|â–‹         | 66560/1000000 [47:40<8:42:21, 29.78steps/s]  7%|â–‹         | 69120/1000000 [48:35<8:07:05, 31.85steps/s]                                                              7%|â–‹         | 69120/1000000 [48:35<8:07:05, 31.85steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -198     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -198     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0156   |
|    mean_entropy      | 13.4     |
|    mean_ent_bonus    | 0.646    |
|    max_target_q      | -4.53    |
|    min_target_q      | -8.33    |
|    max_reward        | -0.68    |
|    min_reward        | -1.52    |
|    encoder_grad_norm | 0.695    |
|    q1_grad_norm      | 0.716    |
|    q2_grad_norm      | 0.726    |
|    actor_loss        | 6.1      |
|    ent_coeff         | 0.0482   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0578   |
|    n_updates         | 1920     |
| time/                |          |
|    iterations        | 27       |
|    fps               | 38.7     |
|    elapsed_time      | 2.92e+03 |
|    elapsed_steps     | 69120    |
-----------------------------------
  7%|â–‹         | 69120/1000000 [48:50<8:07:05, 31.85steps/s]  7%|â–‹         | 71680/1000000 [49:33<7:26:00, 34.69steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_71680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  7%|â–‹         | 71680/1000000 [49:50<7:26:00, 34.69steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  7%|â–‹         | 74240/1000000 [54:54<14:51:53, 17.30steps/s]  8%|â–Š         | 76800/1000000 [55:56<12:13:22, 20.98steps/s]                                                               8%|â–Š         | 76800/1000000 [55:56<12:13:22, 20.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -199     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -199     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0183   |
|    mean_entropy      | 13.1     |
|    mean_ent_bonus    | 0.631    |
|    max_target_q      | -5       |
|    min_target_q      | -9.34    |
|    max_reward        | -0.68    |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 0.91     |
|    q1_grad_norm      | 0.916    |
|    q2_grad_norm      | 0.938    |
|    actor_loss        | 6.77     |
|    ent_coeff         | 0.048    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0627   |
|    n_updates         | 2160     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -200     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -200     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 30       |
|    fps               | 17.4     |
|    elapsed_time      | 3.36e+03 |
|    elapsed_steps     | 76800    |
-----------------------------------
  8%|â–Š         | 76800/1000000 [56:10<12:13:22, 20.98steps/s]  8%|â–Š         | 79360/1000000 [56:55<10:18:55, 24.79steps/s]  8%|â–Š         | 79360/1000000 [57:10<10:18:55, 24.79steps/s]  8%|â–Š         | 81920/1000000 [57:58<9:04:10, 28.12steps/s]   8%|â–Š         | 81920/1000000 [58:10<9:04:10, 28.12steps/s]  8%|â–Š         | 84480/1000000 [59:02<8:15:54, 30.77steps/s]                                                              8%|â–Š         | 84480/1000000 [59:02<8:15:54, 30.77steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -196     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -196     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.021    |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.623    |
|    max_target_q      | -5.42    |
|    min_target_q      | -10.3    |
|    max_reward        | -0.669   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 0.981    |
|    q1_grad_norm      | 0.956    |
|    q2_grad_norm      | 0.976    |
|    actor_loss        | 7.39     |
|    ent_coeff         | 0.0478   |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0628   |
|    n_updates         | 2400     |
| time/                |          |
|    iterations        | 33       |
|    fps               | 41.1     |
|    elapsed_time      | 3.54e+03 |
|    elapsed_steps     | 84480    |
-----------------------------------
  8%|â–Š         | 84480/1000000 [59:20<8:15:54, 30.77steps/s]  9%|â–Š         | 87040/1000000 [1:00:09<7:45:21, 32.70steps/s]  9%|â–Š         | 87040/1000000 [1:00:20<7:45:21, 32.70steps/s]  9%|â–‰         | 89600/1000000 [1:01:14<7:19:44, 34.50steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_89600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  9%|â–‰         | 89600/1000000 [1:01:30<7:19:44, 34.50steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  9%|â–‰         | 92160/1000000 [1:06:39<14:43:55, 17.12steps/s]                                                                 9%|â–‰         | 92160/1000000 [1:06:39<14:43:55, 17.12steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -196     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -196     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.025    |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.619    |
|    max_target_q      | -5.82    |
|    min_target_q      | -11.2    |
|    max_reward        | -0.664   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 1.19     |
|    q1_grad_norm      | 1.15     |
|    q2_grad_norm      | 1.18     |
|    actor_loss        | 7.99     |
|    ent_coeff         | 0.0475   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0628   |
|    n_updates         | 2640     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -202     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -202     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 36       |
|    fps               | 16.8     |
|    elapsed_time      | 4e+03    |
|    elapsed_steps     | 92160    |
-----------------------------------
  9%|â–‰         | 94720/1000000 [1:07:49<12:20:20, 20.38steps/s]  9%|â–‰         | 94720/1000000 [1:08:00<12:20:20, 20.38steps/s] 10%|â–‰         | 97280/1000000 [1:08:55<10:32:23, 23.79steps/s] 10%|â–‰         | 97280/1000000 [1:09:10<10:32:23, 23.79steps/s] 10%|â–‰         | 99840/1000000 [1:10:00<9:16:32, 26.96steps/s]                                                                10%|â–‰         | 99840/1000000 [1:10:00<9:16:32, 26.96steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -195     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -195     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.025    |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.614    |
|    max_target_q      | -6.22    |
|    min_target_q      | -12.2    |
|    max_reward        | -0.639   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 0.951    |
|    q1_grad_norm      | 0.856    |
|    q2_grad_norm      | 0.875    |
|    actor_loss        | 8.59     |
|    ent_coeff         | 0.0473   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0637   |
|    n_updates         | 2880     |
| time/                |          |
|    iterations        | 39       |
|    fps               | 38.2     |
|    elapsed_time      | 4.2e+03  |
|    elapsed_steps     | 99840    |
-----------------------------------
 10%|â–‰         | 99840/1000000 [1:10:20<9:16:32, 26.96steps/s] 10%|â–ˆ         | 102400/1000000 [1:11:09<8:28:36, 29.41steps/s] 10%|â–ˆ         | 102400/1000000 [1:11:20<8:28:36, 29.41steps/s] 10%|â–ˆ         | 104960/1000000 [1:12:14<7:48:30, 31.84steps/s] 10%|â–ˆ         | 104960/1000000 [1:12:30<7:48:30, 31.84steps/s] 11%|â–ˆ         | 107520/1000000 [1:13:16<7:16:28, 34.08steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 11%|â–ˆ         | 107520/1000000 [1:13:30<7:16:28, 34.08steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_107520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                11%|â–ˆ         | 107520/1000000 [1:17:35<7:16:28, 34.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -195     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -195     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0296   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.609    |
|    max_target_q      | -6.58    |
|    min_target_q      | -13.1    |
|    max_reward        | -0.587   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 1.21     |
|    q1_grad_norm      | 1.1      |
|    q2_grad_norm      | 1.11     |
|    actor_loss        | 9.16     |
|    ent_coeff         | 0.0471   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0653   |
|    n_updates         | 3120     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -193     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -193     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 42       |
|    fps               | 16.9     |
|    elapsed_time      | 4.66e+03 |
|    elapsed_steps     | 107520   |
-----------------------------------
 11%|â–ˆ         | 110080/1000000 [1:18:41<14:29:13, 17.06steps/s] 11%|â–ˆâ–        | 112640/1000000 [1:19:45<11:57:08, 20.62steps/s] 11%|â–ˆâ–        | 112640/1000000 [1:20:00<11:57:08, 20.62steps/s] 12%|â–ˆâ–        | 115200/1000000 [1:20:52<10:16:20, 23.93steps/s]                                                                 12%|â–ˆâ–        | 115200/1000000 [1:20:52<10:16:20, 23.93steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -194     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -194     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0339   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.604    |
|    max_target_q      | -6.91    |
|    min_target_q      | -13.9    |
|    max_reward        | -0.549   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 1.46     |
|    q1_grad_norm      | 1.32     |
|    q2_grad_norm      | 1.35     |
|    actor_loss        | 9.71     |
|    ent_coeff         | 0.0469   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0664   |
|    n_updates         | 3360     |
| time/                |          |
|    iterations        | 45       |
|    fps               | 39       |
|    elapsed_time      | 4.85e+03 |
|    elapsed_steps     | 115200   |
-----------------------------------
 12%|â–ˆâ–        | 115200/1000000 [1:21:10<10:16:20, 23.93steps/s] 12%|â–ˆâ–        | 117760/1000000 [1:21:57<9:02:35, 27.10steps/s]  12%|â–ˆâ–        | 117760/1000000 [1:22:10<9:02:35, 27.10steps/s] 12%|â–ˆâ–        | 120320/1000000 [1:23:05<8:15:37, 29.58steps/s] 12%|â–ˆâ–        | 120320/1000000 [1:23:20<8:15:37, 29.58steps/s] 12%|â–ˆâ–        | 122880/1000000 [1:24:10<7:37:00, 31.99steps/s]                                                                12%|â–ˆâ–        | 122880/1000000 [1:24:10<7:37:00, 31.99steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -194     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -194     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0339   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.6      |
|    max_target_q      | -7.23    |
|    min_target_q      | -14.8    |
|    max_reward        | -0.538   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 1.2      |
|    q1_grad_norm      | 1.01     |
|    q2_grad_norm      | 1.03     |
|    actor_loss        | 10.3     |
|    ent_coeff         | 0.0467   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0693   |
|    n_updates         | 3600     |
| time/                |          |
|    iterations        | 48       |
|    fps               | 38.8     |
|    elapsed_time      | 5.05e+03 |
|    elapsed_steps     | 122880   |
-----------------------------------
 12%|â–ˆâ–        | 122880/1000000 [1:24:30<7:37:00, 31.99steps/s] 13%|â–ˆâ–Ž        | 125440/1000000 [1:25:17<7:13:18, 33.64steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 13%|â–ˆâ–Ž        | 125440/1000000 [1:25:30<7:13:18, 33.64steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_125440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 13%|â–ˆâ–Ž        | 128000/1000000 [1:30:55<14:37:59, 16.55steps/s] 13%|â–ˆâ–Ž        | 130560/1000000 [1:32:01<12:05:18, 19.98steps/s]                                                                 13%|â–ˆâ–Ž        | 130560/1000000 [1:32:01<12:05:18, 19.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -191     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -191     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0408   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.598    |
|    max_target_q      | -7.55    |
|    min_target_q      | -15.6    |
|    max_reward        | -0.553   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 1.74     |
|    q1_grad_norm      | 1.5      |
|    q2_grad_norm      | 1.53     |
|    actor_loss        | 10.8     |
|    ent_coeff         | 0.0464   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0692   |
|    n_updates         | 3840     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -188     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -188     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 51       |
|    fps               | 16.3     |
|    elapsed_time      | 5.52e+03 |
|    elapsed_steps     | 130560   |
-----------------------------------
 13%|â–ˆâ–Ž        | 130560/1000000 [1:32:20<12:05:18, 19.98steps/s] 13%|â–ˆâ–Ž        | 133120/1000000 [1:33:08<10:18:37, 23.35steps/s] 13%|â–ˆâ–Ž        | 133120/1000000 [1:33:20<10:18:37, 23.35steps/s] 14%|â–ˆâ–Ž        | 135680/1000000 [1:34:13<9:01:53, 26.58steps/s]  14%|â–ˆâ–Ž        | 135680/1000000 [1:34:30<9:01:53, 26.58steps/s] 14%|â–ˆâ–        | 138240/1000000 [1:35:19<8:09:08, 29.36steps/s]                                                                14%|â–ˆâ–        | 138240/1000000 [1:35:19<8:09:08, 29.36steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -188     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -188     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0423   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.597    |
|    max_target_q      | -7.87    |
|    min_target_q      | -16.4    |
|    max_reward        | -0.531   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 1.64     |
|    q1_grad_norm      | 1.42     |
|    q2_grad_norm      | 1.44     |
|    actor_loss        | 11.3     |
|    ent_coeff         | 0.0462   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0664   |
|    n_updates         | 4080     |
| time/                |          |
|    iterations        | 54       |
|    fps               | 38.9     |
|    elapsed_time      | 5.72e+03 |
|    elapsed_steps     | 138240   |
-----------------------------------
 14%|â–ˆâ–        | 138240/1000000 [1:35:30<8:09:08, 29.36steps/s] 14%|â–ˆâ–        | 140800/1000000 [1:36:28<7:37:57, 31.27steps/s] 14%|â–ˆâ–        | 140800/1000000 [1:36:40<7:37:57, 31.27steps/s] 14%|â–ˆâ–        | 143360/1000000 [1:37:30<7:02:23, 33.80steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 14%|â–ˆâ–        | 143360/1000000 [1:37:40<7:02:23, 33.80steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_143360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 15%|â–ˆâ–        | 145920/1000000 [1:43:29<14:54:34, 15.91steps/s]                                                                 15%|â–ˆâ–        | 145920/1000000 [1:43:29<14:54:34, 15.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -186     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -186     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0462   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.595    |
|    max_target_q      | -8.2     |
|    min_target_q      | -17.2    |
|    max_reward        | -0.512   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 1.92     |
|    q1_grad_norm      | 1.72     |
|    q2_grad_norm      | 1.75     |
|    actor_loss        | 11.8     |
|    ent_coeff         | 0.046    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0659   |
|    n_updates         | 4320     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -189     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -189     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 57       |
|    fps               | 15.7     |
|    elapsed_time      | 6.21e+03 |
|    elapsed_steps     | 145920   |
-----------------------------------
 15%|â–ˆâ–        | 148480/1000000 [1:44:36<12:14:55, 19.31steps/s] 15%|â–ˆâ–        | 148480/1000000 [1:44:50<12:14:55, 19.31steps/s] 15%|â–ˆâ–Œ        | 151040/1000000 [1:45:44<10:25:31, 22.62steps/s] 15%|â–ˆâ–Œ        | 151040/1000000 [1:46:00<10:25:31, 22.62steps/s] 15%|â–ˆâ–Œ        | 153600/1000000 [1:46:50<9:06:16, 25.82steps/s]                                                                 15%|â–ˆâ–Œ        | 153600/1000000 [1:46:50<9:06:16, 25.82steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -185     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -185     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0482   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.593    |
|    max_target_q      | -8.49    |
|    min_target_q      | -17.9    |
|    max_reward        | -0.512   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 1.82     |
|    q1_grad_norm      | 1.58     |
|    q2_grad_norm      | 1.6      |
|    actor_loss        | 12.3     |
|    ent_coeff         | 0.0458   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0642   |
|    n_updates         | 4560     |
| time/                |          |
|    iterations        | 60       |
|    fps               | 38.2     |
|    elapsed_time      | 6.41e+03 |
|    elapsed_steps     | 153600   |
-----------------------------------
 15%|â–ˆâ–Œ        | 153600/1000000 [1:47:10<9:06:16, 25.82steps/s] 16%|â–ˆâ–Œ        | 156160/1000000 [1:48:00<8:17:02, 28.30steps/s] 16%|â–ˆâ–Œ        | 156160/1000000 [1:48:20<8:17:02, 28.30steps/s] 16%|â–ˆâ–Œ        | 158720/1000000 [1:49:05<7:33:29, 30.92steps/s] 16%|â–ˆâ–Œ        | 158720/1000000 [1:49:20<7:33:29, 30.92steps/s] 16%|â–ˆâ–Œ        | 161280/1000000 [1:50:05<6:54:21, 33.74steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 16%|â–ˆâ–Œ        | 161280/1000000 [1:50:20<6:54:21, 33.74steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_161280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                16%|â–ˆâ–Œ        | 161280/1000000 [1:54:25<6:54:21, 33.74steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -183     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -183     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.051    |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.59     |
|    max_target_q      | -8.81    |
|    min_target_q      | -18.6    |
|    max_reward        | -0.509   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 1.76     |
|    q1_grad_norm      | 1.5      |
|    q2_grad_norm      | 1.52     |
|    actor_loss        | 12.8     |
|    ent_coeff         | 0.0455   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0634   |
|    n_updates         | 4800     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -181     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -181     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 63       |
|    fps               | 16.9     |
|    elapsed_time      | 6.87e+03 |
|    elapsed_steps     | 161280   |
-----------------------------------
 16%|â–ˆâ–‹        | 163840/1000000 [1:55:28<13:36:42, 17.06steps/s] 17%|â–ˆâ–‹        | 166400/1000000 [1:56:34<11:16:43, 20.53steps/s] 17%|â–ˆâ–‹        | 166400/1000000 [1:56:50<11:16:43, 20.53steps/s] 17%|â–ˆâ–‹        | 168960/1000000 [1:57:40<9:40:09, 23.87steps/s]                                                                 17%|â–ˆâ–‹        | 168960/1000000 [1:57:40<9:40:09, 23.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -179     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -179     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0554   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.586    |
|    max_target_q      | -9.16    |
|    min_target_q      | -19.4    |
|    max_reward        | -0.483   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 1.96     |
|    q1_grad_norm      | 1.63     |
|    q2_grad_norm      | 1.65     |
|    actor_loss        | 13.2     |
|    ent_coeff         | 0.0453   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0626   |
|    n_updates         | 5040     |
| time/                |          |
|    iterations        | 66       |
|    fps               | 39.3     |
|    elapsed_time      | 7.06e+03 |
|    elapsed_steps     | 168960   |
-----------------------------------
 17%|â–ˆâ–‹        | 168960/1000000 [1:58:00<9:40:09, 23.87steps/s] 17%|â–ˆâ–‹        | 171520/1000000 [1:58:45<8:30:48, 27.03steps/s] 17%|â–ˆâ–‹        | 171520/1000000 [1:59:00<8:30:48, 27.03steps/s] 17%|â–ˆâ–‹        | 174080/1000000 [1:59:52<7:44:00, 29.67steps/s] 17%|â–ˆâ–‹        | 174080/1000000 [2:00:10<7:44:00, 29.67steps/s] 18%|â–ˆâ–Š        | 176640/1000000 [2:01:02<7:15:54, 31.48steps/s]                                                                18%|â–ˆâ–Š        | 176640/1000000 [2:01:02<7:15:54, 31.48steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -175     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -175     |
|    Success           | 0.025    |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0614   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.582    |
|    max_target_q      | -9.49    |
|    min_target_q      | -20.1    |
|    max_reward        | -0.472   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 2.39     |
|    q1_grad_norm      | 2.12     |
|    q2_grad_norm      | 2.14     |
|    actor_loss        | 13.6     |
|    ent_coeff         | 0.0451   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0628   |
|    n_updates         | 5280     |
| time/                |          |
|    iterations        | 69       |
|    fps               | 38       |
|    elapsed_time      | 7.26e+03 |
|    elapsed_steps     | 176640   |
-----------------------------------
 18%|â–ˆâ–Š        | 176640/1000000 [2:01:20<7:15:54, 31.48steps/s] 18%|â–ˆâ–Š        | 179200/1000000 [2:02:09<6:51:49, 33.22steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 18%|â–ˆâ–Š        | 179200/1000000 [2:02:20<6:51:49, 33.22steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_179200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 18%|â–ˆâ–Š        | 181760/1000000 [2:07:29<13:18:47, 17.07steps/s] 18%|â–ˆâ–Š        | 184320/1000000 [2:08:34<11:01:12, 20.56steps/s]                                                                 18%|â–ˆâ–Š        | 184320/1000000 [2:08:34<11:01:12, 20.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -176     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -176     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0621   |
|    mean_entropy      | 12.8     |
|    mean_ent_bonus    | 0.576    |
|    max_target_q      | -9.79    |
|    min_target_q      | -20.7    |
|    max_reward        | -0.46    |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 2.11     |
|    q1_grad_norm      | 1.81     |
|    q2_grad_norm      | 1.83     |
|    actor_loss        | 14       |
|    ent_coeff         | 0.0449   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.063    |
|    n_updates         | 5520     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -176     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -176     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 72       |
|    fps               | 17       |
|    elapsed_time      | 7.71e+03 |
|    elapsed_steps     | 184320   |
-----------------------------------
 18%|â–ˆâ–Š        | 184320/1000000 [2:08:50<11:01:12, 20.56steps/s] 19%|â–ˆâ–Š        | 186880/1000000 [2:09:39<9:25:00, 23.99steps/s]  19%|â–ˆâ–Š        | 186880/1000000 [2:09:50<9:25:00, 23.99steps/s] 19%|â–ˆâ–‰        | 189440/1000000 [2:10:46<8:20:23, 27.00steps/s] 19%|â–ˆâ–‰        | 189440/1000000 [2:11:00<8:20:23, 27.00steps/s] 19%|â–ˆâ–‰        | 192000/1000000 [2:11:54<7:35:47, 29.55steps/s]                                                                19%|â–ˆâ–‰        | 192000/1000000 [2:11:54<7:35:47, 29.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -169     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -169     |
|    Success           | 0.025    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.0661   |
|    mean_entropy      | 12.8     |
|    mean_ent_bonus    | 0.571    |
|    max_target_q      | -10.1    |
|    min_target_q      | -21.4    |
|    max_reward        | -0.448   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 2.17     |
|    q1_grad_norm      | 1.82     |
|    q2_grad_norm      | 1.84     |
|    actor_loss        | 14.4     |
|    ent_coeff         | 0.0447   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0639   |
|    n_updates         | 5760     |
| time/                |          |
|    iterations        | 75       |
|    fps               | 38.4     |
|    elapsed_time      | 7.91e+03 |
|    elapsed_steps     | 192000   |
-----------------------------------
 19%|â–ˆâ–‰        | 192000/1000000 [2:12:10<7:35:47, 29.55steps/s] 19%|â–ˆâ–‰        | 194560/1000000 [2:12:59<7:00:15, 31.94steps/s] 19%|â–ˆâ–‰        | 194560/1000000 [2:13:10<7:00:15, 31.94steps/s] 20%|â–ˆâ–‰        | 197120/1000000 [2:14:04<6:35:12, 33.86steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 20%|â–ˆâ–‰        | 197120/1000000 [2:14:20<6:35:12, 33.86steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_197120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 20%|â–ˆâ–‰        | 199680/1000000 [2:19:30<13:05:14, 16.99steps/s]                                                                 20%|â–ˆâ–‰        | 199680/1000000 [2:19:30<13:05:14, 16.99steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -171     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -171     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0685   |
|    mean_entropy      | 12.7     |
|    mean_ent_bonus    | 0.565    |
|    max_target_q      | -10.3    |
|    min_target_q      | -22.1    |
|    max_reward        | -0.427   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 2.11     |
|    q1_grad_norm      | 1.73     |
|    q2_grad_norm      | 1.74     |
|    actor_loss        | 14.8     |
|    ent_coeff         | 0.0445   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0644   |
|    n_updates         | 6000     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -174     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -174     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 78       |
|    fps               | 16.8     |
|    elapsed_time      | 8.37e+03 |
|    elapsed_steps     | 199680   |
-----------------------------------
 20%|â–ˆâ–ˆ        | 202240/1000000 [2:20:40<10:57:04, 20.23steps/s] 20%|â–ˆâ–ˆ        | 202240/1000000 [2:21:00<10:57:04, 20.23steps/s] 20%|â–ˆâ–ˆ        | 204800/1000000 [2:21:47<9:22:52, 23.55steps/s]  20%|â–ˆâ–ˆ        | 204800/1000000 [2:22:00<9:22:52, 23.55steps/s] 21%|â–ˆâ–ˆ        | 207360/1000000 [2:22:58<8:22:56, 26.27steps/s]                                                                21%|â–ˆâ–ˆ        | 207360/1000000 [2:22:58<8:22:56, 26.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -173     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -173     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0781   |
|    mean_entropy      | 12.7     |
|    mean_ent_bonus    | 0.56     |
|    max_target_q      | -10.6    |
|    min_target_q      | -22.8    |
|    max_reward        | -0.432   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 2.89     |
|    q1_grad_norm      | 2.55     |
|    q2_grad_norm      | 2.57     |
|    actor_loss        | 15.2     |
|    ent_coeff         | 0.0443   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0639   |
|    n_updates         | 6240     |
| time/                |          |
|    iterations        | 81       |
|    fps               | 36.8     |
|    elapsed_time      | 8.58e+03 |
|    elapsed_steps     | 207360   |
-----------------------------------
 21%|â–ˆâ–ˆ        | 207360/1000000 [2:23:10<8:22:56, 26.27steps/s] 21%|â–ˆâ–ˆ        | 209920/1000000 [2:24:11<7:42:31, 28.47steps/s] 21%|â–ˆâ–ˆ        | 209920/1000000 [2:24:30<7:42:31, 28.47steps/s] 21%|â–ˆâ–ˆ        | 212480/1000000 [2:25:22<7:11:36, 30.41steps/s] 21%|â–ˆâ–ˆ        | 212480/1000000 [2:25:40<7:11:36, 30.41steps/s] 22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:26:27<6:41:01, 32.62steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:26:40<6:41:01, 32.62steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_215040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:30:58<6:41:01, 32.62steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -170     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -170     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0766   |
|    mean_entropy      | 12.6     |
|    mean_ent_bonus    | 0.555    |
|    max_target_q      | -10.9    |
|    min_target_q      | -23.4    |
|    max_reward        | -0.43    |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 2.4      |
|    q1_grad_norm      | 2.03     |
|    q2_grad_norm      | 2.05     |
|    actor_loss        | 15.5     |
|    ent_coeff         | 0.044    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0639   |
|    n_updates         | 6480     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -166     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -166     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 84       |
|    fps               | 16       |
|    elapsed_time      | 9.06e+03 |
|    elapsed_steps     | 215040   |
-----------------------------------
 22%|â–ˆâ–ˆâ–       | 217600/1000000 [2:32:05<13:17:19, 16.35steps/s] 22%|â–ˆâ–ˆâ–       | 220160/1000000 [2:33:19<11:08:07, 19.45steps/s] 22%|â–ˆâ–ˆâ–       | 220160/1000000 [2:33:30<11:08:07, 19.45steps/s] 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:34:33<9:39:17, 22.36steps/s]                                                                 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:34:33<9:39:17, 22.36steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -166     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -166     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.0843   |
|    mean_entropy      | 12.6     |
|    mean_ent_bonus    | 0.55     |
|    max_target_q      | -11.2    |
|    min_target_q      | -24      |
|    max_reward        | -0.395   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 2.95     |
|    q1_grad_norm      | 2.62     |
|    q2_grad_norm      | 2.63     |
|    actor_loss        | 15.8     |
|    ent_coeff         | 0.0438   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.064    |
|    n_updates         | 6720     |
| time/                |          |
|    iterations        | 87       |
|    fps               | 35.7     |
|    elapsed_time      | 9.27e+03 |
|    elapsed_steps     | 222720   |
-----------------------------------
 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:34:50<9:39:17, 22.36steps/s] 23%|â–ˆâ–ˆâ–Ž       | 225280/1000000 [2:35:47<8:35:45, 25.03steps/s] 23%|â–ˆâ–ˆâ–Ž       | 225280/1000000 [2:36:00<8:35:45, 25.03steps/s] 23%|â–ˆâ–ˆâ–Ž       | 227840/1000000 [2:37:04<7:55:50, 27.05steps/s] 23%|â–ˆâ–ˆâ–Ž       | 227840/1000000 [2:37:20<7:55:50, 27.05steps/s] 23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:38:20<7:26:34, 28.72steps/s]                                                                23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:38:20<7:26:34, 28.72steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -170     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -170     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0832   |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.545    |
|    max_target_q      | -11.3    |
|    min_target_q      | -24.6    |
|    max_reward        | -0.388   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 2.18     |
|    q1_grad_norm      | 1.79     |
|    q2_grad_norm      | 1.81     |
|    actor_loss        | 16.1     |
|    ent_coeff         | 0.0436   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0645   |
|    n_updates         | 6960     |
| time/                |          |
|    iterations        | 90       |
|    fps               | 33.8     |
|    elapsed_time      | 9.5e+03  |
|    elapsed_steps     | 230400   |
-----------------------------------
 23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:38:40<7:26:34, 28.72steps/s] 23%|â–ˆâ–ˆâ–Ž       | 232960/1000000 [2:39:26<6:49:50, 31.19steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 23%|â–ˆâ–ˆâ–Ž       | 232960/1000000 [2:39:40<6:49:50, 31.19steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_232960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 24%|â–ˆâ–ˆâ–Ž       | 235520/1000000 [2:45:07<13:15:59, 16.01steps/s] 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:46:21<11:04:20, 19.11steps/s]                                                                 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:46:21<11:04:20, 19.11steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -166     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -166     |
|    Success           | 0.0294   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.0896   |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.541    |
|    max_target_q      | -11.5    |
|    min_target_q      | -25.3    |
|    max_reward        | -0.39    |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 2.74     |
|    q1_grad_norm      | 2.32     |
|    q2_grad_norm      | 2.33     |
|    actor_loss        | 16.4     |
|    ent_coeff         | 0.0434   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0654   |
|    n_updates         | 7200     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -164     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -164     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 93       |
|    fps               | 16       |
|    elapsed_time      | 9.98e+03 |
|    elapsed_steps     | 238080   |
-----------------------------------
 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:46:40<11:04:20, 19.11steps/s] 24%|â–ˆâ–ˆâ–       | 240640/1000000 [2:47:34<9:31:58, 22.13steps/s]  24%|â–ˆâ–ˆâ–       | 240640/1000000 [2:47:50<9:31:58, 22.13steps/s] 24%|â–ˆâ–ˆâ–       | 243200/1000000 [2:48:48<8:28:06, 24.82steps/s] 24%|â–ˆâ–ˆâ–       | 243200/1000000 [2:49:00<8:28:06, 24.82steps/s] 25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:50:01<7:42:16, 27.19steps/s]                                                                25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:50:01<7:42:16, 27.19steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -157     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -157     |
|    Success           | 0.075    |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.103    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.536    |
|    max_target_q      | -11.7    |
|    min_target_q      | -25.9    |
|    max_reward        | -0.362   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 3.33     |
|    q1_grad_norm      | 2.95     |
|    q2_grad_norm      | 2.97     |
|    actor_loss        | 16.7     |
|    ent_coeff         | 0.0432   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0665   |
|    n_updates         | 7440     |
| time/                |          |
|    iterations        | 96       |
|    fps               | 34.9     |
|    elapsed_time      | 1.02e+04 |
|    elapsed_steps     | 245760   |
-----------------------------------
 25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:50:20<7:42:16, 27.19steps/s] 25%|â–ˆâ–ˆâ–       | 248320/1000000 [2:51:15<7:12:09, 28.99steps/s] 25%|â–ˆâ–ˆâ–       | 248320/1000000 [2:51:30<7:12:09, 28.99steps/s] 25%|â–ˆâ–ˆâ–Œ       | 250880/1000000 [2:52:19<6:34:57, 31.61steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 25%|â–ˆâ–ˆâ–Œ       | 250880/1000000 [2:52:30<6:34:57, 31.61steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_250880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 25%|â–ˆâ–ˆâ–Œ       | 253440/1000000 [2:57:59<12:50:21, 16.15steps/s]                                                                 25%|â–ˆâ–ˆâ–Œ       | 253440/1000000 [2:57:59<12:50:21, 16.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -162     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -162     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.094    |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.531    |
|    max_target_q      | -11.9    |
|    min_target_q      | -26.4    |
|    max_reward        | -0.382   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 2.44     |
|    q1_grad_norm      | 2.03     |
|    q2_grad_norm      | 2.04     |
|    actor_loss        | 17       |
|    ent_coeff         | 0.043    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0669   |
|    n_updates         | 7680     |
| eval/                |          |
|    Length            | 199      |
|    Return            | -163     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -163     |
|    Success           | 0.111    |
|    SuccessLength     | 199      |
| time/                |          |
|    iterations        | 99       |
|    fps               | 16.1     |
|    elapsed_time      | 1.07e+04 |
|    elapsed_steps     | 253440   |
-----------------------------------
 26%|â–ˆâ–ˆâ–Œ       | 256000/1000000 [2:59:11<10:41:43, 19.32steps/s] 26%|â–ˆâ–ˆâ–Œ       | 256000/1000000 [2:59:30<10:41:43, 19.32steps/s] 26%|â–ˆâ–ˆâ–Œ       | 258560/1000000 [3:00:14<9:00:16, 22.87steps/s]  26%|â–ˆâ–ˆâ–Œ       | 258560/1000000 [3:00:30<9:00:16, 22.87steps/s] 26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:01:18<7:48:42, 26.27steps/s]                                                                26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:01:18<7:48:42, 26.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -166     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -166     |
|    Success           | 0.0513   |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.102    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.527    |
|    max_target_q      | -12      |
|    min_target_q      | -27      |
|    max_reward        | -0.356   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 2.89     |
|    q1_grad_norm      | 2.49     |
|    q2_grad_norm      | 2.49     |
|    actor_loss        | 17.3     |
|    ent_coeff         | 0.0428   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0695   |
|    n_updates         | 7920     |
| time/                |          |
|    iterations        | 102      |
|    fps               | 38.5     |
|    elapsed_time      | 1.09e+04 |
|    elapsed_steps     | 261120   |
-----------------------------------
 26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:01:30<7:48:42, 26.27steps/s] 26%|â–ˆâ–ˆâ–‹       | 263680/1000000 [3:02:23<7:00:35, 29.18steps/s] 26%|â–ˆâ–ˆâ–‹       | 263680/1000000 [3:02:40<7:00:35, 29.18steps/s] 27%|â–ˆâ–ˆâ–‹       | 266240/1000000 [3:03:31<6:30:44, 31.30steps/s] 27%|â–ˆâ–ˆâ–‹       | 266240/1000000 [3:03:50<6:30:44, 31.30steps/s] 27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:04:37<6:05:55, 33.30steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:04:50<6:05:55, 33.30steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_268800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:08:58<6:05:55, 33.30steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -163     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -163     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.116    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.522    |
|    max_target_q      | -12.1    |
|    min_target_q      | -27.6    |
|    max_reward        | -0.36    |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 2.87     |
|    q1_grad_norm      | 2.46     |
|    q2_grad_norm      | 2.46     |
|    actor_loss        | 17.5     |
|    ent_coeff         | 0.0426   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0695   |
|    n_updates         | 8160     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -165     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -165     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 105      |
|    fps               | 16.7     |
|    elapsed_time      | 1.13e+04 |
|    elapsed_steps     | 268800   |
-----------------------------------
 27%|â–ˆâ–ˆâ–‹       | 271360/1000000 [3:10:05<12:02:54, 16.80steps/s] 27%|â–ˆâ–ˆâ–‹       | 273920/1000000 [3:11:11<9:57:15, 20.26steps/s]  27%|â–ˆâ–ˆâ–‹       | 273920/1000000 [3:11:30<9:57:15, 20.26steps/s] 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:12:17<8:30:17, 23.63steps/s]                                                                28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:12:17<8:30:17, 23.63steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -161     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -161     |
|    Success           | 0.0556   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.11     |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.515    |
|    max_target_q      | -12.2    |
|    min_target_q      | -28.2    |
|    max_reward        | -0.35    |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 2.86     |
|    q1_grad_norm      | 2.43     |
|    q2_grad_norm      | 2.44     |
|    actor_loss        | 17.8     |
|    ent_coeff         | 0.0424   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0705   |
|    n_updates         | 8400     |
| time/                |          |
|    iterations        | 108      |
|    fps               | 38.5     |
|    elapsed_time      | 1.15e+04 |
|    elapsed_steps     | 276480   |
-----------------------------------
 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:12:30<8:30:17, 23.63steps/s] 28%|â–ˆâ–ˆâ–Š       | 279040/1000000 [3:13:26<7:33:38, 26.49steps/s] 28%|â–ˆâ–ˆâ–Š       | 279040/1000000 [3:13:40<7:33:38, 26.49steps/s] 28%|â–ˆâ–ˆâ–Š       | 281600/1000000 [3:14:37<6:55:33, 28.81steps/s] 28%|â–ˆâ–ˆâ–Š       | 281600/1000000 [3:14:50<6:55:33, 28.81steps/s] 28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:15:50<6:32:02, 30.43steps/s]                                                                28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:15:50<6:32:02, 30.43steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -158     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -158     |
|    Success           | 0.0513   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.117    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.511    |
|    max_target_q      | -12.4    |
|    min_target_q      | -28.9    |
|    max_reward        | -0.338   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 2.97     |
|    q1_grad_norm      | 2.43     |
|    q2_grad_norm      | 2.45     |
|    actor_loss        | 18       |
|    ent_coeff         | 0.0422   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0719   |
|    n_updates         | 8640     |
| time/                |          |
|    iterations        | 111      |
|    fps               | 36       |
|    elapsed_time      | 1.18e+04 |
|    elapsed_steps     | 284160   |
-----------------------------------
 28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:16:10<6:32:02, 30.43steps/s] 29%|â–ˆâ–ˆâ–Š       | 286720/1000000 [3:17:02<6:12:56, 31.88steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 29%|â–ˆâ–ˆâ–Š       | 286720/1000000 [3:17:20<6:12:56, 31.88steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_286720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 29%|â–ˆâ–ˆâ–‰       | 289280/1000000 [3:22:50<12:23:18, 15.94steps/s] 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:23:55<10:08:40, 19.39steps/s]                                                                 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:23:55<10:08:40, 19.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -157     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -157     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.119    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.505    |
|    max_target_q      | -12.4    |
|    min_target_q      | -29.5    |
|    max_reward        | -0.32    |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 3.27     |
|    q1_grad_norm      | 2.81     |
|    q2_grad_norm      | 2.83     |
|    actor_loss        | 18.3     |
|    ent_coeff         | 0.042    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0732   |
|    n_updates         | 8880     |
| eval/                |          |
|    Length            | 196      |
|    Return            | -158     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -158     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 114      |
|    fps               | 15.8     |
|    elapsed_time      | 1.22e+04 |
|    elapsed_steps     | 291840   |
-----------------------------------
 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:24:10<10:08:40, 19.39steps/s] 29%|â–ˆâ–ˆâ–‰       | 294400/1000000 [3:25:07<8:44:29, 22.42steps/s]  29%|â–ˆâ–ˆâ–‰       | 294400/1000000 [3:25:20<8:44:29, 22.42steps/s] 30%|â–ˆâ–ˆâ–‰       | 296960/1000000 [3:26:21<7:46:18, 25.13steps/s] 30%|â–ˆâ–ˆâ–‰       | 296960/1000000 [3:26:40<7:46:18, 25.13steps/s] 30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:27:37<7:10:09, 27.14steps/s]                                                                30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:27:37<7:10:09, 27.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.129    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.502    |
|    max_target_q      | -12.5    |
|    min_target_q      | -30      |
|    max_reward        | -0.332   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 3.45     |
|    q1_grad_norm      | 3        |
|    q2_grad_norm      | 3.01     |
|    actor_loss        | 18.5     |
|    ent_coeff         | 0.0418   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0738   |
|    n_updates         | 9120     |
| time/                |          |
|    iterations        | 117      |
|    fps               | 34.5     |
|    elapsed_time      | 1.25e+04 |
|    elapsed_steps     | 299520   |
-----------------------------------
 30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:27:50<7:10:09, 27.14steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 302080/1000000 [3:28:52<6:42:13, 28.92steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 302080/1000000 [3:29:10<6:42:13, 28.92steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 304640/1000000 [3:30:05<6:19:12, 30.56steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_304640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
 30%|â–ˆâ–ˆâ–ˆ       | 304640/1000000 [3:30:20<6:19:12, 30.56steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 31%|â–ˆâ–ˆâ–ˆ       | 307200/1000000 [3:35:37<11:53:40, 16.18steps/s]                                                                 31%|â–ˆâ–ˆâ–ˆ       | 307200/1000000 [3:35:37<11:53:40, 16.18steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0.025    |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.13     |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.497    |
|    max_target_q      | -12.6    |
|    min_target_q      | -30.5    |
|    max_reward        | -0.328   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 3.31     |
|    q1_grad_norm      | 2.87     |
|    q2_grad_norm      | 2.89     |
|    actor_loss        | 18.7     |
|    ent_coeff         | 0.0416   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0762   |
|    n_updates         | 9360     |
| eval/                |          |
|    Length            | 196      |
|    Return            | -156     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 120      |
|    fps               | 16       |
|    elapsed_time      | 1.29e+04 |
|    elapsed_steps     | 307200   |
-----------------------------------
 31%|â–ˆâ–ˆâ–ˆ       | 309760/1000000 [3:36:46<9:50:37, 19.48steps/s]  31%|â–ˆâ–ˆâ–ˆ       | 309760/1000000 [3:37:00<9:50:37, 19.48steps/s] 31%|â–ˆâ–ˆâ–ˆ       | 312320/1000000 [3:38:06<8:39:09, 22.08steps/s] 31%|â–ˆâ–ˆâ–ˆ       | 312320/1000000 [3:38:20<8:39:09, 22.08steps/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:25<7:48:50, 24.36steps/s]                                                                31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:25<7:48:50, 24.36steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0.0263   |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.144    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.493    |
|    max_target_q      | -12.7    |
|    min_target_q      | -31.1    |
|    max_reward        | -0.332   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.57     |
|    q1_grad_norm      | 3.13     |
|    q2_grad_norm      | 3.15     |
|    actor_loss        | 18.8     |
|    ent_coeff         | 0.0414   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0759   |
|    n_updates         | 9600     |
| time/                |          |
|    iterations        | 123      |
|    fps               | 33.6     |
|    elapsed_time      | 1.32e+04 |
|    elapsed_steps     | 314880   |
-----------------------------------
 31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:40<7:48:50, 24.36steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317440/1000000 [3:40:43<7:09:51, 26.46steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317440/1000000 [3:41:00<7:09:51, 26.46steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320000/1000000 [3:41:59<6:41:45, 28.21steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320000/1000000 [3:42:10<6:41:45, 28.21steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:43:12<6:16:37, 29.98steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_322560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:43:30<6:16:37, 29.98steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:47:43<6:16:37, 29.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.136    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.489    |
|    max_target_q      | -12.8    |
|    min_target_q      | -31.7    |
|    max_reward        | -0.327   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.02     |
|    q1_grad_norm      | 2.47     |
|    q2_grad_norm      | 2.48     |
|    actor_loss        | 19       |
|    ent_coeff         | 0.0412   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0749   |
|    n_updates         | 9840     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 126      |
|    fps               | 15.4     |
|    elapsed_time      | 1.37e+04 |
|    elapsed_steps     | 322560   |
-----------------------------------
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 325120/1000000 [3:48:50<11:47:37, 15.90steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327680/1000000 [3:49:59<9:44:10, 19.18steps/s]  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327680/1000000 [3:50:10<9:44:10, 19.18steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:10<8:19:35, 22.34steps/s]                                                                33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:10<8:19:35, 22.34steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -165     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -165     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.14     |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.48     |
|    max_target_q      | -12.9    |
|    min_target_q      | -32.3    |
|    max_reward        | -0.32    |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 3.36     |
|    q1_grad_norm      | 2.76     |
|    q2_grad_norm      | 2.78     |
|    actor_loss        | 19.3     |
|    ent_coeff         | 0.041    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0782   |
|    n_updates         | 10080    |
| time/                |          |
|    iterations        | 129      |
|    fps               | 37.1     |
|    elapsed_time      | 1.39e+04 |
|    elapsed_steps     | 330240   |
-----------------------------------
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:20<8:19:35, 22.34steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332800/1000000 [3:52:19<7:19:21, 25.31steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332800/1000000 [3:52:30<7:19:21, 25.31steps/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335360/1000000 [3:53:26<6:32:50, 28.20steps/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335360/1000000 [3:53:40<6:32:50, 28.20steps/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:54:35<6:03:49, 30.33steps/s]                                                                34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:54:35<6:03:49, 30.33steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -164     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -164     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.149    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.478    |
|    max_target_q      | -13      |
|    min_target_q      | -32.8    |
|    max_reward        | -0.317   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.32     |
|    q1_grad_norm      | 2.62     |
|    q2_grad_norm      | 2.65     |
|    actor_loss        | 19.4     |
|    ent_coeff         | 0.0408   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0793   |
|    n_updates         | 10320    |
| time/                |          |
|    iterations        | 132      |
|    fps               | 37.3     |
|    elapsed_time      | 1.41e+04 |
|    elapsed_steps     | 337920   |
-----------------------------------
 34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:54:50<6:03:49, 30.33steps/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 340480/1000000 [3:55:43<5:41:11, 32.22steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_340480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 34%|â–ˆâ–ˆâ–ˆâ–      | 340480/1000000 [3:56:00<5:41:11, 32.22steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 34%|â–ˆâ–ˆâ–ˆâ–      | 343040/1000000 [4:01:08<10:54:28, 16.73steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:02:12<8:58:21, 20.26steps/s]                                                                 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:02:12<8:58:21, 20.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -157     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0732   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.164    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.473    |
|    max_target_q      | -13      |
|    min_target_q      | -33.4    |
|    max_reward        | -0.31    |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 3.72     |
|    q1_grad_norm      | 3.07     |
|    q2_grad_norm      | 3.09     |
|    actor_loss        | 19.6     |
|    ent_coeff         | 0.0406   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0795   |
|    n_updates         | 10560    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -156     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 135      |
|    fps               | 16.8     |
|    elapsed_time      | 1.45e+04 |
|    elapsed_steps     | 345600   |
-----------------------------------
 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:02:30<8:58:21, 20.26steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348160/1000000 [4:03:16<7:37:07, 23.77steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348160/1000000 [4:03:30<7:37:07, 23.77steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350720/1000000 [4:04:30<6:51:39, 26.29steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350720/1000000 [4:04:40<6:51:39, 26.29steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:05:43<6:19:02, 28.44steps/s]                                                                35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:05:43<6:19:02, 28.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -156     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0513   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.154    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.469    |
|    max_target_q      | -13.1    |
|    min_target_q      | -33.9    |
|    max_reward        | -0.308   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 3.42     |
|    q1_grad_norm      | 2.73     |
|    q2_grad_norm      | 2.75     |
|    actor_loss        | 19.7     |
|    ent_coeff         | 0.0404   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0795   |
|    n_updates         | 10800    |
| time/                |          |
|    iterations        | 138      |
|    fps               | 36.5     |
|    elapsed_time      | 1.47e+04 |
|    elapsed_steps     | 353280   |
-----------------------------------
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:06:00<6:19:02, 28.44steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355840/1000000 [4:06:52<5:52:07, 30.49steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355840/1000000 [4:07:10<5:52:07, 30.49steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358400/1000000 [4:08:02<5:32:35, 32.15steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_358400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358400/1000000 [4:08:20<5:32:35, 32.15steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360960/1000000 [4:13:37<10:49:55, 16.39steps/s]                                                                 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360960/1000000 [4:13:37<10:49:55, 16.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -157     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0278   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.15     |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.466    |
|    max_target_q      | -13.1    |
|    min_target_q      | -34.3    |
|    max_reward        | -0.313   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.58     |
|    q1_grad_norm      | 2.97     |
|    q2_grad_norm      | 2.96     |
|    actor_loss        | 19.9     |
|    ent_coeff         | 0.0402   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0806   |
|    n_updates         | 11040    |
| eval/                |          |
|    Length            | 193      |
|    Return            | -153     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0556   |
|    SuccessLength     | 193      |
| time/                |          |
|    iterations        | 141      |
|    fps               | 16.2     |
|    elapsed_time      | 1.52e+04 |
|    elapsed_steps     | 360960   |
-----------------------------------
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 363520/1000000 [4:14:41<8:52:38, 19.92steps/s]  36%|â–ˆâ–ˆâ–ˆâ–‹      | 363520/1000000 [4:15:00<8:52:38, 19.92steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366080/1000000 [4:15:45<7:31:24, 23.41steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366080/1000000 [4:16:00<7:31:24, 23.41steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:16:57<6:43:13, 26.10steps/s]                                                                37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:16:57<6:43:13, 26.10steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -161     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -161     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.171    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.462    |
|    max_target_q      | -13.3    |
|    min_target_q      | -34.8    |
|    max_reward        | -0.312   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 3.37     |
|    q1_grad_norm      | 2.48     |
|    q2_grad_norm      | 2.49     |
|    actor_loss        | 20       |
|    ent_coeff         | 0.0401   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0803   |
|    n_updates         | 11280    |
| time/                |          |
|    iterations        | 144      |
|    fps               | 38.3     |
|    elapsed_time      | 1.54e+04 |
|    elapsed_steps     | 368640   |
-----------------------------------
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:17:10<6:43:13, 26.10steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371200/1000000 [4:18:13<6:14:30, 27.98steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371200/1000000 [4:18:30<6:14:30, 27.98steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373760/1000000 [4:19:24<5:47:53, 30.00steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373760/1000000 [4:19:40<5:47:53, 30.00steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:20:40<5:34:22, 31.09steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:20:50<5:34:22, 31.09steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_376320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:25:13<5:34:22, 31.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -156     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -156     |
|    Success           | 0.025    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.17     |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.458    |
|    max_target_q      | -13.3    |
|    min_target_q      | -35.2    |
|    max_reward        | -0.305   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 4.17     |
|    q1_grad_norm      | 3.52     |
|    q2_grad_norm      | 3.51     |
|    actor_loss        | 20.2     |
|    ent_coeff         | 0.0399   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0805   |
|    n_updates         | 11520    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -153     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -153     |
|    Success           | 0.111    |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 147      |
|    fps               | 15.5     |
|    elapsed_time      | 1.59e+04 |
|    elapsed_steps     | 376320   |
-----------------------------------
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 378880/1000000 [4:26:18<10:43:12, 16.09steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 381440/1000000 [4:27:25<8:49:58, 19.45steps/s]  38%|â–ˆâ–ˆâ–ˆâ–Š      | 381440/1000000 [4:27:40<8:49:58, 19.45steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:28:31<7:28:52, 22.87steps/s]                                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:28:31<7:28:52, 22.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -159     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0263   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.178    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.458    |
|    max_target_q      | -13.4    |
|    min_target_q      | -35.7    |
|    max_reward        | -0.294   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 3.89     |
|    q1_grad_norm      | 3.21     |
|    q2_grad_norm      | 3.21     |
|    actor_loss        | 20.3     |
|    ent_coeff         | 0.0397   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0829   |
|    n_updates         | 11760    |
| time/                |          |
|    iterations        | 150      |
|    fps               | 38.7     |
|    elapsed_time      | 1.61e+04 |
|    elapsed_steps     | 384000   |
-----------------------------------
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:28:50<7:28:52, 22.87steps/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386560/1000000 [4:29:36<6:31:06, 26.14steps/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386560/1000000 [4:29:50<6:31:06, 26.14steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389120/1000000 [4:30:45<5:54:05, 28.75steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389120/1000000 [4:31:00<5:54:05, 28.75steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:31:49<5:22:43, 31.42steps/s]                                                                39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:31:49<5:22:43, 31.42steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.186    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.454    |
|    max_target_q      | -13.5    |
|    min_target_q      | -36.1    |
|    max_reward        | -0.298   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 3.94     |
|    q1_grad_norm      | 3.31     |
|    q2_grad_norm      | 3.33     |
|    actor_loss        | 20.4     |
|    ent_coeff         | 0.0395   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.082    |
|    n_updates         | 12000    |
| time/                |          |
|    iterations        | 153      |
|    fps               | 38.9     |
|    elapsed_time      | 1.63e+04 |
|    elapsed_steps     | 391680   |
-----------------------------------
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:32:00<5:22:43, 31.42steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394240/1000000 [4:32:52<5:00:10, 33.63steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_394240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394240/1000000 [4:33:10<5:00:10, 33.63steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 396800/1000000 [4:38:37<10:15:23, 16.34steps/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:39:47<8:31:35, 19.57steps/s]                                                                 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:39:47<8:31:35, 19.57steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -164     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -164     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.188    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.453    |
|    max_target_q      | -13.6    |
|    min_target_q      | -36.6    |
|    max_reward        | -0.291   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 3.93     |
|    q1_grad_norm      | 3.34     |
|    q2_grad_norm      | 3.34     |
|    actor_loss        | 20.6     |
|    ent_coeff         | 0.0393   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0824   |
|    n_updates         | 12240    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 156      |
|    fps               | 16       |
|    elapsed_time      | 1.68e+04 |
|    elapsed_steps     | 399360   |
-----------------------------------
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:40:00<8:31:35, 19.57steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401920/1000000 [4:40:59<7:19:52, 22.66steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401920/1000000 [4:41:10<7:19:52, 22.66steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404480/1000000 [4:42:09<6:27:57, 25.58steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404480/1000000 [4:42:20<6:27:57, 25.58steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:43:15<5:47:26, 28.44steps/s]                                                                41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:43:15<5:47:26, 28.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -154     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.165    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.45     |
|    max_target_q      | -13.7    |
|    min_target_q      | -36.9    |
|    max_reward        | -0.296   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 3.57     |
|    q1_grad_norm      | 2.87     |
|    q2_grad_norm      | 2.87     |
|    actor_loss        | 20.7     |
|    ent_coeff         | 0.0391   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0794   |
|    n_updates         | 12480    |
| time/                |          |
|    iterations        | 159      |
|    fps               | 37       |
|    elapsed_time      | 1.7e+04  |
|    elapsed_steps     | 407040   |
-----------------------------------
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:43:30<5:47:26, 28.44steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409600/1000000 [4:44:20<5:17:04, 31.03steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409600/1000000 [4:44:40<5:17:04, 31.03steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412160/1000000 [4:45:29<5:00:33, 32.60steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412160/1000000 [4:45:40<5:00:33, 32.60steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_412160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414720/1000000 [4:51:15<10:04:21, 16.14steps/s]                                                                 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414720/1000000 [4:51:15<10:04:21, 16.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.184    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.45     |
|    max_target_q      | -13.9    |
|    min_target_q      | -37.4    |
|    max_reward        | -0.307   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.96     |
|    q1_grad_norm      | 3.26     |
|    q2_grad_norm      | 3.25     |
|    actor_loss        | 20.9     |
|    ent_coeff         | 0.0389   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0801   |
|    n_updates         | 12720    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 162      |
|    fps               | 16       |
|    elapsed_time      | 1.75e+04 |
|    elapsed_steps     | 414720   |
-----------------------------------
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417280/1000000 [4:52:22<8:17:40, 19.51steps/s]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417280/1000000 [4:52:40<8:17:40, 19.51steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419840/1000000 [4:53:26<6:59:45, 23.04steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419840/1000000 [4:53:40<6:59:45, 23.04steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:54:33<6:07:09, 26.22steps/s]                                                                42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:54:33<6:07:09, 26.22steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -159     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.194    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.448    |
|    max_target_q      | -14.1    |
|    min_target_q      | -37.8    |
|    max_reward        | -0.312   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.71     |
|    q1_grad_norm      | 2.92     |
|    q2_grad_norm      | 2.93     |
|    actor_loss        | 21       |
|    ent_coeff         | 0.0387   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0798   |
|    n_updates         | 12960    |
| time/                |          |
|    iterations        | 165      |
|    fps               | 38.8     |
|    elapsed_time      | 1.77e+04 |
|    elapsed_steps     | 422400   |
-----------------------------------
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:54:50<6:07:09, 26.22steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424960/1000000 [4:55:39<5:30:48, 28.97steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424960/1000000 [4:55:50<5:30:48, 28.97steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427520/1000000 [4:56:46<5:05:02, 31.28steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427520/1000000 [4:57:00<5:05:02, 31.28steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [4:57:56<4:50:12, 32.73steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [4:58:10<4:50:12, 32.73steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_430080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [5:02:33<4:50:12, 32.73steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -157     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.192    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.448    |
|    max_target_q      | -14.2    |
|    min_target_q      | -38.2    |
|    max_reward        | -0.288   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.65     |
|    q1_grad_norm      | 2.77     |
|    q2_grad_norm      | 2.77     |
|    actor_loss        | 21.1     |
|    ent_coeff         | 0.0385   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0799   |
|    n_updates         | 13200    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -156     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0556   |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 168      |
|    fps               | 16       |
|    elapsed_time      | 1.82e+04 |
|    elapsed_steps     | 430080   |
-----------------------------------
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 432640/1000000 [5:03:37<9:40:10, 16.30steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435200/1000000 [5:04:48<8:02:31, 19.51steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435200/1000000 [5:05:00<8:02:31, 19.51steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:05:56<6:50:53, 22.81steps/s]                                                                44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:05:56<6:50:53, 22.81steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.191    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.446    |
|    max_target_q      | -14.3    |
|    min_target_q      | -38.4    |
|    max_reward        | -0.3     |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 4.29     |
|    q1_grad_norm      | 3.63     |
|    q2_grad_norm      | 3.64     |
|    actor_loss        | 21.3     |
|    ent_coeff         | 0.0384   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0808   |
|    n_updates         | 13440    |
| time/                |          |
|    iterations        | 171      |
|    fps               | 37.9     |
|    elapsed_time      | 1.84e+04 |
|    elapsed_steps     | 437760   |
-----------------------------------
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:06:10<6:50:53, 22.81steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440320/1000000 [5:07:04<6:00:33, 25.87steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440320/1000000 [5:07:20<6:00:33, 25.87steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442880/1000000 [5:08:11<5:24:57, 28.57steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442880/1000000 [5:08:30<5:24:57, 28.57steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:09:19<4:59:26, 30.87steps/s]                                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:09:19<4:59:26, 30.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.18     |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.446    |
|    max_target_q      | -14.4    |
|    min_target_q      | -38.7    |
|    max_reward        | -0.315   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.73     |
|    q1_grad_norm      | 3.03     |
|    q2_grad_norm      | 3.05     |
|    actor_loss        | 21.4     |
|    ent_coeff         | 0.0382   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0791   |
|    n_updates         | 13680    |
| time/                |          |
|    iterations        | 174      |
|    fps               | 37.8     |
|    elapsed_time      | 1.86e+04 |
|    elapsed_steps     | 445440   |
-----------------------------------
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:09:30<4:59:26, 30.87steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448000/1000000 [5:10:25<4:39:35, 32.91steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_448000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448000/1000000 [5:10:40<4:39:35, 32.91steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 450560/1000000 [5:15:52<9:06:24, 16.76steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:16:59<7:31:57, 20.17steps/s]                                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:16:59<7:31:57, 20.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -155     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0263   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.197    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.442    |
|    max_target_q      | -14.6    |
|    min_target_q      | -39.1    |
|    max_reward        | -0.298   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 3.59     |
|    q1_grad_norm      | 2.79     |
|    q2_grad_norm      | 2.78     |
|    actor_loss        | 21.6     |
|    ent_coeff         | 0.038    |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0798   |
|    n_updates         | 13920    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 177      |
|    fps               | 16.7     |
|    elapsed_time      | 1.9e+04  |
|    elapsed_steps     | 453120   |
-----------------------------------
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:17:10<7:31:57, 20.17steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455680/1000000 [5:18:05<6:25:33, 23.53steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455680/1000000 [5:18:20<6:25:33, 23.53steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458240/1000000 [5:19:09<5:35:34, 26.91steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458240/1000000 [5:19:20<5:35:34, 26.91steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:20:17<5:05:48, 29.39steps/s]                                                                46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:20:17<5:05:48, 29.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.199    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.441    |
|    max_target_q      | -14.7    |
|    min_target_q      | -39.5    |
|    max_reward        | -0.311   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 4.03     |
|    q1_grad_norm      | 3.24     |
|    q2_grad_norm      | 3.23     |
|    actor_loss        | 21.7     |
|    ent_coeff         | 0.0378   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0804   |
|    n_updates         | 14160    |
| time/                |          |
|    iterations        | 180      |
|    fps               | 38.8     |
|    elapsed_time      | 1.92e+04 |
|    elapsed_steps     | 460800   |
-----------------------------------
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:20:30<5:05:48, 29.39steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463360/1000000 [5:21:26<4:45:39, 31.31steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463360/1000000 [5:21:40<4:45:39, 31.31steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465920/1000000 [5:22:36<4:31:42, 32.76steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465920/1000000 [5:22:50<4:31:42, 32.76steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_465920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468480/1000000 [5:28:09<8:54:53, 16.56steps/s]                                                                47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468480/1000000 [5:28:09<8:54:53, 16.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.196    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.44     |
|    max_target_q      | -14.8    |
|    min_target_q      | -39.6    |
|    max_reward        | -0.301   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 3.91     |
|    q1_grad_norm      | 3.18     |
|    q2_grad_norm      | 3.2      |
|    actor_loss        | 21.9     |
|    ent_coeff         | 0.0376   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0812   |
|    n_updates         | 14400    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 183      |
|    fps               | 16.3     |
|    elapsed_time      | 1.97e+04 |
|    elapsed_steps     | 468480   |
-----------------------------------
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471040/1000000 [5:29:19<7:24:31, 19.83steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471040/1000000 [5:29:30<7:24:31, 19.83steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473600/1000000 [5:30:25<6:17:51, 23.22steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473600/1000000 [5:30:40<6:17:51, 23.22steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:31:30<5:30:05, 26.45steps/s]                                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:31:30<5:30:05, 26.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.209    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.436    |
|    max_target_q      | -15      |
|    min_target_q      | -39.9    |
|    max_reward        | -0.31    |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 4.08     |
|    q1_grad_norm      | 3.34     |
|    q2_grad_norm      | 3.34     |
|    actor_loss        | 22       |
|    ent_coeff         | 0.0375   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0822   |
|    n_updates         | 14640    |
| time/                |          |
|    iterations        | 186      |
|    fps               | 38.2     |
|    elapsed_time      | 1.99e+04 |
|    elapsed_steps     | 476160   |
-----------------------------------
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:31:50<5:30:05, 26.45steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478720/1000000 [5:32:42<5:03:08, 28.66steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478720/1000000 [5:33:00<5:03:08, 28.66steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481280/1000000 [5:33:56<4:46:28, 30.18steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481280/1000000 [5:34:10<4:46:28, 30.18steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:35:11<4:34:12, 31.37steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_483840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:35:30<4:34:12, 31.37steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:40:09<4:34:12, 31.37steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.215    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.432    |
|    max_target_q      | -15.2    |
|    min_target_q      | -40.1    |
|    max_reward        | -0.306   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 4.21     |
|    q1_grad_norm      | 3.57     |
|    q2_grad_norm      | 3.58     |
|    actor_loss        | 22.2     |
|    ent_coeff         | 0.0373   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0828   |
|    n_updates         | 14880    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 189      |
|    fps               | 14.8     |
|    elapsed_time      | 2.04e+04 |
|    elapsed_steps     | 483840   |
-----------------------------------
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 486400/1000000 [5:41:15<9:16:33, 15.38steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488960/1000000 [5:42:18<7:30:40, 18.90steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488960/1000000 [5:42:30<7:30:40, 18.90steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:43:25<6:20:09, 22.29steps/s]                                                                49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:43:25<6:20:09, 22.29steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -154     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0263   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.209    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.431    |
|    max_target_q      | -15.3    |
|    min_target_q      | -40.6    |
|    max_reward        | -0.263   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 4.14     |
|    q1_grad_norm      | 3.46     |
|    q2_grad_norm      | 3.45     |
|    actor_loss        | 22.3     |
|    ent_coeff         | 0.0371   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0802   |
|    n_updates         | 15120    |
| time/                |          |
|    iterations        | 192      |
|    fps               | 39.3     |
|    elapsed_time      | 2.06e+04 |
|    elapsed_steps     | 491520   |
-----------------------------------
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:43:40<6:20:09, 22.29steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494080/1000000 [5:44:39<5:38:31, 24.91steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494080/1000000 [5:44:50<5:38:31, 24.91steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496640/1000000 [5:45:56<5:10:44, 27.00steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496640/1000000 [5:46:10<5:10:44, 27.00steps/s]ReplayBuffer: Replay buffer is now full. cursor=0.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:47:12<4:51:05, 28.67steps/s]                                                                50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:47:12<4:51:05, 28.67steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -152     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -152     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.176    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.426    |
|    max_target_q      | -15.3    |
|    min_target_q      | -40.7    |
|    max_reward        | -0.295   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 3.83     |
|    q1_grad_norm      | 3.21     |
|    q2_grad_norm      | 3.21     |
|    actor_loss        | 22.5     |
|    ent_coeff         | 0.0369   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0818   |
|    n_updates         | 15360    |
| time/                |          |
|    iterations        | 195      |
|    fps               | 33.8     |
|    elapsed_time      | 2.08e+04 |
|    elapsed_steps     | 499200   |
-----------------------------------
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:47:30<4:51:05, 28.67steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501760/1000000 [5:48:24<4:32:30, 30.47steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_501760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501760/1000000 [5:48:40<4:32:30, 30.47steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 504320/1000000 [5:53:53<8:28:11, 16.26steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:55:04<7:02:25, 19.46steps/s]                                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:55:04<7:02:25, 19.46steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -146     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0769   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.198    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.422    |
|    max_target_q      | -15.5    |
|    min_target_q      | -40.8    |
|    max_reward        | -0.302   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 3.84     |
|    q1_grad_norm      | 3.26     |
|    q2_grad_norm      | 3.25     |
|    actor_loss        | 22.6     |
|    ent_coeff         | 0.0367   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0823   |
|    n_updates         | 15600    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -152     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -152     |
|    Success           | 0.0556   |
|    SuccessLength     | 197      |
| time/                |          |
|    iterations        | 198      |
|    fps               | 16.3     |
|    elapsed_time      | 2.13e+04 |
|    elapsed_steps     | 506880   |
-----------------------------------
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:55:20<7:02:25, 19.46steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509440/1000000 [5:56:11<5:58:56, 22.78steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509440/1000000 [5:56:30<5:58:56, 22.78steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512000/1000000 [5:57:20<5:15:43, 25.76steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512000/1000000 [5:57:40<5:15:43, 25.76steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [5:58:34<4:49:55, 27.91steps/s]                                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [5:58:34<4:49:55, 27.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.213    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.42     |
|    max_target_q      | -15.5    |
|    min_target_q      | -41.2    |
|    max_reward        | -0.31    |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 4.18     |
|    q1_grad_norm      | 3.46     |
|    q2_grad_norm      | 3.47     |
|    actor_loss        | 22.7     |
|    ent_coeff         | 0.0366   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0827   |
|    n_updates         | 15840    |
| time/                |          |
|    iterations        | 201      |
|    fps               | 36.5     |
|    elapsed_time      | 2.15e+04 |
|    elapsed_steps     | 514560   |
-----------------------------------
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [5:58:50<4:49:55, 27.91steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517120/1000000 [5:59:52<4:35:06, 29.25steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517120/1000000 [6:00:10<4:35:06, 29.25steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519680/1000000 [6:00:58<4:13:33, 31.57steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519680/1000000 [6:01:10<4:13:33, 31.57steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_519680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522240/1000000 [6:06:39<8:14:53, 16.09steps/s]                                                                52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522240/1000000 [6:06:39<8:14:53, 16.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -148     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -148     |
|    Success           | 0.025    |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.2      |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.419    |
|    max_target_q      | -15.5    |
|    min_target_q      | -41.3    |
|    max_reward        | -0.291   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 4.14     |
|    q1_grad_norm      | 3.61     |
|    q2_grad_norm      | 3.59     |
|    actor_loss        | 22.8     |
|    ent_coeff         | 0.0364   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0816   |
|    n_updates         | 16080    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -150     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0556   |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 204      |
|    fps               | 15.8     |
|    elapsed_time      | 2.2e+04  |
|    elapsed_steps     | 522240   |
-----------------------------------
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524800/1000000 [6:07:45<6:45:42, 19.52steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524800/1000000 [6:08:00<6:45:42, 19.52steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527360/1000000 [6:08:55<5:46:58, 22.70steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527360/1000000 [6:09:10<5:46:58, 22.70steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:09:59<5:00:40, 26.06steps/s]                                                                53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:09:59<5:00:40, 26.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -155     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0541   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.208    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.415    |
|    max_target_q      | -15.5    |
|    min_target_q      | -41.6    |
|    max_reward        | -0.292   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 4.73     |
|    q1_grad_norm      | 4.2      |
|    q2_grad_norm      | 4.18     |
|    actor_loss        | 22.9     |
|    ent_coeff         | 0.0362   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0808   |
|    n_updates         | 16320    |
| time/                |          |
|    iterations        | 207      |
|    fps               | 38.4     |
|    elapsed_time      | 2.22e+04 |
|    elapsed_steps     | 529920   |
-----------------------------------
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:10:10<5:00:40, 26.06steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532480/1000000 [6:11:11<4:34:33, 28.38steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532480/1000000 [6:11:30<4:34:33, 28.38steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535040/1000000 [6:12:18<4:12:01, 30.75steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535040/1000000 [6:12:30<4:12:01, 30.75steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:13:24<3:55:18, 32.75steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:13:40<3:55:18, 32.75steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_537600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:17:58<3:55:18, 32.75steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -148     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -148     |
|    Success           | 0.05     |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.185    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.411    |
|    max_target_q      | -15.6    |
|    min_target_q      | -41.8    |
|    max_reward        | -0.284   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 3.94     |
|    q1_grad_norm      | 3.16     |
|    q2_grad_norm      | 3.17     |
|    actor_loss        | 23       |
|    ent_coeff         | 0.036    |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0809   |
|    n_updates         | 16560    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -152     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -152     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 210      |
|    fps               | 16       |
|    elapsed_time      | 2.27e+04 |
|    elapsed_steps     | 537600   |
-----------------------------------
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 540160/1000000 [6:19:04<7:49:06, 16.34steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542720/1000000 [6:20:11<6:26:43, 19.71steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542720/1000000 [6:20:30<6:26:43, 19.71steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:21:21<5:30:53, 22.90steps/s]                                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:21:21<5:30:53, 22.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -153     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -153     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.19     |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.408    |
|    max_target_q      | -15.6    |
|    min_target_q      | -42      |
|    max_reward        | -0.286   |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 4.54     |
|    q1_grad_norm      | 3.81     |
|    q2_grad_norm      | 3.81     |
|    actor_loss        | 23.1     |
|    ent_coeff         | 0.0359   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0792   |
|    n_updates         | 16800    |
| time/                |          |
|    iterations        | 213      |
|    fps               | 37.9     |
|    elapsed_time      | 2.29e+04 |
|    elapsed_steps     | 545280   |
-----------------------------------
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:21:40<5:30:53, 22.90steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547840/1000000 [6:22:34<4:54:55, 25.55steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547840/1000000 [6:22:50<4:54:55, 25.55steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550400/1000000 [6:23:44<4:26:27, 28.12steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550400/1000000 [6:24:00<4:26:27, 28.12steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:24:58<4:09:48, 29.83steps/s]                                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:24:58<4:09:48, 29.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 187      |
|    Return            | -139     |
|    NonzeroRewards    | 187      |
|    DiscountedReturn  | -139     |
|    Success           | 0.143    |
|    SuccessLength     | 187      |
| algo/                |          |
|    critic_loss       | 0.204    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.405    |
|    max_target_q      | -15.7    |
|    min_target_q      | -42      |
|    max_reward        | -0.291   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 4.27     |
|    q1_grad_norm      | 3.34     |
|    q2_grad_norm      | 3.33     |
|    actor_loss        | 23.1     |
|    ent_coeff         | 0.0357   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0825   |
|    n_updates         | 17040    |
| time/                |          |
|    iterations        | 216      |
|    fps               | 35.5     |
|    elapsed_time      | 2.31e+04 |
|    elapsed_steps     | 552960   |
-----------------------------------
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:25:10<4:09:48, 29.83steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555520/1000000 [6:26:05<3:52:02, 31.92steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_555520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555520/1000000 [6:26:20<3:52:02, 31.92steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 558080/1000000 [6:32:02<7:50:00, 15.67steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:33:10<6:25:26, 19.00steps/s]                                                                56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:33:10<6:25:26, 19.00steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -149     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -149     |
|    Success           | 0.027    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.21     |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.402    |
|    max_target_q      | -15.7    |
|    min_target_q      | -42.2    |
|    max_reward        | -0.283   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 4.1      |
|    q1_grad_norm      | 3.02     |
|    q2_grad_norm      | 3.02     |
|    actor_loss        | 23.2     |
|    ent_coeff         | 0.0355   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0795   |
|    n_updates         | 17280    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 219      |
|    fps               | 15.6     |
|    elapsed_time      | 2.36e+04 |
|    elapsed_steps     | 560640   |
-----------------------------------
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:33:20<6:25:26, 19.00steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563200/1000000 [6:34:18<5:25:54, 22.34steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563200/1000000 [6:34:30<5:25:54, 22.34steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565760/1000000 [6:35:28<4:46:28, 25.26steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565760/1000000 [6:35:40<4:46:28, 25.26steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:36:35<4:16:04, 28.10steps/s]                                                                57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:36:35<4:16:04, 28.10steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -146     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0769   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.248    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.399    |
|    max_target_q      | -15.7    |
|    min_target_q      | -42.2    |
|    max_reward        | -0.288   |
|    min_reward        | -1.32    |
|    encoder_grad_norm | 5.68     |
|    q1_grad_norm      | 4.86     |
|    q2_grad_norm      | 4.85     |
|    actor_loss        | 23.2     |
|    ent_coeff         | 0.0354   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0812   |
|    n_updates         | 17520    |
| time/                |          |
|    iterations        | 222      |
|    fps               | 37.4     |
|    elapsed_time      | 2.38e+04 |
|    elapsed_steps     | 568320   |
-----------------------------------
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:36:50<4:16:04, 28.10steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570880/1000000 [6:37:45<3:56:52, 30.19steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570880/1000000 [6:38:00<3:56:52, 30.19steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573440/1000000 [6:38:53<3:41:05, 32.16steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_573440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573440/1000000 [6:39:10<3:41:05, 32.16steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576000/1000000 [6:44:26<7:10:08, 16.43steps/s]                                                                58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576000/1000000 [6:44:26<7:10:08, 16.43steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -147     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0488   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.238    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.397    |
|    max_target_q      | -15.7    |
|    min_target_q      | -42.1    |
|    max_reward        | -0.283   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 4.55     |
|    q1_grad_norm      | 3.46     |
|    q2_grad_norm      | 3.46     |
|    actor_loss        | 23.2     |
|    ent_coeff         | 0.0352   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0818   |
|    n_updates         | 17760    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -145     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -145     |
|    Success           | 0.0556   |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 225      |
|    fps               | 16.3     |
|    elapsed_time      | 2.43e+04 |
|    elapsed_steps     | 576000   |
-----------------------------------
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578560/1000000 [6:45:39<5:58:42, 19.58steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578560/1000000 [6:45:50<5:58:42, 19.58steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581120/1000000 [6:46:46<5:04:33, 22.92steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581120/1000000 [6:47:00<5:04:33, 22.92steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:47:52<4:26:02, 26.08steps/s]                                                                58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:47:52<4:26:02, 26.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -148     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0513   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.25     |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.392    |
|    max_target_q      | -15.8    |
|    min_target_q      | -42.1    |
|    max_reward        | -0.282   |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 5.22     |
|    q1_grad_norm      | 4        |
|    q2_grad_norm      | 4.01     |
|    actor_loss        | 23.3     |
|    ent_coeff         | 0.035    |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0814   |
|    n_updates         | 18000    |
| time/                |          |
|    iterations        | 228      |
|    fps               | 37.3     |
|    elapsed_time      | 2.45e+04 |
|    elapsed_steps     | 583680   |
-----------------------------------
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:48:10<4:26:02, 26.08steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586240/1000000 [6:48:59<3:58:40, 28.89steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586240/1000000 [6:49:10<3:58:40, 28.89steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588800/1000000 [6:50:11<3:43:59, 30.60steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588800/1000000 [6:50:30<3:43:59, 30.60steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:51:18<3:29:08, 32.56steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:51:30<3:29:08, 32.56steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_591360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:55:58<3:29:08, 32.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -147     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -147     |
|    Success           | 0.025    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.256    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.39     |
|    max_target_q      | -15.8    |
|    min_target_q      | -41.8    |
|    max_reward        | -0.279   |
|    min_reward        | -1.32    |
|    encoder_grad_norm | 5.39     |
|    q1_grad_norm      | 4.1      |
|    q2_grad_norm      | 4.11     |
|    actor_loss        | 23.3     |
|    ent_coeff         | 0.0349   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0808   |
|    n_updates         | 18240    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -151     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -151     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 231      |
|    fps               | 15.8     |
|    elapsed_time      | 2.5e+04  |
|    elapsed_steps     | 591360   |
-----------------------------------
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 593920/1000000 [6:57:10<7:05:11, 15.92steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596480/1000000 [6:58:20<5:50:34, 19.18steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596480/1000000 [6:58:30<5:50:34, 19.18steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [6:59:29<4:57:47, 22.44steps/s]                                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [6:59:29<4:57:47, 22.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -141     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -141     |
|    Success           | 0.1      |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.242    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.387    |
|    max_target_q      | -15.8    |
|    min_target_q      | -41.5    |
|    max_reward        | -0.269   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 4.79     |
|    q1_grad_norm      | 3.35     |
|    q2_grad_norm      | 3.36     |
|    actor_loss        | 23.3     |
|    ent_coeff         | 0.0347   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0812   |
|    n_updates         | 18480    |
| time/                |          |
|    iterations        | 234      |
|    fps               | 36.4     |
|    elapsed_time      | 2.52e+04 |
|    elapsed_steps     | 599040   |
-----------------------------------
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [6:59:40<4:57:47, 22.44steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601600/1000000 [7:00:36<4:19:38, 25.57steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601600/1000000 [7:00:50<4:19:38, 25.57steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604160/1000000 [7:01:50<3:57:27, 27.78steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604160/1000000 [7:02:00<3:57:27, 27.78steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:03:00<3:39:12, 29.90steps/s]                                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:03:00<3:39:12, 29.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -147     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -147     |
|    Success           | 0.027    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.268    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.385    |
|    max_target_q      | -15.7    |
|    min_target_q      | -41.2    |
|    max_reward        | -0.283   |
|    min_reward        | -1.3     |
|    encoder_grad_norm | 5.77     |
|    q1_grad_norm      | 3.99     |
|    q2_grad_norm      | 3.99     |
|    actor_loss        | 23.3     |
|    ent_coeff         | 0.0345   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0817   |
|    n_updates         | 18720    |
| time/                |          |
|    iterations        | 237      |
|    fps               | 36.3     |
|    elapsed_time      | 2.54e+04 |
|    elapsed_steps     | 606720   |
-----------------------------------
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:03:20<3:39:12, 29.90steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609280/1000000 [7:04:11<3:26:31, 31.53steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_609280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609280/1000000 [7:04:30<3:26:31, 31.53steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 611840/1000000 [7:10:03<6:50:24, 15.76steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:11:12<5:37:40, 19.03steps/s]                                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:11:12<5:37:40, 19.03steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -141     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -141     |
|    Success           | 0.103    |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.291    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.382    |
|    max_target_q      | -15.6    |
|    min_target_q      | -41.1    |
|    max_reward        | -0.282   |
|    min_reward        | -1.32    |
|    encoder_grad_norm | 5.61     |
|    q1_grad_norm      | 3.77     |
|    q2_grad_norm      | 3.76     |
|    actor_loss        | 23.3     |
|    ent_coeff         | 0.0344   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0819   |
|    n_updates         | 18960    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -150     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0556   |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 240      |
|    fps               | 15.6     |
|    elapsed_time      | 2.59e+04 |
|    elapsed_steps     | 614400   |
-----------------------------------
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:11:30<5:37:40, 19.03steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616960/1000000 [7:12:21<4:45:53, 22.33steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616960/1000000 [7:12:40<4:45:53, 22.33steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619520/1000000 [7:13:26<4:07:13, 25.65steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619520/1000000 [7:13:40<4:07:13, 25.65steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:14:39<3:45:36, 27.92steps/s]                                                                62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:14:39<3:45:36, 27.92steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -150     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -150     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.273    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.38     |
|    max_target_q      | -15.6    |
|    min_target_q      | -40.7    |
|    max_reward        | -0.267   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 5.45     |
|    q1_grad_norm      | 3.93     |
|    q2_grad_norm      | 3.94     |
|    actor_loss        | 23.4     |
|    ent_coeff         | 0.0342   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0811   |
|    n_updates         | 19200    |
| time/                |          |
|    iterations        | 243      |
|    fps               | 37.2     |
|    elapsed_time      | 2.61e+04 |
|    elapsed_steps     | 622080   |
-----------------------------------
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:14:50<3:45:36, 27.92steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624640/1000000 [7:15:47<3:27:13, 30.19steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624640/1000000 [7:16:00<3:27:13, 30.19steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627200/1000000 [7:16:52<3:10:51, 32.55steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_627200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627200/1000000 [7:17:10<3:10:51, 32.55steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629760/1000000 [7:22:29<6:16:24, 16.39steps/s]                                                                63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629760/1000000 [7:22:29<6:16:24, 16.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -149     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -149     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.307    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.379    |
|    max_target_q      | -15.6    |
|    min_target_q      | -41.2    |
|    max_reward        | -0.282   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 6.03     |
|    q1_grad_norm      | 4.23     |
|    q2_grad_norm      | 4.24     |
|    actor_loss        | 23.4     |
|    ent_coeff         | 0.034    |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0805   |
|    n_updates         | 19440    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -151     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 246      |
|    fps               | 16.3     |
|    elapsed_time      | 2.65e+04 |
|    elapsed_steps     | 629760   |
-----------------------------------
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632320/1000000 [7:23:38<5:11:44, 19.66steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632320/1000000 [7:23:50<5:11:44, 19.66steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634880/1000000 [7:24:42<4:22:10, 23.21steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634880/1000000 [7:25:00<4:22:10, 23.21steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:25:53<3:52:06, 26.03steps/s]                                                                64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:25:53<3:52:06, 26.03steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -142     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -142     |
|    Success           | 0.075    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.301    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.376    |
|    max_target_q      | -15.5    |
|    min_target_q      | -40.7    |
|    max_reward        | -0.278   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 6.13     |
|    q1_grad_norm      | 4.33     |
|    q2_grad_norm      | 4.34     |
|    actor_loss        | 23.5     |
|    ent_coeff         | 0.0339   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.082    |
|    n_updates         | 19680    |
| time/                |          |
|    iterations        | 249      |
|    fps               | 37.7     |
|    elapsed_time      | 2.68e+04 |
|    elapsed_steps     | 637440   |
-----------------------------------
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:26:10<3:52:06, 26.03steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640000/1000000 [7:26:59<3:28:08, 28.83steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640000/1000000 [7:27:10<3:28:08, 28.83steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642560/1000000 [7:28:08<3:12:32, 30.94steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642560/1000000 [7:28:20<3:12:32, 30.94steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:29:15<3:00:17, 32.81steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:29:30<3:00:17, 32.81steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_645120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:33:39<3:00:17, 32.81steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -148     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0789   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.317    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.376    |
|    max_target_q      | -15.4    |
|    min_target_q      | -40.7    |
|    max_reward        | -0.268   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 6.27     |
|    q1_grad_norm      | 4.33     |
|    q2_grad_norm      | 4.33     |
|    actor_loss        | 23.5     |
|    ent_coeff         | 0.0337   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0795   |
|    n_updates         | 19920    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -147     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0556   |
|    SuccessLength     | 197      |
| time/                |          |
|    iterations        | 252      |
|    fps               | 16.5     |
|    elapsed_time      | 2.72e+04 |
|    elapsed_steps     | 645120   |
-----------------------------------
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 647680/1000000 [7:34:49<5:55:11, 16.53steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650240/1000000 [7:35:56<4:52:52, 19.90steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650240/1000000 [7:36:10<4:52:52, 19.90steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:37:00<4:06:48, 23.45steps/s]                                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:37:00<4:06:48, 23.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -144     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -144     |
|    Success           | 0.0513   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.315    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.373    |
|    max_target_q      | -15.1    |
|    min_target_q      | -40.9    |
|    max_reward        | -0.269   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 5.98     |
|    q1_grad_norm      | 3.55     |
|    q2_grad_norm      | 3.53     |
|    actor_loss        | 23.6     |
|    ent_coeff         | 0.0335   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0805   |
|    n_updates         | 20160    |
| time/                |          |
|    iterations        | 255      |
|    fps               | 38.2     |
|    elapsed_time      | 2.74e+04 |
|    elapsed_steps     | 652800   |
-----------------------------------
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:37:10<4:06:48, 23.45steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655360/1000000 [7:38:08<3:37:05, 26.46steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655360/1000000 [7:38:20<3:37:05, 26.46steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657920/1000000 [7:39:18<3:17:37, 28.85steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657920/1000000 [7:39:30<3:17:37, 28.85steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:40:24<3:00:47, 31.30steps/s]                                                                66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:40:24<3:00:47, 31.30steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -143     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -143     |
|    Success           | 0.122    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.356    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.368    |
|    max_target_q      | -14.7    |
|    min_target_q      | -41.1    |
|    max_reward        | -0.267   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 7.18     |
|    q1_grad_norm      | 4.36     |
|    q2_grad_norm      | 4.36     |
|    actor_loss        | 23.6     |
|    ent_coeff         | 0.0334   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0841   |
|    n_updates         | 20400    |
| time/                |          |
|    iterations        | 258      |
|    fps               | 37.8     |
|    elapsed_time      | 2.76e+04 |
|    elapsed_steps     | 660480   |
-----------------------------------
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:40:40<3:00:47, 31.30steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663040/1000000 [7:41:32<2:50:46, 32.89steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_663040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663040/1000000 [7:41:50<2:50:46, 32.89steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 665600/1000000 [7:47:17<5:43:34, 16.22steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:48:25<4:43:08, 19.53steps/s]                                                                67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:48:25<4:43:08, 19.53steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -144     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -144     |
|    Success           | 0.0513   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.343    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.363    |
|    max_target_q      | -14.2    |
|    min_target_q      | -41.8    |
|    max_reward        | -0.274   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 7.32     |
|    q1_grad_norm      | 4.62     |
|    q2_grad_norm      | 4.61     |
|    actor_loss        | 23.7     |
|    ent_coeff         | 0.0332   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0845   |
|    n_updates         | 20640    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -143     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -143     |
|    Success           | 0.0556   |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 261      |
|    fps               | 15.9     |
|    elapsed_time      | 2.81e+04 |
|    elapsed_steps     | 668160   |
-----------------------------------
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:48:40<4:43:08, 19.53steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670720/1000000 [7:49:36<4:02:30, 22.63steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670720/1000000 [7:49:50<4:02:30, 22.63steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673280/1000000 [7:50:52<3:36:34, 25.14steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673280/1000000 [7:51:10<3:36:34, 25.14steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:52:08<3:18:29, 27.22steps/s]                                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:52:08<3:18:29, 27.22steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -143     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -143     |
|    Success           | 0.0263   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.359    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.364    |
|    max_target_q      | -13.7    |
|    min_target_q      | -42.1    |
|    max_reward        | -0.268   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 7.03     |
|    q1_grad_norm      | 4.21     |
|    q2_grad_norm      | 4.23     |
|    actor_loss        | 23.7     |
|    ent_coeff         | 0.0331   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0813   |
|    n_updates         | 20880    |
| time/                |          |
|    iterations        | 264      |
|    fps               | 34.5     |
|    elapsed_time      | 2.83e+04 |
|    elapsed_steps     | 675840   |
-----------------------------------
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:52:20<3:18:29, 27.22steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678400/1000000 [7:53:18<3:01:48, 29.48steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678400/1000000 [7:53:30<3:01:48, 29.48steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680960/1000000 [7:54:31<2:52:04, 30.90steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_680960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680960/1000000 [7:54:50<2:52:04, 30.90steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683520/1000000 [8:00:29<5:40:48, 15.48steps/s]                                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683520/1000000 [8:00:29<5:40:48, 15.48steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -135     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -135     |
|    Success           | 0.143    |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.388    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.36     |
|    max_target_q      | -12.5    |
|    min_target_q      | -42.7    |
|    max_reward        | -0.264   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 7.75     |
|    q1_grad_norm      | 4.84     |
|    q2_grad_norm      | 4.84     |
|    actor_loss        | 23.8     |
|    ent_coeff         | 0.0329   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0835   |
|    n_updates         | 21120    |
| eval/                |          |
|    Length            | 198      |
|    Return            | -146     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0556   |
|    SuccessLength     | 198      |
| time/                |          |
|    iterations        | 267      |
|    fps               | 15.3     |
|    elapsed_time      | 2.88e+04 |
|    elapsed_steps     | 683520   |
-----------------------------------
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686080/1000000 [8:01:36<4:37:21, 18.86steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686080/1000000 [8:01:50<4:37:21, 18.86steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688640/1000000 [8:02:42<3:52:58, 22.27steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688640/1000000 [8:03:00<3:52:58, 22.27steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:03:48<3:21:22, 25.56steps/s]                                                                69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:03:48<3:21:22, 25.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -140     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -140     |
|    Success           | 0.1      |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.391    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.358    |
|    max_target_q      | -11.9    |
|    min_target_q      | -42.9    |
|    max_reward        | -0.252   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 8        |
|    q1_grad_norm      | 4.74     |
|    q2_grad_norm      | 4.74     |
|    actor_loss        | 23.8     |
|    ent_coeff         | 0.0327   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0822   |
|    n_updates         | 21360    |
| time/                |          |
|    iterations        | 270      |
|    fps               | 38.7     |
|    elapsed_time      | 2.9e+04  |
|    elapsed_steps     | 691200   |
-----------------------------------
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:04:00<3:21:22, 25.56steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693760/1000000 [8:04:58<3:01:50, 28.07steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693760/1000000 [8:05:10<3:01:50, 28.07steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696320/1000000 [8:06:06<2:46:11, 30.45steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696320/1000000 [8:06:20<2:46:11, 30.45steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:07:14<2:35:38, 32.24steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:07:30<2:35:38, 32.24steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_698880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:11:50<2:35:38, 32.24steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -142     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -142     |
|    Success           | 0.0541   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.406    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.356    |
|    max_target_q      | -11.3    |
|    min_target_q      | -43.1    |
|    max_reward        | -0.262   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 8.88     |
|    q1_grad_norm      | 5.78     |
|    q2_grad_norm      | 5.78     |
|    actor_loss        | 23.8     |
|    ent_coeff         | 0.0326   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0849   |
|    n_updates         | 21600    |
| eval/                |          |
|    Length            | 186      |
|    Return            | -134     |
|    NonzeroRewards    | 186      |
|    DiscountedReturn  | -134     |
|    Success           | 0.278    |
|    SuccessLength     | 185      |
| time/                |          |
|    iterations        | 273      |
|    fps               | 15.9     |
|    elapsed_time      | 2.95e+04 |
|    elapsed_steps     | 698880   |
-----------------------------------
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 701440/1000000 [8:13:01<5:10:16, 16.04steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704000/1000000 [8:14:10<4:15:03, 19.34steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704000/1000000 [8:14:20<4:15:03, 19.34steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:15:21<3:37:48, 22.45steps/s]                                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:15:21<3:37:48, 22.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -142     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -142     |
|    Success           | 0.122    |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.423    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.354    |
|    max_target_q      | -10.1    |
|    min_target_q      | -43.5    |
|    max_reward        | -0.249   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 8.62     |
|    q1_grad_norm      | 4.73     |
|    q2_grad_norm      | 4.75     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0324   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0838   |
|    n_updates         | 21840    |
| time/                |          |
|    iterations        | 276      |
|    fps               | 36.4     |
|    elapsed_time      | 2.97e+04 |
|    elapsed_steps     | 706560   |
-----------------------------------
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:15:40<3:37:48, 22.45steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709120/1000000 [8:16:33<3:12:12, 25.22steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709120/1000000 [8:16:50<3:12:12, 25.22steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711680/1000000 [8:17:45<2:53:42, 27.66steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711680/1000000 [8:18:00<2:53:42, 27.66steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:18:52<2:38:14, 30.10steps/s]                                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:18:52<2:38:14, 30.10steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -146     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -146     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.481    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.35     |
|    max_target_q      | -8.39    |
|    min_target_q      | -43.8    |
|    max_reward        | -0.251   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.65     |
|    q1_grad_norm      | 5.38     |
|    q2_grad_norm      | 5.38     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0323   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0847   |
|    n_updates         | 22080    |
| time/                |          |
|    iterations        | 279      |
|    fps               | 36.3     |
|    elapsed_time      | 2.99e+04 |
|    elapsed_steps     | 714240   |
-----------------------------------
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:19:10<2:38:14, 30.10steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716800/1000000 [8:19:59<2:26:43, 32.17steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716800/1000000 [8:20:10<2:26:43, 32.17steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_716800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 719360/1000000 [8:25:51<4:54:37, 15.88steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:27:01<4:02:34, 19.11steps/s]                                                                72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:27:01<4:02:34, 19.11steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -148     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.431    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.346    |
|    max_target_q      | -8.67    |
|    min_target_q      | -44.1    |
|    max_reward        | -0.261   |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 9.34     |
|    q1_grad_norm      | 5.68     |
|    q2_grad_norm      | 5.69     |
|    actor_loss        | 23.8     |
|    ent_coeff         | 0.0321   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0838   |
|    n_updates         | 22320    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -148     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 282      |
|    fps               | 15.7     |
|    elapsed_time      | 3.04e+04 |
|    elapsed_steps     | 721920   |
-----------------------------------
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:27:20<4:02:34, 19.11steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724480/1000000 [8:28:13<3:26:33, 22.23steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724480/1000000 [8:28:30<3:26:33, 22.23steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727040/1000000 [8:29:27<3:02:59, 24.86steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727040/1000000 [8:29:40<3:02:59, 24.86steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:30:39<2:44:55, 27.32steps/s]                                                                73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:30:39<2:44:55, 27.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -138     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -138     |
|    Success           | 0.119    |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.431    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.342    |
|    max_target_q      | -7.93    |
|    min_target_q      | -44.3    |
|    max_reward        | -0.26    |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 8.83     |
|    q1_grad_norm      | 4.52     |
|    q2_grad_norm      | 4.53     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.032    |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0872   |
|    n_updates         | 22560    |
| time/                |          |
|    iterations        | 285      |
|    fps               | 35.3     |
|    elapsed_time      | 3.06e+04 |
|    elapsed_steps     | 729600   |
-----------------------------------
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:30:50<2:44:55, 27.32steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732160/1000000 [8:31:51<2:32:07, 29.35steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732160/1000000 [8:32:10<2:32:07, 29.35steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734720/1000000 [8:33:00<2:21:10, 31.32steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734720/1000000 [8:33:10<2:21:10, 31.32steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_734720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737280/1000000 [8:38:51<4:37:34, 15.77steps/s]                                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737280/1000000 [8:38:51<4:37:34, 15.77steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 187      |
|    Return            | -135     |
|    NonzeroRewards    | 187      |
|    DiscountedReturn  | -135     |
|    Success           | 0.154    |
|    SuccessLength     | 187      |
| algo/                |          |
|    critic_loss       | 0.511    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.339    |
|    max_target_q      | -6.09    |
|    min_target_q      | -44.8    |
|    max_reward        | -0.26    |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 9.58     |
|    q1_grad_norm      | 4.27     |
|    q2_grad_norm      | 4.29     |
|    actor_loss        | 23.8     |
|    ent_coeff         | 0.0318   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0877   |
|    n_updates         | 22800    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -150     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -150     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 288      |
|    fps               | 15.6     |
|    elapsed_time      | 3.11e+04 |
|    elapsed_steps     | 737280   |
-----------------------------------
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739840/1000000 [8:40:05<3:50:13, 18.83steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739840/1000000 [8:40:20<3:50:13, 18.83steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742400/1000000 [8:41:17<3:15:53, 21.92steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742400/1000000 [8:41:30<3:15:53, 21.92steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:42:32<2:53:02, 24.56steps/s]                                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:42:32<2:53:02, 24.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -144     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -144     |
|    Success           | 0.075    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.476    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.338    |
|    max_target_q      | -6.4     |
|    min_target_q      | -45.2    |
|    max_reward        | -0.261   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.28     |
|    q1_grad_norm      | 4.8      |
|    q2_grad_norm      | 4.82     |
|    actor_loss        | 23.8     |
|    ent_coeff         | 0.0317   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0851   |
|    n_updates         | 23040    |
| time/                |          |
|    iterations        | 291      |
|    fps               | 34.7     |
|    elapsed_time      | 3.14e+04 |
|    elapsed_steps     | 744960   |
-----------------------------------
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:42:50<2:53:02, 24.56steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747520/1000000 [8:43:45<2:35:47, 27.01steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747520/1000000 [8:44:00<2:35:47, 27.01steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750080/1000000 [8:44:54<2:21:51, 29.36steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750080/1000000 [8:45:10<2:21:51, 29.36steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:46:01<2:10:27, 31.60steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_752640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:46:20<2:10:27, 31.60steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:50:53<2:10:27, 31.60steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -150     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -150     |
|    Success           | 0.05     |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.491    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.337    |
|    max_target_q      | -6.7     |
|    min_target_q      | -45.3    |
|    max_reward        | -0.261   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 9.78     |
|    q1_grad_norm      | 4.8      |
|    q2_grad_norm      | 4.82     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0315   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.085    |
|    n_updates         | 23280    |
| eval/                |          |
|    Length            | 187      |
|    Return            | -133     |
|    NonzeroRewards    | 187      |
|    DiscountedReturn  | -133     |
|    Success           | 0.111    |
|    SuccessLength     | 187      |
| time/                |          |
|    iterations        | 294      |
|    fps               | 15.3     |
|    elapsed_time      | 3.19e+04 |
|    elapsed_steps     | 752640   |
-----------------------------------
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 755200/1000000 [8:52:06<4:24:59, 15.40steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757760/1000000 [8:53:15<3:36:19, 18.66steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757760/1000000 [8:53:30<3:36:19, 18.66steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:54:35<3:07:19, 21.33steps/s]                                                                76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:54:35<3:07:19, 21.33steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -140     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -140     |
|    Success           | 0.0769   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.494    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.337    |
|    max_target_q      | -6.17    |
|    min_target_q      | -45.9    |
|    max_reward        | -0.254   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 9.58     |
|    q1_grad_norm      | 4.38     |
|    q2_grad_norm      | 4.39     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0314   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0849   |
|    n_updates         | 23520    |
| time/                |          |
|    iterations        | 297      |
|    fps               | 34.5     |
|    elapsed_time      | 3.21e+04 |
|    elapsed_steps     | 760320   |
-----------------------------------
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:54:50<3:07:19, 21.33steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 762880/1000000 [8:55:44<2:41:29, 24.47steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 762880/1000000 [8:56:00<2:41:29, 24.47steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765440/1000000 [8:56:54<2:24:00, 27.15steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765440/1000000 [8:57:10<2:24:00, 27.15steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:58:04<2:11:25, 29.42steps/s]                                                                77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:58:04<2:11:25, 29.42steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -145     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -145     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.479    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.335    |
|    max_target_q      | -5.71    |
|    min_target_q      | -46.3    |
|    max_reward        | -0.263   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 10.1     |
|    q1_grad_norm      | 5.06     |
|    q2_grad_norm      | 5.04     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0312   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0834   |
|    n_updates         | 23760    |
| time/                |          |
|    iterations        | 300      |
|    fps               | 36.8     |
|    elapsed_time      | 3.23e+04 |
|    elapsed_steps     | 768000   |
-----------------------------------
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:58:20<2:11:25, 29.42steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770560/1000000 [8:59:11<2:01:06, 31.57steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_770560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770560/1000000 [8:59:30<2:01:06, 31.57steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 773120/1000000 [9:04:46<3:52:02, 16.30steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:05:56<3:11:15, 19.55steps/s]                                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:05:56<3:11:15, 19.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -146     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0256   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.504    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.331    |
|    max_target_q      | -5.14    |
|    min_target_q      | -47      |
|    max_reward        | -0.26    |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 10.8     |
|    q1_grad_norm      | 5.07     |
|    q2_grad_norm      | 5.1      |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0311   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0849   |
|    n_updates         | 24000    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -152     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -152     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 303      |
|    fps               | 16.3     |
|    elapsed_time      | 3.28e+04 |
|    elapsed_steps     | 775680   |
-----------------------------------
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:06:10<3:11:15, 19.55steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778240/1000000 [9:07:13<2:45:42, 22.31steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778240/1000000 [9:07:30<2:45:42, 22.31steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780800/1000000 [9:08:23<2:24:27, 25.29steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780800/1000000 [9:08:40<2:24:27, 25.29steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:09:38<2:11:42, 27.42steps/s]                                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:09:38<2:11:42, 27.42steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -142     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -142     |
|    Success           | 0.0256   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.528    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.329    |
|    max_target_q      | -5.04    |
|    min_target_q      | -47.3    |
|    max_reward        | -0.256   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 10.8     |
|    q1_grad_norm      | 5.17     |
|    q2_grad_norm      | 5.19     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0309   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0831   |
|    n_updates         | 24240    |
| time/                |          |
|    iterations        | 306      |
|    fps               | 34.6     |
|    elapsed_time      | 3.3e+04  |
|    elapsed_steps     | 783360   |
-----------------------------------
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:09:50<2:11:42, 27.42steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785920/1000000 [9:10:44<1:58:44, 30.05steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785920/1000000 [9:11:00<1:58:44, 30.05steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788480/1000000 [9:11:52<1:50:19, 31.95steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_788480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788480/1000000 [9:12:10<1:50:19, 31.95steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791040/1000000 [9:17:30<3:34:17, 16.25steps/s]                                                                79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791040/1000000 [9:17:30<3:34:17, 16.25steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -143     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -143     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.523    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.327    |
|    max_target_q      | -5.11    |
|    min_target_q      | -48.1    |
|    max_reward        | -0.259   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 9.95     |
|    q1_grad_norm      | 4.11     |
|    q2_grad_norm      | 4.13     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0308   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0842   |
|    n_updates         | 24480    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -142     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -142     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 309      |
|    fps               | 16.3     |
|    elapsed_time      | 3.35e+04 |
|    elapsed_steps     | 791040   |
-----------------------------------
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793600/1000000 [9:18:40<2:56:10, 19.53steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793600/1000000 [9:18:50<2:56:10, 19.53steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796160/1000000 [9:19:52<2:30:27, 22.58steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796160/1000000 [9:20:10<2:30:27, 22.58steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:21:00<2:10:57, 25.62steps/s]                                                                80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:21:00<2:10:57, 25.62steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -142     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -142     |
|    Success           | 0.0513   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.511    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.328    |
|    max_target_q      | -3.81    |
|    min_target_q      | -48.6    |
|    max_reward        | -0.263   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 10.8     |
|    q1_grad_norm      | 4.97     |
|    q2_grad_norm      | 5        |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0306   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0826   |
|    n_updates         | 24720    |
| time/                |          |
|    iterations        | 312      |
|    fps               | 36.6     |
|    elapsed_time      | 3.37e+04 |
|    elapsed_steps     | 798720   |
-----------------------------------
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:21:10<2:10:57, 25.62steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801280/1000000 [9:22:14<1:59:11, 27.79steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801280/1000000 [9:22:30<1:59:11, 27.79steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803840/1000000 [9:23:23<1:48:37, 30.10steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803840/1000000 [9:23:40<1:48:37, 30.10steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:24:35<1:42:21, 31.52steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_806400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:24:50<1:42:21, 31.52steps/s]EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:29:32<1:42:21, 31.52steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -145     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -145     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.545    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.324    |
|    max_target_q      | -3.8     |
|    min_target_q      | -49.2    |
|    max_reward        | -0.259   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 11.6     |
|    q1_grad_norm      | 5.06     |
|    q2_grad_norm      | 5.09     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0305   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0837   |
|    n_updates         | 24960    |
| eval/                |          |
|    Length            | 194      |
|    Return            | -142     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -142     |
|    Success           | 0.167    |
|    SuccessLength     | 194      |
| time/                |          |
|    iterations        | 315      |
|    fps               | 15       |
|    elapsed_time      | 3.42e+04 |
|    elapsed_steps     | 806400   |
-----------------------------------
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 808960/1000000 [9:30:40<3:26:57, 15.39steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811520/1000000 [9:31:52<2:49:16, 18.56steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811520/1000000 [9:32:10<2:49:16, 18.56steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:33:02<2:22:36, 21.73steps/s]                                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:33:02<2:22:36, 21.73steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -143     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -143     |
|    Success           | 0.027    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.528    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.324    |
|    max_target_q      | -2.81    |
|    min_target_q      | -49.9    |
|    max_reward        | -0.258   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 10.7     |
|    q1_grad_norm      | 4.77     |
|    q2_grad_norm      | 4.79     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0303   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0824   |
|    n_updates         | 25200    |
| time/                |          |
|    iterations        | 318      |
|    fps               | 36.4     |
|    elapsed_time      | 3.44e+04 |
|    elapsed_steps     | 814080   |
-----------------------------------
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:33:20<2:22:36, 21.73steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816640/1000000 [9:34:09<2:02:08, 25.02steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816640/1000000 [9:34:20<2:02:08, 25.02steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819200/1000000 [9:35:20<1:49:31, 27.51steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819200/1000000 [9:35:30<1:49:31, 27.51steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:36:33<1:40:50, 29.46steps/s]                                                                82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:36:33<1:40:50, 29.46steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -139     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -139     |
|    Success           | 0.0976   |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.537    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.319    |
|    max_target_q      | -2.75    |
|    min_target_q      | -50.5    |
|    max_reward        | -0.261   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 11.2     |
|    q1_grad_norm      | 4.86     |
|    q2_grad_norm      | 4.88     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0302   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.084    |
|    n_updates         | 25440    |
| time/                |          |
|    iterations        | 321      |
|    fps               | 36.5     |
|    elapsed_time      | 3.46e+04 |
|    elapsed_steps     | 821760   |
-----------------------------------
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:36:50<1:40:50, 29.46steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824320/1000000 [9:37:48<1:35:21, 30.71steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824320/1000000 [9:38:00<1:35:21, 30.71steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_824320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 826880/1000000 [9:43:36<3:03:39, 15.71steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:44:56<2:33:01, 18.58steps/s]                                                                83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:44:56<2:33:01, 18.58steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -147     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -147     |
|    Success           | 0.025    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.576    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.316    |
|    max_target_q      | -1.73    |
|    min_target_q      | -51      |
|    max_reward        | -0.257   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 11.8     |
|    q1_grad_norm      | 4.89     |
|    q2_grad_norm      | 4.93     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.03     |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0838   |
|    n_updates         | 25680    |
| eval/                |          |
|    Length            | 193      |
|    Return            | -142     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -142     |
|    Success           | 0.222    |
|    SuccessLength     | 193      |
| time/                |          |
|    iterations        | 324      |
|    fps               | 15.3     |
|    elapsed_time      | 3.51e+04 |
|    elapsed_steps     | 829440   |
-----------------------------------
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:45:10<2:33:01, 18.58steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832000/1000000 [9:46:05<2:08:26, 21.80steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832000/1000000 [9:46:20<2:08:26, 21.80steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834560/1000000 [9:47:14<1:50:46, 24.89steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834560/1000000 [9:47:30<1:50:46, 24.89steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:48:20<1:37:17, 27.90steps/s]                                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:48:20<1:37:17, 27.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -146     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0769   |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.62     |
|    mean_entropy      | 10.4     |
|    mean_ent_bonus    | 0.31     |
|    max_target_q      | -1.29    |
|    min_target_q      | -51.7    |
|    max_reward        | -0.261   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 13.3     |
|    q1_grad_norm      | 5.68     |
|    q2_grad_norm      | 5.72     |
|    actor_loss        | 24       |
|    ent_coeff         | 0.0299   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0859   |
|    n_updates         | 25920    |
| time/                |          |
|    iterations        | 327      |
|    fps               | 37.5     |
|    elapsed_time      | 3.53e+04 |
|    elapsed_steps     | 837120   |
-----------------------------------
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:48:30<1:37:17, 27.90steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839680/1000000 [9:49:32<1:29:38, 29.81steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839680/1000000 [9:49:50<1:29:38, 29.81steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842240/1000000 [9:50:44<1:23:57, 31.31steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842240/1000000 [9:51:00<1:23:57, 31.31steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_842240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844800/1000000 [9:56:43<2:46:38, 15.52steps/s]                                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844800/1000000 [9:56:43<2:46:38, 15.52steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -145     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -145     |
|    Success           | 0.05     |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.611    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.311    |
|    max_target_q      | -1.32    |
|    min_target_q      | -52.3    |
|    max_reward        | -0.249   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 12.5     |
|    q1_grad_norm      | 4.98     |
|    q2_grad_norm      | 5.03     |
|    actor_loss        | 24       |
|    ent_coeff         | 0.0298   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0855   |
|    n_updates         | 26160    |
| eval/                |          |
|    Length            | 187      |
|    Return            | -143     |
|    NonzeroRewards    | 187      |
|    DiscountedReturn  | -143     |
|    Success           | 0.111    |
|    SuccessLength     | 187      |
| time/                |          |
|    iterations        | 330      |
|    fps               | 15.3     |
|    elapsed_time      | 3.58e+04 |
|    elapsed_steps     | 844800   |
-----------------------------------
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847360/1000000 [9:57:51<2:14:55, 18.86steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847360/1000000 [9:58:11<2:14:55, 18.86steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849920/1000000 [9:59:00<1:53:01, 22.13steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849920/1000000 [9:59:11<1:53:01, 22.13steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [10:00:14<1:39:13, 24.78steps/s]                                                                 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [10:00:14<1:39:13, 24.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -151     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -151     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.614    |
|    mean_entropy      | 10.4     |
|    mean_ent_bonus    | 0.309    |
|    max_target_q      | -1.28    |
|    min_target_q      | -52.8    |
|    max_reward        | -0.259   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 12.6     |
|    q1_grad_norm      | 5.03     |
|    q2_grad_norm      | 5.07     |
|    actor_loss        | 24       |
|    ent_coeff         | 0.0296   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0849   |
|    n_updates         | 26400    |
| time/                |          |
|    iterations        | 333      |
|    fps               | 36.4     |
|    elapsed_time      | 3.6e+04  |
|    elapsed_steps     | 852480   |
-----------------------------------
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [10:00:31<1:39:13, 24.78steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855040/1000000 [10:01:24<1:27:54, 27.48steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855040/1000000 [10:01:41<1:27:54, 27.48steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857600/1000000 [10:02:34<1:19:49, 29.73steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857600/1000000 [10:02:51<1:19:49, 29.73steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:03:47<1:15:00, 31.07steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:04:01<1:15:00, 31.07steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_860160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:08:27<1:15:00, 31.07steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 182      |
|    Return            | -135     |
|    NonzeroRewards    | 182      |
|    DiscountedReturn  | -135     |
|    Success           | 0.167    |
|    SuccessLength     | 182      |
| algo/                |          |
|    critic_loss       | 0.594    |
|    mean_entropy      | 10.4     |
|    mean_ent_bonus    | 0.307    |
|    max_target_q      | -1.43    |
|    min_target_q      | -53.3    |
|    max_reward        | -0.256   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 11.6     |
|    q1_grad_norm      | 4.62     |
|    q2_grad_norm      | 4.63     |
|    actor_loss        | 24.1     |
|    ent_coeff         | 0.0295   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0851   |
|    n_updates         | 26640    |
| eval/                |          |
|    Length            | 189      |
|    Return            | -139     |
|    NonzeroRewards    | 189      |
|    DiscountedReturn  | -139     |
|    Success           | 0.167    |
|    SuccessLength     | 189      |
| time/                |          |
|    iterations        | 336      |
|    fps               | 15.6     |
|    elapsed_time      | 3.65e+04 |
|    elapsed_steps     | 860160   |
-----------------------------------
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 862720/1000000 [10:09:47<2:27:55, 15.47steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865280/1000000 [10:10:59<2:00:45, 18.59steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865280/1000000 [10:11:11<2:00:45, 18.59steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:12:10<1:41:13, 21.76steps/s]                                                                 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:12:10<1:41:13, 21.76steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -142     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -142     |
|    Success           | 0.0789   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.602    |
|    mean_entropy      | 10.4     |
|    mean_ent_bonus    | 0.305    |
|    max_target_q      | -1.9     |
|    min_target_q      | -54      |
|    max_reward        | -0.244   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 13.1     |
|    q1_grad_norm      | 6.37     |
|    q2_grad_norm      | 6.38     |
|    actor_loss        | 24.1     |
|    ent_coeff         | 0.0293   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0843   |
|    n_updates         | 26880    |
| time/                |          |
|    iterations        | 339      |
|    fps               | 34.4     |
|    elapsed_time      | 3.67e+04 |
|    elapsed_steps     | 867840   |
-----------------------------------
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:12:21<1:41:13, 21.76steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870400/1000000 [10:13:24<1:28:14, 24.48steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870400/1000000 [10:13:41<1:28:14, 24.48steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872960/1000000 [10:14:34<1:17:49, 27.21steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872960/1000000 [10:14:51<1:17:49, 27.21steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:15:44<1:10:27, 29.45steps/s]                                                                 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:15:44<1:10:27, 29.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -145     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -145     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.624    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.305    |
|    max_target_q      | -2.04    |
|    min_target_q      | -54.5    |
|    max_reward        | -0.251   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 12.9     |
|    q1_grad_norm      | 5.57     |
|    q2_grad_norm      | 5.59     |
|    actor_loss        | 24.2     |
|    ent_coeff         | 0.0292   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0858   |
|    n_updates         | 27120    |
| time/                |          |
|    iterations        | 342      |
|    fps               | 35.9     |
|    elapsed_time      | 3.69e+04 |
|    elapsed_steps     | 875520   |
-----------------------------------
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:16:01<1:10:27, 29.45steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878080/1000000 [10:16:55<1:05:05, 31.22steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_878080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878080/1000000 [10:17:11<1:05:05, 31.22steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 880640/1000000 [10:22:45<2:06:16, 15.75steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:23:51<1:41:34, 19.17steps/s]                                                                 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:23:51<1:41:34, 19.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -141     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -141     |
|    Success           | 0.1      |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.596    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.305    |
|    max_target_q      | -1.96    |
|    min_target_q      | -54.8    |
|    max_reward        | -0.247   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 12.6     |
|    q1_grad_norm      | 5.55     |
|    q2_grad_norm      | 5.57     |
|    actor_loss        | 24.3     |
|    ent_coeff         | 0.029    |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0834   |
|    n_updates         | 27360    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 345      |
|    fps               | 15.8     |
|    elapsed_time      | 3.74e+04 |
|    elapsed_steps     | 883200   |
-----------------------------------
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:24:11<1:41:34, 19.17steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885760/1000000 [10:24:58<1:24:28, 22.54steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885760/1000000 [10:25:11<1:24:28, 22.54steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888320/1000000 [10:26:06<1:12:34, 25.65steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888320/1000000 [10:26:21<1:12:34, 25.65steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:27:16<1:04:36, 28.15steps/s]                                                                 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:27:16<1:04:36, 28.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -142     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -142     |
|    Success           | 0.0488   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.622    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.304    |
|    max_target_q      | -1.25    |
|    min_target_q      | -55.6    |
|    max_reward        | -0.243   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 12.9     |
|    q1_grad_norm      | 4.92     |
|    q2_grad_norm      | 4.93     |
|    actor_loss        | 24.5     |
|    ent_coeff         | 0.0289   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0854   |
|    n_updates         | 27600    |
| time/                |          |
|    iterations        | 348      |
|    fps               | 37.5     |
|    elapsed_time      | 3.76e+04 |
|    elapsed_steps     | 890880   |
-----------------------------------
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:27:31<1:04:36, 28.15steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893440/1000000 [10:28:29<59:14, 29.98steps/s]   89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893440/1000000 [10:28:41<59:14, 29.98steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896000/1000000 [10:29:42<55:25, 31.27steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_896000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896000/1000000 [10:30:01<55:25, 31.27steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898560/1000000 [10:35:39<1:48:33, 15.57steps/s]                                                                 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898560/1000000 [10:35:39<1:48:33, 15.57steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -141     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -141     |
|    Success           | 0.05     |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.659    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.305    |
|    max_target_q      | -1.63    |
|    min_target_q      | -56.3    |
|    max_reward        | -0.247   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 13.4     |
|    q1_grad_norm      | 5.59     |
|    q2_grad_norm      | 5.61     |
|    actor_loss        | 24.6     |
|    ent_coeff         | 0.0288   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0814   |
|    n_updates         | 27840    |
| eval/                |          |
|    Length            | 193      |
|    Return            | -138     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -138     |
|    Success           | 0.0556   |
|    SuccessLength     | 193      |
| time/                |          |
|    iterations        | 351      |
|    fps               | 15.3     |
|    elapsed_time      | 3.81e+04 |
|    elapsed_steps     | 898560   |
-----------------------------------
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901120/1000000 [10:36:47<1:27:14, 18.89steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901120/1000000 [10:37:01<1:27:14, 18.89steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903680/1000000 [10:38:02<1:13:29, 21.84steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903680/1000000 [10:38:21<1:13:29, 21.84steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:39:12<1:02:57, 24.82steps/s]                                                                 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:39:12<1:02:57, 24.82steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -134     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -134     |
|    Success           | 0.0789   |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.651    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.302    |
|    max_target_q      | -1.45    |
|    min_target_q      | -56.8    |
|    max_reward        | -0.242   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 13.7     |
|    q1_grad_norm      | 6.08     |
|    q2_grad_norm      | 6.1      |
|    actor_loss        | 24.6     |
|    ent_coeff         | 0.0286   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0815   |
|    n_updates         | 28080    |
| time/                |          |
|    iterations        | 354      |
|    fps               | 36.1     |
|    elapsed_time      | 3.84e+04 |
|    elapsed_steps     | 906240   |
-----------------------------------
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:39:31<1:02:57, 24.82steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908800/1000000 [10:40:22<55:16, 27.50steps/s]   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908800/1000000 [10:40:41<55:16, 27.50steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911360/1000000 [10:41:34<50:10, 29.45steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911360/1000000 [10:41:51<50:10, 29.45steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:42:43<45:40, 31.41steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_913920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:43:01<45:40, 31.41steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:47:22<45:40, 31.41steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -139     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -139     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.666    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.3      |
|    max_target_q      | -0.68    |
|    min_target_q      | -57.1    |
|    max_reward        | -0.243   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 14.4     |
|    q1_grad_norm      | 6.32     |
|    q2_grad_norm      | 6.36     |
|    actor_loss        | 24.8     |
|    ent_coeff         | 0.0285   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.081    |
|    n_updates         | 28320    |
| eval/                |          |
|    Length            | 198      |
|    Return            | -140     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -140     |
|    Success           | 0.0556   |
|    SuccessLength     | 198      |
| time/                |          |
|    iterations        | 357      |
|    fps               | 15.7     |
|    elapsed_time      | 3.88e+04 |
|    elapsed_steps     | 913920   |
-----------------------------------
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 916480/1000000 [10:48:35<1:28:26, 15.74steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919040/1000000 [10:49:48<1:11:28, 18.88steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919040/1000000 [10:50:01<1:11:28, 18.88steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:50:58<59:14, 22.06steps/s]                                                                 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:50:58<59:14, 22.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -138     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -138     |
|    Success           | 0.122    |
|    SuccessLength     | 189      |
| algo/                |          |
|    critic_loss       | 0.68     |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.304    |
|    max_target_q      | -1.08    |
|    min_target_q      | -57.5    |
|    max_reward        | -0.25    |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 15.2     |
|    q1_grad_norm      | 6.55     |
|    q2_grad_norm      | 6.58     |
|    actor_loss        | 24.9     |
|    ent_coeff         | 0.0284   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0795   |
|    n_updates         | 28560    |
| time/                |          |
|    iterations        | 360      |
|    fps               | 35.5     |
|    elapsed_time      | 3.91e+04 |
|    elapsed_steps     | 921600   |
-----------------------------------
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:51:11<59:14, 22.06steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924160/1000000 [10:52:11<50:56, 24.81steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924160/1000000 [10:52:31<50:56, 24.81steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926720/1000000 [10:53:22<44:38, 27.36steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926720/1000000 [10:53:41<44:38, 27.36steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:54:33<39:52, 29.56steps/s]                                                               93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:54:33<39:52, 29.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 186      |
|    Return            | -136     |
|    NonzeroRewards    | 186      |
|    DiscountedReturn  | -136     |
|    Success           | 0.146    |
|    SuccessLength     | 186      |
| algo/                |          |
|    critic_loss       | 0.706    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.301    |
|    max_target_q      | -1.45    |
|    min_target_q      | -58      |
|    max_reward        | -0.232   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 14.5     |
|    q1_grad_norm      | 5.62     |
|    q2_grad_norm      | 5.65     |
|    actor_loss        | 25.1     |
|    ent_coeff         | 0.0282   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.079    |
|    n_updates         | 28800    |
| time/                |          |
|    iterations        | 363      |
|    fps               | 35.8     |
|    elapsed_time      | 3.93e+04 |
|    elapsed_steps     | 929280   |
-----------------------------------
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:54:51<39:52, 29.56steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931840/1000000 [10:55:45<36:31, 31.10steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_931840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931840/1000000 [10:56:01<36:31, 31.10steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 934400/1000000 [11:01:38<1:09:50, 15.65steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:02:50<55:48, 18.83steps/s]                                                                 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:02:50<55:48, 18.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 187      |
|    Return            | -136     |
|    NonzeroRewards    | 187      |
|    DiscountedReturn  | -136     |
|    Success           | 0.0976   |
|    SuccessLength     | 187      |
| algo/                |          |
|    critic_loss       | 0.659    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.299    |
|    max_target_q      | -1.33    |
|    min_target_q      | -58.4    |
|    max_reward        | -0.24    |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 13.4     |
|    q1_grad_norm      | 4.92     |
|    q2_grad_norm      | 4.94     |
|    actor_loss        | 25.2     |
|    ent_coeff         | 0.0281   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0786   |
|    n_updates         | 29040    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -147     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -147     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 366      |
|    fps               | 15.5     |
|    elapsed_time      | 3.98e+04 |
|    elapsed_steps     | 936960   |
-----------------------------------
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [11:03:01<55:48, 18.83steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939520/1000000 [11:04:04<46:13, 21.81steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939520/1000000 [11:04:21<46:13, 21.81steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942080/1000000 [11:05:13<38:50, 24.86steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942080/1000000 [11:05:31<38:50, 24.86steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:06:22<33:24, 27.62steps/s]                                                               94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:06:22<33:24, 27.62steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 172      |
|    Return            | -121     |
|    NonzeroRewards    | 172      |
|    DiscountedReturn  | -121     |
|    Success           | 0.244    |
|    SuccessLength     | 172      |
| algo/                |          |
|    critic_loss       | 0.77     |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.299    |
|    max_target_q      | -0.274   |
|    min_target_q      | -59      |
|    max_reward        | -0.235   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 16.4     |
|    q1_grad_norm      | 6.21     |
|    q2_grad_norm      | 6.25     |
|    actor_loss        | 25.4     |
|    ent_coeff         | 0.028    |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0793   |
|    n_updates         | 29280    |
| time/                |          |
|    iterations        | 369      |
|    fps               | 36.2     |
|    elapsed_time      | 4e+04    |
|    elapsed_steps     | 944640   |
-----------------------------------
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [11:06:41<33:24, 27.62steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947200/1000000 [11:07:31<29:28, 29.85steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947200/1000000 [11:07:51<29:28, 29.85steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949760/1000000 [11:08:38<26:10, 31.99steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949760/1000000 [11:08:51<26:10, 31.99steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_949760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952320/1000000 [11:14:30<50:11, 15.83steps/s]                                                               95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952320/1000000 [11:14:30<50:11, 15.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 187      |
|    Return            | -137     |
|    NonzeroRewards    | 187      |
|    DiscountedReturn  | -137     |
|    Success           | 0.15     |
|    SuccessLength     | 187      |
| algo/                |          |
|    critic_loss       | 0.815    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.299    |
|    max_target_q      | -0.883   |
|    min_target_q      | -59.2    |
|    max_reward        | -0.232   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 17.2     |
|    q1_grad_norm      | 5.74     |
|    q2_grad_norm      | 5.78     |
|    actor_loss        | 25.6     |
|    ent_coeff         | 0.0278   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0807   |
|    n_updates         | 29520    |
| eval/                |          |
|    Length            | 186      |
|    Return            | -138     |
|    NonzeroRewards    | 186      |
|    DiscountedReturn  | -138     |
|    Success           | 0.111    |
|    SuccessLength     | 186      |
| time/                |          |
|    iterations        | 372      |
|    fps               | 15.7     |
|    elapsed_time      | 4.05e+04 |
|    elapsed_steps     | 952320   |
-----------------------------------
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954880/1000000 [11:15:40<39:26, 19.06steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954880/1000000 [11:15:51<39:26, 19.06steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957440/1000000 [11:16:52<32:00, 22.16steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957440/1000000 [11:17:11<32:00, 22.16steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:18:04<26:38, 25.03steps/s]                                                               96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:18:04<26:38, 25.03steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 183      |
|    Return            | -136     |
|    NonzeroRewards    | 183      |
|    DiscountedReturn  | -136     |
|    Success           | 0.14     |
|    SuccessLength     | 183      |
| algo/                |          |
|    critic_loss       | 0.729    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.297    |
|    max_target_q      | 0.0408   |
|    min_target_q      | -59.8    |
|    max_reward        | -0.235   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 14.6     |
|    q1_grad_norm      | 5.38     |
|    q2_grad_norm      | 5.4      |
|    actor_loss        | 25.7     |
|    ent_coeff         | 0.0277   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0811   |
|    n_updates         | 29760    |
| time/                |          |
|    iterations        | 375      |
|    fps               | 36       |
|    elapsed_time      | 4.07e+04 |
|    elapsed_steps     | 960000   |
-----------------------------------
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:18:21<26:38, 25.03steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 962560/1000000 [11:19:14<22:33, 27.65steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 962560/1000000 [11:19:31<22:33, 27.65steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965120/1000000 [11:20:23<19:28, 29.85steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965120/1000000 [11:20:41<19:28, 29.85steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:21:31<16:52, 31.93steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:21:41<16:52, 31.93steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_967680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:26:15<16:52, 31.93steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -139     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -139     |
|    Success           | 0.0789   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.764    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.298    |
|    max_target_q      | -3.75    |
|    min_target_q      | -60.1    |
|    max_reward        | -0.233   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 15.8     |
|    q1_grad_norm      | 6.94     |
|    q2_grad_norm      | 6.97     |
|    actor_loss        | 26       |
|    ent_coeff         | 0.0276   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0764   |
|    n_updates         | 30000    |
| eval/                |          |
|    Length            | 192      |
|    Return            | -142     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -142     |
|    Success           | 0.0556   |
|    SuccessLength     | 192      |
| time/                |          |
|    iterations        | 378      |
|    fps               | 15.6     |
|    elapsed_time      | 4.12e+04 |
|    elapsed_steps     | 967680   |
-----------------------------------
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 970240/1000000 [11:27:26<31:31, 15.73steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972800/1000000 [11:28:42<24:11, 18.74steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972800/1000000 [11:29:01<24:11, 18.74steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:29:59<19:03, 21.54steps/s]                                                               98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:29:59<19:03, 21.54steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 170      |
|    Return            | -121     |
|    NonzeroRewards    | 170      |
|    DiscountedReturn  | -121     |
|    Success           | 0.292    |
|    SuccessLength     | 170      |
| algo/                |          |
|    critic_loss       | 0.782    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.298    |
|    max_target_q      | -4.59    |
|    min_target_q      | -60.8    |
|    max_reward        | -0.23    |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 15.4     |
|    q1_grad_norm      | 6.11     |
|    q2_grad_norm      | 6.14     |
|    actor_loss        | 26.2     |
|    ent_coeff         | 0.0274   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0748   |
|    n_updates         | 30240    |
| time/                |          |
|    iterations        | 381      |
|    fps               | 34.3     |
|    elapsed_time      | 4.14e+04 |
|    elapsed_steps     | 975360   |
-----------------------------------
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:30:11<19:03, 21.54steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977920/1000000 [11:31:11<15:04, 24.41steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977920/1000000 [11:31:31<15:04, 24.41steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980480/1000000 [11:32:20<11:57, 27.21steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980480/1000000 [11:32:31<11:57, 27.21steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:33:27<09:29, 29.77steps/s]                                                               98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:33:27<09:29, 29.77steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 188      |
|    Return            | -136     |
|    NonzeroRewards    | 188      |
|    DiscountedReturn  | -136     |
|    Success           | 0.128    |
|    SuccessLength     | 188      |
| algo/                |          |
|    critic_loss       | 0.722    |
|    mean_entropy      | 10.9     |
|    mean_ent_bonus    | 0.297    |
|    max_target_q      | -4.61    |
|    min_target_q      | -60.9    |
|    max_reward        | -0.228   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 14.2     |
|    q1_grad_norm      | 5.35     |
|    q2_grad_norm      | 5.37     |
|    actor_loss        | 26.3     |
|    ent_coeff         | 0.0273   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0747   |
|    n_updates         | 30480    |
| time/                |          |
|    iterations        | 384      |
|    fps               | 36.9     |
|    elapsed_time      | 4.16e+04 |
|    elapsed_steps     | 983040   |
-----------------------------------
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:33:41<09:29, 29.77steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985600/1000000 [11:34:36<07:34, 31.69steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985600/1000000 [11:34:51<07:34, 31.69steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_985600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 988160/1000000 [11:40:25<12:25, 15.88steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:41:34<08:04, 19.17steps/s]                                                               99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:41:34<08:04, 19.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -140     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -140     |
|    Success           | 0.0769   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.777    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.29     |
|    max_target_q      | -4.71    |
|    min_target_q      | -61.3    |
|    max_reward        | -0.227   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 16       |
|    q1_grad_norm      | 6.37     |
|    q2_grad_norm      | 6.41     |
|    actor_loss        | 26.5     |
|    ent_coeff         | 0.0272   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0776   |
|    n_updates         | 30720    |
| eval/                |          |
|    Length            | 187      |
|    Return            | -135     |
|    NonzeroRewards    | 187      |
|    DiscountedReturn  | -135     |
|    Success           | 0.111    |
|    SuccessLength     | 186      |
| time/                |          |
|    iterations        | 387      |
|    fps               | 15.8     |
|    elapsed_time      | 4.21e+04 |
|    elapsed_steps     | 990720   |
-----------------------------------
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:41:51<08:04, 19.17steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993280/1000000 [11:42:44<05:00, 22.35steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993280/1000000 [11:43:01<05:00, 22.35steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995840/1000000 [11:43:52<02:43, 25.47steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995840/1000000 [11:44:11<02:43, 25.47steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:44:58<00:56, 28.37steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:45:11<00:56, 28.37steps/s]Saved video of policy to videos/2025-09-08/0ny84k5k/nominal/policy_step_998400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:49:33<00:56, 28.37steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 183      |
|    Return            | -133     |
|    NonzeroRewards    | 183      |
|    DiscountedReturn  | -133     |
|    Success           | 0.178    |
|    SuccessLength     | 183      |
| algo/                |          |
|    critic_loss       | 0.797    |
|    mean_entropy      | 10.5     |
|    mean_ent_bonus    | 0.284    |
|    max_target_q      | -4.94    |
|    min_target_q      | -61.6    |
|    max_reward        | -0.219   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 15.9     |
|    q1_grad_norm      | 5.87     |
|    q2_grad_norm      | 5.9      |
|    actor_loss        | 26.7     |
|    ent_coeff         | 0.027    |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0773   |
|    n_updates         | 30960    |
| eval/                |          |
|    Length            | 183      |
|    Return            | -130     |
|    NonzeroRewards    | 183      |
|    DiscountedReturn  | -130     |
|    Success           | 0.167    |
|    SuccessLength     | 183      |
| time/                |          |
|    iterations        | 390      |
|    fps               | 16       |
|    elapsed_time      | 4.26e+04 |
|    elapsed_steps     | 998400   |
-----------------------------------
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:49:33<01:08, 23.45steps/s]
RLRunner: Finished training.
RLRunner: Log files saved to /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-0ny84k5k/files
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/along_view+50/success_rate â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:         eval/fov30/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–â–â–â–â–â–ˆ
wandb:         eval/fov70/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:       eval/nominal/success_rate â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–â–
wandb:    eval/roll+15deg/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:    eval/roll+30deg/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–â–â–â–ˆâ–â–ˆâ–â–
wandb:    eval/shift+x+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–â–ˆâ–â–â–â–ˆâ–â–
wandb:    eval/shift+y+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–
wandb:    eval/shift+z+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb: eval/along_view+50/success_rate 0.5
wandb:         eval/fov30/success_rate 0
wandb:         eval/fov70/success_rate 0.5
wandb:       eval/nominal/success_rate 0
wandb:    eval/roll+15deg/success_rate 0.5
wandb:    eval/roll+30deg/success_rate 0
wandb:    eval/shift+x+50/success_rate 0
wandb:    eval/shift+y+50/success_rate 0
wandb:    eval/shift+z+50/success_rate 0
wandb: 
wandb: ðŸš€ View run fancy-darkness-987 at: https://wandb.ai/michael-bezick-purdue-university/pprl/runs/0ny84k5k
wandb: â­ï¸ View project at: https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: Synced 7 W&B file(s), 57 media file(s), 0 artifact file(s) and 42 other file(s)
wandb: Find logs at: ./wandb/run-20250908_150535-0ny84k5k/logs
