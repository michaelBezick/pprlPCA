/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
wandb: Currently logged in as: michael-bezick (michael-bezick-purdue-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: creating run
wandb: Tracking run with wandb version 0.20.1
wandb: Run data is saved locally in /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-5ak0blzx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-silence-988
wandb: â­ï¸ View project at https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: ðŸš€ View run at https://wandb.ai/michael-bezick-purdue-university/pprl/runs/5ak0blzx
Group name is:  PCA_push_chair
Instantiating 8 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
Instantiating 1 environments...
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/sapien/core/renderer_config.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Environments instantiated.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
BasicSampler: Resetting all environments.
BasicSampler: Resetting agent.
SAC: Given sampler batch size 2560, training batch size 512, and replay ratio 16, there will be 80 updates per iteration.
SAC: Using learnable entropy coefficient with target entropy of -20
RLRunner: Starting training...
RLRunner: Saving log files to /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-5ak0blzx/files
  0%|          | 0/1000000 [00:00<?, ?steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_0.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
wandb: WARNING Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                0%|          | 0/1000000 [04:25<?, ?steps/s]----------------------------------
| eval/               |          |
|    Length           | 200      |
|    Return           | -210     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -210     |
|    Success          | 0        |
|    SuccessLength    | 200      |
| time/               |          |
|    iterations       | 0        |
|    fps              | 0        |
|    elapsed_time     | 265      |
|    elapsed_steps    | 0        |
----------------------------------
For the first 10000 steps, agent will use a fixed std of 0.75 for exploration.
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
/home/exx/anaconda3/envs/pprl/lib/python3.10/site-packages/mani_skill2/utils/visualization/misc.py:56: RuntimeWarning: invalid value encountered in divide
  depth = (depth - min_depth) / (max_depth - min_depth)
  0%|          | 2560/1000000 [05:23<35:03:52,  7.90steps/s]  1%|          | 5120/1000000 [06:23<18:09:57, 15.21steps/s]  1%|          | 5120/1000000 [06:40<18:09:57, 15.21steps/s]  1%|          | 7680/1000000 [07:17<12:31:37, 22.00steps/s]                                                              1%|          | 7680/1000000 [07:17<12:31:37, 22.00steps/s]----------------------------------
| rollout/            |          |
|    Length           | 200      |
|    Return           | -204     |
|    NonzeroRewards   | 200      |
|    DiscountedReturn | -204     |
|    Success          | 0        |
|    SuccessLength    | 200      |
| time/               |          |
|    iterations       | 3        |
|    fps              | 44.5     |
|    elapsed_time     | 438      |
|    elapsed_steps    | 7680     |
----------------------------------
  1%|          | 7680/1000000 [07:30<12:31:37, 22.00steps/s]  1%|          | 10240/1000000 [08:34<10:48:08, 25.45steps/s]  1%|          | 10240/1000000 [08:50<10:48:08, 25.45steps/s]  1%|â–         | 12800/1000000 [09:54<9:59:05, 27.46steps/s]   1%|â–         | 12800/1000000 [10:10<9:59:05, 27.46steps/s]  2%|â–         | 15360/1000000 [11:13<9:26:12, 28.98steps/s]                                                              2%|â–         | 15360/1000000 [11:13<9:26:12, 28.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -205     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -205     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00639  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.68     |
|    max_target_q      | -0.39    |
|    min_target_q      | -0.679   |
|    max_reward        | -0.736   |
|    min_reward        | -1.53    |
|    encoder_grad_norm | 0.0669   |
|    q1_grad_norm      | 0.136    |
|    q2_grad_norm      | 0.147    |
|    actor_loss        | 0.183    |
|    ent_coeff         | 0.0499   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.111    |
|    n_updates         | 240      |
| time/                |          |
|    iterations        | 6        |
|    fps               | 32.6     |
|    elapsed_time      | 673      |
|    elapsed_steps     | 15360    |
-----------------------------------
  2%|â–         | 15360/1000000 [11:30<9:26:12, 28.98steps/s]  2%|â–         | 17920/1000000 [12:31<9:02:50, 30.15steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_17920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  2%|â–         | 17920/1000000 [12:50<9:02:50, 30.15steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  2%|â–         | 20480/1000000 [17:55<17:06:48, 15.90steps/s]  2%|â–         | 23040/1000000 [19:12<14:18:32, 18.97steps/s]                                                               2%|â–         | 23040/1000000 [19:12<14:18:32, 18.97steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -212     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -212     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00455  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.677    |
|    max_target_q      | -0.956   |
|    min_target_q      | -1.75    |
|    max_reward        | -0.746   |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 0.12     |
|    q1_grad_norm      | 0.144    |
|    q2_grad_norm      | 0.136    |
|    actor_loss        | 0.984    |
|    ent_coeff         | 0.0496   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0835   |
|    n_updates         | 480      |
| eval/                |          |
|    Length            | 200      |
|    Return            | -212     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -212     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 9        |
|    fps               | 16       |
|    elapsed_time      | 1.15e+03 |
|    elapsed_steps     | 23040    |
-----------------------------------
  2%|â–         | 23040/1000000 [19:30<14:18:32, 18.97steps/s]  3%|â–Ž         | 25600/1000000 [20:27<12:17:47, 22.01steps/s]  3%|â–Ž         | 25600/1000000 [20:40<12:17:47, 22.01steps/s]  3%|â–Ž         | 28160/1000000 [21:41<10:53:48, 24.77steps/s]  3%|â–Ž         | 28160/1000000 [22:00<10:53:48, 24.77steps/s]  3%|â–Ž         | 30720/1000000 [22:57<10:00:56, 26.88steps/s]                                                               3%|â–Ž         | 30720/1000000 [22:57<10:00:56, 26.88steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -206     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -206     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00595  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.674    |
|    max_target_q      | -1.48    |
|    min_target_q      | -2.86    |
|    max_reward        | -0.753   |
|    min_reward        | -1.53    |
|    encoder_grad_norm | 0.201    |
|    q1_grad_norm      | 0.196    |
|    q2_grad_norm      | 0.198    |
|    actor_loss        | 1.79     |
|    ent_coeff         | 0.0494   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0735   |
|    n_updates         | 720      |
| time/                |          |
|    iterations        | 12       |
|    fps               | 34.1     |
|    elapsed_time      | 1.38e+03 |
|    elapsed_steps     | 30720    |
-----------------------------------
  3%|â–Ž         | 30720/1000000 [23:10<10:00:56, 26.88steps/s]  3%|â–Ž         | 33280/1000000 [24:12<9:19:56, 28.77steps/s]   3%|â–Ž         | 33280/1000000 [24:30<9:19:56, 28.77steps/s]  4%|â–Ž         | 35840/1000000 [25:26<8:50:15, 30.30steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  4%|â–Ž         | 35840/1000000 [25:40<8:50:15, 30.30steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_35840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  4%|â–         | 38400/1000000 [30:39<16:00:52, 16.68steps/s]                                                               4%|â–         | 38400/1000000 [30:39<16:00:52, 16.68steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -203     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -203     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.00837  |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.67     |
|    max_target_q      | -1.98    |
|    min_target_q      | -3.97    |
|    max_reward        | -0.739   |
|    min_reward        | -1.51    |
|    encoder_grad_norm | 0.351    |
|    q1_grad_norm      | 0.309    |
|    q2_grad_norm      | 0.313    |
|    actor_loss        | 2.59     |
|    ent_coeff         | 0.0492   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0666   |
|    n_updates         | 960      |
| eval/                |          |
|    Length            | 200      |
|    Return            | -206     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -206     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 15       |
|    fps               | 16.6     |
|    elapsed_time      | 1.84e+03 |
|    elapsed_steps     | 38400    |
-----------------------------------
  4%|â–         | 40960/1000000 [31:42<13:08:12, 20.28steps/s]  4%|â–         | 40960/1000000 [32:00<13:08:12, 20.28steps/s]  4%|â–         | 43520/1000000 [32:46<11:08:55, 23.83steps/s]  4%|â–         | 43520/1000000 [33:00<11:08:55, 23.83steps/s]  5%|â–         | 46080/1000000 [33:53<9:51:03, 26.90steps/s]                                                               5%|â–         | 46080/1000000 [33:53<9:51:03, 26.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -202     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -202     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0106   |
|    mean_entropy      | 13.6     |
|    mean_ent_bonus    | 0.666    |
|    max_target_q      | -2.47    |
|    min_target_q      | -5.09    |
|    max_reward        | -0.725   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 0.493    |
|    q1_grad_norm      | 0.406    |
|    q2_grad_norm      | 0.413    |
|    actor_loss        | 3.35     |
|    ent_coeff         | 0.0489   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0622   |
|    n_updates         | 1200     |
| time/                |          |
|    iterations        | 18       |
|    fps               | 39.7     |
|    elapsed_time      | 2.03e+03 |
|    elapsed_steps     | 46080    |
-----------------------------------
  5%|â–         | 46080/1000000 [34:10<9:51:03, 26.90steps/s]  5%|â–         | 48640/1000000 [34:53<8:44:16, 30.24steps/s]  5%|â–         | 48640/1000000 [35:10<8:44:16, 30.24steps/s]  5%|â–Œ         | 51200/1000000 [35:57<8:05:09, 32.59steps/s]  5%|â–Œ         | 51200/1000000 [36:10<8:05:09, 32.59steps/s]  5%|â–Œ         | 53760/1000000 [37:00<7:35:27, 34.63steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_53760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  5%|â–Œ         | 53760/1000000 [37:20<7:35:27, 34.63steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              5%|â–Œ         | 53760/1000000 [41:15<7:35:27, 34.63steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -199     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -199     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.013    |
|    mean_entropy      | 13.5     |
|    mean_ent_bonus    | 0.658    |
|    max_target_q      | -2.96    |
|    min_target_q      | -6.18    |
|    max_reward        | -0.696   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 0.662    |
|    q1_grad_norm      | 0.53     |
|    q2_grad_norm      | 0.536    |
|    actor_loss        | 4.1      |
|    ent_coeff         | 0.0487   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0608   |
|    n_updates         | 1440     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -194     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -194     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 21       |
|    fps               | 17.4     |
|    elapsed_time      | 2.48e+03 |
|    elapsed_steps     | 53760    |
-----------------------------------
  6%|â–Œ         | 56320/1000000 [42:17<15:02:15, 17.43steps/s]  6%|â–Œ         | 58880/1000000 [43:24<12:32:55, 20.83steps/s]  6%|â–Œ         | 58880/1000000 [43:40<12:32:55, 20.83steps/s]  6%|â–Œ         | 61440/1000000 [44:30<10:46:35, 24.19steps/s]                                                               6%|â–Œ         | 61440/1000000 [44:30<10:46:35, 24.19steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -198     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -198     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0152   |
|    mean_entropy      | 13.3     |
|    mean_ent_bonus    | 0.646    |
|    max_target_q      | -3.44    |
|    min_target_q      | -7.24    |
|    max_reward        | -0.685   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 0.781    |
|    q1_grad_norm      | 0.595    |
|    q2_grad_norm      | 0.604    |
|    actor_loss        | 4.79     |
|    ent_coeff         | 0.0485   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0613   |
|    n_updates         | 1680     |
| time/                |          |
|    iterations        | 24       |
|    fps               | 39.4     |
|    elapsed_time      | 2.67e+03 |
|    elapsed_steps     | 61440    |
-----------------------------------
  6%|â–Œ         | 61440/1000000 [44:50<10:46:35, 24.19steps/s]  6%|â–‹         | 64000/1000000 [45:41<9:40:15, 26.88steps/s]   6%|â–‹         | 64000/1000000 [46:00<9:40:15, 26.88steps/s]  7%|â–‹         | 66560/1000000 [46:46<8:44:47, 29.64steps/s]  7%|â–‹         | 66560/1000000 [47:00<8:44:47, 29.64steps/s]  7%|â–‹         | 69120/1000000 [47:53<8:07:48, 31.80steps/s]                                                              7%|â–‹         | 69120/1000000 [47:53<8:07:48, 31.80steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -195     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -195     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0181   |
|    mean_entropy      | 13.2     |
|    mean_ent_bonus    | 0.638    |
|    max_target_q      | -3.85    |
|    min_target_q      | -8.3     |
|    max_reward        | -0.679   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 0.907    |
|    q1_grad_norm      | 0.677    |
|    q2_grad_norm      | 0.686    |
|    actor_loss        | 5.45     |
|    ent_coeff         | 0.0482   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0623   |
|    n_updates         | 1920     |
| time/                |          |
|    iterations        | 27       |
|    fps               | 37.8     |
|    elapsed_time      | 2.87e+03 |
|    elapsed_steps     | 69120    |
-----------------------------------
  7%|â–‹         | 69120/1000000 [48:10<8:07:48, 31.80steps/s]  7%|â–‹         | 71680/1000000 [49:02<7:45:40, 33.22steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_71680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  7%|â–‹         | 71680/1000000 [49:20<7:45:40, 33.22steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  7%|â–‹         | 74240/1000000 [54:35<15:25:56, 16.66steps/s]  8%|â–Š         | 76800/1000000 [55:39<12:42:59, 20.17steps/s]                                                               8%|â–Š         | 76800/1000000 [55:39<12:42:59, 20.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -196     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -196     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0207   |
|    mean_entropy      | 13.1     |
|    mean_ent_bonus    | 0.631    |
|    max_target_q      | -4.25    |
|    min_target_q      | -9.28    |
|    max_reward        | -0.673   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 1.02     |
|    q1_grad_norm      | 0.75     |
|    q2_grad_norm      | 0.764    |
|    actor_loss        | 6.09     |
|    ent_coeff         | 0.048    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0627   |
|    n_updates         | 2160     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -196     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -196     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 30       |
|    fps               | 16.5     |
|    elapsed_time      | 3.34e+03 |
|    elapsed_steps     | 76800    |
-----------------------------------
  8%|â–Š         | 76800/1000000 [55:50<12:42:59, 20.17steps/s]  8%|â–Š         | 79360/1000000 [56:43<10:47:05, 23.71steps/s]  8%|â–Š         | 79360/1000000 [57:00<10:47:05, 23.71steps/s]  8%|â–Š         | 81920/1000000 [57:47<9:27:23, 26.97steps/s]   8%|â–Š         | 81920/1000000 [58:00<9:27:23, 26.97steps/s]  8%|â–Š         | 84480/1000000 [58:56<8:39:00, 29.40steps/s]                                                              8%|â–Š         | 84480/1000000 [58:56<8:39:00, 29.40steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -197     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -197     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0234   |
|    mean_entropy      | 13.1     |
|    mean_ent_bonus    | 0.625    |
|    max_target_q      | -4.67    |
|    min_target_q      | -10.3    |
|    max_reward        | -0.651   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 1.12     |
|    q1_grad_norm      | 0.822    |
|    q2_grad_norm      | 0.834    |
|    actor_loss        | 6.7      |
|    ent_coeff         | 0.0478   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0644   |
|    n_updates         | 2400     |
| time/                |          |
|    iterations        | 33       |
|    fps               | 39       |
|    elapsed_time      | 3.54e+03 |
|    elapsed_steps     | 84480    |
-----------------------------------
  8%|â–Š         | 84480/1000000 [59:10<8:39:00, 29.40steps/s]  9%|â–Š         | 87040/1000000 [1:00:04<8:03:59, 31.44steps/s]  9%|â–Š         | 87040/1000000 [1:00:20<8:03:59, 31.44steps/s]  9%|â–‰         | 89600/1000000 [1:01:13<7:40:18, 32.96steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_89600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  9%|â–‰         | 89600/1000000 [1:01:30<7:40:18, 32.96steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  9%|â–‰         | 92160/1000000 [1:06:38<14:57:15, 16.86steps/s]                                                                 9%|â–‰         | 92160/1000000 [1:06:38<14:57:15, 16.86steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -193     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -193     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0258   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.619    |
|    max_target_q      | -5.01    |
|    min_target_q      | -11.2    |
|    max_reward        | -0.605   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 1.12     |
|    q1_grad_norm      | 0.808    |
|    q2_grad_norm      | 0.815    |
|    actor_loss        | 7.29     |
|    ent_coeff         | 0.0476   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0644   |
|    n_updates         | 2640     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -191     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -191     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 36       |
|    fps               | 16.6     |
|    elapsed_time      | 4e+03    |
|    elapsed_steps     | 92160    |
-----------------------------------
  9%|â–‰         | 94720/1000000 [1:07:46<12:25:41, 20.23steps/s]  9%|â–‰         | 94720/1000000 [1:08:00<12:25:41, 20.23steps/s] 10%|â–‰         | 97280/1000000 [1:08:50<10:34:37, 23.71steps/s] 10%|â–‰         | 97280/1000000 [1:09:10<10:34:37, 23.71steps/s] 10%|â–‰         | 99840/1000000 [1:10:00<9:25:10, 26.55steps/s]                                                                10%|â–‰         | 99840/1000000 [1:10:00<9:25:10, 26.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -193     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -193     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0316   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.615    |
|    max_target_q      | -5.35    |
|    min_target_q      | -12.1    |
|    max_reward        | -0.577   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 1.62     |
|    q1_grad_norm      | 1.19     |
|    q2_grad_norm      | 1.21     |
|    actor_loss        | 7.86     |
|    ent_coeff         | 0.0473   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0642   |
|    n_updates         | 2880     |
| time/                |          |
|    iterations        | 39       |
|    fps               | 38.1     |
|    elapsed_time      | 4.2e+03  |
|    elapsed_steps     | 99840    |
-----------------------------------
 10%|â–‰         | 99840/1000000 [1:10:20<9:25:10, 26.55steps/s] 10%|â–ˆ         | 102400/1000000 [1:11:09<8:35:54, 29.00steps/s] 10%|â–ˆ         | 102400/1000000 [1:11:20<8:35:54, 29.00steps/s] 10%|â–ˆ         | 104960/1000000 [1:12:15<7:54:52, 31.41steps/s] 10%|â–ˆ         | 104960/1000000 [1:12:30<7:54:52, 31.41steps/s] 11%|â–ˆ         | 107520/1000000 [1:13:20<7:24:51, 33.44steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_107520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 11%|â–ˆ         | 107520/1000000 [1:13:40<7:24:51, 33.44steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                11%|â–ˆ         | 107520/1000000 [1:17:27<7:24:51, 33.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -189     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -189     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0313   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.611    |
|    max_target_q      | -5.69    |
|    min_target_q      | -13      |
|    max_reward        | -0.564   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 1.23     |
|    q1_grad_norm      | 0.894    |
|    q2_grad_norm      | 0.905    |
|    actor_loss        | 8.4      |
|    ent_coeff         | 0.0471   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0662   |
|    n_updates         | 3120     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -192     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -192     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 42       |
|    fps               | 17.2     |
|    elapsed_time      | 4.65e+03 |
|    elapsed_steps     | 107520   |
-----------------------------------
 11%|â–ˆ         | 110080/1000000 [1:18:30<14:10:02, 17.45steps/s] 11%|â–ˆâ–        | 112640/1000000 [1:19:39<11:52:38, 20.75steps/s] 11%|â–ˆâ–        | 112640/1000000 [1:19:50<11:52:38, 20.75steps/s] 12%|â–ˆâ–        | 115200/1000000 [1:20:48<10:15:46, 23.95steps/s]                                                                 12%|â–ˆâ–        | 115200/1000000 [1:20:48<10:15:46, 23.95steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -192     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -192     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0345   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.608    |
|    max_target_q      | -5.99    |
|    min_target_q      | -13.7    |
|    max_reward        | -0.557   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 1.4      |
|    q1_grad_norm      | 1.01     |
|    q2_grad_norm      | 1.02     |
|    actor_loss        | 8.95     |
|    ent_coeff         | 0.0469   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0646   |
|    n_updates         | 3360     |
| time/                |          |
|    iterations        | 45       |
|    fps               | 38.2     |
|    elapsed_time      | 4.85e+03 |
|    elapsed_steps     | 115200   |
-----------------------------------
 12%|â–ˆâ–        | 115200/1000000 [1:21:00<10:15:46, 23.95steps/s] 12%|â–ˆâ–        | 117760/1000000 [1:21:53<9:02:53, 27.08steps/s]  12%|â–ˆâ–        | 117760/1000000 [1:22:10<9:02:53, 27.08steps/s] 12%|â–ˆâ–        | 120320/1000000 [1:23:02<8:17:40, 29.46steps/s] 12%|â–ˆâ–        | 120320/1000000 [1:23:20<8:17:40, 29.46steps/s] 12%|â–ˆâ–        | 122880/1000000 [1:24:10<7:43:31, 31.54steps/s]                                                                12%|â–ˆâ–        | 122880/1000000 [1:24:10<7:43:31, 31.54steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -186     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -186     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0385   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.608    |
|    max_target_q      | -6.36    |
|    min_target_q      | -14.6    |
|    max_reward        | -0.545   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 1.67     |
|    q1_grad_norm      | 1.21     |
|    q2_grad_norm      | 1.23     |
|    actor_loss        | 9.48     |
|    ent_coeff         | 0.0467   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0645   |
|    n_updates         | 3600     |
| time/                |          |
|    iterations        | 48       |
|    fps               | 37.9     |
|    elapsed_time      | 5.05e+03 |
|    elapsed_steps     | 122880   |
-----------------------------------
 12%|â–ˆâ–        | 122880/1000000 [1:24:30<7:43:31, 31.54steps/s] 13%|â–ˆâ–Ž        | 125440/1000000 [1:25:17<7:17:59, 33.28steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 13%|â–ˆâ–Ž        | 125440/1000000 [1:25:30<7:17:59, 33.28steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_125440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 13%|â–ˆâ–Ž        | 128000/1000000 [1:30:47<14:26:36, 16.77steps/s] 13%|â–ˆâ–Ž        | 130560/1000000 [1:31:52<11:55:51, 20.24steps/s]                                                                 13%|â–ˆâ–Ž        | 130560/1000000 [1:31:52<11:55:51, 20.24steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -185     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -185     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0417   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.606    |
|    max_target_q      | -6.63    |
|    min_target_q      | -15.3    |
|    max_reward        | -0.52    |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 1.72     |
|    q1_grad_norm      | 1.28     |
|    q2_grad_norm      | 1.29     |
|    actor_loss        | 10       |
|    ent_coeff         | 0.0464   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0613   |
|    n_updates         | 3840     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -186     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -186     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 51       |
|    fps               | 16.6     |
|    elapsed_time      | 5.51e+03 |
|    elapsed_steps     | 130560   |
-----------------------------------
 13%|â–ˆâ–Ž        | 130560/1000000 [1:32:10<11:55:51, 20.24steps/s] 13%|â–ˆâ–Ž        | 133120/1000000 [1:32:58<10:12:15, 23.60steps/s] 13%|â–ˆâ–Ž        | 133120/1000000 [1:33:10<10:12:15, 23.60steps/s] 14%|â–ˆâ–Ž        | 135680/1000000 [1:34:08<9:04:16, 26.47steps/s]  14%|â–ˆâ–Ž        | 135680/1000000 [1:34:20<9:04:16, 26.47steps/s] 14%|â–ˆâ–        | 138240/1000000 [1:35:17<8:16:20, 28.94steps/s]                                                                14%|â–ˆâ–        | 138240/1000000 [1:35:17<8:16:20, 28.94steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -181     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -181     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0456   |
|    mean_entropy      | 13.1     |
|    mean_ent_bonus    | 0.603    |
|    max_target_q      | -6.98    |
|    min_target_q      | -16.1    |
|    max_reward        | -0.515   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 1.94     |
|    q1_grad_norm      | 1.42     |
|    q2_grad_norm      | 1.44     |
|    actor_loss        | 10.5     |
|    ent_coeff         | 0.0462   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0613   |
|    n_updates         | 4080     |
| time/                |          |
|    iterations        | 54       |
|    fps               | 37.5     |
|    elapsed_time      | 5.72e+03 |
|    elapsed_steps     | 138240   |
-----------------------------------
 14%|â–ˆâ–        | 138240/1000000 [1:35:30<8:16:20, 28.94steps/s] 14%|â–ˆâ–        | 140800/1000000 [1:36:28<7:46:29, 30.70steps/s] 14%|â–ˆâ–        | 140800/1000000 [1:36:40<7:46:29, 30.70steps/s] 14%|â–ˆâ–        | 143360/1000000 [1:37:32<7:12:15, 33.03steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_143360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 14%|â–ˆâ–        | 143360/1000000 [1:37:50<7:12:15, 33.03steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 15%|â–ˆâ–        | 145920/1000000 [1:42:58<14:04:42, 16.85steps/s]                                                                 15%|â–ˆâ–        | 145920/1000000 [1:42:58<14:04:42, 16.85steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -180     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -180     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0478   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.599    |
|    max_target_q      | -7.28    |
|    min_target_q      | -16.9    |
|    max_reward        | -0.479   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 1.91     |
|    q1_grad_norm      | 1.41     |
|    q2_grad_norm      | 1.42     |
|    actor_loss        | 11       |
|    ent_coeff         | 0.046    |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.061    |
|    n_updates         | 4320     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -179     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -179     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 57       |
|    fps               | 16.7     |
|    elapsed_time      | 6.18e+03 |
|    elapsed_steps     | 145920   |
-----------------------------------
 15%|â–ˆâ–        | 148480/1000000 [1:44:00<11:33:35, 20.46steps/s] 15%|â–ˆâ–        | 148480/1000000 [1:44:20<11:33:35, 20.46steps/s] 15%|â–ˆâ–Œ        | 151040/1000000 [1:45:05<9:51:14, 23.93steps/s]  15%|â–ˆâ–Œ        | 151040/1000000 [1:45:20<9:51:14, 23.93steps/s] 15%|â–ˆâ–Œ        | 153600/1000000 [1:46:08<8:36:13, 27.33steps/s]                                                                15%|â–ˆâ–Œ        | 153600/1000000 [1:46:08<8:36:13, 27.33steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -180     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -180     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0543   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.594    |
|    max_target_q      | -7.55    |
|    min_target_q      | -17.6    |
|    max_reward        | -0.478   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 2.43     |
|    q1_grad_norm      | 1.84     |
|    q2_grad_norm      | 1.87     |
|    actor_loss        | 11.4     |
|    ent_coeff         | 0.0458   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0615   |
|    n_updates         | 4560     |
| time/                |          |
|    iterations        | 60       |
|    fps               | 40.4     |
|    elapsed_time      | 6.37e+03 |
|    elapsed_steps     | 153600   |
-----------------------------------
 15%|â–ˆâ–Œ        | 153600/1000000 [1:46:20<8:36:13, 27.33steps/s] 16%|â–ˆâ–Œ        | 156160/1000000 [1:47:15<7:51:03, 29.86steps/s] 16%|â–ˆâ–Œ        | 156160/1000000 [1:47:30<7:51:03, 29.86steps/s] 16%|â–ˆâ–Œ        | 158720/1000000 [1:48:24<7:22:29, 31.69steps/s] 16%|â–ˆâ–Œ        | 158720/1000000 [1:48:40<7:22:29, 31.69steps/s] 16%|â–ˆâ–Œ        | 161280/1000000 [1:49:29<6:54:48, 33.70steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 16%|â–ˆâ–Œ        | 161280/1000000 [1:49:40<6:54:48, 33.70steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_161280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                16%|â–ˆâ–Œ        | 161280/1000000 [1:54:01<6:54:48, 33.70steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -178     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -178     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0557   |
|    mean_entropy      | 13       |
|    mean_ent_bonus    | 0.591    |
|    max_target_q      | -7.82    |
|    min_target_q      | -18.3    |
|    max_reward        | -0.476   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 2.1      |
|    q1_grad_norm      | 1.57     |
|    q2_grad_norm      | 1.59     |
|    actor_loss        | 11.9     |
|    ent_coeff         | 0.0455   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0616   |
|    n_updates         | 4800     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -175     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -175     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 63       |
|    fps               | 16.2     |
|    elapsed_time      | 6.84e+03 |
|    elapsed_steps     | 161280   |
-----------------------------------
 16%|â–ˆâ–‹        | 163840/1000000 [1:55:08<14:03:03, 16.53steps/s] 17%|â–ˆâ–‹        | 166400/1000000 [1:56:18<11:42:42, 19.77steps/s] 17%|â–ˆâ–‹        | 166400/1000000 [1:56:30<11:42:42, 19.77steps/s] 17%|â–ˆâ–‹        | 168960/1000000 [1:57:24<9:57:16, 23.19steps/s]                                                                 17%|â–ˆâ–‹        | 168960/1000000 [1:57:24<9:57:16, 23.19steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -174     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -174     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0607   |
|    mean_entropy      | 12.9     |
|    mean_ent_bonus    | 0.586    |
|    max_target_q      | -8.08    |
|    min_target_q      | -19.1    |
|    max_reward        | -0.456   |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 2.33     |
|    q1_grad_norm      | 1.69     |
|    q2_grad_norm      | 1.71     |
|    actor_loss        | 12.3     |
|    ent_coeff         | 0.0453   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0613   |
|    n_updates         | 5040     |
| time/                |          |
|    iterations        | 66       |
|    fps               | 37.8     |
|    elapsed_time      | 7.04e+03 |
|    elapsed_steps     | 168960   |
-----------------------------------
 17%|â–ˆâ–‹        | 168960/1000000 [1:57:40<9:57:16, 23.19steps/s] 17%|â–ˆâ–‹        | 171520/1000000 [1:58:32<8:46:57, 26.20steps/s] 17%|â–ˆâ–‹        | 171520/1000000 [1:58:50<8:46:57, 26.20steps/s] 17%|â–ˆâ–‹        | 174080/1000000 [1:59:42<8:00:22, 28.66steps/s] 17%|â–ˆâ–‹        | 174080/1000000 [2:00:00<8:00:22, 28.66steps/s] 18%|â–ˆâ–Š        | 176640/1000000 [2:00:52<7:28:25, 30.60steps/s]                                                                18%|â–ˆâ–Š        | 176640/1000000 [2:00:52<7:28:25, 30.60steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -171     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -171     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.0677   |
|    mean_entropy      | 12.8     |
|    mean_ent_bonus    | 0.579    |
|    max_target_q      | -8.36    |
|    min_target_q      | -19.7    |
|    max_reward        | -0.43    |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 2.78     |
|    q1_grad_norm      | 2.14     |
|    q2_grad_norm      | 2.17     |
|    actor_loss        | 12.7     |
|    ent_coeff         | 0.0451   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0635   |
|    n_updates         | 5280     |
| time/                |          |
|    iterations        | 69       |
|    fps               | 36.9     |
|    elapsed_time      | 7.25e+03 |
|    elapsed_steps     | 176640   |
-----------------------------------
 18%|â–ˆâ–Š        | 176640/1000000 [2:01:10<7:28:25, 30.60steps/s] 18%|â–ˆâ–Š        | 179200/1000000 [2:02:00<7:00:55, 32.50steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 18%|â–ˆâ–Š        | 179200/1000000 [2:02:10<7:00:55, 32.50steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_179200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 18%|â–ˆâ–Š        | 181760/1000000 [2:07:27<13:37:29, 16.68steps/s] 18%|â–ˆâ–Š        | 184320/1000000 [2:08:34<11:16:13, 20.10steps/s]                                                                 18%|â–ˆâ–Š        | 184320/1000000 [2:08:34<11:16:13, 20.10steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -171     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -171     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0692   |
|    mean_entropy      | 12.7     |
|    mean_ent_bonus    | 0.572    |
|    max_target_q      | -8.59    |
|    min_target_q      | -20.4    |
|    max_reward        | -0.413   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 2.5      |
|    q1_grad_norm      | 1.87     |
|    q2_grad_norm      | 1.89     |
|    actor_loss        | 13       |
|    ent_coeff         | 0.0449   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0644   |
|    n_updates         | 5520     |
| eval/                |          |
|    Length            | 189      |
|    Return            | -159     |
|    NonzeroRewards    | 189      |
|    DiscountedReturn  | -159     |
|    Success           | 0.167    |
|    SuccessLength     | 189      |
| time/                |          |
|    iterations        | 72       |
|    fps               | 16.6     |
|    elapsed_time      | 7.71e+03 |
|    elapsed_steps     | 184320   |
-----------------------------------
 18%|â–ˆâ–Š        | 184320/1000000 [2:08:50<11:16:13, 20.10steps/s] 19%|â–ˆâ–Š        | 186880/1000000 [2:09:41<9:38:19, 23.43steps/s]  19%|â–ˆâ–Š        | 186880/1000000 [2:10:00<9:38:19, 23.43steps/s] 19%|â–ˆâ–‰        | 189440/1000000 [2:10:48<8:30:36, 26.46steps/s] 19%|â–ˆâ–‰        | 189440/1000000 [2:11:00<8:30:36, 26.46steps/s] 19%|â–ˆâ–‰        | 192000/1000000 [2:11:55<7:41:58, 29.15steps/s]                                                                19%|â–ˆâ–‰        | 192000/1000000 [2:11:55<7:41:58, 29.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -170     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -170     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0734   |
|    mean_entropy      | 12.7     |
|    mean_ent_bonus    | 0.567    |
|    max_target_q      | -8.81    |
|    min_target_q      | -21.2    |
|    max_reward        | -0.419   |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 2.42     |
|    q1_grad_norm      | 1.74     |
|    q2_grad_norm      | 1.76     |
|    actor_loss        | 13.4     |
|    ent_coeff         | 0.0447   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0656   |
|    n_updates         | 5760     |
| time/                |          |
|    iterations        | 75       |
|    fps               | 38.1     |
|    elapsed_time      | 7.92e+03 |
|    elapsed_steps     | 192000   |
-----------------------------------
 19%|â–ˆâ–‰        | 192000/1000000 [2:12:10<7:41:58, 29.15steps/s] 19%|â–ˆâ–‰        | 194560/1000000 [2:13:01<7:05:52, 31.52steps/s] 19%|â–ˆâ–‰        | 194560/1000000 [2:13:20<7:05:52, 31.52steps/s] 20%|â–ˆâ–‰        | 197120/1000000 [2:14:05<6:37:53, 33.63steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 20%|â–ˆâ–‰        | 197120/1000000 [2:14:20<6:37:53, 33.63steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_197120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 20%|â–ˆâ–‰        | 199680/1000000 [2:19:29<13:03:18, 17.03steps/s]                                                                 20%|â–ˆâ–‰        | 199680/1000000 [2:19:29<13:03:18, 17.03steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -171     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -171     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0765   |
|    mean_entropy      | 12.6     |
|    mean_ent_bonus    | 0.56     |
|    max_target_q      | -9.03    |
|    min_target_q      | -22      |
|    max_reward        | -0.405   |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 2.71     |
|    q1_grad_norm      | 2.04     |
|    q2_grad_norm      | 2.07     |
|    actor_loss        | 13.7     |
|    ent_coeff         | 0.0445   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0652   |
|    n_updates         | 6000     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -167     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -167     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 78       |
|    fps               | 16.9     |
|    elapsed_time      | 8.37e+03 |
|    elapsed_steps     | 199680   |
-----------------------------------
 20%|â–ˆâ–ˆ        | 202240/1000000 [2:20:39<10:56:25, 20.26steps/s] 20%|â–ˆâ–ˆ        | 202240/1000000 [2:20:50<10:56:25, 20.26steps/s] 20%|â–ˆâ–ˆ        | 204800/1000000 [2:21:51<9:30:00, 23.25steps/s]  20%|â–ˆâ–ˆ        | 204800/1000000 [2:22:10<9:30:00, 23.25steps/s] 21%|â–ˆâ–ˆ        | 207360/1000000 [2:23:02<8:27:19, 26.04steps/s]                                                                21%|â–ˆâ–ˆ        | 207360/1000000 [2:23:02<8:27:19, 26.04steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -168     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -168     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.0822   |
|    mean_entropy      | 12.5     |
|    mean_ent_bonus    | 0.554    |
|    max_target_q      | -9.17    |
|    min_target_q      | -22.7    |
|    max_reward        | -0.385   |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 2.91     |
|    q1_grad_norm      | 2.14     |
|    q2_grad_norm      | 2.18     |
|    actor_loss        | 14.1     |
|    ent_coeff         | 0.0443   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0668   |
|    n_updates         | 6240     |
| time/                |          |
|    iterations        | 81       |
|    fps               | 36       |
|    elapsed_time      | 8.58e+03 |
|    elapsed_steps     | 207360   |
-----------------------------------
 21%|â–ˆâ–ˆ        | 207360/1000000 [2:23:20<8:27:19, 26.04steps/s] 21%|â–ˆâ–ˆ        | 209920/1000000 [2:24:16<7:48:06, 28.13steps/s] 21%|â–ˆâ–ˆ        | 209920/1000000 [2:24:30<7:48:06, 28.13steps/s] 21%|â–ˆâ–ˆ        | 212480/1000000 [2:25:28<7:16:19, 30.08steps/s] 21%|â–ˆâ–ˆ        | 212480/1000000 [2:25:40<7:16:19, 30.08steps/s] 22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:26:32<6:43:38, 32.41steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_215040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:26:50<6:43:38, 32.41steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                22%|â–ˆâ–ˆâ–       | 215040/1000000 [2:30:52<6:43:38, 32.41steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -163     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -163     |
|    Success           | 0.05     |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.0875   |
|    mean_entropy      | 12.4     |
|    mean_ent_bonus    | 0.547    |
|    max_target_q      | -9.33    |
|    min_target_q      | -23.5    |
|    max_reward        | -0.37    |
|    min_reward        | -1.45    |
|    encoder_grad_norm | 2.99     |
|    q1_grad_norm      | 2.25     |
|    q2_grad_norm      | 2.28     |
|    actor_loss        | 14.4     |
|    ent_coeff         | 0.0441   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0689   |
|    n_updates         | 6480     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0.0556   |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 84       |
|    fps               | 16.3     |
|    elapsed_time      | 9.05e+03 |
|    elapsed_steps     | 215040   |
-----------------------------------
 22%|â–ˆâ–ˆâ–       | 217600/1000000 [2:32:00<13:01:52, 16.68steps/s] 22%|â–ˆâ–ˆâ–       | 220160/1000000 [2:33:15<11:00:53, 19.67steps/s] 22%|â–ˆâ–ˆâ–       | 220160/1000000 [2:33:30<11:00:53, 19.67steps/s] 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:34:29<9:32:39, 22.62steps/s]                                                                 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:34:29<9:32:39, 22.62steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -161     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -161     |
|    Success           | 0.075    |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.0946   |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.541    |
|    max_target_q      | -9.42    |
|    min_target_q      | -24.2    |
|    max_reward        | -0.356   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 3        |
|    q1_grad_norm      | 2.22     |
|    q2_grad_norm      | 2.25     |
|    actor_loss        | 14.7     |
|    ent_coeff         | 0.0438   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0695   |
|    n_updates         | 6720     |
| time/                |          |
|    iterations        | 87       |
|    fps               | 35.4     |
|    elapsed_time      | 9.27e+03 |
|    elapsed_steps     | 222720   |
-----------------------------------
 22%|â–ˆâ–ˆâ–       | 222720/1000000 [2:34:40<9:32:39, 22.62steps/s] 23%|â–ˆâ–ˆâ–Ž       | 225280/1000000 [2:35:45<8:34:33, 25.09steps/s] 23%|â–ˆâ–ˆâ–Ž       | 225280/1000000 [2:36:00<8:34:33, 25.09steps/s] 23%|â–ˆâ–ˆâ–Ž       | 227840/1000000 [2:37:01<7:53:12, 27.20steps/s] 23%|â–ˆâ–ˆâ–Ž       | 227840/1000000 [2:37:20<7:53:12, 27.20steps/s] 23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:38:17<7:25:13, 28.81steps/s]                                                                23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:38:17<7:25:13, 28.81steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -165     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -165     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.094    |
|    mean_entropy      | 12.3     |
|    mean_ent_bonus    | 0.537    |
|    max_target_q      | -9.52    |
|    min_target_q      | -24.9    |
|    max_reward        | -0.364   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 2.84     |
|    q1_grad_norm      | 2.1      |
|    q2_grad_norm      | 2.14     |
|    actor_loss        | 14.9     |
|    ent_coeff         | 0.0436   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0689   |
|    n_updates         | 6960     |
| time/                |          |
|    iterations        | 90       |
|    fps               | 33.6     |
|    elapsed_time      | 9.5e+03  |
|    elapsed_steps     | 230400   |
-----------------------------------
 23%|â–ˆâ–ˆâ–Ž       | 230400/1000000 [2:38:30<7:25:13, 28.81steps/s] 23%|â–ˆâ–ˆâ–Ž       | 232960/1000000 [2:39:23<6:49:56, 31.19steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 23%|â–ˆâ–ˆâ–Ž       | 232960/1000000 [2:39:40<6:49:56, 31.19steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_232960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 24%|â–ˆâ–ˆâ–Ž       | 235520/1000000 [2:45:07<13:18:18, 15.96steps/s] 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:46:19<11:05:04, 19.09steps/s]                                                                 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:46:19<11:05:04, 19.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -159     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -159     |
|    Success           | 0.114    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.106    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.53     |
|    max_target_q      | -9.57    |
|    min_target_q      | -25.4    |
|    max_reward        | -0.361   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 3.02     |
|    q1_grad_norm      | 2.19     |
|    q2_grad_norm      | 2.24     |
|    actor_loss        | 15.2     |
|    ent_coeff         | 0.0434   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0706   |
|    n_updates         | 7200     |
| eval/                |          |
|    Length            | 190      |
|    Return            | -152     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -152     |
|    Success           | 0.222    |
|    SuccessLength     | 190      |
| time/                |          |
|    iterations        | 93       |
|    fps               | 15.9     |
|    elapsed_time      | 9.98e+03 |
|    elapsed_steps     | 238080   |
-----------------------------------
 24%|â–ˆâ–ˆâ–       | 238080/1000000 [2:46:30<11:05:04, 19.09steps/s] 24%|â–ˆâ–ˆâ–       | 240640/1000000 [2:47:32<9:32:12, 22.12steps/s]  24%|â–ˆâ–ˆâ–       | 240640/1000000 [2:47:50<9:32:12, 22.12steps/s] 24%|â–ˆâ–ˆâ–       | 243200/1000000 [2:48:47<8:29:51, 24.74steps/s] 24%|â–ˆâ–ˆâ–       | 243200/1000000 [2:49:00<8:29:51, 24.74steps/s] 25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:50:00<7:43:50, 27.10steps/s]                                                                25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:50:00<7:43:50, 27.10steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -157     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0513   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.115    |
|    mean_entropy      | 12.2     |
|    mean_ent_bonus    | 0.528    |
|    max_target_q      | -9.7     |
|    min_target_q      | -26.1    |
|    max_reward        | -0.341   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 3.52     |
|    q1_grad_norm      | 2.69     |
|    q2_grad_norm      | 2.73     |
|    actor_loss        | 15.5     |
|    ent_coeff         | 0.0432   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0721   |
|    n_updates         | 7440     |
| time/                |          |
|    iterations        | 96       |
|    fps               | 34.7     |
|    elapsed_time      | 1.02e+04 |
|    elapsed_steps     | 245760   |
-----------------------------------
 25%|â–ˆâ–ˆâ–       | 245760/1000000 [2:50:20<7:43:50, 27.10steps/s] 25%|â–ˆâ–ˆâ–       | 248320/1000000 [2:51:13<7:10:10, 29.12steps/s] 25%|â–ˆâ–ˆâ–       | 248320/1000000 [2:51:30<7:10:10, 29.12steps/s] 25%|â–ˆâ–ˆâ–Œ       | 250880/1000000 [2:52:20<6:38:20, 31.34steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_250880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 25%|â–ˆâ–ˆâ–Œ       | 250880/1000000 [2:52:40<6:38:20, 31.34steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 25%|â–ˆâ–ˆâ–Œ       | 253440/1000000 [2:58:02<12:56:51, 16.02steps/s]                                                                 25%|â–ˆâ–ˆâ–Œ       | 253440/1000000 [2:58:02<12:56:51, 16.02steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -163     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -163     |
|    Success           | 0.025    |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.115    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.521    |
|    max_target_q      | -9.82    |
|    min_target_q      | -26.7    |
|    max_reward        | -0.342   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 3.09     |
|    q1_grad_norm      | 2.23     |
|    q2_grad_norm      | 2.26     |
|    actor_loss        | 15.7     |
|    ent_coeff         | 0.043    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0729   |
|    n_updates         | 7680     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 99       |
|    fps               | 15.9     |
|    elapsed_time      | 1.07e+04 |
|    elapsed_steps     | 253440   |
-----------------------------------
 26%|â–ˆâ–ˆâ–Œ       | 256000/1000000 [2:59:15<10:47:42, 19.14steps/s] 26%|â–ˆâ–ˆâ–Œ       | 256000/1000000 [2:59:30<10:47:42, 19.14steps/s] 26%|â–ˆâ–ˆâ–Œ       | 258560/1000000 [3:00:24<9:11:31, 22.41steps/s]  26%|â–ˆâ–ˆâ–Œ       | 258560/1000000 [3:00:40<9:11:31, 22.41steps/s] 26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:01:33<8:03:42, 25.46steps/s]                                                                26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:01:33<8:03:42, 25.46steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.127    |
|    mean_entropy      | 12.1     |
|    mean_ent_bonus    | 0.518    |
|    max_target_q      | -9.9     |
|    min_target_q      | -27.6    |
|    max_reward        | -0.335   |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 3.48     |
|    q1_grad_norm      | 2.56     |
|    q2_grad_norm      | 2.61     |
|    actor_loss        | 16       |
|    ent_coeff         | 0.0428   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0727   |
|    n_updates         | 7920     |
| time/                |          |
|    iterations        | 102      |
|    fps               | 36.5     |
|    elapsed_time      | 1.09e+04 |
|    elapsed_steps     | 261120   |
-----------------------------------
 26%|â–ˆâ–ˆâ–Œ       | 261120/1000000 [3:01:50<8:03:42, 25.46steps/s] 26%|â–ˆâ–ˆâ–‹       | 263680/1000000 [3:02:42<7:17:31, 28.05steps/s] 26%|â–ˆâ–ˆâ–‹       | 263680/1000000 [3:03:00<7:17:31, 28.05steps/s] 27%|â–ˆâ–ˆâ–‹       | 266240/1000000 [3:03:54<6:47:44, 29.99steps/s] 27%|â–ˆâ–ˆâ–‹       | 266240/1000000 [3:04:10<6:47:44, 29.99steps/s] 27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:04:59<6:17:48, 32.26steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:05:10<6:17:48, 32.26steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_268800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                27%|â–ˆâ–ˆâ–‹       | 268800/1000000 [3:09:31<6:17:48, 32.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -159     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -159     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.123    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.511    |
|    max_target_q      | -10      |
|    min_target_q      | -28      |
|    max_reward        | -0.341   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 3.27     |
|    q1_grad_norm      | 2.38     |
|    q2_grad_norm      | 2.42     |
|    actor_loss        | 16.2     |
|    ent_coeff         | 0.0426   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.073    |
|    n_updates         | 8160     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 105      |
|    fps               | 16       |
|    elapsed_time      | 1.14e+04 |
|    elapsed_steps     | 268800   |
-----------------------------------
 27%|â–ˆâ–ˆâ–‹       | 271360/1000000 [3:10:34<12:20:10, 16.41steps/s] 27%|â–ˆâ–ˆâ–‹       | 273920/1000000 [3:11:40<10:10:11, 19.83steps/s] 27%|â–ˆâ–ˆâ–‹       | 273920/1000000 [3:12:00<10:10:11, 19.83steps/s] 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:12:49<8:42:46, 23.07steps/s]                                                                 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:12:49<8:42:46, 23.07steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.134    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.507    |
|    max_target_q      | -10.1    |
|    min_target_q      | -28.6    |
|    max_reward        | -0.339   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 4        |
|    q1_grad_norm      | 3.07     |
|    q2_grad_norm      | 3.11     |
|    actor_loss        | 16.5     |
|    ent_coeff         | 0.0424   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0737   |
|    n_updates         | 8400     |
| time/                |          |
|    iterations        | 108      |
|    fps               | 38.9     |
|    elapsed_time      | 1.16e+04 |
|    elapsed_steps     | 276480   |
-----------------------------------
 28%|â–ˆâ–ˆâ–Š       | 276480/1000000 [3:13:00<8:42:46, 23.07steps/s] 28%|â–ˆâ–ˆâ–Š       | 279040/1000000 [3:13:59<7:43:22, 25.93steps/s] 28%|â–ˆâ–ˆâ–Š       | 279040/1000000 [3:14:10<7:43:22, 25.93steps/s] 28%|â–ˆâ–ˆâ–Š       | 281600/1000000 [3:15:13<7:06:31, 28.07steps/s] 28%|â–ˆâ–ˆâ–Š       | 281600/1000000 [3:15:30<7:06:31, 28.07steps/s] 28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:16:23<6:35:39, 30.15steps/s]                                                                28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:16:23<6:35:39, 30.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -153     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -153     |
|    Success           | 0.1      |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.131    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.502    |
|    max_target_q      | -10.1    |
|    min_target_q      | -29.2    |
|    max_reward        | -0.33    |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.07     |
|    q1_grad_norm      | 2.16     |
|    q2_grad_norm      | 2.19     |
|    actor_loss        | 16.7     |
|    ent_coeff         | 0.0422   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0737   |
|    n_updates         | 8640     |
| time/                |          |
|    iterations        | 111      |
|    fps               | 35.9     |
|    elapsed_time      | 1.18e+04 |
|    elapsed_steps     | 284160   |
-----------------------------------
 28%|â–ˆâ–ˆâ–Š       | 284160/1000000 [3:16:40<6:35:39, 30.15steps/s] 29%|â–ˆâ–ˆâ–Š       | 286720/1000000 [3:17:27<6:05:12, 32.55steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 29%|â–ˆâ–ˆâ–Š       | 286720/1000000 [3:17:40<6:05:12, 32.55steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_286720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 29%|â–ˆâ–ˆâ–‰       | 289280/1000000 [3:23:03<12:00:47, 16.43steps/s] 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:24:11<9:56:28, 19.79steps/s]                                                                 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:24:11<9:56:28, 19.79steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -157     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -157     |
|    Success           | 0.075    |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.142    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.497    |
|    max_target_q      | -10.2    |
|    min_target_q      | -30.1    |
|    max_reward        | -0.333   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 4        |
|    q1_grad_norm      | 3.01     |
|    q2_grad_norm      | 3.06     |
|    actor_loss        | 16.9     |
|    ent_coeff         | 0.042    |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0748   |
|    n_updates         | 8880     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 114      |
|    fps               | 16.4     |
|    elapsed_time      | 1.23e+04 |
|    elapsed_steps     | 291840   |
-----------------------------------
 29%|â–ˆâ–ˆâ–‰       | 291840/1000000 [3:24:30<9:56:28, 19.79steps/s] 29%|â–ˆâ–ˆâ–‰       | 294400/1000000 [3:25:24<8:37:27, 22.73steps/s] 29%|â–ˆâ–ˆâ–‰       | 294400/1000000 [3:25:40<8:37:27, 22.73steps/s] 30%|â–ˆâ–ˆâ–‰       | 296960/1000000 [3:26:37<7:40:48, 25.43steps/s] 30%|â–ˆâ–ˆâ–‰       | 296960/1000000 [3:26:50<7:40:48, 25.43steps/s] 30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:27:54<7:06:42, 27.36steps/s]                                                                30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:27:54<7:06:42, 27.36steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -155     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -155     |
|    Success           | 0.05     |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.155    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.49     |
|    max_target_q      | -10.2    |
|    min_target_q      | -30.7    |
|    max_reward        | -0.326   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 4        |
|    q1_grad_norm      | 3.01     |
|    q2_grad_norm      | 3.06     |
|    actor_loss        | 17.1     |
|    ent_coeff         | 0.0418   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0769   |
|    n_updates         | 9120     |
| time/                |          |
|    iterations        | 117      |
|    fps               | 34.4     |
|    elapsed_time      | 1.25e+04 |
|    elapsed_steps     | 299520   |
-----------------------------------
 30%|â–ˆâ–ˆâ–‰       | 299520/1000000 [3:28:10<7:06:42, 27.36steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 302080/1000000 [3:29:06<6:36:31, 29.33steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 302080/1000000 [3:29:20<6:36:31, 29.33steps/s] 30%|â–ˆâ–ˆâ–ˆ       | 304640/1000000 [3:30:17<6:12:53, 31.08steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 30%|â–ˆâ–ˆâ–ˆ       | 304640/1000000 [3:30:30<6:12:53, 31.08steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_304640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 31%|â–ˆâ–ˆâ–ˆ       | 307200/1000000 [3:35:51<11:52:00, 16.22steps/s]                                                                 31%|â–ˆâ–ˆâ–ˆ       | 307200/1000000 [3:35:51<11:52:00, 16.22steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -148     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0976   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.155    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.485    |
|    max_target_q      | -10.2    |
|    min_target_q      | -31.2    |
|    max_reward        | -0.31    |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 3.84     |
|    q1_grad_norm      | 2.69     |
|    q2_grad_norm      | 2.72     |
|    actor_loss        | 17.3     |
|    ent_coeff         | 0.0416   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0772   |
|    n_updates         | 9360     |
| eval/                |          |
|    Length            | 199      |
|    Return            | -158     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -158     |
|    Success           | 0.0556   |
|    SuccessLength     | 199      |
| time/                |          |
|    iterations        | 120      |
|    fps               | 16.1     |
|    elapsed_time      | 1.3e+04  |
|    elapsed_steps     | 307200   |
-----------------------------------
 31%|â–ˆâ–ˆâ–ˆ       | 309760/1000000 [3:37:00<9:49:39, 19.51steps/s]  31%|â–ˆâ–ˆâ–ˆ       | 309760/1000000 [3:37:20<9:49:39, 19.51steps/s] 31%|â–ˆâ–ˆâ–ˆ       | 312320/1000000 [3:38:17<8:34:17, 22.29steps/s] 31%|â–ˆâ–ˆâ–ˆ       | 312320/1000000 [3:38:30<8:34:17, 22.29steps/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:37<7:45:28, 24.53steps/s]                                                                31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:37<7:45:28, 24.53steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -158     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -158     |
|    Success           | 0.027    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.154    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.478    |
|    max_target_q      | -10.3    |
|    min_target_q      | -32      |
|    max_reward        | -0.315   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 4.37     |
|    q1_grad_norm      | 3.27     |
|    q2_grad_norm      | 3.32     |
|    actor_loss        | 17.4     |
|    ent_coeff         | 0.0414   |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0774   |
|    n_updates         | 9600     |
| time/                |          |
|    iterations        | 123      |
|    fps               | 34       |
|    elapsed_time      | 1.32e+04 |
|    elapsed_steps     | 314880   |
-----------------------------------
 31%|â–ˆâ–ˆâ–ˆâ–      | 314880/1000000 [3:39:50<7:45:28, 24.53steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317440/1000000 [3:40:57<7:10:45, 26.41steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 317440/1000000 [3:41:10<7:10:45, 26.41steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320000/1000000 [3:42:13<6:42:02, 28.19steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 320000/1000000 [3:42:30<6:42:02, 28.19steps/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:43:27<6:18:24, 29.84steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:43:40<6:18:24, 29.84steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_322560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                32%|â–ˆâ–ˆâ–ˆâ–      | 322560/1000000 [3:47:51<6:18:24, 29.84steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -152     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -152     |
|    Success           | 0.103    |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.173    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.474    |
|    max_target_q      | -10.4    |
|    min_target_q      | -32.3    |
|    max_reward        | -0.306   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.55     |
|    q1_grad_norm      | 3.42     |
|    q2_grad_norm      | 3.49     |
|    actor_loss        | 17.6     |
|    ent_coeff         | 0.0412   |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0793   |
|    n_updates         | 9840     |
| eval/                |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 126      |
|    fps               | 15.6     |
|    elapsed_time      | 1.37e+04 |
|    elapsed_steps     | 322560   |
-----------------------------------
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 325120/1000000 [3:49:02<11:44:59, 15.95steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327680/1000000 [3:50:10<9:40:23, 19.31steps/s]  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 327680/1000000 [3:50:20<9:40:23, 19.31steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:23<8:20:18, 22.31steps/s]                                                                33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:23<8:20:18, 22.31steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 191      |
|    Return            | -153     |
|    NonzeroRewards    | 191      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0952   |
|    SuccessLength     | 191      |
| algo/                |          |
|    critic_loss       | 0.179    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.471    |
|    max_target_q      | -10.4    |
|    min_target_q      | -33      |
|    max_reward        | -0.305   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.88     |
|    q1_grad_norm      | 2.71     |
|    q2_grad_norm      | 2.76     |
|    actor_loss        | 17.7     |
|    ent_coeff         | 0.041    |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0787   |
|    n_updates         | 10080    |
| time/                |          |
|    iterations        | 129      |
|    fps               | 36.3     |
|    elapsed_time      | 1.39e+04 |
|    elapsed_steps     | 330240   |
-----------------------------------
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 330240/1000000 [3:51:40<8:20:18, 22.31steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332800/1000000 [3:52:35<7:23:49, 25.05steps/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 332800/1000000 [3:52:50<7:23:49, 25.05steps/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335360/1000000 [3:53:48<6:43:58, 27.42steps/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 335360/1000000 [3:54:00<6:43:58, 27.42steps/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:55:01<6:15:39, 29.37steps/s]                                                                34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:55:01<6:15:39, 29.37steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -153     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -153     |
|    Success           | 0.075    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.165    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.466    |
|    max_target_q      | -10.4    |
|    min_target_q      | -33.4    |
|    max_reward        | -0.309   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 3.95     |
|    q1_grad_norm      | 2.83     |
|    q2_grad_norm      | 2.88     |
|    actor_loss        | 17.9     |
|    ent_coeff         | 0.0408   |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0794   |
|    n_updates         | 10320    |
| time/                |          |
|    iterations        | 132      |
|    fps               | 35.2     |
|    elapsed_time      | 1.41e+04 |
|    elapsed_steps     | 337920   |
-----------------------------------
 34%|â–ˆâ–ˆâ–ˆâ–      | 337920/1000000 [3:55:20<6:15:39, 29.37steps/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 340480/1000000 [3:56:12<5:54:00, 31.05steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_340480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 34%|â–ˆâ–ˆâ–ˆâ–      | 340480/1000000 [3:56:30<5:54:00, 31.05steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 34%|â–ˆâ–ˆâ–ˆâ–      | 343040/1000000 [4:01:44<11:11:42, 16.30steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:02:47<9:10:01, 19.83steps/s]                                                                 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:02:47<9:10:01, 19.83steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -157     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0526   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.179    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.461    |
|    max_target_q      | -10.5    |
|    min_target_q      | -33.6    |
|    max_reward        | -0.307   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.02     |
|    q1_grad_norm      | 2.76     |
|    q2_grad_norm      | 2.81     |
|    actor_loss        | 18       |
|    ent_coeff         | 0.0406   |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0796   |
|    n_updates         | 10560    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 135      |
|    fps               | 16.5     |
|    elapsed_time      | 1.46e+04 |
|    elapsed_steps     | 345600   |
-----------------------------------
 35%|â–ˆâ–ˆâ–ˆâ–      | 345600/1000000 [4:03:00<9:10:01, 19.83steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348160/1000000 [4:03:59<7:54:12, 22.91steps/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 348160/1000000 [4:04:10<7:54:12, 22.91steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350720/1000000 [4:05:07<6:57:30, 25.92steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 350720/1000000 [4:05:20<6:57:30, 25.92steps/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:06:17<6:19:22, 28.41steps/s]                                                                35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:06:17<6:19:22, 28.41steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.186    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.458    |
|    max_target_q      | -10.6    |
|    min_target_q      | -34.1    |
|    max_reward        | -0.316   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 4.26     |
|    q1_grad_norm      | 3.09     |
|    q2_grad_norm      | 3.15     |
|    actor_loss        | 18.1     |
|    ent_coeff         | 0.0404   |
|    ent_coeff_loss    | -100     |
|    pi_grad_norm      | 0.0802   |
|    n_updates         | 10800    |
| time/                |          |
|    iterations        | 138      |
|    fps               | 36.6     |
|    elapsed_time      | 1.48e+04 |
|    elapsed_steps     | 353280   |
-----------------------------------
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 353280/1000000 [4:06:30<6:19:22, 28.41steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355840/1000000 [4:07:21<5:45:18, 31.09steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 355840/1000000 [4:07:40<5:45:18, 31.09steps/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358400/1000000 [4:08:31<5:27:37, 32.64steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_358400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 358400/1000000 [4:08:50<5:27:37, 32.64steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360960/1000000 [4:13:56<10:34:06, 16.80steps/s]                                                                 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 360960/1000000 [4:13:56<10:34:06, 16.80steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -159     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0513   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.198    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.458    |
|    max_target_q      | -10.7    |
|    min_target_q      | -34.6    |
|    max_reward        | -0.307   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 3.92     |
|    q1_grad_norm      | 2.62     |
|    q2_grad_norm      | 2.67     |
|    actor_loss        | 18.3     |
|    ent_coeff         | 0.0402   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0792   |
|    n_updates         | 11040    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0.0556   |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 141      |
|    fps               | 16.7     |
|    elapsed_time      | 1.52e+04 |
|    elapsed_steps     | 360960   |
-----------------------------------
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 363520/1000000 [4:15:01<8:43:40, 20.26steps/s]  36%|â–ˆâ–ˆâ–ˆâ–‹      | 363520/1000000 [4:15:20<8:43:40, 20.26steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366080/1000000 [4:16:06<7:25:51, 23.70steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 366080/1000000 [4:16:20<7:25:51, 23.70steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:17:21<6:42:17, 26.16steps/s]                                                                37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:17:21<6:42:17, 26.16steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -158     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -158     |
|    Success           | 0.05     |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.217    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.456    |
|    max_target_q      | -10.7    |
|    min_target_q      | -35      |
|    max_reward        | -0.306   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.35     |
|    q1_grad_norm      | 3.07     |
|    q2_grad_norm      | 3.13     |
|    actor_loss        | 18.5     |
|    ent_coeff         | 0.0401   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0796   |
|    n_updates         | 11280    |
| time/                |          |
|    iterations        | 144      |
|    fps               | 37.5     |
|    elapsed_time      | 1.54e+04 |
|    elapsed_steps     | 368640   |
-----------------------------------
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 368640/1000000 [4:17:40<6:42:17, 26.16steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371200/1000000 [4:18:34<6:10:41, 28.27steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 371200/1000000 [4:18:50<6:10:41, 28.27steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373760/1000000 [4:19:48<5:48:25, 29.96steps/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 373760/1000000 [4:20:00<5:48:25, 29.96steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:21:03<5:34:37, 31.06steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_376320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:21:20<5:34:37, 31.06steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 376320/1000000 [4:25:30<5:34:37, 31.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -163     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -163     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.209    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.454    |
|    max_target_q      | -10.8    |
|    min_target_q      | -35.4    |
|    max_reward        | -0.292   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.13     |
|    q1_grad_norm      | 2.81     |
|    q2_grad_norm      | 2.84     |
|    actor_loss        | 18.6     |
|    ent_coeff         | 0.0399   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0809   |
|    n_updates         | 11520    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 147      |
|    fps               | 15.7     |
|    elapsed_time      | 1.59e+04 |
|    elapsed_steps     | 376320   |
-----------------------------------
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 378880/1000000 [4:26:37<10:38:37, 16.21steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 381440/1000000 [4:27:43<8:45:04, 19.63steps/s]  38%|â–ˆâ–ˆâ–ˆâ–Š      | 381440/1000000 [4:28:00<8:45:04, 19.63steps/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:28:52<7:29:00, 22.87steps/s]                                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:28:52<7:29:00, 22.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -158     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -158     |
|    Success           | 0.05     |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.199    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.45     |
|    max_target_q      | -10.9    |
|    min_target_q      | -35.9    |
|    max_reward        | -0.295   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 4.53     |
|    q1_grad_norm      | 3.21     |
|    q2_grad_norm      | 3.27     |
|    actor_loss        | 18.8     |
|    ent_coeff         | 0.0397   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0809   |
|    n_updates         | 11760    |
| time/                |          |
|    iterations        | 150      |
|    fps               | 37.9     |
|    elapsed_time      | 1.61e+04 |
|    elapsed_steps     | 384000   |
-----------------------------------
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 384000/1000000 [4:29:10<7:29:00, 22.87steps/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386560/1000000 [4:30:03<6:37:22, 25.73steps/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 386560/1000000 [4:30:20<6:37:22, 25.73steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389120/1000000 [4:31:11<5:58:26, 28.40steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 389120/1000000 [4:31:30<5:58:26, 28.40steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:32:18<5:29:02, 30.81steps/s]                                                                39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:32:18<5:29:02, 30.81steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -158     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -158     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.212    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.448    |
|    max_target_q      | -11      |
|    min_target_q      | -35.9    |
|    max_reward        | -0.293   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.69     |
|    q1_grad_norm      | 3.34     |
|    q2_grad_norm      | 3.41     |
|    actor_loss        | 18.9     |
|    ent_coeff         | 0.0395   |
|    ent_coeff_loss    | -101     |
|    pi_grad_norm      | 0.0786   |
|    n_updates         | 12000    |
| time/                |          |
|    iterations        | 153      |
|    fps               | 37.4     |
|    elapsed_time      | 1.63e+04 |
|    elapsed_steps     | 391680   |
-----------------------------------
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 391680/1000000 [4:32:30<5:29:02, 30.81steps/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394240/1000000 [4:33:26<5:10:41, 32.50steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 394240/1000000 [4:33:40<5:10:41, 32.50steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_394240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 396800/1000000 [4:38:56<10:05:18, 16.61steps/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:40:02<8:18:48, 20.07steps/s]                                                                 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:40:02<8:18:48, 20.07steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -153     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0526   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.209    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.447    |
|    max_target_q      | -11      |
|    min_target_q      | -36.7    |
|    max_reward        | -0.298   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 4.68     |
|    q1_grad_norm      | 3.37     |
|    q2_grad_norm      | 3.44     |
|    actor_loss        | 19.1     |
|    ent_coeff         | 0.0393   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0781   |
|    n_updates         | 12240    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 156      |
|    fps               | 16.5     |
|    elapsed_time      | 1.68e+04 |
|    elapsed_steps     | 399360   |
-----------------------------------
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 399360/1000000 [4:40:20<8:18:48, 20.07steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401920/1000000 [4:41:11<7:08:45, 23.25steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 401920/1000000 [4:41:30<7:08:45, 23.25steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404480/1000000 [4:42:18<6:16:02, 26.39steps/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 404480/1000000 [4:42:30<6:16:02, 26.39steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:43:27<5:42:25, 28.86steps/s]                                                                41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:43:27<5:42:25, 28.86steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -155     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -155     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.221    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.444    |
|    max_target_q      | -11.2    |
|    min_target_q      | -37.2    |
|    max_reward        | -0.292   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 4.47     |
|    q1_grad_norm      | 3.24     |
|    q2_grad_norm      | 3.31     |
|    actor_loss        | 19.2     |
|    ent_coeff         | 0.0391   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0794   |
|    n_updates         | 12480    |
| time/                |          |
|    iterations        | 159      |
|    fps               | 37.4     |
|    elapsed_time      | 1.7e+04  |
|    elapsed_steps     | 407040   |
-----------------------------------
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 407040/1000000 [4:43:40<5:42:25, 28.86steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409600/1000000 [4:44:34<5:16:07, 31.13steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 409600/1000000 [4:44:50<5:16:07, 31.13steps/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412160/1000000 [4:45:42<4:57:57, 32.88steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_412160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 412160/1000000 [4:46:00<4:57:57, 32.88steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414720/1000000 [4:51:18<9:52:26, 16.47steps/s]                                                                41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 414720/1000000 [4:51:18<9:52:26, 16.47steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -153     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0256   |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.23     |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.445    |
|    max_target_q      | -11.2    |
|    min_target_q      | -37.4    |
|    max_reward        | -0.294   |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 4.8      |
|    q1_grad_norm      | 3.34     |
|    q2_grad_norm      | 3.39     |
|    actor_loss        | 19.4     |
|    ent_coeff         | 0.0389   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0793   |
|    n_updates         | 12720    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 162      |
|    fps               | 16.3     |
|    elapsed_time      | 1.75e+04 |
|    elapsed_steps     | 414720   |
-----------------------------------
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417280/1000000 [4:52:30<8:14:43, 19.63steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 417280/1000000 [4:52:50<8:14:43, 19.63steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419840/1000000 [4:53:38<7:01:17, 22.95steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 419840/1000000 [4:53:50<7:01:17, 22.95steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:54:45<6:09:05, 26.08steps/s]                                                                42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:54:45<6:09:05, 26.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -154     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0541   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.231    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.442    |
|    max_target_q      | -11.3    |
|    min_target_q      | -38.1    |
|    max_reward        | -0.297   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 4.99     |
|    q1_grad_norm      | 3.44     |
|    q2_grad_norm      | 3.51     |
|    actor_loss        | 19.6     |
|    ent_coeff         | 0.0387   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0788   |
|    n_updates         | 12960    |
| time/                |          |
|    iterations        | 165      |
|    fps               | 37.2     |
|    elapsed_time      | 1.77e+04 |
|    elapsed_steps     | 422400   |
-----------------------------------
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 422400/1000000 [4:55:00<6:09:05, 26.08steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424960/1000000 [4:55:53<5:33:38, 28.73steps/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 424960/1000000 [4:56:10<5:33:38, 28.73steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427520/1000000 [4:57:01<5:08:54, 30.89steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 427520/1000000 [4:57:20<5:08:54, 30.89steps/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [4:58:08<4:49:37, 32.80steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [4:58:20<4:49:37, 32.80steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_430080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 430080/1000000 [5:02:34<4:49:37, 32.80steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -154     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.224    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.44     |
|    max_target_q      | -11.5    |
|    min_target_q      | -38.8    |
|    max_reward        | -0.29    |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 4.51     |
|    q1_grad_norm      | 3.02     |
|    q2_grad_norm      | 3.09     |
|    actor_loss        | 19.7     |
|    ent_coeff         | 0.0385   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0786   |
|    n_updates         | 13200    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 168      |
|    fps               | 16.3     |
|    elapsed_time      | 1.82e+04 |
|    elapsed_steps     | 430080   |
-----------------------------------
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 432640/1000000 [5:03:42<9:32:07, 16.53steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435200/1000000 [5:04:48<7:51:04, 19.98steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 435200/1000000 [5:05:00<7:51:04, 19.98steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:05:57<6:44:18, 23.18steps/s]                                                                44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:05:57<6:44:18, 23.18steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -150     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0732   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.246    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.437    |
|    max_target_q      | -11.6    |
|    min_target_q      | -39.6    |
|    max_reward        | -0.29    |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 4.95     |
|    q1_grad_norm      | 3.3      |
|    q2_grad_norm      | 3.36     |
|    actor_loss        | 19.9     |
|    ent_coeff         | 0.0384   |
|    ent_coeff_loss    | -102     |
|    pi_grad_norm      | 0.0776   |
|    n_updates         | 13440    |
| time/                |          |
|    iterations        | 171      |
|    fps               | 37.9     |
|    elapsed_time      | 1.84e+04 |
|    elapsed_steps     | 437760   |
-----------------------------------
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 437760/1000000 [5:06:10<6:44:18, 23.18steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440320/1000000 [5:07:07<5:58:25, 26.02steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 440320/1000000 [5:07:20<5:58:25, 26.02steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442880/1000000 [5:08:15<5:23:49, 28.67steps/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 442880/1000000 [5:08:30<5:23:49, 28.67steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:09:23<4:58:49, 30.93steps/s]                                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:09:23<4:58:49, 30.93steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -151     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.236    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.435    |
|    max_target_q      | -11.6    |
|    min_target_q      | -39.3    |
|    max_reward        | -0.29    |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 4.83     |
|    q1_grad_norm      | 3.02     |
|    q2_grad_norm      | 3.08     |
|    actor_loss        | 20       |
|    ent_coeff         | 0.0382   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.078    |
|    n_updates         | 13680    |
| time/                |          |
|    iterations        | 174      |
|    fps               | 37.3     |
|    elapsed_time      | 1.86e+04 |
|    elapsed_steps     | 445440   |
-----------------------------------
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 445440/1000000 [5:09:40<4:58:49, 30.93steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448000/1000000 [5:10:32<4:43:04, 32.50steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_448000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 448000/1000000 [5:10:50<4:43:04, 32.50steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 450560/1000000 [5:16:08<9:17:37, 16.42steps/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:17:13<7:37:58, 19.90steps/s]                                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:17:13<7:37:58, 19.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -151     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0513   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.254    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.434    |
|    max_target_q      | -11.6    |
|    min_target_q      | -39.5    |
|    max_reward        | -0.294   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 5.4      |
|    q1_grad_norm      | 3.64     |
|    q2_grad_norm      | 3.71     |
|    actor_loss        | 20.2     |
|    ent_coeff         | 0.038    |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0778   |
|    n_updates         | 13920    |
| eval/                |          |
|    Length            | 189      |
|    Return            | -151     |
|    NonzeroRewards    | 189      |
|    DiscountedReturn  | -151     |
|    Success           | 0.111    |
|    SuccessLength     | 188      |
| time/                |          |
|    iterations        | 177      |
|    fps               | 16.3     |
|    elapsed_time      | 1.9e+04  |
|    elapsed_steps     | 453120   |
-----------------------------------
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 453120/1000000 [5:17:30<7:37:58, 19.90steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455680/1000000 [5:18:21<6:31:00, 23.20steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 455680/1000000 [5:18:40<6:31:00, 23.20steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458240/1000000 [5:19:26<5:41:57, 26.40steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 458240/1000000 [5:19:40<5:41:57, 26.40steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:20:36<5:11:38, 28.84steps/s]                                                                46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:20:36<5:11:38, 28.84steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -150     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -150     |
|    Success           | 0.075    |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.285    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.431    |
|    max_target_q      | -11.4    |
|    min_target_q      | -40      |
|    max_reward        | -0.288   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 5.44     |
|    q1_grad_norm      | 3.53     |
|    q2_grad_norm      | 3.63     |
|    actor_loss        | 20.3     |
|    ent_coeff         | 0.0378   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0787   |
|    n_updates         | 14160    |
| time/                |          |
|    iterations        | 180      |
|    fps               | 37.8     |
|    elapsed_time      | 1.92e+04 |
|    elapsed_steps     | 460800   |
-----------------------------------
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 460800/1000000 [5:20:50<5:11:38, 28.84steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463360/1000000 [5:21:46<4:50:25, 30.80steps/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463360/1000000 [5:22:00<4:50:25, 30.80steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465920/1000000 [5:22:52<4:31:17, 32.81steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_465920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 465920/1000000 [5:23:10<4:31:17, 32.81steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468480/1000000 [5:28:25<8:54:19, 16.58steps/s]                                                                47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 468480/1000000 [5:28:25<8:54:19, 16.58steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -153     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.275    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.432    |
|    max_target_q      | -11.3    |
|    min_target_q      | -40.8    |
|    max_reward        | -0.291   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 5.72     |
|    q1_grad_norm      | 3.71     |
|    q2_grad_norm      | 3.78     |
|    actor_loss        | 20.5     |
|    ent_coeff         | 0.0376   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0776   |
|    n_updates         | 14400    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -151     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -151     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 183      |
|    fps               | 16.4     |
|    elapsed_time      | 1.97e+04 |
|    elapsed_steps     | 468480   |
-----------------------------------
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471040/1000000 [5:29:29<7:19:03, 20.08steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 471040/1000000 [5:29:40<7:19:03, 20.08steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473600/1000000 [5:30:34<6:12:28, 23.55steps/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 473600/1000000 [5:30:50<6:12:28, 23.55steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:31:38<5:24:31, 26.90steps/s]                                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:31:38<5:24:31, 26.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -151     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.284    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.427    |
|    max_target_q      | -11.2    |
|    min_target_q      | -41.2    |
|    max_reward        | -0.302   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 6.02     |
|    q1_grad_norm      | 3.78     |
|    q2_grad_norm      | 3.87     |
|    actor_loss        | 20.6     |
|    ent_coeff         | 0.0375   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.077    |
|    n_updates         | 14640    |
| time/                |          |
|    iterations        | 186      |
|    fps               | 39.8     |
|    elapsed_time      | 1.99e+04 |
|    elapsed_steps     | 476160   |
-----------------------------------
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 476160/1000000 [5:31:50<5:24:31, 26.90steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478720/1000000 [5:32:48<4:57:48, 29.17steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 478720/1000000 [5:33:00<4:57:48, 29.17steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481280/1000000 [5:34:01<4:41:08, 30.75steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 481280/1000000 [5:34:20<4:41:08, 30.75steps/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:35:16<4:31:14, 31.72steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:35:30<4:31:14, 31.72steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_483840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 483840/1000000 [5:39:37<4:31:14, 31.72steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -151     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0769   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.309    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.424    |
|    max_target_q      | -11.1    |
|    min_target_q      | -41.5    |
|    max_reward        | -0.29    |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 6.08     |
|    q1_grad_norm      | 3.35     |
|    q2_grad_norm      | 3.41     |
|    actor_loss        | 20.7     |
|    ent_coeff         | 0.0373   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0782   |
|    n_updates         | 14880    |
| eval/                |          |
|    Length            | 199      |
|    Return            | -158     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -158     |
|    Success           | 0.0556   |
|    SuccessLength     | 199      |
| time/                |          |
|    iterations        | 189      |
|    fps               | 16       |
|    elapsed_time      | 2.04e+04 |
|    elapsed_steps     | 483840   |
-----------------------------------
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 486400/1000000 [5:40:42<8:35:53, 16.59steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488960/1000000 [5:41:45<7:02:37, 20.15steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 488960/1000000 [5:42:00<7:02:37, 20.15steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:42:50<5:58:30, 23.64steps/s]                                                                49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:42:50<5:58:30, 23.64steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -153     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0513   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.299    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.422    |
|    max_target_q      | -11      |
|    min_target_q      | -42.2    |
|    max_reward        | -0.278   |
|    min_reward        | -1.43    |
|    encoder_grad_norm | 6.58     |
|    q1_grad_norm      | 4.09     |
|    q2_grad_norm      | 4.21     |
|    actor_loss        | 20.9     |
|    ent_coeff         | 0.0371   |
|    ent_coeff_loss    | -103     |
|    pi_grad_norm      | 0.0768   |
|    n_updates         | 15120    |
| time/                |          |
|    iterations        | 192      |
|    fps               | 39.8     |
|    elapsed_time      | 2.06e+04 |
|    elapsed_steps     | 491520   |
-----------------------------------
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 491520/1000000 [5:43:00<5:58:30, 23.64steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494080/1000000 [5:43:53<5:12:25, 26.99steps/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 494080/1000000 [5:44:10<5:12:25, 26.99steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496640/1000000 [5:45:00<4:43:10, 29.63steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 496640/1000000 [5:45:10<4:43:10, 29.63steps/s]ReplayBuffer: Replay buffer is now full. cursor=0.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:46:15<4:30:52, 30.81steps/s]                                                                50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:46:15<4:30:52, 30.81steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -154     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -154     |
|    Success           | 0.05     |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.312    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.42     |
|    max_target_q      | -11.1    |
|    min_target_q      | -42.7    |
|    max_reward        | -0.273   |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 6.39     |
|    q1_grad_norm      | 3.86     |
|    q2_grad_norm      | 3.95     |
|    actor_loss        | 21.1     |
|    ent_coeff         | 0.0369   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0762   |
|    n_updates         | 15360    |
| time/                |          |
|    iterations        | 195      |
|    fps               | 37.4     |
|    elapsed_time      | 2.08e+04 |
|    elapsed_steps     | 499200   |
-----------------------------------
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 499200/1000000 [5:46:30<4:30:52, 30.81steps/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501760/1000000 [5:47:32<4:22:47, 31.60steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_501760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501760/1000000 [5:47:50<4:22:47, 31.60steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 504320/1000000 [5:53:13<8:33:45, 16.08steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:54:18<7:00:04, 19.56steps/s]                                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:54:18<7:00:04, 19.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -155     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0513   |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.301    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.418    |
|    max_target_q      | -11      |
|    min_target_q      | -42.9    |
|    max_reward        | -0.294   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 5.83     |
|    q1_grad_norm      | 3.21     |
|    q2_grad_norm      | 3.28     |
|    actor_loss        | 21.2     |
|    ent_coeff         | 0.0367   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0771   |
|    n_updates         | 15600    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -150     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 198      |
|    fps               | 15.9     |
|    elapsed_time      | 2.13e+04 |
|    elapsed_steps     | 506880   |
-----------------------------------
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 506880/1000000 [5:54:30<7:00:04, 19.56steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509440/1000000 [5:55:23<5:54:47, 23.04steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 509440/1000000 [5:55:40<5:54:47, 23.04steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512000/1000000 [5:56:34<5:14:43, 25.84steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 512000/1000000 [5:56:50<5:14:43, 25.84steps/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [5:57:41<4:43:14, 28.56steps/s]                                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [5:57:41<4:43:14, 28.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -159     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -159     |
|    Success           | 0.025    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.309    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.416    |
|    max_target_q      | -10.9    |
|    min_target_q      | -43.4    |
|    max_reward        | -0.285   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 5.83     |
|    q1_grad_norm      | 3.07     |
|    q2_grad_norm      | 3.15     |
|    actor_loss        | 21.3     |
|    ent_coeff         | 0.0366   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0767   |
|    n_updates         | 15840    |
| time/                |          |
|    iterations        | 201      |
|    fps               | 37.7     |
|    elapsed_time      | 2.15e+04 |
|    elapsed_steps     | 514560   |
-----------------------------------
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 514560/1000000 [5:58:00<4:43:14, 28.56steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517120/1000000 [5:58:56<4:27:14, 30.12steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517120/1000000 [5:59:10<4:27:14, 30.12steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519680/1000000 [6:00:10<4:15:30, 31.33steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 519680/1000000 [6:00:20<4:15:30, 31.33steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_519680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522240/1000000 [6:05:56<8:20:46, 15.90steps/s]                                                                52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 522240/1000000 [6:05:56<8:20:46, 15.90steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -150     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0833   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.336    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.417    |
|    max_target_q      | -10.8    |
|    min_target_q      | -43.5    |
|    max_reward        | -0.28    |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 7.28     |
|    q1_grad_norm      | 4.53     |
|    q2_grad_norm      | 4.65     |
|    actor_loss        | 21.4     |
|    ent_coeff         | 0.0364   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0751   |
|    n_updates         | 16080    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -155     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -155     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 204      |
|    fps               | 15.5     |
|    elapsed_time      | 2.2e+04  |
|    elapsed_steps     | 522240   |
-----------------------------------
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524800/1000000 [6:07:05<6:53:18, 19.16steps/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 524800/1000000 [6:07:20<6:53:18, 19.16steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527360/1000000 [6:08:13<5:49:51, 22.52steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 527360/1000000 [6:08:30<5:49:51, 22.52steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:09:19<5:04:59, 25.69steps/s]                                                                53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:09:19<5:04:59, 25.69steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -157     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0244   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.345    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.414    |
|    max_target_q      | -10.7    |
|    min_target_q      | -43.8    |
|    max_reward        | -0.288   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 6.97     |
|    q1_grad_norm      | 3.99     |
|    q2_grad_norm      | 4.1      |
|    actor_loss        | 21.6     |
|    ent_coeff         | 0.0362   |
|    ent_coeff_loss    | -104     |
|    pi_grad_norm      | 0.0753   |
|    n_updates         | 16320    |
| time/                |          |
|    iterations        | 207      |
|    fps               | 37.7     |
|    elapsed_time      | 2.22e+04 |
|    elapsed_steps     | 529920   |
-----------------------------------
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 529920/1000000 [6:09:30<5:04:59, 25.69steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532480/1000000 [6:10:27<4:34:04, 28.43steps/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 532480/1000000 [6:10:40<4:34:04, 28.43steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535040/1000000 [6:11:41<4:17:42, 30.07steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 535040/1000000 [6:12:00<4:17:42, 30.07steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:12:49<4:01:15, 31.94steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:13:00<4:01:15, 31.94steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_537600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 537600/1000000 [6:17:22<4:01:15, 31.94steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 190      |
|    Return            | -148     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -148     |
|    Success           | 0.103    |
|    SuccessLength     | 190      |
| algo/                |          |
|    critic_loss       | 0.352    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.413    |
|    max_target_q      | -10.3    |
|    min_target_q      | -44.4    |
|    max_reward        | -0.278   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 6.53     |
|    q1_grad_norm      | 3.67     |
|    q2_grad_norm      | 3.75     |
|    actor_loss        | 21.7     |
|    ent_coeff         | 0.036    |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0754   |
|    n_updates         | 16560    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 210      |
|    fps               | 15.9     |
|    elapsed_time      | 2.26e+04 |
|    elapsed_steps     | 537600   |
-----------------------------------
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 540160/1000000 [6:18:32<7:55:43, 16.11steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542720/1000000 [6:19:36<6:27:55, 19.65steps/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 542720/1000000 [6:19:50<6:27:55, 19.65steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:20:45<5:31:30, 22.86steps/s]                                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:20:45<5:31:30, 22.86steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -150     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -150     |
|    Success           | 0.0526   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.334    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.414    |
|    max_target_q      | -10.6    |
|    min_target_q      | -44.9    |
|    max_reward        | -0.278   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 7.09     |
|    q1_grad_norm      | 3.96     |
|    q2_grad_norm      | 4.07     |
|    actor_loss        | 21.8     |
|    ent_coeff         | 0.0359   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0738   |
|    n_updates         | 16800    |
| time/                |          |
|    iterations        | 213      |
|    fps               | 37.9     |
|    elapsed_time      | 2.28e+04 |
|    elapsed_steps     | 545280   |
-----------------------------------
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 545280/1000000 [6:21:00<5:31:30, 22.86steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547840/1000000 [6:21:52<4:50:20, 25.96steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 547840/1000000 [6:22:10<4:50:20, 25.96steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550400/1000000 [6:23:01<4:22:32, 28.54steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550400/1000000 [6:23:20<4:22:32, 28.54steps/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:24:13<4:05:27, 30.36steps/s]                                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:24:13<4:05:27, 30.36steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -152     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -152     |
|    Success           | 0.093    |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.34     |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.412    |
|    max_target_q      | -10.2    |
|    min_target_q      | -45.8    |
|    max_reward        | -0.274   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 7.09     |
|    q1_grad_norm      | 4.08     |
|    q2_grad_norm      | 4.16     |
|    actor_loss        | 21.9     |
|    ent_coeff         | 0.0357   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.074    |
|    n_updates         | 17040    |
| time/                |          |
|    iterations        | 216      |
|    fps               | 36.9     |
|    elapsed_time      | 2.31e+04 |
|    elapsed_steps     | 552960   |
-----------------------------------
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 552960/1000000 [6:24:30<4:05:27, 30.36steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555520/1000000 [6:25:27<3:54:54, 31.54steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 555520/1000000 [6:25:40<3:54:54, 31.54steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_555520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 558080/1000000 [6:30:52<7:24:19, 16.58steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:31:59<6:06:51, 19.96steps/s]                                                                56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:31:59<6:06:51, 19.96steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -153     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0541   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.374    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.412    |
|    max_target_q      | -10.2    |
|    min_target_q      | -45.9    |
|    max_reward        | -0.282   |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 7.66     |
|    q1_grad_norm      | 4.35     |
|    q2_grad_norm      | 4.46     |
|    actor_loss        | 22       |
|    ent_coeff         | 0.0355   |
|    ent_coeff_loss    | -105     |
|    pi_grad_norm      | 0.0728   |
|    n_updates         | 17280    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 219      |
|    fps               | 16.5     |
|    elapsed_time      | 2.35e+04 |
|    elapsed_steps     | 560640   |
-----------------------------------
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 560640/1000000 [6:32:10<6:06:51, 19.96steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563200/1000000 [6:33:06<5:12:02, 23.33steps/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 563200/1000000 [6:33:20<5:12:02, 23.33steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565760/1000000 [6:34:10<4:31:40, 26.64steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 565760/1000000 [6:34:20<4:31:40, 26.64steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:35:16<4:04:38, 29.41steps/s]                                                                57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:35:16<4:04:38, 29.41steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -153     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.398    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.411    |
|    max_target_q      | -10      |
|    min_target_q      | -46.8    |
|    max_reward        | -0.285   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 8.02     |
|    q1_grad_norm      | 3.61     |
|    q2_grad_norm      | 3.68     |
|    actor_loss        | 22.1     |
|    ent_coeff         | 0.0354   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0728   |
|    n_updates         | 17520    |
| time/                |          |
|    iterations        | 222      |
|    fps               | 39       |
|    elapsed_time      | 2.37e+04 |
|    elapsed_steps     | 568320   |
-----------------------------------
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 568320/1000000 [6:35:30<4:04:38, 29.41steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570880/1000000 [6:36:23<3:46:37, 31.56steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 570880/1000000 [6:36:40<3:46:37, 31.56steps/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573440/1000000 [6:37:32<3:34:37, 33.12steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_573440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 573440/1000000 [6:37:50<3:34:37, 33.12steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576000/1000000 [6:42:58<6:59:22, 16.85steps/s]                                                                58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 576000/1000000 [6:42:58<6:59:22, 16.85steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -149     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -149     |
|    Success           | 0.075    |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.396    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.409    |
|    max_target_q      | -9.88    |
|    min_target_q      | -47.3    |
|    max_reward        | -0.279   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 8.6      |
|    q1_grad_norm      | 5.07     |
|    q2_grad_norm      | 5.19     |
|    actor_loss        | 22.2     |
|    ent_coeff         | 0.0352   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.071    |
|    n_updates         | 17760    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 225      |
|    fps               | 16.6     |
|    elapsed_time      | 2.42e+04 |
|    elapsed_steps     | 576000   |
-----------------------------------
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578560/1000000 [6:44:04<5:46:02, 20.30steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 578560/1000000 [6:44:20<5:46:02, 20.30steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581120/1000000 [6:45:10<4:54:46, 23.68steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 581120/1000000 [6:45:20<4:54:46, 23.68steps/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:46:13<4:16:23, 27.06steps/s]                                                                58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:46:13<4:16:23, 27.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -152     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -152     |
|    Success           | 0.05     |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.404    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.409    |
|    max_target_q      | -9.16    |
|    min_target_q      | -47.5    |
|    max_reward        | -0.276   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 7.69     |
|    q1_grad_norm      | 3.7      |
|    q2_grad_norm      | 3.79     |
|    actor_loss        | 22.3     |
|    ent_coeff         | 0.035    |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0724   |
|    n_updates         | 18000    |
| time/                |          |
|    iterations        | 228      |
|    fps               | 39.4     |
|    elapsed_time      | 2.44e+04 |
|    elapsed_steps     | 583680   |
-----------------------------------
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 583680/1000000 [6:46:30<4:16:23, 27.06steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586240/1000000 [6:47:20<3:53:03, 29.59steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 586240/1000000 [6:47:40<3:53:03, 29.59steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588800/1000000 [6:48:28<3:36:39, 31.63steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 588800/1000000 [6:48:40<3:36:39, 31.63steps/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:49:39<3:26:51, 32.92steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:49:50<3:26:51, 32.92steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_591360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 591360/1000000 [6:54:04<3:26:51, 32.92steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 189      |
|    Return            | -146     |
|    NonzeroRewards    | 189      |
|    DiscountedReturn  | -146     |
|    Success           | 0.132    |
|    SuccessLength     | 189      |
| algo/                |          |
|    critic_loss       | 0.416    |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.409    |
|    max_target_q      | -8.67    |
|    min_target_q      | -47.9    |
|    max_reward        | -0.279   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 8.83     |
|    q1_grad_norm      | 4.38     |
|    q2_grad_norm      | 4.51     |
|    actor_loss        | 22.4     |
|    ent_coeff         | 0.0348   |
|    ent_coeff_loss    | -106     |
|    pi_grad_norm      | 0.0709   |
|    n_updates         | 18240    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -161     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -161     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 231      |
|    fps               | 16.3     |
|    elapsed_time      | 2.48e+04 |
|    elapsed_steps     | 591360   |
-----------------------------------
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 593920/1000000 [6:55:13<6:48:44, 16.56steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596480/1000000 [6:56:19<5:36:50, 19.97steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 596480/1000000 [6:56:30<5:36:50, 19.97steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [6:57:28<4:48:08, 23.19steps/s]                                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [6:57:28<4:48:08, 23.19steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -153     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0488   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.425    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.408    |
|    max_target_q      | -7.55    |
|    min_target_q      | -48.7    |
|    max_reward        | -0.27    |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 9.39     |
|    q1_grad_norm      | 4.76     |
|    q2_grad_norm      | 4.87     |
|    actor_loss        | 22.5     |
|    ent_coeff         | 0.0347   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0705   |
|    n_updates         | 18480    |
| time/                |          |
|    iterations        | 234      |
|    fps               | 37.6     |
|    elapsed_time      | 2.5e+04  |
|    elapsed_steps     | 599040   |
-----------------------------------
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 599040/1000000 [6:57:40<4:48:08, 23.19steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601600/1000000 [6:58:38<4:14:38, 26.08steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 601600/1000000 [6:58:50<4:14:38, 26.08steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604160/1000000 [6:59:48<3:51:45, 28.47steps/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 604160/1000000 [7:00:00<3:51:45, 28.47steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:00:53<3:30:52, 31.08steps/s]                                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:00:53<3:30:52, 31.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -156     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0513   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.461    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.408    |
|    max_target_q      | -7.87    |
|    min_target_q      | -47.8    |
|    max_reward        | -0.278   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 9.44     |
|    q1_grad_norm      | 4.48     |
|    q2_grad_norm      | 4.59     |
|    actor_loss        | 22.6     |
|    ent_coeff         | 0.0345   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0708   |
|    n_updates         | 18720    |
| time/                |          |
|    iterations        | 237      |
|    fps               | 37.5     |
|    elapsed_time      | 2.53e+04 |
|    elapsed_steps     | 606720   |
-----------------------------------
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 606720/1000000 [7:01:10<3:30:52, 31.08steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609280/1000000 [7:02:06<3:22:13, 32.20steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 609280/1000000 [7:02:20<3:22:13, 32.20steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_609280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 611840/1000000 [7:07:32<6:28:02, 16.67steps/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:08:39<5:20:04, 20.08steps/s]                                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:08:39<5:20:04, 20.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -159     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -159     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.441    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.407    |
|    max_target_q      | -7.34    |
|    min_target_q      | -48.3    |
|    max_reward        | -0.269   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 9.66     |
|    q1_grad_norm      | 5.26     |
|    q2_grad_norm      | 5.41     |
|    actor_loss        | 22.8     |
|    ent_coeff         | 0.0343   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0698   |
|    n_updates         | 18960    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -156     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -156     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 240      |
|    fps               | 16.5     |
|    elapsed_time      | 2.57e+04 |
|    elapsed_steps     | 614400   |
-----------------------------------
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 614400/1000000 [7:08:50<5:20:04, 20.08steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616960/1000000 [7:09:45<4:32:18, 23.44steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 616960/1000000 [7:10:00<4:32:18, 23.44steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619520/1000000 [7:10:53<3:59:36, 26.47steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 619520/1000000 [7:11:10<3:59:36, 26.47steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:11:59<3:35:09, 29.28steps/s]                                                                62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:11:59<3:35:09, 29.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -153     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -153     |
|    Success           | 0.027    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.461    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.406    |
|    max_target_q      | -7.18    |
|    min_target_q      | -48      |
|    max_reward        | -0.268   |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 8.79     |
|    q1_grad_norm      | 4.11     |
|    q2_grad_norm      | 4.23     |
|    actor_loss        | 23       |
|    ent_coeff         | 0.0342   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.069    |
|    n_updates         | 19200    |
| time/                |          |
|    iterations        | 243      |
|    fps               | 38.4     |
|    elapsed_time      | 2.59e+04 |
|    elapsed_steps     | 622080   |
-----------------------------------
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 622080/1000000 [7:12:10<3:35:09, 29.28steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624640/1000000 [7:13:08<3:20:15, 31.24steps/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 624640/1000000 [7:13:20<3:20:15, 31.24steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627200/1000000 [7:14:21<3:12:29, 32.28steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_627200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 627200/1000000 [7:14:40<3:12:29, 32.28steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629760/1000000 [7:19:50<6:11:59, 16.59steps/s]                                                                63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 629760/1000000 [7:19:51<6:11:59, 16.59steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -147     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0976   |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.441    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.405    |
|    max_target_q      | -6.57    |
|    min_target_q      | -48.1    |
|    max_reward        | -0.268   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 9.66     |
|    q1_grad_norm      | 5.3      |
|    q2_grad_norm      | 5.45     |
|    actor_loss        | 23.1     |
|    ent_coeff         | 0.034    |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0688   |
|    n_updates         | 19440    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -157     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -157     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 246      |
|    fps               | 16.3     |
|    elapsed_time      | 2.64e+04 |
|    elapsed_steps     | 629760   |
-----------------------------------
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632320/1000000 [7:20:56<5:05:21, 20.07steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 632320/1000000 [7:21:10<5:05:21, 20.07steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634880/1000000 [7:22:02<4:19:48, 23.42steps/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 634880/1000000 [7:22:20<4:19:48, 23.42steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:23:11<3:49:17, 26.35steps/s]                                                                64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:23:11<3:49:17, 26.35steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -154     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.459    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.403    |
|    max_target_q      | -5.84    |
|    min_target_q      | -49.6    |
|    max_reward        | -0.269   |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 8.95     |
|    q1_grad_norm      | 4.15     |
|    q2_grad_norm      | 4.28     |
|    actor_loss        | 23.3     |
|    ent_coeff         | 0.0339   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0695   |
|    n_updates         | 19680    |
| time/                |          |
|    iterations        | 249      |
|    fps               | 38.3     |
|    elapsed_time      | 2.66e+04 |
|    elapsed_steps     | 637440   |
-----------------------------------
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 637440/1000000 [7:23:30<3:49:17, 26.35steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640000/1000000 [7:24:21<3:28:21, 28.80steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 640000/1000000 [7:24:40<3:28:21, 28.80steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642560/1000000 [7:25:29<3:12:38, 30.92steps/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 642560/1000000 [7:25:40<3:12:38, 30.92steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:26:38<3:01:34, 32.57steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:26:50<3:01:34, 32.57steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_645120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 645120/1000000 [7:31:25<3:01:34, 32.57steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -153     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -153     |
|    Success           | 0.025    |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.461    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.399    |
|    max_target_q      | -5.42    |
|    min_target_q      | -48.9    |
|    max_reward        | -0.273   |
|    min_reward        | -1.4     |
|    encoder_grad_norm | 8.79     |
|    q1_grad_norm      | 4.07     |
|    q2_grad_norm      | 4.15     |
|    actor_loss        | 23.4     |
|    ent_coeff         | 0.0337   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0703   |
|    n_updates         | 19920    |
| eval/                |          |
|    Length            | 186      |
|    Return            | -138     |
|    NonzeroRewards    | 186      |
|    DiscountedReturn  | -138     |
|    Success           | 0.167    |
|    SuccessLength     | 186      |
| time/                |          |
|    iterations        | 252      |
|    fps               | 15.6     |
|    elapsed_time      | 2.71e+04 |
|    elapsed_steps     | 645120   |
-----------------------------------
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 647680/1000000 [7:32:31<6:08:55, 15.92steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650240/1000000 [7:33:40<5:03:43, 19.19steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 650240/1000000 [7:33:50<5:03:43, 19.19steps/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:34:47<4:16:42, 22.54steps/s]                                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:34:47<4:16:42, 22.54steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -145     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -145     |
|    Success           | 0.1      |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.472    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.399    |
|    max_target_q      | -5.14    |
|    min_target_q      | -48      |
|    max_reward        | -0.267   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.16     |
|    q1_grad_norm      | 4.16     |
|    q2_grad_norm      | 4.26     |
|    actor_loss        | 23.6     |
|    ent_coeff         | 0.0335   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0689   |
|    n_updates         | 20160    |
| time/                |          |
|    iterations        | 255      |
|    fps               | 37.8     |
|    elapsed_time      | 2.73e+04 |
|    elapsed_steps     | 652800   |
-----------------------------------
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 652800/1000000 [7:35:00<4:16:42, 22.54steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655360/1000000 [7:35:56<3:44:48, 25.55steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 655360/1000000 [7:36:10<3:44:48, 25.55steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657920/1000000 [7:37:08<3:23:52, 27.96steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 657920/1000000 [7:37:20<3:23:52, 27.96steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:38:16<3:06:54, 30.27steps/s]                                                                66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:38:16<3:06:54, 30.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -154     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0541   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.478    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.397    |
|    max_target_q      | -4.8     |
|    min_target_q      | -47      |
|    max_reward        | -0.269   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 9.67     |
|    q1_grad_norm      | 4.73     |
|    q2_grad_norm      | 4.86     |
|    actor_loss        | 23.8     |
|    ent_coeff         | 0.0334   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0692   |
|    n_updates         | 20400    |
| time/                |          |
|    iterations        | 258      |
|    fps               | 36.8     |
|    elapsed_time      | 2.75e+04 |
|    elapsed_steps     | 660480   |
-----------------------------------
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 660480/1000000 [7:38:30<3:06:54, 30.27steps/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663040/1000000 [7:39:24<2:54:33, 32.17steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_663040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 663040/1000000 [7:39:40<2:54:33, 32.17steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 665600/1000000 [7:45:03<5:42:29, 16.27steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:46:10<4:41:16, 19.66steps/s]                                                                67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:46:10<4:41:16, 19.66steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -154     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -154     |
|    Success           | 0.0513   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.453    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.394    |
|    max_target_q      | -5.02    |
|    min_target_q      | -47.2    |
|    max_reward        | -0.267   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.15     |
|    q1_grad_norm      | 4.61     |
|    q2_grad_norm      | 4.75     |
|    actor_loss        | 23.9     |
|    ent_coeff         | 0.0332   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0693   |
|    n_updates         | 20640    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -162     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -162     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 261      |
|    fps               | 16.2     |
|    elapsed_time      | 2.8e+04  |
|    elapsed_steps     | 668160   |
-----------------------------------
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 668160/1000000 [7:46:20<4:41:16, 19.66steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670720/1000000 [7:47:23<4:02:19, 22.65steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 670720/1000000 [7:47:40<4:02:19, 22.65steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673280/1000000 [7:48:32<3:32:53, 25.58steps/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 673280/1000000 [7:48:50<3:32:53, 25.58steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:49:41<3:10:55, 28.30steps/s]                                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:49:41<3:10:55, 28.30steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 192      |
|    Return            | -145     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -145     |
|    Success           | 0.0732   |
|    SuccessLength     | 192      |
| algo/                |          |
|    critic_loss       | 0.453    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.396    |
|    max_target_q      | -4.72    |
|    min_target_q      | -46.9    |
|    max_reward        | -0.274   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.44     |
|    q1_grad_norm      | 4.52     |
|    q2_grad_norm      | 4.62     |
|    actor_loss        | 24.1     |
|    ent_coeff         | 0.0331   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.068    |
|    n_updates         | 20880    |
| time/                |          |
|    iterations        | 264      |
|    fps               | 36.4     |
|    elapsed_time      | 2.82e+04 |
|    elapsed_steps     | 675840   |
-----------------------------------
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 675840/1000000 [7:50:00<3:10:55, 28.30steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678400/1000000 [7:50:49<2:55:52, 30.48steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 678400/1000000 [7:51:00<2:55:52, 30.48steps/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680960/1000000 [7:52:04<2:48:28, 31.56steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_680960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 680960/1000000 [7:52:20<2:48:28, 31.56steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683520/1000000 [7:57:34<5:20:47, 16.44steps/s]                                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 683520/1000000 [7:57:34<5:20:47, 16.44steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -146     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0769   |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.473    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.393    |
|    max_target_q      | -4.92    |
|    min_target_q      | -46.7    |
|    max_reward        | -0.265   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.22     |
|    q1_grad_norm      | 4.2      |
|    q2_grad_norm      | 4.29     |
|    actor_loss        | 24.2     |
|    ent_coeff         | 0.0329   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0677   |
|    n_updates         | 21120    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -157     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -157     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 267      |
|    fps               | 16.2     |
|    elapsed_time      | 2.87e+04 |
|    elapsed_steps     | 683520   |
-----------------------------------
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686080/1000000 [7:58:42<4:24:59, 19.74steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 686080/1000000 [7:59:00<4:24:59, 19.74steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688640/1000000 [7:59:49<3:44:27, 23.12steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 688640/1000000 [8:00:00<3:44:27, 23.12steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:00:58<3:17:10, 26.10steps/s]                                                                69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:00:58<3:17:10, 26.10steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -150     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -150     |
|    Success           | 0.05     |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.478    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.393    |
|    max_target_q      | -4.94    |
|    min_target_q      | -47.1    |
|    max_reward        | -0.26    |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.49     |
|    q1_grad_norm      | 4.35     |
|    q2_grad_norm      | 4.45     |
|    actor_loss        | 24.4     |
|    ent_coeff         | 0.0327   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0667   |
|    n_updates         | 21360    |
| time/                |          |
|    iterations        | 270      |
|    fps               | 37.6     |
|    elapsed_time      | 2.89e+04 |
|    elapsed_steps     | 691200   |
-----------------------------------
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 691200/1000000 [8:01:10<3:17:10, 26.10steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693760/1000000 [8:02:08<2:59:04, 28.50steps/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 693760/1000000 [8:02:20<2:59:04, 28.50steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696320/1000000 [8:03:15<2:44:16, 30.81steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 696320/1000000 [8:03:30<2:44:16, 30.81steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:04:23<2:33:30, 32.69steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_698880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:04:40<2:33:30, 32.69steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 698880/1000000 [8:08:56<2:33:30, 32.69steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -151     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0513   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.482    |
|    mean_entropy      | 12       |
|    mean_ent_bonus    | 0.39     |
|    max_target_q      | -4.62    |
|    min_target_q      | -47.2    |
|    max_reward        | -0.27    |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 9.25     |
|    q1_grad_norm      | 3.96     |
|    q2_grad_norm      | 4.04     |
|    actor_loss        | 24.6     |
|    ent_coeff         | 0.0326   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0668   |
|    n_updates         | 21600    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 273      |
|    fps               | 16.1     |
|    elapsed_time      | 2.93e+04 |
|    elapsed_steps     | 698880   |
-----------------------------------
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 701440/1000000 [8:10:00<5:03:28, 16.40steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704000/1000000 [8:11:04<4:07:36, 19.92steps/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 704000/1000000 [8:11:20<4:07:36, 19.92steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:12:11<3:30:15, 23.26steps/s]                                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:12:11<3:30:15, 23.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 193      |
|    Return            | -151     |
|    NonzeroRewards    | 193      |
|    DiscountedReturn  | -151     |
|    Success           | 0.075    |
|    SuccessLength     | 193      |
| algo/                |          |
|    critic_loss       | 0.499    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.385    |
|    max_target_q      | -4.57    |
|    min_target_q      | -47.2    |
|    max_reward        | -0.261   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 10.7     |
|    q1_grad_norm      | 5.67     |
|    q2_grad_norm      | 5.81     |
|    actor_loss        | 24.7     |
|    ent_coeff         | 0.0324   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0682   |
|    n_updates         | 21840    |
| time/                |          |
|    iterations        | 276      |
|    fps               | 39.2     |
|    elapsed_time      | 2.95e+04 |
|    elapsed_steps     | 706560   |
-----------------------------------
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 706560/1000000 [8:12:30<3:30:15, 23.26steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709120/1000000 [8:13:18<3:03:41, 26.39steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 709120/1000000 [8:13:30<3:03:41, 26.39steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711680/1000000 [8:14:27<2:46:09, 28.92steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 711680/1000000 [8:14:40<2:46:09, 28.92steps/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:15:36<2:33:48, 30.97steps/s]                                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:15:36<2:33:48, 30.97steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -156     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -156     |
|    Success           | 0.05     |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.49     |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.382    |
|    max_target_q      | -4.45    |
|    min_target_q      | -47.2    |
|    max_reward        | -0.266   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.98     |
|    q1_grad_norm      | 4.92     |
|    q2_grad_norm      | 5.06     |
|    actor_loss        | 24.9     |
|    ent_coeff         | 0.0323   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0672   |
|    n_updates         | 22080    |
| time/                |          |
|    iterations        | 279      |
|    fps               | 37.6     |
|    elapsed_time      | 2.97e+04 |
|    elapsed_steps     | 714240   |
-----------------------------------
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 714240/1000000 [8:15:50<2:33:48, 30.97steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716800/1000000 [8:16:45<2:25:02, 32.54steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 716800/1000000 [8:17:00<2:25:02, 32.54steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_716800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 719360/1000000 [8:22:21<4:44:59, 16.41steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:23:27<3:53:14, 19.87steps/s]                                                                72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:23:27<3:53:14, 19.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -153     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -153     |
|    Success           | 0.0263   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.533    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.382    |
|    max_target_q      | -4.19    |
|    min_target_q      | -47.6    |
|    max_reward        | -0.263   |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 10.9     |
|    q1_grad_norm      | 5.27     |
|    q2_grad_norm      | 5.39     |
|    actor_loss        | 25.1     |
|    ent_coeff         | 0.0321   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0679   |
|    n_updates         | 22320    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -152     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -152     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 282      |
|    fps               | 16.3     |
|    elapsed_time      | 3.02e+04 |
|    elapsed_steps     | 721920   |
-----------------------------------
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 721920/1000000 [8:23:40<3:53:14, 19.87steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724480/1000000 [8:24:36<3:19:03, 23.07steps/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 724480/1000000 [8:24:50<3:19:03, 23.07steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727040/1000000 [8:25:47<2:55:57, 25.85steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 727040/1000000 [8:26:00<2:55:57, 25.85steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:26:55<2:37:51, 28.55steps/s]                                                                73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:26:55<2:37:51, 28.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -151     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -151     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.52     |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.379    |
|    max_target_q      | -4.52    |
|    min_target_q      | -47.3    |
|    max_reward        | -0.261   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 10.4     |
|    q1_grad_norm      | 4.81     |
|    q2_grad_norm      | 4.95     |
|    actor_loss        | 25.2     |
|    ent_coeff         | 0.032    |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0671   |
|    n_updates         | 22560    |
| time/                |          |
|    iterations        | 285      |
|    fps               | 36.9     |
|    elapsed_time      | 3.04e+04 |
|    elapsed_steps     | 729600   |
-----------------------------------
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 729600/1000000 [8:27:10<2:37:51, 28.55steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732160/1000000 [8:28:07<2:27:08, 30.34steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 732160/1000000 [8:28:20<2:27:08, 30.34steps/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734720/1000000 [8:29:19<2:19:26, 31.71steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 734720/1000000 [8:29:30<2:19:26, 31.71steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_734720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737280/1000000 [8:35:09<4:36:05, 15.86steps/s]                                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 737280/1000000 [8:35:09<4:36:05, 15.86steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -150     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -150     |
|    Success           | 0.025    |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.503    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.379    |
|    max_target_q      | -4.88    |
|    min_target_q      | -47.8    |
|    max_reward        | -0.261   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 9.8      |
|    q1_grad_norm      | 4.45     |
|    q2_grad_norm      | 4.56     |
|    actor_loss        | 25.4     |
|    ent_coeff         | 0.0318   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0668   |
|    n_updates         | 22800    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -155     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -155     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 288      |
|    fps               | 15.5     |
|    elapsed_time      | 3.09e+04 |
|    elapsed_steps     | 737280   |
-----------------------------------
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739840/1000000 [8:36:15<3:44:48, 19.29steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 739840/1000000 [8:36:30<3:44:48, 19.29steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742400/1000000 [8:37:20<3:08:24, 22.79steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 742400/1000000 [8:37:30<3:08:24, 22.79steps/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:38:31<2:46:19, 25.56steps/s]                                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:38:31<2:46:19, 25.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -155     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -155     |
|    Success           | 0.0256   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.521    |
|    mean_entropy      | 11.9     |
|    mean_ent_bonus    | 0.375    |
|    max_target_q      | -5.29    |
|    min_target_q      | -48.2    |
|    max_reward        | -0.266   |
|    min_reward        | -1.37    |
|    encoder_grad_norm | 10.6     |
|    q1_grad_norm      | 5.05     |
|    q2_grad_norm      | 5.13     |
|    actor_loss        | 25.6     |
|    ent_coeff         | 0.0317   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0673   |
|    n_updates         | 23040    |
| time/                |          |
|    iterations        | 291      |
|    fps               | 38       |
|    elapsed_time      | 3.11e+04 |
|    elapsed_steps     | 744960   |
-----------------------------------
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 744960/1000000 [8:38:50<2:46:19, 25.56steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747520/1000000 [8:39:41<2:29:25, 28.16steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 747520/1000000 [8:40:00<2:29:25, 28.16steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750080/1000000 [8:40:51<2:17:53, 30.21steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750080/1000000 [8:41:10<2:17:53, 30.21steps/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:42:06<2:11:32, 31.34steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:42:20<2:11:32, 31.34steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_752640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 752640/1000000 [8:46:34<2:11:32, 31.34steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -160     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -160     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.549    |
|    mean_entropy      | 11.8     |
|    mean_ent_bonus    | 0.37     |
|    max_target_q      | -5.33    |
|    min_target_q      | -48.4    |
|    max_reward        | -0.266   |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 12       |
|    q1_grad_norm      | 5.86     |
|    q2_grad_norm      | 6.01     |
|    actor_loss        | 25.7     |
|    ent_coeff         | 0.0315   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0689   |
|    n_updates         | 23280    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 294      |
|    fps               | 15.9     |
|    elapsed_time      | 3.16e+04 |
|    elapsed_steps     | 752640   |
-----------------------------------
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 755200/1000000 [8:47:40<4:10:55, 16.26steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757760/1000000 [8:48:47<3:25:21, 19.66steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 757760/1000000 [8:49:00<3:25:21, 19.66steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:49:55<2:54:10, 22.94steps/s]                                                                76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:49:55<2:54:10, 22.94steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.55     |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.368    |
|    max_target_q      | -5.07    |
|    min_target_q      | -48.7    |
|    max_reward        | -0.268   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 10.4     |
|    q1_grad_norm      | 4.49     |
|    q2_grad_norm      | 4.59     |
|    actor_loss        | 25.8     |
|    ent_coeff         | 0.0314   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0687   |
|    n_updates         | 23520    |
| time/                |          |
|    iterations        | 297      |
|    fps               | 38.2     |
|    elapsed_time      | 3.18e+04 |
|    elapsed_steps     | 760320   |
-----------------------------------
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 760320/1000000 [8:50:10<2:54:10, 22.94steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 762880/1000000 [8:51:01<2:31:15, 26.13steps/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 762880/1000000 [8:51:20<2:31:15, 26.13steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765440/1000000 [8:52:12<2:17:27, 28.44steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 765440/1000000 [8:52:30<2:17:27, 28.44steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:53:25<2:08:15, 30.15steps/s]                                                                77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:53:25<2:08:15, 30.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.519    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.363    |
|    max_target_q      | -4.95    |
|    min_target_q      | -49      |
|    max_reward        | -0.263   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 9.95     |
|    q1_grad_norm      | 4.11     |
|    q2_grad_norm      | 4.19     |
|    actor_loss        | 26       |
|    ent_coeff         | 0.0312   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0696   |
|    n_updates         | 23760    |
| time/                |          |
|    iterations        | 300      |
|    fps               | 36.5     |
|    elapsed_time      | 3.2e+04  |
|    elapsed_steps     | 768000   |
-----------------------------------
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 768000/1000000 [8:53:40<2:08:15, 30.15steps/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770560/1000000 [8:54:45<2:04:27, 30.72steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_770560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 770560/1000000 [8:55:00<2:04:27, 30.72steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 773120/1000000 [9:00:12<3:51:16, 16.35steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:01:19<3:09:13, 19.76steps/s]                                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:01:19<3:09:13, 19.76steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -152     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -152     |
|    Success           | 0.0513   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.57     |
|    mean_entropy      | 11.7     |
|    mean_ent_bonus    | 0.364    |
|    max_target_q      | -5.19    |
|    min_target_q      | -49.3    |
|    max_reward        | -0.267   |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 11.6     |
|    q1_grad_norm      | 5.29     |
|    q2_grad_norm      | 5.43     |
|    actor_loss        | 26.1     |
|    ent_coeff         | 0.0311   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.069    |
|    n_updates         | 24000    |
| eval/                |          |
|    Length            | 192      |
|    Return            | -146     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -146     |
|    Success           | 0.111    |
|    SuccessLength     | 192      |
| time/                |          |
|    iterations        | 303      |
|    fps               | 16.2     |
|    elapsed_time      | 3.25e+04 |
|    elapsed_steps     | 775680   |
-----------------------------------
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775680/1000000 [9:01:30<3:09:13, 19.76steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778240/1000000 [9:02:24<2:39:16, 23.21steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 778240/1000000 [9:02:40<2:39:16, 23.21steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780800/1000000 [9:03:29<2:17:42, 26.53steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 780800/1000000 [9:03:40<2:17:42, 26.53steps/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:04:41<2:05:45, 28.71steps/s]                                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:04:41<2:05:45, 28.71steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -148     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -148     |
|    Success           | 0.0732   |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.562    |
|    mean_entropy      | 11.6     |
|    mean_ent_bonus    | 0.358    |
|    max_target_q      | -5.06    |
|    min_target_q      | -49.6    |
|    max_reward        | -0.27    |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 11.7     |
|    q1_grad_norm      | 5.36     |
|    q2_grad_norm      | 5.51     |
|    actor_loss        | 26.3     |
|    ent_coeff         | 0.0309   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0721   |
|    n_updates         | 24240    |
| time/                |          |
|    iterations        | 306      |
|    fps               | 38.1     |
|    elapsed_time      | 3.27e+04 |
|    elapsed_steps     | 783360   |
-----------------------------------
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 783360/1000000 [9:05:00<2:05:45, 28.71steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785920/1000000 [9:05:49<1:55:44, 30.83steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 785920/1000000 [9:06:00<1:55:44, 30.83steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788480/1000000 [9:07:04<1:50:55, 31.78steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_788480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 788480/1000000 [9:07:20<1:50:55, 31.78steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791040/1000000 [9:12:47<3:36:37, 16.08steps/s]                                                                79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 791040/1000000 [9:12:47<3:36:37, 16.08steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -149     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0526   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.544    |
|    mean_entropy      | 11.5     |
|    mean_ent_bonus    | 0.354    |
|    max_target_q      | -5.36    |
|    min_target_q      | -50.2    |
|    max_reward        | -0.274   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 10.8     |
|    q1_grad_norm      | 4.37     |
|    q2_grad_norm      | 4.48     |
|    actor_loss        | 26.4     |
|    ent_coeff         | 0.0308   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0709   |
|    n_updates         | 24480    |
| eval/                |          |
|    Length            | 192      |
|    Return            | -146     |
|    NonzeroRewards    | 192      |
|    DiscountedReturn  | -146     |
|    Success           | 0.111    |
|    SuccessLength     | 192      |
| time/                |          |
|    iterations        | 309      |
|    fps               | 15.8     |
|    elapsed_time      | 3.32e+04 |
|    elapsed_steps     | 791040   |
-----------------------------------
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793600/1000000 [9:13:52<2:56:04, 19.54steps/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 793600/1000000 [9:14:10<2:56:04, 19.54steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796160/1000000 [9:15:00<2:28:38, 22.86steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 796160/1000000 [9:15:10<2:28:38, 22.86steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:16:06<2:08:50, 26.04steps/s]                                                                80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:16:06<2:08:50, 26.04steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 195      |
|    Return            | -147     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0513   |
|    SuccessLength     | 195      |
| algo/                |          |
|    critic_loss       | 0.594    |
|    mean_entropy      | 11.4     |
|    mean_ent_bonus    | 0.349    |
|    max_target_q      | -5.28    |
|    min_target_q      | -50.8    |
|    max_reward        | -0.263   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 12.3     |
|    q1_grad_norm      | 5.52     |
|    q2_grad_norm      | 5.67     |
|    actor_loss        | 26.5     |
|    ent_coeff         | 0.0306   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0744   |
|    n_updates         | 24720    |
| time/                |          |
|    iterations        | 312      |
|    fps               | 38.5     |
|    elapsed_time      | 3.34e+04 |
|    elapsed_steps     | 798720   |
-----------------------------------
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 798720/1000000 [9:16:20<2:08:50, 26.04steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801280/1000000 [9:17:15<1:55:32, 28.67steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801280/1000000 [9:17:30<1:55:32, 28.67steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803840/1000000 [9:18:21<1:45:24, 31.01steps/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 803840/1000000 [9:18:40<1:45:24, 31.01steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:19:29<1:38:26, 32.78steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:19:40<1:38:26, 32.78steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_806400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 806400/1000000 [9:24:11<1:38:26, 32.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -150     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -150     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.587    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.345    |
|    max_target_q      | -5.49    |
|    min_target_q      | -51.2    |
|    max_reward        | -0.27    |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 10.9     |
|    q1_grad_norm      | 4.31     |
|    q2_grad_norm      | 4.4      |
|    actor_loss        | 26.6     |
|    ent_coeff         | 0.0305   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0727   |
|    n_updates         | 24960    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -156     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -156     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 315      |
|    fps               | 15.8     |
|    elapsed_time      | 3.39e+04 |
|    elapsed_steps     | 806400   |
-----------------------------------
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 808960/1000000 [9:25:19<3:18:23, 16.05steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811520/1000000 [9:26:23<2:40:51, 19.53steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 811520/1000000 [9:26:40<2:40:51, 19.53steps/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:27:31<2:15:45, 22.82steps/s]                                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:27:31<2:15:45, 22.82steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -151     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -151     |
|    Success           | 0.0263   |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.562    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.342    |
|    max_target_q      | -5.51    |
|    min_target_q      | -51.6    |
|    max_reward        | -0.27    |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 11.1     |
|    q1_grad_norm      | 5.18     |
|    q2_grad_norm      | 5.3      |
|    actor_loss        | 26.7     |
|    ent_coeff         | 0.0303   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0739   |
|    n_updates         | 25200    |
| time/                |          |
|    iterations        | 318      |
|    fps               | 38.3     |
|    elapsed_time      | 3.41e+04 |
|    elapsed_steps     | 814080   |
-----------------------------------
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 814080/1000000 [9:27:50<2:15:45, 22.82steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816640/1000000 [9:28:46<2:00:26, 25.37steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 816640/1000000 [9:29:00<2:00:26, 25.37steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819200/1000000 [9:29:55<1:47:24, 28.05steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 819200/1000000 [9:30:10<1:47:24, 28.05steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:31:01<1:37:17, 30.53steps/s]                                                                82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:31:01<1:37:17, 30.53steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 194      |
|    Return            | -142     |
|    NonzeroRewards    | 194      |
|    DiscountedReturn  | -142     |
|    Success           | 0.075    |
|    SuccessLength     | 194      |
| algo/                |          |
|    critic_loss       | 0.556    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.341    |
|    max_target_q      | -5.97    |
|    min_target_q      | -52.1    |
|    max_reward        | -0.28    |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 11.2     |
|    q1_grad_norm      | 5.01     |
|    q2_grad_norm      | 5.16     |
|    actor_loss        | 26.9     |
|    ent_coeff         | 0.0302   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0734   |
|    n_updates         | 25440    |
| time/                |          |
|    iterations        | 321      |
|    fps               | 36.6     |
|    elapsed_time      | 3.43e+04 |
|    elapsed_steps     | 821760   |
-----------------------------------
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 821760/1000000 [9:31:20<1:37:17, 30.53steps/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824320/1000000 [9:32:13<1:31:39, 31.94steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_824320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 824320/1000000 [9:32:30<1:31:39, 31.94steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 826880/1000000 [9:37:55<2:59:00, 16.12steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:39:03<2:25:57, 19.48steps/s]                                                                83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:39:03<2:25:57, 19.48steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -145     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -145     |
|    Success           | 0.0513   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.584    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.336    |
|    max_target_q      | -5.93    |
|    min_target_q      | -52.2    |
|    max_reward        | -0.276   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 11.6     |
|    q1_grad_norm      | 5.27     |
|    q2_grad_norm      | 5.36     |
|    actor_loss        | 27       |
|    ent_coeff         | 0.03     |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0749   |
|    n_updates         | 25680    |
| eval/                |          |
|    Length            | 195      |
|    Return            | -148     |
|    NonzeroRewards    | 195      |
|    DiscountedReturn  | -148     |
|    Success           | 0.111    |
|    SuccessLength     | 195      |
| time/                |          |
|    iterations        | 324      |
|    fps               | 16       |
|    elapsed_time      | 3.47e+04 |
|    elapsed_steps     | 829440   |
-----------------------------------
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 829440/1000000 [9:39:20<2:25:57, 19.48steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832000/1000000 [9:40:08<2:01:59, 22.95steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 832000/1000000 [9:40:20<2:01:59, 22.95steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834560/1000000 [9:41:14<1:45:24, 26.16steps/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 834560/1000000 [9:41:30<1:45:24, 26.16steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:42:20<1:33:51, 28.92steps/s]                                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:42:20<1:33:51, 28.92steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -147     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0513   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.567    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.331    |
|    max_target_q      | -6.02    |
|    min_target_q      | -52.9    |
|    max_reward        | -0.267   |
|    min_reward        | -1.34    |
|    encoder_grad_norm | 10.9     |
|    q1_grad_norm      | 4.39     |
|    q2_grad_norm      | 4.5      |
|    actor_loss        | 27.1     |
|    ent_coeff         | 0.0299   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0761   |
|    n_updates         | 25920    |
| time/                |          |
|    iterations        | 327      |
|    fps               | 38.8     |
|    elapsed_time      | 3.49e+04 |
|    elapsed_steps     | 837120   |
-----------------------------------
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 837120/1000000 [9:42:31<1:33:51, 28.92steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839680/1000000 [9:43:29<1:26:17, 30.97steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 839680/1000000 [9:43:41<1:26:17, 30.97steps/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842240/1000000 [9:44:47<1:23:28, 31.50steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 842240/1000000 [9:45:01<1:23:28, 31.50steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_842240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844800/1000000 [9:50:39<2:43:57, 15.78steps/s]                                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 844800/1000000 [9:50:39<2:43:57, 15.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -151     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -151     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.555    |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.33     |
|    max_target_q      | -5.9     |
|    min_target_q      | -52.9    |
|    max_reward        | -0.28    |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 11.4     |
|    q1_grad_norm      | 5.38     |
|    q2_grad_norm      | 5.5      |
|    actor_loss        | 27.3     |
|    ent_coeff         | 0.0297   |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0775   |
|    n_updates         | 26160    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -148     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -148     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 330      |
|    fps               | 15.4     |
|    elapsed_time      | 3.54e+04 |
|    elapsed_steps     | 844800   |
-----------------------------------
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847360/1000000 [9:51:44<2:12:27, 19.21steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 847360/1000000 [9:52:01<2:12:27, 19.21steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849920/1000000 [9:52:50<1:50:26, 22.65steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 849920/1000000 [9:53:01<1:50:26, 22.65steps/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [9:54:00<1:36:10, 25.56steps/s]                                                                85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [9:54:00<1:36:10, 25.56steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -148     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -148     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.526    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.317    |
|    max_target_q      | -6.13    |
|    min_target_q      | -53.4    |
|    max_reward        | -0.272   |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 11       |
|    q1_grad_norm      | 5.33     |
|    q2_grad_norm      | 5.45     |
|    actor_loss        | 27.4     |
|    ent_coeff         | 0.0296   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0803   |
|    n_updates         | 26400    |
| time/                |          |
|    iterations        | 333      |
|    fps               | 38.1     |
|    elapsed_time      | 3.56e+04 |
|    elapsed_steps     | 852480   |
-----------------------------------
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 852480/1000000 [9:54:11<1:36:10, 25.56steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855040/1000000 [9:55:10<1:25:59, 28.09steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 855040/1000000 [9:55:21<1:25:59, 28.09steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857600/1000000 [9:56:21<1:18:41, 30.16steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 857600/1000000 [9:56:41<1:18:41, 30.16steps/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [9:57:32<1:13:35, 31.67steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_860160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [9:57:51<1:13:35, 31.67steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 860160/1000000 [10:02:12<1:13:35, 31.67steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -146     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -146     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.591    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.319    |
|    max_target_q      | -6.35    |
|    min_target_q      | -53.7    |
|    max_reward        | -0.268   |
|    min_reward        | -1.31    |
|    encoder_grad_norm | 12.1     |
|    q1_grad_norm      | 5.8      |
|    q2_grad_norm      | 5.88     |
|    actor_loss        | 27.5     |
|    ent_coeff         | 0.0295   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0809   |
|    n_updates         | 26640    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -145     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -145     |
|    Success           | 0.0556   |
|    SuccessLength     | 196      |
| time/                |          |
|    iterations        | 336      |
|    fps               | 15.6     |
|    elapsed_time      | 3.61e+04 |
|    elapsed_steps     | 860160   |
-----------------------------------
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 862720/1000000 [10:03:20<2:23:46, 15.91steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865280/1000000 [10:04:24<1:55:37, 19.42steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 865280/1000000 [10:04:41<1:55:37, 19.42steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:05:29<1:36:19, 22.87steps/s]                                                                 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:05:29<1:36:19, 22.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -145     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -145     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.593    |
|    mean_entropy      | 10.7     |
|    mean_ent_bonus    | 0.313    |
|    max_target_q      | -6.76    |
|    min_target_q      | -53.9    |
|    max_reward        | -0.272   |
|    min_reward        | -1.31    |
|    encoder_grad_norm | 12.4     |
|    q1_grad_norm      | 5.53     |
|    q2_grad_norm      | 5.7      |
|    actor_loss        | 27.5     |
|    ent_coeff         | 0.0293   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0838   |
|    n_updates         | 26880    |
| time/                |          |
|    iterations        | 339      |
|    fps               | 39       |
|    elapsed_time      | 3.63e+04 |
|    elapsed_steps     | 867840   |
-----------------------------------
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 867840/1000000 [10:05:41<1:36:19, 22.87steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870400/1000000 [10:06:34<1:22:27, 26.19steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 870400/1000000 [10:06:51<1:22:27, 26.19steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872960/1000000 [10:07:39<1:12:49, 29.08steps/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 872960/1000000 [10:07:51<1:12:49, 29.08steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:08:44<1:05:47, 31.53steps/s]                                                                 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:08:44<1:05:47, 31.53steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -149     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -149     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.568    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.308    |
|    max_target_q      | -7.08    |
|    min_target_q      | -54.3    |
|    max_reward        | -0.288   |
|    min_reward        | -1.32    |
|    encoder_grad_norm | 11.8     |
|    q1_grad_norm      | 5.74     |
|    q2_grad_norm      | 5.85     |
|    actor_loss        | 27.6     |
|    ent_coeff         | 0.0292   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0855   |
|    n_updates         | 27120    |
| time/                |          |
|    iterations        | 342      |
|    fps               | 39.3     |
|    elapsed_time      | 3.65e+04 |
|    elapsed_steps     | 875520   |
-----------------------------------
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 875520/1000000 [10:09:01<1:05:47, 31.53steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878080/1000000 [10:10:01<1:03:16, 32.12steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 878080/1000000 [10:10:21<1:03:16, 32.12steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_878080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 880640/1000000 [10:15:54<2:05:45, 15.82steps/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:17:04<1:42:09, 19.06steps/s]                                                                 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:17:04<1:42:09, 19.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -147     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -147     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.576    |
|    mean_entropy      | 10.4     |
|    mean_ent_bonus    | 0.303    |
|    max_target_q      | -7.07    |
|    min_target_q      | -54.4    |
|    max_reward        | -0.274   |
|    min_reward        | -1.31    |
|    encoder_grad_norm | 11       |
|    q1_grad_norm      | 5.11     |
|    q2_grad_norm      | 5.25     |
|    actor_loss        | 27.6     |
|    ent_coeff         | 0.0291   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0898   |
|    n_updates         | 27360    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -145     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -145     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 345      |
|    fps               | 15.4     |
|    elapsed_time      | 3.7e+04  |
|    elapsed_steps     | 883200   |
-----------------------------------
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 883200/1000000 [10:17:21<1:42:09, 19.06steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885760/1000000 [10:18:09<1:24:27, 22.54steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 885760/1000000 [10:18:21<1:24:27, 22.54steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888320/1000000 [10:19:18<1:12:44, 25.59steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 888320/1000000 [10:19:31<1:12:44, 25.59steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:20:23<1:03:38, 28.58steps/s]                                                                 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:20:23<1:03:38, 28.58steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -149     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -149     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.54     |
|    mean_entropy      | 10.3     |
|    mean_ent_bonus    | 0.298    |
|    max_target_q      | -7.26    |
|    min_target_q      | -54.8    |
|    max_reward        | -0.282   |
|    min_reward        | -1.29    |
|    encoder_grad_norm | 10.9     |
|    q1_grad_norm      | 5.09     |
|    q2_grad_norm      | 5.23     |
|    actor_loss        | 27.6     |
|    ent_coeff         | 0.0289   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0937   |
|    n_updates         | 27600    |
| time/                |          |
|    iterations        | 348      |
|    fps               | 38.6     |
|    elapsed_time      | 3.72e+04 |
|    elapsed_steps     | 890880   |
-----------------------------------
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 890880/1000000 [10:20:41<1:03:38, 28.58steps/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893440/1000000 [10:21:29<57:08, 31.08steps/s]   89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 893440/1000000 [10:21:41<57:08, 31.08steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896000/1000000 [10:22:41<53:39, 32.31steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 896000/1000000 [10:22:51<53:39, 32.31steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_896000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898560/1000000 [10:28:29<1:45:40, 16.00steps/s]                                                                 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 898560/1000000 [10:28:29<1:45:40, 16.00steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -148     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -148     |
|    Success           | 0.027    |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.571    |
|    mean_entropy      | 10.2     |
|    mean_ent_bonus    | 0.293    |
|    max_target_q      | -7.42    |
|    min_target_q      | -55.4    |
|    max_reward        | -0.274   |
|    min_reward        | -1.31    |
|    encoder_grad_norm | 11.7     |
|    q1_grad_norm      | 5.35     |
|    q2_grad_norm      | 5.47     |
|    actor_loss        | 27.6     |
|    ent_coeff         | 0.0288   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0975   |
|    n_updates         | 27840    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -149     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -149     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 351      |
|    fps               | 15.8     |
|    elapsed_time      | 3.77e+04 |
|    elapsed_steps     | 898560   |
-----------------------------------
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901120/1000000 [10:29:38<1:25:26, 19.29steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 901120/1000000 [10:29:51<1:25:26, 19.29steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903680/1000000 [10:30:46<1:11:02, 22.60steps/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 903680/1000000 [10:31:01<1:11:02, 22.60steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:31:52<1:00:23, 25.88steps/s]                                                                 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:31:52<1:00:23, 25.88steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -148     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -148     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.539    |
|    mean_entropy      | 10.2     |
|    mean_ent_bonus    | 0.292    |
|    max_target_q      | -7.12    |
|    min_target_q      | -55.3    |
|    max_reward        | -0.284   |
|    min_reward        | -1.3     |
|    encoder_grad_norm | 11       |
|    q1_grad_norm      | 5.74     |
|    q2_grad_norm      | 5.88     |
|    actor_loss        | 27.6     |
|    ent_coeff         | 0.0286   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0951   |
|    n_updates         | 28080    |
| time/                |          |
|    iterations        | 354      |
|    fps               | 37.9     |
|    elapsed_time      | 3.79e+04 |
|    elapsed_steps     | 906240   |
-----------------------------------
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 906240/1000000 [10:32:11<1:00:23, 25.88steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908800/1000000 [10:32:57<52:41, 28.85steps/s]   91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 908800/1000000 [10:33:11<52:41, 28.85steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911360/1000000 [10:34:05<47:45, 30.93steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 911360/1000000 [10:34:21<47:45, 30.93steps/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:35:18<44:42, 32.09steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:35:31<44:42, 32.09steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_913920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 913920/1000000 [10:40:08<44:42, 32.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -147     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0256   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.561    |
|    mean_entropy      | 10.2     |
|    mean_ent_bonus    | 0.292    |
|    max_target_q      | -7.08    |
|    min_target_q      | -55.9    |
|    max_reward        | -0.274   |
|    min_reward        | -1.31    |
|    encoder_grad_norm | 11.5     |
|    q1_grad_norm      | 4.83     |
|    q2_grad_norm      | 4.96     |
|    actor_loss        | 27.6     |
|    ent_coeff         | 0.0285   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.095    |
|    n_updates         | 28320    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -152     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -152     |
|    Success           | 0.0556   |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 357      |
|    fps               | 15.5     |
|    elapsed_time      | 3.84e+04 |
|    elapsed_steps     | 913920   |
-----------------------------------
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 916480/1000000 [10:41:23<1:29:54, 15.48steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919040/1000000 [10:42:29<1:11:28, 18.88steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 919040/1000000 [10:42:41<1:11:28, 18.88steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:43:35<58:30, 22.34steps/s]                                                                 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:43:35<58:30, 22.34steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -149     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.521    |
|    mean_entropy      | 10.2     |
|    mean_ent_bonus    | 0.289    |
|    max_target_q      | -7.4     |
|    min_target_q      | -56.3    |
|    max_reward        | -0.281   |
|    min_reward        | -1.31    |
|    encoder_grad_norm | 10.1     |
|    q1_grad_norm      | 5.03     |
|    q2_grad_norm      | 5.12     |
|    actor_loss        | 27.7     |
|    ent_coeff         | 0.0284   |
|    ent_coeff_loss    | -107     |
|    pi_grad_norm      | 0.0956   |
|    n_updates         | 28560    |
| time/                |          |
|    iterations        | 360      |
|    fps               | 37.2     |
|    elapsed_time      | 3.86e+04 |
|    elapsed_steps     | 921600   |
-----------------------------------
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 921600/1000000 [10:43:51<58:30, 22.34steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924160/1000000 [10:44:44<49:51, 25.36steps/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 924160/1000000 [10:45:01<49:51, 25.36steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926720/1000000 [10:45:53<43:31, 28.06steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 926720/1000000 [10:46:11<43:31, 28.06steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:47:01<38:52, 30.32steps/s]                                                               93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:47:01<38:52, 30.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 200      |
|    Return            | -152     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -152     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| algo/                |          |
|    critic_loss       | 0.592    |
|    mean_entropy      | 10.3     |
|    mean_ent_bonus    | 0.291    |
|    max_target_q      | -7.26    |
|    min_target_q      | -56.7    |
|    max_reward        | -0.276   |
|    min_reward        | -1.3     |
|    encoder_grad_norm | 11.1     |
|    q1_grad_norm      | 4.08     |
|    q2_grad_norm      | 4.17     |
|    actor_loss        | 27.7     |
|    ent_coeff         | 0.0282   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.095    |
|    n_updates         | 28800    |
| time/                |          |
|    iterations        | 363      |
|    fps               | 37.2     |
|    elapsed_time      | 3.88e+04 |
|    elapsed_steps     | 929280   |
-----------------------------------
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 929280/1000000 [10:47:21<38:52, 30.32steps/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931840/1000000 [10:48:17<36:19, 31.28steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 931840/1000000 [10:48:31<36:19, 31.28steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_931840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 934400/1000000 [10:54:09<1:09:36, 15.71steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [10:55:15<54:53, 19.14steps/s]                                                                 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [10:55:15<54:53, 19.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -147     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0263   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.588    |
|    mean_entropy      | 10.4     |
|    mean_ent_bonus    | 0.292    |
|    max_target_q      | -6.52    |
|    min_target_q      | -57      |
|    max_reward        | -0.286   |
|    min_reward        | -1.31    |
|    encoder_grad_norm | 11.3     |
|    q1_grad_norm      | 5.11     |
|    q2_grad_norm      | 5.17     |
|    actor_loss        | 27.8     |
|    ent_coeff         | 0.0281   |
|    ent_coeff_loss    | -108     |
|    pi_grad_norm      | 0.0937   |
|    n_updates         | 29040    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -146     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -146     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 366      |
|    fps               | 15.6     |
|    elapsed_time      | 3.93e+04 |
|    elapsed_steps     | 936960   |
-----------------------------------
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 936960/1000000 [10:55:31<54:53, 19.14steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939520/1000000 [10:56:25<45:06, 22.35steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 939520/1000000 [10:56:41<45:06, 22.35steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942080/1000000 [10:57:30<37:36, 25.66steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 942080/1000000 [10:57:41<37:36, 25.66steps/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [10:58:38<32:30, 28.38steps/s]                                                               94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [10:58:38<32:30, 28.38steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -146     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0244   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.586    |
|    mean_entropy      | 10.6     |
|    mean_ent_bonus    | 0.296    |
|    max_target_q      | -6.99    |
|    min_target_q      | -57.6    |
|    max_reward        | -0.282   |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 11.7     |
|    q1_grad_norm      | 5.43     |
|    q2_grad_norm      | 5.57     |
|    actor_loss        | 27.9     |
|    ent_coeff         | 0.028    |
|    ent_coeff_loss    | -109     |
|    pi_grad_norm      | 0.0892   |
|    n_updates         | 29280    |
| time/                |          |
|    iterations        | 369      |
|    fps               | 37.9     |
|    elapsed_time      | 3.95e+04 |
|    elapsed_steps     | 944640   |
-----------------------------------
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 944640/1000000 [10:58:51<32:30, 28.38steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947200/1000000 [10:59:49<29:01, 30.31steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 947200/1000000 [11:00:01<29:01, 30.31steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949760/1000000 [11:00:59<26:15, 31.89steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 949760/1000000 [11:01:11<26:15, 31.89steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_949760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952320/1000000 [11:06:46<49:44, 15.97steps/s]                                                               95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 952320/1000000 [11:06:46<49:44, 15.97steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -140     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -140     |
|    Success           | 0.0526   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.577    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.3      |
|    max_target_q      | -7.12    |
|    min_target_q      | -57.7    |
|    max_reward        | -0.28    |
|    min_reward        | -1.29    |
|    encoder_grad_norm | 11.8     |
|    q1_grad_norm      | 5.01     |
|    q2_grad_norm      | 5.11     |
|    actor_loss        | 28.1     |
|    ent_coeff         | 0.0278   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.0843   |
|    n_updates         | 29520    |
| eval/                |          |
|    Length            | 199      |
|    Return            | -142     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -142     |
|    Success           | 0.0556   |
|    SuccessLength     | 199      |
| time/                |          |
|    iterations        | 372      |
|    fps               | 15.7     |
|    elapsed_time      | 4e+04    |
|    elapsed_steps     | 952320   |
-----------------------------------
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954880/1000000 [11:07:52<38:47, 19.39steps/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954880/1000000 [11:08:11<38:47, 19.39steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957440/1000000 [11:09:03<31:28, 22.54steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 957440/1000000 [11:09:21<31:28, 22.54steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:10:11<25:59, 25.65steps/s]                                                               96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:10:11<25:59, 25.65steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -143     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -143     |
|    Success           | 0.0513   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.577    |
|    mean_entropy      | 10.8     |
|    mean_ent_bonus    | 0.299    |
|    max_target_q      | -6.22    |
|    min_target_q      | -58.2    |
|    max_reward        | -0.271   |
|    min_reward        | -1.3     |
|    encoder_grad_norm | 11.7     |
|    q1_grad_norm      | 5.56     |
|    q2_grad_norm      | 5.72     |
|    actor_loss        | 28.1     |
|    ent_coeff         | 0.0277   |
|    ent_coeff_loss    | -110     |
|    pi_grad_norm      | 0.083    |
|    n_updates         | 29760    |
| time/                |          |
|    iterations        | 375      |
|    fps               | 37.6     |
|    elapsed_time      | 4.02e+04 |
|    elapsed_steps     | 960000   |
-----------------------------------
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 960000/1000000 [11:10:21<25:59, 25.65steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 962560/1000000 [11:11:19<22:04, 28.28steps/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 962560/1000000 [11:11:31<22:04, 28.28steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965120/1000000 [11:12:30<19:09, 30.33steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 965120/1000000 [11:12:41<19:09, 30.33steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:13:40<16:54, 31.87steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:13:51<16:54, 31.87steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_967680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 967680/1000000 [11:18:39<16:54, 31.87steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -142     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -142     |
|    Success           | 0.075    |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.577    |
|    mean_entropy      | 11       |
|    mean_ent_bonus    | 0.303    |
|    max_target_q      | -6.06    |
|    min_target_q      | -58.6    |
|    max_reward        | -0.285   |
|    min_reward        | -1.29    |
|    encoder_grad_norm | 11.8     |
|    q1_grad_norm      | 5.3      |
|    q2_grad_norm      | 5.42     |
|    actor_loss        | 28.3     |
|    ent_coeff         | 0.0276   |
|    ent_coeff_loss    | -111     |
|    pi_grad_norm      | 0.0807   |
|    n_updates         | 30000    |
| eval/                |          |
|    Length            | 190      |
|    Return            | -140     |
|    NonzeroRewards    | 190      |
|    DiscountedReturn  | -140     |
|    Success           | 0.111    |
|    SuccessLength     | 190      |
| time/                |          |
|    iterations        | 378      |
|    fps               | 15.1     |
|    elapsed_time      | 4.07e+04 |
|    elapsed_steps     | 967680   |
-----------------------------------
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 970240/1000000 [11:19:47<32:13, 15.39steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972800/1000000 [11:20:53<24:05, 18.82steps/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 972800/1000000 [11:21:11<24:05, 18.82steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:21:59<18:29, 22.22steps/s]                                                               98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:21:59<18:29, 22.22steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 198      |
|    Return            | -146     |
|    NonzeroRewards    | 198      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0256   |
|    SuccessLength     | 198      |
| algo/                |          |
|    critic_loss       | 0.61     |
|    mean_entropy      | 11.1     |
|    mean_ent_bonus    | 0.303    |
|    max_target_q      | -4.86    |
|    min_target_q      | -59      |
|    max_reward        | -0.277   |
|    min_reward        | -1.3     |
|    encoder_grad_norm | 12.8     |
|    q1_grad_norm      | 6.25     |
|    q2_grad_norm      | 6.42     |
|    actor_loss        | 28.5     |
|    ent_coeff         | 0.0274   |
|    ent_coeff_loss    | -112     |
|    pi_grad_norm      | 0.08     |
|    n_updates         | 30240    |
| time/                |          |
|    iterations        | 381      |
|    fps               | 38.3     |
|    elapsed_time      | 4.09e+04 |
|    elapsed_steps     | 975360   |
-----------------------------------
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 975360/1000000 [11:22:11<18:29, 22.22steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977920/1000000 [11:23:11<14:40, 25.07steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 977920/1000000 [11:23:31<14:40, 25.07steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980480/1000000 [11:24:20<11:43, 27.74steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 980480/1000000 [11:24:31<11:43, 27.74steps/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:25:28<09:22, 30.14steps/s]                                                               98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:25:28<09:22, 30.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 199      |
|    Return            | -149     |
|    NonzeroRewards    | 199      |
|    DiscountedReturn  | -149     |
|    Success           | 0.0263   |
|    SuccessLength     | 199      |
| algo/                |          |
|    critic_loss       | 0.594    |
|    mean_entropy      | 11.2     |
|    mean_ent_bonus    | 0.305    |
|    max_target_q      | -4.03    |
|    min_target_q      | -59.2    |
|    max_reward        | -0.28    |
|    min_reward        | -1.28    |
|    encoder_grad_norm | 12.4     |
|    q1_grad_norm      | 5.37     |
|    q2_grad_norm      | 5.47     |
|    actor_loss        | 28.6     |
|    ent_coeff         | 0.0273   |
|    ent_coeff_loss    | -112     |
|    pi_grad_norm      | 0.0795   |
|    n_updates         | 30480    |
| time/                |          |
|    iterations        | 384      |
|    fps               | 36.8     |
|    elapsed_time      | 4.11e+04 |
|    elapsed_steps     | 983040   |
-----------------------------------
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 983040/1000000 [11:25:41<09:22, 30.14steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985600/1000000 [11:26:38<07:32, 31.86steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 985600/1000000 [11:26:51<07:32, 31.86steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_985600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 988160/1000000 [11:32:26<12:23, 15.93steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:33:33<08:00, 19.30steps/s]                                                               99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:33:33<08:00, 19.30steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 197      |
|    Return            | -146     |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -146     |
|    Success           | 0.0541   |
|    SuccessLength     | 197      |
| algo/                |          |
|    critic_loss       | 0.567    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.307    |
|    max_target_q      | -4.65    |
|    min_target_q      | -59.4    |
|    max_reward        | -0.281   |
|    min_reward        | -1.3     |
|    encoder_grad_norm | 11.4     |
|    q1_grad_norm      | 4.54     |
|    q2_grad_norm      | 4.65     |
|    actor_loss        | 28.8     |
|    ent_coeff         | 0.0272   |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0774   |
|    n_updates         | 30720    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -154     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -154     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 387      |
|    fps               | 15.8     |
|    elapsed_time      | 4.16e+04 |
|    elapsed_steps     | 990720   |
-----------------------------------
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 990720/1000000 [11:33:51<08:00, 19.30steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993280/1000000 [11:34:43<04:58, 22.51steps/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 993280/1000000 [11:35:01<04:58, 22.51steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995840/1000000 [11:35:50<02:42, 25.61steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 995840/1000000 [11:36:01<02:42, 25.61steps/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:36:57<00:56, 28.43steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:37:11<00:56, 28.43steps/s]Saved video of policy to videos/2025-09-08/5ak0blzx/nominal/policy_step_998400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:41:31<00:56, 28.43steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 196      |
|    Return            | -147     |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0488   |
|    SuccessLength     | 196      |
| algo/                |          |
|    critic_loss       | 0.616    |
|    mean_entropy      | 11.3     |
|    mean_ent_bonus    | 0.306    |
|    max_target_q      | -3.74    |
|    min_target_q      | -59.8    |
|    max_reward        | -0.276   |
|    min_reward        | -1.27    |
|    encoder_grad_norm | 13.5     |
|    q1_grad_norm      | 6.51     |
|    q2_grad_norm      | 6.62     |
|    actor_loss        | 28.9     |
|    ent_coeff         | 0.027    |
|    ent_coeff_loss    | -113     |
|    pi_grad_norm      | 0.0742   |
|    n_updates         | 30960    |
| eval/                |          |
|    Length            | 200      |
|    Return            | -142     |
|    NonzeroRewards    | 200      |
|    DiscountedReturn  | -142     |
|    Success           | 0        |
|    SuccessLength     | 200      |
| time/                |          |
|    iterations        | 390      |
|    fps               | 16.1     |
|    elapsed_time      | 4.21e+04 |
|    elapsed_steps     | 998400   |
-----------------------------------
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 998400/1000000 [11:41:31<01:07, 23.72steps/s]
RLRunner: Finished training.
RLRunner: Log files saved to /home/exx/Michael/pprlPCA/wandb/run-20250908_150535-5ak0blzx/files
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: eval/along_view+50/success_rate â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         eval/fov30/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–
wandb:         eval/fov70/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–
wandb:       eval/nominal/success_rate â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–
wandb:    eval/roll+15deg/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    eval/roll+30deg/success_rate â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–
wandb:    eval/shift+x+50/success_rate â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–…â–â–â–â–â–
wandb:    eval/shift+y+50/success_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    eval/shift+z+50/success_rate â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–
wandb: 
wandb: Run summary:
wandb: eval/along_view+50/success_rate 0
wandb:         eval/fov30/success_rate 0
wandb:         eval/fov70/success_rate 0
wandb:       eval/nominal/success_rate 0
wandb:    eval/roll+15deg/success_rate 0
wandb:    eval/roll+30deg/success_rate 0
wandb:    eval/shift+x+50/success_rate 0
wandb:    eval/shift+y+50/success_rate 0
wandb:    eval/shift+z+50/success_rate 0
wandb: 
wandb: ðŸš€ View run desert-silence-988 at: https://wandb.ai/michael-bezick-purdue-university/pprl/runs/5ak0blzx
wandb: â­ï¸ View project at: https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: Synced 7 W&B file(s), 57 media file(s), 0 artifact file(s) and 42 other file(s)
wandb: Find logs at: ./wandb/run-20250908_150535-5ak0blzx/logs
