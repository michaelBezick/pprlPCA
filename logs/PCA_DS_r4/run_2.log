wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: michael-bezick (michael-bezick-purdue-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home/michaelbezick/Repos/pprlPCA/wandb/run-20250903_101920-clx77it2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-elevator-901
wandb: ‚≠êÔ∏è View project at https://wandb.ai/michael-bezick-purdue-university/pprl
wandb: üöÄ View run at https://wandb.ai/michael-bezick-purdue-university/pprl/runs/clx77it2
Group name is:  PCA_DS_r4
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
Instantiating 20 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
BasicSampler: Resetting all environments.
BasicSampler: Resetting agent.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
Instantiating 1 environments...
---------------------------------------
Checking SOFA_ROOT and SOFAPYTHON3_ROOT
Using environment variable SOFA_ROOT: /home/michaelbezick/sofa/build/install
---------------------------------------
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Iterative.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Projective.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SolidMechanics.Spring.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Correction.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Constant.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Grid.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.LinearSolver.Direct.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Algorithm.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.StateContainer.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Shader.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Topology.Container.Dynamic.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.IO.Mesh.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.AnimationLoop.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Forward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.NonLinear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.ODESolver.Backward.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mapping.Linear.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.SceneUtility.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Engine.Select.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Detection.Intersection.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.GL.Component.Rendering3D.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Setting.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Geometry.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Model.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Mass.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Visual.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Collision.Response.Contact.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/lib/libSofa.Component.Constraint.Lagrangian.Solver.so
[INFO]    [PluginManager] Loaded plugin: /home/michaelbezick/sofa/build/install/plugins/ArticulatedSystemPlugin/lib/libArticulatedSystemPlugin.so
[WARNING] [DirectionalLight(unnamed)] Could not read value for data field color: 1.3 1.3 1.3 
[WARNING] [InteractiveCamera(camera)] Too many missing parameters ; taking default ...
Environments instantiated.
SAC: Given sampler batch size 2560, training batch size 512, and replay ratio 32, there will be 160 updates per iteration.
SAC: Using learnable entropy coefficient with target entropy of -4
RLRunner: Starting training...
RLRunner: Saving log files to /home/michaelbezick/Repos/pprlPCA/wandb/run-20250903_101920-clx77it2/files
  0%|          | 0/1000000 [00:00<?, ?steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_0.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
wandb: WARNING Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                0%|          | 0/1000000 [03:59<?, ?steps/s]----------------------------------
| eval/               |          |
|    Length           | 500      |
|    Return           | -162     |
|    NonzeroRewards   | 500      |
|    DiscountedReturn | -162     |
|    Success          | 0        |
| time/               |          |
|    iterations       | 0        |
|    fps              | 0        |
|    elapsed_time     | 239      |
|    elapsed_steps    | 0        |
----------------------------------
For the first 10000 steps, agent will use a fixed std of 0.75 for exploration.
  0%|          | 2560/1000000 [04:05<26:34:21, 10.43steps/s]  1%|          | 5120/1000000 [04:11<11:16:53, 24.50steps/s]  1%|          | 7680/1000000 [04:17<6:23:59, 43.07steps/s]                                                              1%|          | 7680/1000000 [04:17<6:23:59, 43.07steps/s]-------------------------------
| time/            |          |
|    iterations    | 3        |
|    fps           | 434      |
|    elapsed_time  | 257      |
|    elapsed_steps | 7680     |
-------------------------------
  1%|          | 7680/1000000 [04:30<6:23:59, 43.07steps/s]  1%|          | 10240/1000000 [05:45<7:36:15, 36.16steps/s]  1%|          | 10240/1000000 [06:00<7:36:15, 36.16steps/s]  1%|‚ñè         | 12800/1000000 [07:13<8:15:46, 33.19steps/s]  1%|‚ñè         | 12800/1000000 [07:30<8:15:46, 33.19steps/s]  2%|‚ñè         | 15360/1000000 [08:43<8:41:02, 31.50steps/s]                                                              2%|‚ñè         | 15360/1000000 [08:43<8:41:02, 31.50steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 500      |
|    Return            | -169     |
|    NonzeroRewards    | 500      |
|    DiscountedReturn  | -169     |
|    Success           | 0        |
| algo/                |          |
|    critic_loss       | 0.00881  |
|    mean_entropy      | 2.72     |
|    mean_ent_bonus    | 0.531    |
|    max_target_q      | 0.536    |
|    min_target_q      | 0.0105   |
|    max_reward        | 0.0273   |
|    min_reward        | -0.821   |
|    encoder_grad_norm | 0.0922   |
|    q1_grad_norm      | 0.104    |
|    q2_grad_norm      | 0.115    |
|    actor_loss        | -0.902   |
|    ent_coeff         | 0.195    |
|    ent_coeff_loss    | -11      |
|    pi_grad_norm      | 0.146    |
|    n_updates         | 480      |
| time/                |          |
|    iterations        | 6        |
|    fps               | 28.9     |
|    elapsed_time      | 523      |
|    elapsed_steps     | 15360    |
-----------------------------------
  2%|‚ñè         | 15360/1000000 [09:00<8:41:02, 31.50steps/s]  2%|‚ñè         | 17920/1000000 [10:13<8:59:07, 30.36steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_17920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  2%|‚ñè         | 17920/1000000 [10:30<8:59:07, 30.36steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  2%|‚ñè         | 20480/1000000 [15:43<17:15:15, 15.77steps/s]  2%|‚ñè         | 23040/1000000 [17:12<14:47:50, 18.34steps/s]                                                               2%|‚ñè         | 23040/1000000 [17:12<14:47:50, 18.34steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 470      |
|    Return            | -145     |
|    NonzeroRewards    | 470      |
|    DiscountedReturn  | -145     |
|    Success           | 0.0952   |
| algo/                |          |
|    critic_loss       | 0.0207   |
|    mean_entropy      | 2.73     |
|    mean_ent_bonus    | 0.507    |
|    max_target_q      | 2        |
|    min_target_q      | -0.188   |
|    max_reward        | 0.731    |
|    min_reward        | -0.795   |
|    encoder_grad_norm | 0.266    |
|    q1_grad_norm      | 0.143    |
|    q2_grad_norm      | 0.141    |
|    actor_loss        | -1.31    |
|    ent_coeff         | 0.186    |
|    ent_coeff_loss    | -11.3    |
|    pi_grad_norm      | 0.0864   |
|    n_updates         | 960      |
| eval/                |          |
|    Length            | 481      |
|    Return            | -147     |
|    NonzeroRewards    | 481      |
|    DiscountedReturn  | -147     |
|    Success           | 0.0556   |
| time/                |          |
|    iterations        | 9        |
|    fps               | 15.1     |
|    elapsed_time      | 1.03e+03 |
|    elapsed_steps     | 23040    |
-----------------------------------
  2%|‚ñè         | 23040/1000000 [17:30<14:47:50, 18.34steps/s]  3%|‚ñé         | 25600/1000000 [18:42<13:08:53, 20.59steps/s]  3%|‚ñé         | 25600/1000000 [19:00<13:08:53, 20.59steps/s]  3%|‚ñé         | 28160/1000000 [20:12<12:00:02, 22.50steps/s]  3%|‚ñé         | 28160/1000000 [20:30<12:00:02, 22.50steps/s]  3%|‚ñé         | 30720/1000000 [21:43<11:14:15, 23.96steps/s]                                                               3%|‚ñé         | 30720/1000000 [21:43<11:14:15, 23.96steps/s]-----------------------------------
| algo/                |          |
|    critic_loss       | 0.024    |
|    mean_entropy      | 2.72     |
|    mean_ent_bonus    | 0.483    |
|    max_target_q      | 3.96     |
|    min_target_q      | -0.536   |
|    max_reward        | 0.765    |
|    min_reward        | -0.757   |
|    encoder_grad_norm | 0.494    |
|    q1_grad_norm      | 0.224    |
|    q2_grad_norm      | 0.226    |
|    actor_loss        | -1.56    |
|    ent_coeff         | 0.177    |
|    ent_coeff_loss    | -11.6    |
|    pi_grad_norm      | 0.0715   |
|    n_updates         | 1440     |
| rollout/             |          |
|    Length            | 500      |
|    Return            | -150     |
|    NonzeroRewards    | 500      |
|    DiscountedReturn  | -150     |
|    Success           | 0        |
| time/                |          |
|    iterations        | 12       |
|    fps               | 28.3     |
|    elapsed_time      | 1.3e+03  |
|    elapsed_steps     | 30720    |
-----------------------------------
  3%|‚ñé         | 30720/1000000 [22:00<11:14:15, 23.96steps/s]  3%|‚ñé         | 33280/1000000 [23:13<10:40:24, 25.16steps/s]  3%|‚ñé         | 33280/1000000 [23:30<10:40:24, 25.16steps/s]  4%|‚ñé         | 35840/1000000 [24:44<10:18:04, 26.00steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_35840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
  4%|‚ñé         | 35840/1000000 [25:00<10:18:04, 26.00steps/s]EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  4%|‚ñç         | 38400/1000000 [30:16<17:37:12, 15.16steps/s]                                                               4%|‚ñç         | 38400/1000000 [30:16<17:37:12, 15.16steps/s]-----------------------------------
| algo/                |          |
|    critic_loss       | 0.0279   |
|    mean_entropy      | 2.72     |
|    mean_ent_bonus    | 0.46     |
|    max_target_q      | 6        |
|    min_target_q      | -0.864   |
|    max_reward        | 0.829    |
|    min_reward        | -0.761   |
|    encoder_grad_norm | 0.567    |
|    q1_grad_norm      | 0.244    |
|    q2_grad_norm      | 0.248    |
|    actor_loss        | -1.66    |
|    ent_coeff         | 0.169    |
|    ent_coeff_loss    | -11.9    |
|    pi_grad_norm      | 0.0631   |
|    n_updates         | 1920     |
| rollout/             |          |
|    Length            | 374      |
|    Return            | -61.5    |
|    NonzeroRewards    | 374      |
|    DiscountedReturn  | -61.5    |
|    Success           | 0.5      |
| eval/                |          |
|    Length            | 500      |
|    Return            | -150     |
|    NonzeroRewards    | 500      |
|    DiscountedReturn  | -150     |
|    Success           | 0        |
| time/                |          |
|    iterations        | 15       |
|    fps               | 15       |
|    elapsed_time      | 1.82e+03 |
|    elapsed_steps     | 38400    |
-----------------------------------
  4%|‚ñç         | 40960/1000000 [31:47<15:08:48, 17.59steps/s]  4%|‚ñç         | 40960/1000000 [32:00<15:08:48, 17.59steps/s]  4%|‚ñç         | 43520/1000000 [33:18<13:23:13, 19.85steps/s]  4%|‚ñç         | 43520/1000000 [33:30<13:23:13, 19.85steps/s]  5%|‚ñç         | 46080/1000000 [34:49<12:10:44, 21.76steps/s]                                                               5%|‚ñç         | 46080/1000000 [34:49<12:10:44, 21.76steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 440      |
|    Return            | -110     |
|    NonzeroRewards    | 440      |
|    DiscountedReturn  | -110     |
|    Success           | 0.174    |
| algo/                |          |
|    critic_loss       | 0.05     |
|    mean_entropy      | 2.71     |
|    mean_ent_bonus    | 0.437    |
|    max_target_q      | 7        |
|    min_target_q      | -1.18    |
|    max_reward        | 1.53     |
|    min_reward        | -0.752   |
|    encoder_grad_norm | 0.899    |
|    q1_grad_norm      | 0.37     |
|    q2_grad_norm      | 0.376    |
|    actor_loss        | -1.67    |
|    ent_coeff         | 0.161    |
|    ent_coeff_loss    | -12.3    |
|    pi_grad_norm      | 0.0593   |
|    n_updates         | 2400     |
| time/                |          |
|    iterations        | 18       |
|    fps               | 28.1     |
|    elapsed_time      | 2.09e+03 |
|    elapsed_steps     | 46080    |
-----------------------------------
  5%|‚ñç         | 46080/1000000 [35:00<12:10:44, 21.76steps/s]  5%|‚ñç         | 48640/1000000 [36:20<11:18:42, 23.36steps/s]  5%|‚ñç         | 48640/1000000 [36:40<11:18:42, 23.36steps/s]  5%|‚ñå         | 51200/1000000 [37:51<10:43:01, 24.59steps/s]  5%|‚ñå         | 51200/1000000 [38:10<10:43:01, 24.59steps/s]  5%|‚ñå         | 53760/1000000 [39:22<10:17:20, 25.55steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_53760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  5%|‚ñå         | 53760/1000000 [39:40<10:17:20, 25.55steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               5%|‚ñå         | 53760/1000000 [43:25<10:17:20, 25.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 472      |
|    Return            | -117     |
|    NonzeroRewards    | 472      |
|    DiscountedReturn  | -117     |
|    Success           | 0.118    |
| algo/                |          |
|    critic_loss       | 0.0605   |
|    mean_entropy      | 2.71     |
|    mean_ent_bonus    | 0.416    |
|    max_target_q      | 7.72     |
|    min_target_q      | -1.47    |
|    max_reward        | 1.93     |
|    min_reward        | -0.757   |
|    encoder_grad_norm | 0.982    |
|    q1_grad_norm      | 0.349    |
|    q2_grad_norm      | 0.351    |
|    actor_loss        | -1.63    |
|    ent_coeff         | 0.154    |
|    ent_coeff_loss    | -12.6    |
|    pi_grad_norm      | 0.0556   |
|    n_updates         | 2880     |
| eval/                |          |
|    Length            | 500      |
|    Return            | -138     |
|    NonzeroRewards    | 500      |
|    DiscountedReturn  | -138     |
|    Success           | 0        |
| time/                |          |
|    iterations        | 21       |
|    fps               | 14.9     |
|    elapsed_time      | 2.61e+03 |
|    elapsed_steps     | 53760    |
-----------------------------------
  6%|‚ñå         | 56320/1000000 [44:55<17:24:46, 15.05steps/s]  6%|‚ñå         | 58880/1000000 [46:27<14:57:22, 17.48steps/s]  6%|‚ñå         | 58880/1000000 [46:40<14:57:22, 17.48steps/s]  6%|‚ñå         | 61440/1000000 [47:58<13:13:28, 19.71steps/s]                                                               6%|‚ñå         | 61440/1000000 [47:58<13:13:28, 19.71steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 471      |
|    Return            | -104     |
|    NonzeroRewards    | 471      |
|    DiscountedReturn  | -104     |
|    Success           | 0.143    |
| algo/                |          |
|    critic_loss       | 0.0804   |
|    mean_entropy      | 2.7      |
|    mean_ent_bonus    | 0.396    |
|    max_target_q      | 8.89     |
|    min_target_q      | -1.75    |
|    max_reward        | 2.44     |
|    min_reward        | -0.763   |
|    encoder_grad_norm | 1.23     |
|    q1_grad_norm      | 0.44     |
|    q2_grad_norm      | 0.441    |
|    actor_loss        | -1.53    |
|    ent_coeff         | 0.146    |
|    ent_coeff_loss    | -12.9    |
|    pi_grad_norm      | 0.0545   |
|    n_updates         | 3360     |
| time/                |          |
|    iterations        | 24       |
|    fps               | 28.1     |
|    elapsed_time      | 2.88e+03 |
|    elapsed_steps     | 61440    |
-----------------------------------
  6%|‚ñå         | 61440/1000000 [48:10<13:13:28, 19.71steps/s]  6%|‚ñã         | 64000/1000000 [49:29<12:00:21, 21.66steps/s]  6%|‚ñã         | 64000/1000000 [49:40<12:00:21, 21.66steps/s]  7%|‚ñã         | 66560/1000000 [51:00<11:08:25, 23.27steps/s]  7%|‚ñã         | 66560/1000000 [51:20<11:08:25, 23.27steps/s]  7%|‚ñã         | 69120/1000000 [52:30<10:31:20, 24.57steps/s]                                                               7%|‚ñã         | 69120/1000000 [52:30<10:31:20, 24.57steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 442      |
|    Return            | -88.8    |
|    NonzeroRewards    | 442      |
|    DiscountedReturn  | -88.8    |
|    Success           | 0.375    |
| algo/                |          |
|    critic_loss       | 0.089    |
|    mean_entropy      | 2.7      |
|    mean_ent_bonus    | 0.377    |
|    max_target_q      | 8.73     |
|    min_target_q      | -1.98    |
|    max_reward        | 2.62     |
|    min_reward        | -0.751   |
|    encoder_grad_norm | 1.32     |
|    q1_grad_norm      | 0.44     |
|    q2_grad_norm      | 0.44     |
|    actor_loss        | -1.4     |
|    ent_coeff         | 0.14     |
|    ent_coeff_loss    | -13.2    |
|    pi_grad_norm      | 0.0496   |
|    n_updates         | 3840     |
| time/                |          |
|    iterations        | 27       |
|    fps               | 28.2     |
|    elapsed_time      | 3.15e+03 |
|    elapsed_steps     | 69120    |
-----------------------------------
  7%|‚ñã         | 69120/1000000 [52:50<10:31:20, 24.57steps/s]  7%|‚ñã         | 71680/1000000 [54:02<10:07:00, 25.49steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_71680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  7%|‚ñã         | 71680/1000000 [54:20<10:07:00, 25.49steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  7%|‚ñã         | 74240/1000000 [59:36<17:07:45, 15.01steps/s]  8%|‚ñä         | 76800/1000000 [1:01:08<14:42:45, 17.43steps/s]                                                                 8%|‚ñä         | 76800/1000000 [1:01:08<14:42:45, 17.43steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 454      |
|    Return            | -107     |
|    NonzeroRewards    | 454      |
|    DiscountedReturn  | -107     |
|    Success           | 0.19     |
| algo/                |          |
|    critic_loss       | 0.094    |
|    mean_entropy      | 2.69     |
|    mean_ent_bonus    | 0.358    |
|    max_target_q      | 9.35     |
|    min_target_q      | -2.11    |
|    max_reward        | 2.61     |
|    min_reward        | -0.755   |
|    encoder_grad_norm | 1.45     |
|    q1_grad_norm      | 0.441    |
|    q2_grad_norm      | 0.44     |
|    actor_loss        | -1.25    |
|    ent_coeff         | 0.133    |
|    ent_coeff_loss    | -13.5    |
|    pi_grad_norm      | 0.0487   |
|    n_updates         | 4320     |
| eval/                |          |
|    Length            | 500      |
|    Return            | -140     |
|    NonzeroRewards    | 500      |
|    DiscountedReturn  | -140     |
|    Success           | 0        |
| time/                |          |
|    iterations        | 30       |
|    fps               | 14.8     |
|    elapsed_time      | 3.67e+03 |
|    elapsed_steps     | 76800    |
-----------------------------------
  8%|‚ñä         | 76800/1000000 [1:01:20<14:42:45, 17.43steps/s]  8%|‚ñä         | 79360/1000000 [1:02:39<13:00:45, 19.65steps/s]  8%|‚ñä         | 79360/1000000 [1:02:50<13:00:45, 19.65steps/s]  8%|‚ñä         | 81920/1000000 [1:04:11<11:48:30, 21.60steps/s]  8%|‚ñä         | 81920/1000000 [1:04:30<11:48:30, 21.60steps/s]  8%|‚ñä         | 84480/1000000 [1:05:42<10:58:12, 23.18steps/s]                                                                 8%|‚ñä         | 84480/1000000 [1:05:42<10:58:12, 23.18steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 480      |
|    Return            | -101     |
|    NonzeroRewards    | 480      |
|    DiscountedReturn  | -101     |
|    Success           | 0.111    |
| algo/                |          |
|    critic_loss       | 0.111    |
|    mean_entropy      | 2.68     |
|    mean_ent_bonus    | 0.34     |
|    max_target_q      | 9.55     |
|    min_target_q      | -2.27    |
|    max_reward        | 3.1      |
|    min_reward        | -0.755   |
|    encoder_grad_norm | 1.56     |
|    q1_grad_norm      | 0.456    |
|    q2_grad_norm      | 0.452    |
|    actor_loss        | -1.12    |
|    ent_coeff         | 0.127    |
|    ent_coeff_loss    | -13.8    |
|    pi_grad_norm      | 0.0467   |
|    n_updates         | 4800     |
| time/                |          |
|    iterations        | 33       |
|    fps               | 28       |
|    elapsed_time      | 3.94e+03 |
|    elapsed_steps     | 84480    |
-----------------------------------
  8%|‚ñä         | 84480/1000000 [1:06:00<10:58:12, 23.18steps/s]  9%|‚ñä         | 87040/1000000 [1:07:14<10:22:57, 24.43steps/s]  9%|‚ñä         | 87040/1000000 [1:07:30<10:22:57, 24.43steps/s]  9%|‚ñâ         | 89600/1000000 [1:08:46<9:58:26, 25.36steps/s] RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
  9%|‚ñâ         | 89600/1000000 [1:09:00<9:58:26, 25.36steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_89600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
  9%|‚ñâ         | 92160/1000000 [1:14:22<16:54:36, 14.91steps/s]                                                                 9%|‚ñâ         | 92160/1000000 [1:14:22<16:54:36, 14.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 465      |
|    Return            | -97.7    |
|    NonzeroRewards    | 465      |
|    DiscountedReturn  | -97.7    |
|    Success           | 0.188    |
| algo/                |          |
|    critic_loss       | 0.117    |
|    mean_entropy      | 2.68     |
|    mean_ent_bonus    | 0.324    |
|    max_target_q      | 10.2     |
|    min_target_q      | -2.42    |
|    max_reward        | 3.22     |
|    min_reward        | -0.769   |
|    encoder_grad_norm | 1.65     |
|    q1_grad_norm      | 0.485    |
|    q2_grad_norm      | 0.48     |
|    actor_loss        | -1.03    |
|    ent_coeff         | 0.121    |
|    ent_coeff_loss    | -14.1    |
|    pi_grad_norm      | 0.048    |
|    n_updates         | 5280     |
| eval/                |          |
|    Length            | 486      |
|    Return            | -118     |
|    NonzeroRewards    | 486      |
|    DiscountedReturn  | -118     |
|    Success           | 0.0556   |
| time/                |          |
|    iterations        | 36       |
|    fps               | 14.8     |
|    elapsed_time      | 4.46e+03 |
|    elapsed_steps     | 92160    |
-----------------------------------
  9%|‚ñâ         | 94720/1000000 [1:15:55<14:32:04, 17.30steps/s]  9%|‚ñâ         | 94720/1000000 [1:16:10<14:32:04, 17.30steps/s] 10%|‚ñâ         | 97280/1000000 [1:17:27<12:50:21, 19.53steps/s] 10%|‚ñâ         | 97280/1000000 [1:17:40<12:50:21, 19.53steps/s] 10%|‚ñâ         | 99840/1000000 [1:18:59<11:39:32, 21.45steps/s]                                                                10%|‚ñâ         | 99840/1000000 [1:18:59<11:39:32, 21.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 433      |
|    Return            | -88.4    |
|    NonzeroRewards    | 433      |
|    DiscountedReturn  | -88.4    |
|    Success           | 0.4      |
| algo/                |          |
|    critic_loss       | 0.108    |
|    mean_entropy      | 2.67     |
|    mean_ent_bonus    | 0.308    |
|    max_target_q      | 9.79     |
|    min_target_q      | -2.56    |
|    max_reward        | 4.03     |
|    min_reward        | -0.752   |
|    encoder_grad_norm | 1.31     |
|    q1_grad_norm      | 0.386    |
|    q2_grad_norm      | 0.381    |
|    actor_loss        | -0.9     |
|    ent_coeff         | 0.115    |
|    ent_coeff_loss    | -14.4    |
|    pi_grad_norm      | 0.0464   |
|    n_updates         | 5760     |
| time/                |          |
|    iterations        | 39       |
|    fps               | 27.8     |
|    elapsed_time      | 4.74e+03 |
|    elapsed_steps     | 99840    |
-----------------------------------
 10%|‚ñâ         | 99840/1000000 [1:19:10<11:39:32, 21.45steps/s] 10%|‚ñà         | 102400/1000000 [1:20:31<10:49:39, 23.03steps/s] 10%|‚ñà         | 102400/1000000 [1:20:50<10:49:39, 23.03steps/s] 10%|‚ñà         | 104960/1000000 [1:22:03<10:14:07, 24.29steps/s] 10%|‚ñà         | 104960/1000000 [1:22:20<10:14:07, 24.29steps/s] 11%|‚ñà         | 107520/1000000 [1:23:35<9:50:09, 25.20steps/s] RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 11%|‚ñà         | 107520/1000000 [1:23:50<9:50:09, 25.20steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_107520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                11%|‚ñà         | 107520/1000000 [1:27:43<9:50:09, 25.20steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 478      |
|    Return            | -89.9    |
|    NonzeroRewards    | 478      |
|    DiscountedReturn  | -89.9    |
|    Success           | 0.118    |
| algo/                |          |
|    critic_loss       | 0.129    |
|    mean_entropy      | 2.66     |
|    mean_ent_bonus    | 0.292    |
|    max_target_q      | 10.2     |
|    min_target_q      | -2.69    |
|    max_reward        | 3.78     |
|    min_reward        | -0.761   |
|    encoder_grad_norm | 1.95     |
|    q1_grad_norm      | 0.533    |
|    q2_grad_norm      | 0.527    |
|    actor_loss        | -0.755   |
|    ent_coeff         | 0.11     |
|    ent_coeff_loss    | -14.7    |
|    pi_grad_norm      | 0.0494   |
|    n_updates         | 6240     |
| eval/                |          |
|    Length            | 467      |
|    Return            | -143     |
|    NonzeroRewards    | 467      |
|    DiscountedReturn  | -143     |
|    Success           | 0.105    |
| time/                |          |
|    iterations        | 42       |
|    fps               | 14.7     |
|    elapsed_time      | 5.26e+03 |
|    elapsed_steps     | 107520   |
-----------------------------------
 11%|‚ñà         | 110080/1000000 [1:29:15<16:42:00, 14.80steps/s] 11%|‚ñà‚ñè        | 112640/1000000 [1:30:46<14:18:10, 17.23steps/s] 11%|‚ñà‚ñè        | 112640/1000000 [1:31:00<14:18:10, 17.23steps/s] 12%|‚ñà‚ñè        | 115200/1000000 [1:32:19<12:38:08, 19.45steps/s]                                                                 12%|‚ñà‚ñè        | 115200/1000000 [1:32:19<12:38:08, 19.45steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 420      |
|    Return            | -83.9    |
|    NonzeroRewards    | 420      |
|    DiscountedReturn  | -83.9    |
|    Success           | 0.333    |
| algo/                |          |
|    critic_loss       | 0.135    |
|    mean_entropy      | 2.65     |
|    mean_ent_bonus    | 0.278    |
|    max_target_q      | 10.1     |
|    min_target_q      | -2.89    |
|    max_reward        | 3.97     |
|    min_reward        | -0.751   |
|    encoder_grad_norm | 1.8      |
|    q1_grad_norm      | 0.498    |
|    q2_grad_norm      | 0.492    |
|    actor_loss        | -0.621   |
|    ent_coeff         | 0.105    |
|    ent_coeff_loss    | -15      |
|    pi_grad_norm      | 0.0513   |
|    n_updates         | 6720     |
| time/                |          |
|    iterations        | 45       |
|    fps               | 27.8     |
|    elapsed_time      | 5.54e+03 |
|    elapsed_steps     | 115200   |
-----------------------------------
 12%|‚ñà‚ñè        | 115200/1000000 [1:32:30<12:38:08, 19.45steps/s] 12%|‚ñà‚ñè        | 117760/1000000 [1:33:51<11:27:55, 21.37steps/s] 12%|‚ñà‚ñè        | 117760/1000000 [1:34:10<11:27:55, 21.37steps/s] 12%|‚ñà‚ñè        | 120320/1000000 [1:35:23<10:38:23, 22.97steps/s] 12%|‚ñà‚ñè        | 120320/1000000 [1:35:40<10:38:23, 22.97steps/s] 12%|‚ñà‚ñè        | 122880/1000000 [1:36:55<10:04:10, 24.20steps/s]                                                                 12%|‚ñà‚ñè        | 122880/1000000 [1:36:55<10:04:10, 24.20steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 382      |
|    Return            | -75.8    |
|    NonzeroRewards    | 382      |
|    DiscountedReturn  | -75.8    |
|    Success           | 0.526    |
| algo/                |          |
|    critic_loss       | 0.151    |
|    mean_entropy      | 2.64     |
|    mean_ent_bonus    | 0.263    |
|    max_target_q      | 9.75     |
|    min_target_q      | -3       |
|    max_reward        | 4.49     |
|    min_reward        | -0.753   |
|    encoder_grad_norm | 1.96     |
|    q1_grad_norm      | 0.51     |
|    q2_grad_norm      | 0.504    |
|    actor_loss        | -0.505   |
|    ent_coeff         | 0.0998   |
|    ent_coeff_loss    | -15.3    |
|    pi_grad_norm      | 0.0558   |
|    n_updates         | 7200     |
| time/                |          |
|    iterations        | 48       |
|    fps               | 27.7     |
|    elapsed_time      | 5.82e+03 |
|    elapsed_steps     | 122880   |
-----------------------------------
 12%|‚ñà‚ñè        | 122880/1000000 [1:37:10<10:04:10, 24.20steps/s] 13%|‚ñà‚ñé        | 125440/1000000 [1:38:28<9:40:07, 25.13steps/s] RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 13%|‚ñà‚ñé        | 125440/1000000 [1:38:40<9:40:07, 25.13steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_125440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 13%|‚ñà‚ñé        | 128000/1000000 [1:44:10<16:27:21, 14.72steps/s] 13%|‚ñà‚ñé        | 130560/1000000 [1:45:42<14:05:00, 17.15steps/s]                                                                 13%|‚ñà‚ñé        | 130560/1000000 [1:45:42<14:05:00, 17.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 346      |
|    Return            | -59.3    |
|    NonzeroRewards    | 346      |
|    DiscountedReturn  | -59.3    |
|    Success           | 0.5      |
| algo/                |          |
|    critic_loss       | 0.16     |
|    mean_entropy      | 2.62     |
|    mean_ent_bonus    | 0.249    |
|    max_target_q      | 9.59     |
|    min_target_q      | -3.1     |
|    max_reward        | 4.74     |
|    min_reward        | -0.743   |
|    encoder_grad_norm | 2.07     |
|    q1_grad_norm      | 0.553    |
|    q2_grad_norm      | 0.55     |
|    actor_loss        | -0.403   |
|    ent_coeff         | 0.0952   |
|    ent_coeff_loss    | -15.6    |
|    pi_grad_norm      | 0.0569   |
|    n_updates         | 7680     |
| eval/                |          |
|    Length            | 476      |
|    Return            | -134     |
|    NonzeroRewards    | 476      |
|    DiscountedReturn  | -134     |
|    Success           | 0.167    |
| time/                |          |
|    iterations        | 51       |
|    fps               | 14.6     |
|    elapsed_time      | 6.34e+03 |
|    elapsed_steps     | 130560   |
-----------------------------------
 13%|‚ñà‚ñé        | 130560/1000000 [1:46:00<14:05:00, 17.15steps/s] 13%|‚ñà‚ñé        | 133120/1000000 [1:47:14<12:25:37, 19.38steps/s] 13%|‚ñà‚ñé        | 133120/1000000 [1:47:30<12:25:37, 19.38steps/s] 14%|‚ñà‚ñé        | 135680/1000000 [1:48:46<11:16:02, 21.31steps/s] 14%|‚ñà‚ñé        | 135680/1000000 [1:49:00<11:16:02, 21.31steps/s] 14%|‚ñà‚ñç        | 138240/1000000 [1:50:18<10:26:53, 22.91steps/s]                                                                 14%|‚ñà‚ñç        | 138240/1000000 [1:50:18<10:26:53, 22.91steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 268      |
|    Return            | -33.7    |
|    NonzeroRewards    | 268      |
|    DiscountedReturn  | -33.7    |
|    Success           | 0.765    |
| algo/                |          |
|    critic_loss       | 0.189    |
|    mean_entropy      | 2.59     |
|    mean_ent_bonus    | 0.235    |
|    max_target_q      | 10.1     |
|    min_target_q      | -3.2     |
|    max_reward        | 5.85     |
|    min_reward        | -0.752   |
|    encoder_grad_norm | 2.18     |
|    q1_grad_norm      | 0.589    |
|    q2_grad_norm      | 0.582    |
|    actor_loss        | -0.332   |
|    ent_coeff         | 0.0907   |
|    ent_coeff_loss    | -15.8    |
|    pi_grad_norm      | 0.0613   |
|    n_updates         | 8160     |
| time/                |          |
|    iterations        | 54       |
|    fps               | 27.8     |
|    elapsed_time      | 6.62e+03 |
|    elapsed_steps     | 138240   |
-----------------------------------
 14%|‚ñà‚ñç        | 138240/1000000 [1:50:30<10:26:53, 22.91steps/s] 14%|‚ñà‚ñç        | 140800/1000000 [1:51:51<9:52:25, 24.17steps/s]  14%|‚ñà‚ñç        | 140800/1000000 [1:52:10<9:52:25, 24.17steps/s] 14%|‚ñà‚ñç        | 143360/1000000 [1:53:23<9:27:34, 25.16steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_143360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 14%|‚ñà‚ñç        | 143360/1000000 [1:53:40<9:27:34, 25.16steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 15%|‚ñà‚ñç        | 145920/1000000 [1:59:05<16:07:12, 14.72steps/s]                                                                 15%|‚ñà‚ñç        | 145920/1000000 [1:59:05<16:07:12, 14.72steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 291      |
|    Return            | -30.5    |
|    NonzeroRewards    | 291      |
|    DiscountedReturn  | -30.5    |
|    Success           | 0.682    |
| algo/                |          |
|    critic_loss       | 0.226    |
|    mean_entropy      | 2.56     |
|    mean_ent_bonus    | 0.221    |
|    max_target_q      | 9.88     |
|    min_target_q      | -3.34    |
|    max_reward        | 6.29     |
|    min_reward        | -0.781   |
|    encoder_grad_norm | 2.51     |
|    q1_grad_norm      | 0.652    |
|    q2_grad_norm      | 0.645    |
|    actor_loss        | -0.272   |
|    ent_coeff         | 0.0865   |
|    ent_coeff_loss    | -16.1    |
|    pi_grad_norm      | 0.069    |
|    n_updates         | 8640     |
| eval/                |          |
|    Length            | 463      |
|    Return            | -130     |
|    NonzeroRewards    | 463      |
|    DiscountedReturn  | -130     |
|    Success           | 0.111    |
| time/                |          |
|    iterations        | 57       |
|    fps               | 14.6     |
|    elapsed_time      | 7.15e+03 |
|    elapsed_steps     | 145920   |
-----------------------------------
 15%|‚ñà‚ñç        | 148480/1000000 [2:00:37<13:47:52, 17.14steps/s] 15%|‚ñà‚ñç        | 148480/1000000 [2:00:50<13:47:52, 17.14steps/s] 15%|‚ñà‚ñå        | 151040/1000000 [2:02:08<12:09:08, 19.41steps/s] 15%|‚ñà‚ñå        | 151040/1000000 [2:02:20<12:09:08, 19.41steps/s] 15%|‚ñà‚ñå        | 153600/1000000 [2:03:39<10:59:35, 21.39steps/s]                                                                 15%|‚ñà‚ñå        | 153600/1000000 [2:03:39<10:59:35, 21.39steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 385      |
|    Return            | -58.4    |
|    NonzeroRewards    | 385      |
|    DiscountedReturn  | -58.4    |
|    Success           | 0.471    |
| algo/                |          |
|    critic_loss       | 0.234    |
|    mean_entropy      | 2.52     |
|    mean_ent_bonus    | 0.208    |
|    max_target_q      | 10.4     |
|    min_target_q      | -3.41    |
|    max_reward        | 6.75     |
|    min_reward        | -0.757   |
|    encoder_grad_norm | 2.57     |
|    q1_grad_norm      | 0.692    |
|    q2_grad_norm      | 0.688    |
|    actor_loss        | -0.204   |
|    ent_coeff         | 0.0825   |
|    ent_coeff_loss    | -16.3    |
|    pi_grad_norm      | 0.0719   |
|    n_updates         | 9120     |
| time/                |          |
|    iterations        | 60       |
|    fps               | 28       |
|    elapsed_time      | 7.42e+03 |
|    elapsed_steps     | 153600   |
-----------------------------------
 15%|‚ñà‚ñå        | 153600/1000000 [2:03:50<10:59:35, 21.39steps/s] 16%|‚ñà‚ñå        | 156160/1000000 [2:05:12<10:12:13, 22.97steps/s] 16%|‚ñà‚ñå        | 156160/1000000 [2:05:30<10:12:13, 22.97steps/s] 16%|‚ñà‚ñå        | 158720/1000000 [2:06:44<9:38:25, 24.24steps/s]  16%|‚ñà‚ñå        | 158720/1000000 [2:07:00<9:38:25, 24.24steps/s] 16%|‚ñà‚ñå        | 161280/1000000 [2:08:16<9:15:02, 25.18steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 16%|‚ñà‚ñå        | 161280/1000000 [2:08:30<9:15:02, 25.18steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_161280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                16%|‚ñà‚ñå        | 161280/1000000 [2:12:28<9:15:02, 25.18steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 345      |
|    Return            | -44.2    |
|    NonzeroRewards    | 345      |
|    DiscountedReturn  | -44.2    |
|    Success           | 0.5      |
| algo/                |          |
|    critic_loss       | 0.269    |
|    mean_entropy      | 2.49     |
|    mean_ent_bonus    | 0.196    |
|    max_target_q      | 11.4     |
|    min_target_q      | -3.49    |
|    max_reward        | 6.55     |
|    min_reward        | -0.765   |
|    encoder_grad_norm | 3.15     |
|    q1_grad_norm      | 0.747    |
|    q2_grad_norm      | 0.749    |
|    actor_loss        | -0.159   |
|    ent_coeff         | 0.0786   |
|    ent_coeff_loss    | -16.5    |
|    pi_grad_norm      | 0.0765   |
|    n_updates         | 9600     |
| eval/                |          |
|    Length            | 457      |
|    Return            | -145     |
|    NonzeroRewards    | 457      |
|    DiscountedReturn  | -145     |
|    Success           | 0.105    |
| time/                |          |
|    iterations        | 63       |
|    fps               | 14.5     |
|    elapsed_time      | 7.95e+03 |
|    elapsed_steps     | 161280   |
-----------------------------------
 16%|‚ñà‚ñã        | 163840/1000000 [2:14:00<15:48:24, 14.69steps/s] 17%|‚ñà‚ñã        | 166400/1000000 [2:15:32<13:32:26, 17.10steps/s] 17%|‚ñà‚ñã        | 166400/1000000 [2:15:50<13:32:26, 17.10steps/s] 17%|‚ñà‚ñã        | 168960/1000000 [2:17:04<11:56:32, 19.33steps/s]                                                                 17%|‚ñà‚ñã        | 168960/1000000 [2:17:04<11:56:32, 19.33steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 268      |
|    Return            | -35.5    |
|    NonzeroRewards    | 268      |
|    DiscountedReturn  | -35.5    |
|    Success           | 0.733    |
| algo/                |          |
|    critic_loss       | 0.294    |
|    mean_entropy      | 2.45     |
|    mean_ent_bonus    | 0.184    |
|    max_target_q      | 12.3     |
|    min_target_q      | -3.61    |
|    max_reward        | 7.13     |
|    min_reward        | -0.768   |
|    encoder_grad_norm | 3.42     |
|    q1_grad_norm      | 0.805    |
|    q2_grad_norm      | 0.799    |
|    actor_loss        | -0.0918  |
|    ent_coeff         | 0.075    |
|    ent_coeff_loss    | -16.7    |
|    pi_grad_norm      | 0.0883   |
|    n_updates         | 10080    |
| time/                |          |
|    iterations        | 66       |
|    fps               | 27.8     |
|    elapsed_time      | 8.22e+03 |
|    elapsed_steps     | 168960   |
-----------------------------------
 17%|‚ñà‚ñã        | 168960/1000000 [2:17:20<11:56:32, 19.33steps/s] 17%|‚ñà‚ñã        | 171520/1000000 [2:18:37<10:50:02, 21.24steps/s] 17%|‚ñà‚ñã        | 171520/1000000 [2:18:50<10:50:02, 21.24steps/s] 17%|‚ñà‚ñã        | 174080/1000000 [2:20:09<10:01:54, 22.87steps/s] 17%|‚ñà‚ñã        | 174080/1000000 [2:20:20<10:01:54, 22.87steps/s] 18%|‚ñà‚ñä        | 176640/1000000 [2:21:41<9:28:03, 24.16steps/s]                                                                 18%|‚ñà‚ñä        | 176640/1000000 [2:21:41<9:28:03, 24.16steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 284      |
|    Return            | -39.1    |
|    NonzeroRewards    | 284      |
|    DiscountedReturn  | -39.1    |
|    Success           | 0.7      |
| algo/                |          |
|    critic_loss       | 0.32     |
|    mean_entropy      | 2.39     |
|    mean_ent_bonus    | 0.171    |
|    max_target_q      | 11.6     |
|    min_target_q      | -3.69    |
|    max_reward        | 7.78     |
|    min_reward        | -0.776   |
|    encoder_grad_norm | 3.45     |
|    q1_grad_norm      | 0.846    |
|    q2_grad_norm      | 0.848    |
|    actor_loss        | -0.0466  |
|    ent_coeff         | 0.0715   |
|    ent_coeff_loss    | -16.9    |
|    pi_grad_norm      | 0.0894   |
|    n_updates         | 10560    |
| time/                |          |
|    iterations        | 69       |
|    fps               | 27.8     |
|    elapsed_time      | 8.5e+03  |
|    elapsed_steps     | 176640   |
-----------------------------------
 18%|‚ñà‚ñä        | 176640/1000000 [2:22:00<9:28:03, 24.16steps/s] 18%|‚ñà‚ñä        | 179200/1000000 [2:23:13<9:04:15, 25.14steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_179200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 18%|‚ñà‚ñä        | 179200/1000000 [2:23:30<9:04:15, 25.14steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 18%|‚ñà‚ñä        | 181760/1000000 [2:29:01<15:34:58, 14.59steps/s] 18%|‚ñà‚ñä        | 184320/1000000 [2:30:32<13:18:43, 17.02steps/s]                                                                 18%|‚ñà‚ñä        | 184320/1000000 [2:30:32<13:18:43, 17.02steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 258      |
|    Return            | -29.7    |
|    NonzeroRewards    | 258      |
|    DiscountedReturn  | -29.7    |
|    Success           | 0.786    |
| algo/                |          |
|    critic_loss       | 0.326    |
|    mean_entropy      | 2.35     |
|    mean_ent_bonus    | 0.16     |
|    max_target_q      | 12.5     |
|    min_target_q      | -3.81    |
|    max_reward        | 7.97     |
|    min_reward        | -0.788   |
|    encoder_grad_norm | 3.61     |
|    q1_grad_norm      | 0.908    |
|    q2_grad_norm      | 0.904    |
|    actor_loss        | -0.0204  |
|    ent_coeff         | 0.0682   |
|    ent_coeff_loss    | -17.1    |
|    pi_grad_norm      | 0.0982   |
|    n_updates         | 11040    |
| eval/                |          |
|    Length            | 500      |
|    Return            | -143     |
|    NonzeroRewards    | 500      |
|    DiscountedReturn  | -143     |
|    Success           | 0        |
| time/                |          |
|    iterations        | 72       |
|    fps               | 14.5     |
|    elapsed_time      | 9.03e+03 |
|    elapsed_steps     | 184320   |
-----------------------------------
 18%|‚ñà‚ñä        | 184320/1000000 [2:30:50<13:18:43, 17.02steps/s] 19%|‚ñà‚ñä        | 186880/1000000 [2:32:05<11:44:27, 19.24steps/s] 19%|‚ñà‚ñä        | 186880/1000000 [2:32:20<11:44:27, 19.24steps/s] 19%|‚ñà‚ñâ        | 189440/1000000 [2:33:38<10:38:02, 21.17steps/s] 19%|‚ñà‚ñâ        | 189440/1000000 [2:33:50<10:38:02, 21.17steps/s] 19%|‚ñà‚ñâ        | 192000/1000000 [2:35:10<9:51:06, 22.78steps/s]                                                                 19%|‚ñà‚ñâ        | 192000/1000000 [2:35:10<9:51:06, 22.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 186      |
|    Return            | -8.5     |
|    NonzeroRewards    | 186      |
|    DiscountedReturn  | -8.5     |
|    Success           | 0.872    |
| algo/                |          |
|    critic_loss       | 0.389    |
|    mean_entropy      | 2.29     |
|    mean_ent_bonus    | 0.149    |
|    max_target_q      | 13.5     |
|    min_target_q      | -3.88    |
|    max_reward        | 8.64     |
|    min_reward        | -0.819   |
|    encoder_grad_norm | 4.39     |
|    q1_grad_norm      | 0.98     |
|    q2_grad_norm      | 0.983    |
|    actor_loss        | 0.0196   |
|    ent_coeff         | 0.0651   |
|    ent_coeff_loss    | -17.2    |
|    pi_grad_norm      | 0.117    |
|    n_updates         | 11520    |
| time/                |          |
|    iterations        | 75       |
|    fps               | 27.7     |
|    elapsed_time      | 9.31e+03 |
|    elapsed_steps     | 192000   |
-----------------------------------
 19%|‚ñà‚ñâ        | 192000/1000000 [2:35:30<9:51:06, 22.78steps/s] 19%|‚ñà‚ñâ        | 194560/1000000 [2:36:43<9:19:08, 24.01steps/s] 19%|‚ñà‚ñâ        | 194560/1000000 [2:37:00<9:19:08, 24.01steps/s] 20%|‚ñà‚ñâ        | 197120/1000000 [2:38:16<8:56:08, 24.96steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 20%|‚ñà‚ñâ        | 197120/1000000 [2:38:30<8:56:08, 24.96steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_197120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 20%|‚ñà‚ñâ        | 199680/1000000 [2:44:07<15:22:45, 14.46steps/s]                                                                 20%|‚ñà‚ñâ        | 199680/1000000 [2:44:07<15:22:45, 14.46steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 217      |
|    Return            | -19      |
|    NonzeroRewards    | 217      |
|    DiscountedReturn  | -19      |
|    Success           | 0.767    |
| algo/                |          |
|    critic_loss       | 0.431    |
|    mean_entropy      | 2.21     |
|    mean_ent_bonus    | 0.137    |
|    max_target_q      | 14       |
|    min_target_q      | -3.95    |
|    max_reward        | 9.34     |
|    min_reward        | -0.807   |
|    encoder_grad_norm | 4.78     |
|    q1_grad_norm      | 1.04     |
|    q2_grad_norm      | 1.05     |
|    actor_loss        | 0.0279   |
|    ent_coeff         | 0.0621   |
|    ent_coeff_loss    | -17.3    |
|    pi_grad_norm      | 0.115    |
|    n_updates         | 12000    |
| eval/                |          |
|    Length            | 396      |
|    Return            | -91.3    |
|    NonzeroRewards    | 396      |
|    DiscountedReturn  | -91.3    |
|    Success           | 0.263    |
| time/                |          |
|    iterations        | 78       |
|    fps               | 14.3     |
|    elapsed_time      | 9.85e+03 |
|    elapsed_steps     | 199680   |
-----------------------------------
 20%|‚ñà‚ñà        | 202240/1000000 [2:45:39<13:06:53, 16.90steps/s] 20%|‚ñà‚ñà        | 202240/1000000 [2:45:50<13:06:53, 16.90steps/s] 20%|‚ñà‚ñà        | 204800/1000000 [2:47:12<11:32:48, 19.13steps/s] 20%|‚ñà‚ñà        | 204800/1000000 [2:47:30<11:32:48, 19.13steps/s] 21%|‚ñà‚ñà        | 207360/1000000 [2:48:45<10:27:08, 21.07steps/s]                                                                 21%|‚ñà‚ñà        | 207360/1000000 [2:48:45<10:27:08, 21.07steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 132      |
|    Return            | 1.4      |
|    NonzeroRewards    | 132      |
|    DiscountedReturn  | 1.4      |
|    Success           | 0.981    |
| algo/                |          |
|    critic_loss       | 0.442    |
|    mean_entropy      | 2.1      |
|    mean_ent_bonus    | 0.125    |
|    max_target_q      | 14.2     |
|    min_target_q      | -4.01    |
|    max_reward        | 9.7      |
|    min_reward        | -0.809   |
|    encoder_grad_norm | 4.7      |
|    q1_grad_norm      | 1.06     |
|    q2_grad_norm      | 1.07     |
|    actor_loss        | 0.0141   |
|    ent_coeff         | 0.0592   |
|    ent_coeff_loss    | -17.3    |
|    pi_grad_norm      | 0.123    |
|    n_updates         | 12480    |
| time/                |          |
|    iterations        | 81       |
|    fps               | 27.7     |
|    elapsed_time      | 1.01e+04 |
|    elapsed_steps     | 207360   |
-----------------------------------
 21%|‚ñà‚ñà        | 207360/1000000 [2:49:00<10:27:08, 21.07steps/s] 21%|‚ñà‚ñà        | 209920/1000000 [2:50:18<9:41:50, 22.63steps/s]  21%|‚ñà‚ñà        | 209920/1000000 [2:50:30<9:41:50, 22.63steps/s] 21%|‚ñà‚ñà        | 212480/1000000 [2:51:51<9:08:43, 23.92steps/s] 21%|‚ñà‚ñà        | 212480/1000000 [2:52:10<9:08:43, 23.92steps/s] 22%|‚ñà‚ñà‚ñè       | 215040/1000000 [2:53:24<8:46:19, 24.86steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_215040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
 22%|‚ñà‚ñà‚ñè       | 215040/1000000 [2:53:40<8:46:19, 24.86steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                22%|‚ñà‚ñà‚ñè       | 215040/1000000 [2:57:44<8:46:19, 24.86steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 141      |
|    Return            | 2.61     |
|    NonzeroRewards    | 141      |
|    DiscountedReturn  | 2.61     |
|    Success           | 0.962    |
| algo/                |          |
|    critic_loss       | 0.547    |
|    mean_entropy      | 2.01     |
|    mean_ent_bonus    | 0.114    |
|    max_target_q      | 15.2     |
|    min_target_q      | -4.07    |
|    max_reward        | 10.2     |
|    min_reward        | -0.866   |
|    encoder_grad_norm | 5.78     |
|    q1_grad_norm      | 1.46     |
|    q2_grad_norm      | 1.48     |
|    actor_loss        | -0.00695 |
|    ent_coeff         | 0.0565   |
|    ent_coeff_loss    | -17.3    |
|    pi_grad_norm      | 0.148    |
|    n_updates         | 12960    |
| eval/                |          |
|    Length            | 283      |
|    Return            | -43.1    |
|    NonzeroRewards    | 283      |
|    DiscountedReturn  | -43.1    |
|    Success           | 0.524    |
| time/                |          |
|    iterations        | 84       |
|    fps               | 14.2     |
|    elapsed_time      | 1.07e+04 |
|    elapsed_steps     | 215040   |
-----------------------------------
 22%|‚ñà‚ñà‚ñè       | 217600/1000000 [2:59:17<15:05:28, 14.40steps/s] 22%|‚ñà‚ñà‚ñè       | 220160/1000000 [3:00:49<12:53:05, 16.81steps/s] 22%|‚ñà‚ñà‚ñè       | 220160/1000000 [3:01:00<12:53:05, 16.81steps/s] 22%|‚ñà‚ñà‚ñè       | 222720/1000000 [3:02:22<11:19:57, 19.05steps/s]                                                                 22%|‚ñà‚ñà‚ñè       | 222720/1000000 [3:02:22<11:19:57, 19.05steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 152      |
|    Return            | -0.0169  |
|    NonzeroRewards    | 152      |
|    DiscountedReturn  | -0.0169  |
|    Success           | 0.902    |
| algo/                |          |
|    critic_loss       | 0.61     |
|    mean_entropy      | 1.94     |
|    mean_ent_bonus    | 0.105    |
|    max_target_q      | 16.2     |
|    min_target_q      | -4.12    |
|    max_reward        | 10.8     |
|    min_reward        | -0.872   |
|    encoder_grad_norm | 6.25     |
|    q1_grad_norm      | 1.44     |
|    q2_grad_norm      | 1.46     |
|    actor_loss        | -0.0861  |
|    ent_coeff         | 0.0539   |
|    ent_coeff_loss    | -17.4    |
|    pi_grad_norm      | 0.14     |
|    n_updates         | 13440    |
| time/                |          |
|    iterations        | 87       |
|    fps               | 27.6     |
|    elapsed_time      | 1.09e+04 |
|    elapsed_steps     | 222720   |
-----------------------------------
 22%|‚ñà‚ñà‚ñè       | 222720/1000000 [3:02:40<11:19:57, 19.05steps/s] 23%|‚ñà‚ñà‚ñé       | 225280/1000000 [3:03:55<10:14:30, 21.01steps/s] 23%|‚ñà‚ñà‚ñé       | 225280/1000000 [3:04:10<10:14:30, 21.01steps/s] 23%|‚ñà‚ñà‚ñé       | 227840/1000000 [3:05:27<9:28:36, 22.63steps/s]  23%|‚ñà‚ñà‚ñé       | 227840/1000000 [3:05:40<9:28:36, 22.63steps/s] 23%|‚ñà‚ñà‚ñé       | 230400/1000000 [3:07:00<8:55:45, 23.94steps/s]                                                                23%|‚ñà‚ñà‚ñé       | 230400/1000000 [3:07:00<8:55:45, 23.94steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 172      |
|    Return            | -8.91    |
|    NonzeroRewards    | 172      |
|    DiscountedReturn  | -8.91    |
|    Success           | 0.884    |
| algo/                |          |
|    critic_loss       | 0.656    |
|    mean_entropy      | 1.79     |
|    mean_ent_bonus    | 0.0923   |
|    max_target_q      | 16.9     |
|    min_target_q      | -4.18    |
|    max_reward        | 11.5     |
|    min_reward        | -0.851   |
|    encoder_grad_norm | 6.55     |
|    q1_grad_norm      | 1.53     |
|    q2_grad_norm      | 1.55     |
|    actor_loss        | -0.135   |
|    ent_coeff         | 0.0515   |
|    ent_coeff_loss    | -17.2    |
|    pi_grad_norm      | 0.158    |
|    n_updates         | 13920    |
| time/                |          |
|    iterations        | 90       |
|    fps               | 27.6     |
|    elapsed_time      | 1.12e+04 |
|    elapsed_steps     | 230400   |
-----------------------------------
 23%|‚ñà‚ñà‚ñé       | 230400/1000000 [3:07:20<8:55:45, 23.94steps/s] 23%|‚ñà‚ñà‚ñé       | 232960/1000000 [3:08:33<8:33:18, 24.91steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_232960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 23%|‚ñà‚ñà‚ñé       | 232960/1000000 [3:08:50<8:33:18, 24.91steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 24%|‚ñà‚ñà‚ñé       | 235520/1000000 [3:14:27<14:46:50, 14.37steps/s] 24%|‚ñà‚ñà‚ñç       | 238080/1000000 [3:16:00<12:36:55, 16.78steps/s]                                                                 24%|‚ñà‚ñà‚ñç       | 238080/1000000 [3:16:00<12:36:55, 16.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 151      |
|    Return            | -1.47    |
|    NonzeroRewards    | 151      |
|    DiscountedReturn  | -1.47    |
|    Success           | 0.912    |
| algo/                |          |
|    critic_loss       | 0.675    |
|    mean_entropy      | 1.69     |
|    mean_ent_bonus    | 0.0831   |
|    max_target_q      | 16.6     |
|    min_target_q      | -4.21    |
|    max_reward        | 11.3     |
|    min_reward        | -0.847   |
|    encoder_grad_norm | 6.76     |
|    q1_grad_norm      | 1.62     |
|    q2_grad_norm      | 1.63     |
|    actor_loss        | -0.181   |
|    ent_coeff         | 0.0492   |
|    ent_coeff_loss    | -17.2    |
|    pi_grad_norm      | 0.159    |
|    n_updates         | 14400    |
| eval/                |          |
|    Length            | 197      |
|    Return            | -16.4    |
|    NonzeroRewards    | 197      |
|    DiscountedReturn  | -16.4    |
|    Success           | 0.767    |
| time/                |          |
|    iterations        | 93       |
|    fps               | 14.2     |
|    elapsed_time      | 1.18e+04 |
|    elapsed_steps     | 238080   |
-----------------------------------
 24%|‚ñà‚ñà‚ñç       | 238080/1000000 [3:16:20<12:36:55, 16.78steps/s] 24%|‚ñà‚ñà‚ñç       | 240640/1000000 [3:17:33<11:05:54, 19.01steps/s] 24%|‚ñà‚ñà‚ñç       | 240640/1000000 [3:17:50<11:05:54, 19.01steps/s] 24%|‚ñà‚ñà‚ñç       | 243200/1000000 [3:19:06<10:01:32, 20.97steps/s] 24%|‚ñà‚ñà‚ñç       | 243200/1000000 [3:19:20<10:01:32, 20.97steps/s] 25%|‚ñà‚ñà‚ñç       | 245760/1000000 [3:20:39<9:16:40, 22.58steps/s]                                                                 25%|‚ñà‚ñà‚ñç       | 245760/1000000 [3:20:39<9:16:40, 22.58steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 136      |
|    Return            | 2.61     |
|    NonzeroRewards    | 136      |
|    DiscountedReturn  | 2.61     |
|    Success           | 0.923    |
| algo/                |          |
|    critic_loss       | 0.688    |
|    mean_entropy      | 1.6      |
|    mean_ent_bonus    | 0.0753   |
|    max_target_q      | 16.9     |
|    min_target_q      | -4.2     |
|    max_reward        | 11.8     |
|    min_reward        | -0.929   |
|    encoder_grad_norm | 6.78     |
|    q1_grad_norm      | 1.64     |
|    q2_grad_norm      | 1.67     |
|    actor_loss        | -0.212   |
|    ent_coeff         | 0.0469   |
|    ent_coeff_loss    | -17.2    |
|    pi_grad_norm      | 0.169    |
|    n_updates         | 14880    |
| time/                |          |
|    iterations        | 96       |
|    fps               | 27.6     |
|    elapsed_time      | 1.2e+04  |
|    elapsed_steps     | 245760   |
-----------------------------------
 25%|‚ñà‚ñà‚ñç       | 245760/1000000 [3:20:50<9:16:40, 22.58steps/s] 25%|‚ñà‚ñà‚ñç       | 248320/1000000 [3:22:12<8:44:54, 23.87steps/s] 25%|‚ñà‚ñà‚ñç       | 248320/1000000 [3:22:30<8:44:54, 23.87steps/s] 25%|‚ñà‚ñà‚ñå       | 250880/1000000 [3:23:46<8:23:44, 24.79steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 25%|‚ñà‚ñà‚ñå       | 250880/1000000 [3:24:00<8:23:44, 24.79steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_250880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 25%|‚ñà‚ñà‚ñå       | 253440/1000000 [3:29:42<14:31:21, 14.28steps/s]                                                                 25%|‚ñà‚ñà‚ñå       | 253440/1000000 [3:29:42<14:31:21, 14.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 110      |
|    Return            | 6.93     |
|    NonzeroRewards    | 110      |
|    DiscountedReturn  | 6.93     |
|    Success           | 0.946    |
| algo/                |          |
|    critic_loss       | 0.713    |
|    mean_entropy      | 1.43     |
|    mean_ent_bonus    | 0.0643   |
|    max_target_q      | 17.2     |
|    min_target_q      | -4.19    |
|    max_reward        | 12.3     |
|    min_reward        | -0.916   |
|    encoder_grad_norm | 6.98     |
|    q1_grad_norm      | 1.68     |
|    q2_grad_norm      | 1.71     |
|    actor_loss        | -0.29    |
|    ent_coeff         | 0.0448   |
|    ent_coeff_loss    | -16.9    |
|    pi_grad_norm      | 0.159    |
|    n_updates         | 15360    |
| eval/                |          |
|    Length            | 196      |
|    Return            | -18.5    |
|    NonzeroRewards    | 196      |
|    DiscountedReturn  | -18.5    |
|    Success           | 0.781    |
| time/                |          |
|    iterations        | 99       |
|    fps               | 14.1     |
|    elapsed_time      | 1.26e+04 |
|    elapsed_steps     | 253440   |
-----------------------------------
 26%|‚ñà‚ñà‚ñå       | 256000/1000000 [3:31:15<12:22:53, 16.69steps/s] 26%|‚ñà‚ñà‚ñå       | 256000/1000000 [3:31:30<12:22:53, 16.69steps/s] 26%|‚ñà‚ñà‚ñå       | 258560/1000000 [3:32:48<10:52:54, 18.93steps/s] 26%|‚ñà‚ñà‚ñå       | 258560/1000000 [3:33:00<10:52:54, 18.93steps/s] 26%|‚ñà‚ñà‚ñå       | 261120/1000000 [3:34:22<9:50:38, 20.85steps/s]                                                                 26%|‚ñà‚ñà‚ñå       | 261120/1000000 [3:34:22<9:50:38, 20.85steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 115      |
|    Return            | 8.93     |
|    NonzeroRewards    | 115      |
|    DiscountedReturn  | 8.93     |
|    Success           | 0.944    |
| algo/                |          |
|    critic_loss       | 0.812    |
|    mean_entropy      | 1.24     |
|    mean_ent_bonus    | 0.0532   |
|    max_target_q      | 17.8     |
|    min_target_q      | -4.21    |
|    max_reward        | 12.7     |
|    min_reward        | -0.903   |
|    encoder_grad_norm | 7.4      |
|    q1_grad_norm      | 1.81     |
|    q2_grad_norm      | 1.83     |
|    actor_loss        | -0.403   |
|    ent_coeff         | 0.0428   |
|    ent_coeff_loss    | -16.5    |
|    pi_grad_norm      | 0.187    |
|    n_updates         | 15840    |
| time/                |          |
|    iterations        | 102      |
|    fps               | 27.5     |
|    elapsed_time      | 1.29e+04 |
|    elapsed_steps     | 261120   |
-----------------------------------
 26%|‚ñà‚ñà‚ñå       | 261120/1000000 [3:34:40<9:50:38, 20.85steps/s] 26%|‚ñà‚ñà‚ñã       | 263680/1000000 [3:35:56<9:06:49, 22.44steps/s] 26%|‚ñà‚ñà‚ñã       | 263680/1000000 [3:36:10<9:06:49, 22.44steps/s] 27%|‚ñà‚ñà‚ñã       | 266240/1000000 [3:37:29<8:35:09, 23.74steps/s] 27%|‚ñà‚ñà‚ñã       | 266240/1000000 [3:37:40<8:35:09, 23.74steps/s] 27%|‚ñà‚ñà‚ñã       | 268800/1000000 [3:39:02<8:12:12, 24.76steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_268800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 27%|‚ñà‚ñà‚ñã       | 268800/1000000 [3:39:20<8:12:12, 24.76steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                27%|‚ñà‚ñà‚ñã       | 268800/1000000 [3:43:27<8:12:12, 24.76steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 90.9     |
|    Return            | 11.1     |
|    NonzeroRewards    | 90.9     |
|    DiscountedReturn  | 11.1     |
|    Success           | 0.947    |
| algo/                |          |
|    critic_loss       | 0.923    |
|    mean_entropy      | 1.12     |
|    mean_ent_bonus    | 0.046    |
|    max_target_q      | 18.1     |
|    min_target_q      | -4.25    |
|    max_reward        | 13       |
|    min_reward        | -0.968   |
|    encoder_grad_norm | 8.23     |
|    q1_grad_norm      | 1.91     |
|    q2_grad_norm      | 1.94     |
|    actor_loss        | -0.53    |
|    ent_coeff         | 0.0409   |
|    ent_coeff_loss    | -16.4    |
|    pi_grad_norm      | 0.151    |
|    n_updates         | 16320    |
| eval/                |          |
|    Length            | 406      |
|    Return            | -96.8    |
|    NonzeroRewards    | 406      |
|    DiscountedReturn  | -96.8    |
|    Success           | 0.211    |
| time/                |          |
|    iterations        | 105      |
|    fps               | 14.1     |
|    elapsed_time      | 1.34e+04 |
|    elapsed_steps     | 268800   |
-----------------------------------
 27%|‚ñà‚ñà‚ñã       | 271360/1000000 [3:45:01<14:14:33, 14.21steps/s] 27%|‚ñà‚ñà‚ñã       | 273920/1000000 [3:46:34<12:07:33, 16.63steps/s] 27%|‚ñà‚ñà‚ñã       | 273920/1000000 [3:46:50<12:07:33, 16.63steps/s] 28%|‚ñà‚ñà‚ñä       | 276480/1000000 [3:48:07<10:38:38, 18.88steps/s]                                                                 28%|‚ñà‚ñà‚ñä       | 276480/1000000 [3:48:07<10:38:38, 18.88steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 103      |
|    Return            | 9.99     |
|    NonzeroRewards    | 103      |
|    DiscountedReturn  | 9.99     |
|    Success           | 0.944    |
| algo/                |          |
|    critic_loss       | 0.926    |
|    mean_entropy      | 0.965    |
|    mean_ent_bonus    | 0.0378   |
|    max_target_q      | 19.2     |
|    min_target_q      | -4.25    |
|    max_reward        | 13.2     |
|    min_reward        | -0.888   |
|    encoder_grad_norm | 8.85     |
|    q1_grad_norm      | 2.14     |
|    q2_grad_norm      | 2.18     |
|    actor_loss        | -0.655   |
|    ent_coeff         | 0.0391   |
|    ent_coeff_loss    | -16.1    |
|    pi_grad_norm      | 0.165    |
|    n_updates         | 16800    |
| time/                |          |
|    iterations        | 108      |
|    fps               | 27.5     |
|    elapsed_time      | 1.37e+04 |
|    elapsed_steps     | 276480   |
-----------------------------------
 28%|‚ñà‚ñà‚ñä       | 276480/1000000 [3:48:20<10:38:38, 18.88steps/s] 28%|‚ñà‚ñà‚ñä       | 279040/1000000 [3:49:40<9:36:22, 20.85steps/s]  28%|‚ñà‚ñà‚ñä       | 279040/1000000 [3:49:50<9:36:22, 20.85steps/s] 28%|‚ñà‚ñà‚ñä       | 281600/1000000 [3:51:13<8:53:07, 22.46steps/s] 28%|‚ñà‚ñà‚ñä       | 281600/1000000 [3:51:30<8:53:07, 22.46steps/s] 28%|‚ñà‚ñà‚ñä       | 284160/1000000 [3:52:46<8:22:06, 23.76steps/s]                                                                28%|‚ñà‚ñà‚ñä       | 284160/1000000 [3:52:46<8:22:06, 23.76steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 68.8     |
|    Return            | 17.2     |
|    NonzeroRewards    | 68.8     |
|    DiscountedReturn  | 17.2     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 0.977    |
|    mean_entropy      | 0.809    |
|    mean_ent_bonus    | 0.0303   |
|    max_target_q      | 18.6     |
|    min_target_q      | -4.21    |
|    max_reward        | 13.5     |
|    min_reward        | -0.956   |
|    encoder_grad_norm | 8.44     |
|    q1_grad_norm      | 2.25     |
|    q2_grad_norm      | 2.29     |
|    actor_loss        | -0.779   |
|    ent_coeff         | 0.0374   |
|    ent_coeff_loss    | -15.8    |
|    pi_grad_norm      | 0.171    |
|    n_updates         | 17280    |
| time/                |          |
|    iterations        | 111      |
|    fps               | 27.5     |
|    elapsed_time      | 1.4e+04  |
|    elapsed_steps     | 284160   |
-----------------------------------
 28%|‚ñà‚ñà‚ñä       | 284160/1000000 [3:53:00<8:22:06, 23.76steps/s] 29%|‚ñà‚ñà‚ñä       | 286720/1000000 [3:54:20<8:01:10, 24.71steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_286720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 29%|‚ñà‚ñà‚ñä       | 286720/1000000 [3:54:40<8:01:10, 24.71steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 29%|‚ñà‚ñà‚ñâ       | 289280/1000000 [4:00:18<13:52:28, 14.23steps/s] 29%|‚ñà‚ñà‚ñâ       | 291840/1000000 [4:01:51<11:49:24, 16.64steps/s]                                                                 29%|‚ñà‚ñà‚ñâ       | 291840/1000000 [4:01:51<11:49:24, 16.64steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 83.8     |
|    Return            | 11.1     |
|    NonzeroRewards    | 83.8     |
|    DiscountedReturn  | 11.1     |
|    Success           | 0.968    |
| algo/                |          |
|    critic_loss       | 1.09     |
|    mean_entropy      | 0.619    |
|    mean_ent_bonus    | 0.0222   |
|    max_target_q      | 19.3     |
|    min_target_q      | -4.25    |
|    max_reward        | 14       |
|    min_reward        | -0.99    |
|    encoder_grad_norm | 9.4      |
|    q1_grad_norm      | 2.4      |
|    q2_grad_norm      | 2.43     |
|    actor_loss        | -0.911   |
|    ent_coeff         | 0.0358   |
|    ent_coeff_loss    | -15.4    |
|    pi_grad_norm      | 0.179    |
|    n_updates         | 17760    |
| eval/                |          |
|    Length            | 179      |
|    Return            | -19.5    |
|    NonzeroRewards    | 179      |
|    DiscountedReturn  | -19.5    |
|    Success           | 0.75     |
| time/                |          |
|    iterations        | 114      |
|    fps               | 14.1     |
|    elapsed_time      | 1.45e+04 |
|    elapsed_steps     | 291840   |
-----------------------------------
 29%|‚ñà‚ñà‚ñâ       | 291840/1000000 [4:02:10<11:49:24, 16.64steps/s] 29%|‚ñà‚ñà‚ñâ       | 294400/1000000 [4:03:24<10:22:51, 18.88steps/s] 29%|‚ñà‚ñà‚ñâ       | 294400/1000000 [4:03:40<10:22:51, 18.88steps/s] 30%|‚ñà‚ñà‚ñâ       | 296960/1000000 [4:04:58<9:23:57, 20.78steps/s]  30%|‚ñà‚ñà‚ñâ       | 296960/1000000 [4:05:10<9:23:57, 20.78steps/s] 30%|‚ñà‚ñà‚ñâ       | 299520/1000000 [4:06:34<8:43:19, 22.31steps/s]                                                                30%|‚ñà‚ñà‚ñâ       | 299520/1000000 [4:06:34<8:43:19, 22.31steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 71.5     |
|    Return            | 16.1     |
|    NonzeroRewards    | 71.5     |
|    DiscountedReturn  | 16.1     |
|    Success           | 0.991    |
| algo/                |          |
|    critic_loss       | 1.11     |
|    mean_entropy      | 0.469    |
|    mean_ent_bonus    | 0.0161   |
|    max_target_q      | 19.4     |
|    min_target_q      | -4.33    |
|    max_reward        | 14       |
|    min_reward        | -1.02    |
|    encoder_grad_norm | 9.15     |
|    q1_grad_norm      | 2.17     |
|    q2_grad_norm      | 2.2      |
|    actor_loss        | -1.05    |
|    ent_coeff         | 0.0342   |
|    ent_coeff_loss    | -15.1    |
|    pi_grad_norm      | 0.166    |
|    n_updates         | 18240    |
| time/                |          |
|    iterations        | 117      |
|    fps               | 27.2     |
|    elapsed_time      | 1.48e+04 |
|    elapsed_steps     | 299520   |
-----------------------------------
 30%|‚ñà‚ñà‚ñâ       | 299520/1000000 [4:06:50<8:43:19, 22.31steps/s] 30%|‚ñà‚ñà‚ñà       | 302080/1000000 [4:08:08<8:13:52, 23.55steps/s] 30%|‚ñà‚ñà‚ñà       | 302080/1000000 [4:08:20<8:13:52, 23.55steps/s] 30%|‚ñà‚ñà‚ñà       | 304640/1000000 [4:09:42<7:52:39, 24.52steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_304640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 30%|‚ñà‚ñà‚ñà       | 304640/1000000 [4:10:00<7:52:39, 24.52steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 31%|‚ñà‚ñà‚ñà       | 307200/1000000 [4:15:42<13:36:28, 14.14steps/s]                                                                 31%|‚ñà‚ñà‚ñà       | 307200/1000000 [4:15:42<13:36:28, 14.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 67.8     |
|    Return            | 15.3     |
|    NonzeroRewards    | 67.8     |
|    DiscountedReturn  | 15.3     |
|    Success           | 0.981    |
| algo/                |          |
|    critic_loss       | 1.15     |
|    mean_entropy      | 0.311    |
|    mean_ent_bonus    | 0.0102   |
|    max_target_q      | 18.9     |
|    min_target_q      | -4.33    |
|    max_reward        | 14.3     |
|    min_reward        | -1.02    |
|    encoder_grad_norm | 9.25     |
|    q1_grad_norm      | 2.45     |
|    q2_grad_norm      | 2.49     |
|    actor_loss        | -1.19    |
|    ent_coeff         | 0.0327   |
|    ent_coeff_loss    | -14.8    |
|    pi_grad_norm      | 0.174    |
|    n_updates         | 18720    |
| eval/                |          |
|    Length            | 139      |
|    Return            | -6.9     |
|    NonzeroRewards    | 139      |
|    DiscountedReturn  | -6.9     |
|    Success           | 0.833    |
| time/                |          |
|    iterations        | 120      |
|    fps               | 14       |
|    elapsed_time      | 1.53e+04 |
|    elapsed_steps     | 307200   |
-----------------------------------
 31%|‚ñà‚ñà‚ñà       | 309760/1000000 [4:17:16<11:35:32, 16.54steps/s] 31%|‚ñà‚ñà‚ñà       | 309760/1000000 [4:17:30<11:35:32, 16.54steps/s] 31%|‚ñà‚ñà‚ñà       | 312320/1000000 [4:18:49<10:10:51, 18.76steps/s] 31%|‚ñà‚ñà‚ñà       | 312320/1000000 [4:19:00<10:10:51, 18.76steps/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 314880/1000000 [4:20:24<9:13:10, 20.64steps/s]                                                                 31%|‚ñà‚ñà‚ñà‚ñè      | 314880/1000000 [4:20:24<9:13:10, 20.64steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 62.4     |
|    Return            | 17.3     |
|    NonzeroRewards    | 62.4     |
|    DiscountedReturn  | 17.3     |
|    Success           | 0.979    |
| algo/                |          |
|    critic_loss       | 1.21     |
|    mean_entropy      | 0.145    |
|    mean_ent_bonus    | 0.00457  |
|    max_target_q      | 19.5     |
|    min_target_q      | -4.4     |
|    max_reward        | 14.7     |
|    min_reward        | -1.09    |
|    encoder_grad_norm | 9.9      |
|    q1_grad_norm      | 2.38     |
|    q2_grad_norm      | 2.43     |
|    actor_loss        | -1.33    |
|    ent_coeff         | 0.0313   |
|    ent_coeff_loss    | -14.4    |
|    pi_grad_norm      | 0.162    |
|    n_updates         | 19200    |
| time/                |          |
|    iterations        | 123      |
|    fps               | 27.2     |
|    elapsed_time      | 1.56e+04 |
|    elapsed_steps     | 314880   |
-----------------------------------
 31%|‚ñà‚ñà‚ñà‚ñè      | 314880/1000000 [4:20:40<9:13:10, 20.64steps/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 317440/1000000 [4:21:59<8:32:21, 22.20steps/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 317440/1000000 [4:22:10<8:32:21, 22.20steps/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 320000/1000000 [4:23:34<8:03:05, 23.46steps/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 320000/1000000 [4:23:50<8:03:05, 23.46steps/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 322560/1000000 [4:25:09<7:42:26, 24.42steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 32%|‚ñà‚ñà‚ñà‚ñè      | 322560/1000000 [4:25:20<7:42:26, 24.42steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_322560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                32%|‚ñà‚ñà‚ñà‚ñè      | 322560/1000000 [4:29:36<7:42:26, 24.42steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 54.7     |
|    Return            | 18.5     |
|    NonzeroRewards    | 54.7     |
|    DiscountedReturn  | 18.5     |
|    Success           | 0.993    |
| algo/                |          |
|    critic_loss       | 1.37     |
|    mean_entropy      | -0.0924  |
|    mean_ent_bonus    | -0.00274 |
|    max_target_q      | 20.5     |
|    min_target_q      | -4.47    |
|    max_reward        | 15.4     |
|    min_reward        | -1.05    |
|    encoder_grad_norm | 11       |
|    q1_grad_norm      | 2.64     |
|    q2_grad_norm      | 2.66     |
|    actor_loss        | -1.49    |
|    ent_coeff         | 0.0299   |
|    ent_coeff_loss    | -13.8    |
|    pi_grad_norm      | 0.173    |
|    n_updates         | 19680    |
| eval/                |          |
|    Length            | 103      |
|    Return            | 0.779    |
|    NonzeroRewards    | 103      |
|    DiscountedReturn  | 0.779    |
|    Success           | 0.933    |
| time/                |          |
|    iterations        | 126      |
|    fps               | 13.9     |
|    elapsed_time      | 1.62e+04 |
|    elapsed_steps     | 322560   |
-----------------------------------
 33%|‚ñà‚ñà‚ñà‚ñé      | 325120/1000000 [4:31:10<13:18:37, 14.08steps/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 327680/1000000 [4:32:44<11:19:59, 16.48steps/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 327680/1000000 [4:33:00<11:19:59, 16.48steps/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 330240/1000000 [4:34:18<9:57:01, 18.70steps/s]                                                                 33%|‚ñà‚ñà‚ñà‚ñé      | 330240/1000000 [4:34:18<9:57:01, 18.70steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 61.1     |
|    Return            | 18.5     |
|    NonzeroRewards    | 61.1     |
|    DiscountedReturn  | 18.5     |
|    Success           | 0.984    |
| algo/                |          |
|    critic_loss       | 1.41     |
|    mean_entropy      | -0.328   |
|    mean_ent_bonus    | -0.00938 |
|    max_target_q      | 20.5     |
|    min_target_q      | -4.56    |
|    max_reward        | 15.3     |
|    min_reward        | -1.01    |
|    encoder_grad_norm | 11       |
|    q1_grad_norm      | 2.84     |
|    q2_grad_norm      | 2.88     |
|    actor_loss        | -1.66    |
|    ent_coeff         | 0.0287   |
|    ent_coeff_loss    | -13.1    |
|    pi_grad_norm      | 0.182    |
|    n_updates         | 20160    |
| time/                |          |
|    iterations        | 129      |
|    fps               | 27.3     |
|    elapsed_time      | 1.65e+04 |
|    elapsed_steps     | 330240   |
-----------------------------------
 33%|‚ñà‚ñà‚ñà‚ñé      | 330240/1000000 [4:34:30<9:57:01, 18.70steps/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 332800/1000000 [4:35:53<8:59:50, 20.60steps/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 332800/1000000 [4:36:10<8:59:50, 20.60steps/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 335360/1000000 [4:37:27<8:19:11, 22.19steps/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 335360/1000000 [4:37:40<8:19:11, 22.19steps/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 337920/1000000 [4:39:02<7:50:12, 23.47steps/s]                                                                34%|‚ñà‚ñà‚ñà‚ñç      | 337920/1000000 [4:39:02<7:50:12, 23.47steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 55.4     |
|    Return            | 19.3     |
|    NonzeroRewards    | 55.4     |
|    DiscountedReturn  | 19.3     |
|    Success           | 0.985    |
| algo/                |          |
|    critic_loss       | 1.49     |
|    mean_entropy      | -0.437   |
|    mean_ent_bonus    | -0.012   |
|    max_target_q      | 21.3     |
|    min_target_q      | -4.61    |
|    max_reward        | 15.6     |
|    min_reward        | -0.988   |
|    encoder_grad_norm | 11.9     |
|    q1_grad_norm      | 2.93     |
|    q2_grad_norm      | 2.97     |
|    actor_loss        | -1.84    |
|    ent_coeff         | 0.0275   |
|    ent_coeff_loss    | -12.9    |
|    pi_grad_norm      | 0.196    |
|    n_updates         | 20640    |
| time/                |          |
|    iterations        | 132      |
|    fps               | 27.1     |
|    elapsed_time      | 1.67e+04 |
|    elapsed_steps     | 337920   |
-----------------------------------
 34%|‚ñà‚ñà‚ñà‚ñç      | 337920/1000000 [4:39:20<7:50:12, 23.47steps/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 340480/1000000 [4:40:37<7:30:54, 24.38steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 34%|‚ñà‚ñà‚ñà‚ñç      | 340480/1000000 [4:40:50<7:30:54, 24.38steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_340480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 34%|‚ñà‚ñà‚ñà‚ñç      | 343040/1000000 [4:46:38<12:56:52, 14.09steps/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 345600/1000000 [4:48:11<11:01:19, 16.49steps/s]                                                                 35%|‚ñà‚ñà‚ñà‚ñç      | 345600/1000000 [4:48:11<11:01:19, 16.49steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 56.5     |
|    Return            | 19.4     |
|    NonzeroRewards    | 56.5     |
|    DiscountedReturn  | 19.4     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 1.44     |
|    mean_entropy      | -0.561   |
|    mean_ent_bonus    | -0.0147  |
|    max_target_q      | 20.6     |
|    min_target_q      | -4.67    |
|    max_reward        | 15.4     |
|    min_reward        | -1.13    |
|    encoder_grad_norm | 11.1     |
|    q1_grad_norm      | 2.81     |
|    q2_grad_norm      | 2.84     |
|    actor_loss        | -1.94    |
|    ent_coeff         | 0.0263   |
|    ent_coeff_loss    | -12.5    |
|    pi_grad_norm      | 0.164    |
|    n_updates         | 21120    |
| eval/                |          |
|    Length            | 88.7     |
|    Return            | 13.6     |
|    NonzeroRewards    | 88.7     |
|    DiscountedReturn  | 13.6     |
|    Success           | 0.939    |
| time/                |          |
|    iterations        | 135      |
|    fps               | 14       |
|    elapsed_time      | 1.73e+04 |
|    elapsed_steps     | 345600   |
-----------------------------------
 35%|‚ñà‚ñà‚ñà‚ñç      | 345600/1000000 [4:48:30<11:01:19, 16.49steps/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 348160/1000000 [4:49:45<9:40:13, 18.72steps/s]  35%|‚ñà‚ñà‚ñà‚ñç      | 348160/1000000 [4:50:00<9:40:13, 18.72steps/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 350720/1000000 [4:51:20<8:44:53, 20.62steps/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 350720/1000000 [4:51:30<8:44:53, 20.62steps/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 353280/1000000 [4:52:54<8:05:13, 22.21steps/s]                                                                35%|‚ñà‚ñà‚ñà‚ñå      | 353280/1000000 [4:52:54<8:05:13, 22.21steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 57.6     |
|    Return            | 19.8     |
|    NonzeroRewards    | 57.6     |
|    DiscountedReturn  | 19.8     |
|    Success           | 0.993    |
| algo/                |          |
|    critic_loss       | 1.53     |
|    mean_entropy      | -0.86    |
|    mean_ent_bonus    | -0.0217  |
|    max_target_q      | 21.2     |
|    min_target_q      | -4.64    |
|    max_reward        | 15.7     |
|    min_reward        | -1.07    |
|    encoder_grad_norm | 11.8     |
|    q1_grad_norm      | 3.06     |
|    q2_grad_norm      | 3.1      |
|    actor_loss        | -2.07    |
|    ent_coeff         | 0.0252   |
|    ent_coeff_loss    | -11.6    |
|    pi_grad_norm      | 0.157    |
|    n_updates         | 21600    |
| time/                |          |
|    iterations        | 138      |
|    fps               | 27.2     |
|    elapsed_time      | 1.76e+04 |
|    elapsed_steps     | 353280   |
-----------------------------------
 35%|‚ñà‚ñà‚ñà‚ñå      | 353280/1000000 [4:53:10<8:05:13, 22.21steps/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 355840/1000000 [4:54:28<7:37:06, 23.49steps/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 355840/1000000 [4:54:40<7:37:06, 23.49steps/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 358400/1000000 [4:56:04<7:17:49, 24.42steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_358400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 36%|‚ñà‚ñà‚ñà‚ñå      | 358400/1000000 [4:56:20<7:17:49, 24.42steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 36%|‚ñà‚ñà‚ñà‚ñå      | 360960/1000000 [5:02:10<12:42:25, 13.97steps/s]                                                                 36%|‚ñà‚ñà‚ñà‚ñå      | 360960/1000000 [5:02:10<12:42:25, 13.97steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 62.2     |
|    Return            | 19.1     |
|    NonzeroRewards    | 62.2     |
|    DiscountedReturn  | 19.1     |
|    Success           | 0.984    |
| algo/                |          |
|    critic_loss       | 1.57     |
|    mean_entropy      | -1.02    |
|    mean_ent_bonus    | -0.0247  |
|    max_target_q      | 21.2     |
|    min_target_q      | -4.71    |
|    max_reward        | 15.8     |
|    min_reward        | -1.05    |
|    encoder_grad_norm | 12       |
|    q1_grad_norm      | 3.13     |
|    q2_grad_norm      | 3.17     |
|    actor_loss        | -2.2     |
|    ent_coeff         | 0.0242   |
|    ent_coeff_loss    | -11.1    |
|    pi_grad_norm      | 0.177    |
|    n_updates         | 22080    |
| eval/                |          |
|    Length            | 131      |
|    Return            | -3.58    |
|    NonzeroRewards    | 131      |
|    DiscountedReturn  | -3.58    |
|    Success           | 0.833    |
| time/                |          |
|    iterations        | 141      |
|    fps               | 13.8     |
|    elapsed_time      | 1.81e+04 |
|    elapsed_steps     | 360960   |
-----------------------------------
 36%|‚ñà‚ñà‚ñà‚ñã      | 363520/1000000 [5:03:44<10:48:09, 16.37steps/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 363520/1000000 [5:04:00<10:48:09, 16.37steps/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 366080/1000000 [5:05:17<9:28:04, 18.60steps/s]  37%|‚ñà‚ñà‚ñà‚ñã      | 366080/1000000 [5:05:30<9:28:04, 18.60steps/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 368640/1000000 [5:06:52<8:32:46, 20.52steps/s]                                                                37%|‚ñà‚ñà‚ñà‚ñã      | 368640/1000000 [5:06:52<8:32:46, 20.52steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 57.9     |
|    Return            | 19.8     |
|    NonzeroRewards    | 57.9     |
|    DiscountedReturn  | 19.8     |
|    Success           | 0.992    |
| algo/                |          |
|    critic_loss       | 1.61     |
|    mean_entropy      | -1.14    |
|    mean_ent_bonus    | -0.0264  |
|    max_target_q      | 21.4     |
|    min_target_q      | -4.77    |
|    max_reward        | 16       |
|    min_reward        | -1.12    |
|    encoder_grad_norm | 12.4     |
|    q1_grad_norm      | 3.24     |
|    q2_grad_norm      | 3.28     |
|    actor_loss        | -2.33    |
|    ent_coeff         | 0.0232   |
|    ent_coeff_loss    | -10.8    |
|    pi_grad_norm      | 0.176    |
|    n_updates         | 22560    |
| time/                |          |
|    iterations        | 144      |
|    fps               | 27.2     |
|    elapsed_time      | 1.84e+04 |
|    elapsed_steps     | 368640   |
-----------------------------------
 37%|‚ñà‚ñà‚ñà‚ñã      | 368640/1000000 [5:07:10<8:32:46, 20.52steps/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 371200/1000000 [5:08:27<7:53:31, 22.13steps/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 371200/1000000 [5:08:40<7:53:31, 22.13steps/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 373760/1000000 [5:10:00<7:24:51, 23.46steps/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 373760/1000000 [5:10:20<7:24:51, 23.46steps/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 376320/1000000 [5:11:36<7:06:27, 24.37steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 38%|‚ñà‚ñà‚ñà‚ñä      | 376320/1000000 [5:11:50<7:06:27, 24.37steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_376320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                38%|‚ñà‚ñà‚ñà‚ñä      | 376320/1000000 [5:16:08<7:06:27, 24.37steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 62.9     |
|    Return            | 20.6     |
|    NonzeroRewards    | 62.9     |
|    DiscountedReturn  | 20.6     |
|    Success           | 0.977    |
| algo/                |          |
|    critic_loss       | 1.64     |
|    mean_entropy      | -1.31    |
|    mean_ent_bonus    | -0.029   |
|    max_target_q      | 21.6     |
|    min_target_q      | -4.82    |
|    max_reward        | 15.8     |
|    min_reward        | -1.11    |
|    encoder_grad_norm | 12.2     |
|    q1_grad_norm      | 3.29     |
|    q2_grad_norm      | 3.33     |
|    actor_loss        | -2.43    |
|    ent_coeff         | 0.0222   |
|    ent_coeff_loss    | -10.3    |
|    pi_grad_norm      | 0.159    |
|    n_updates         | 23040    |
| eval/                |          |
|    Length            | 82.3     |
|    Return            | 7.31     |
|    NonzeroRewards    | 82.3     |
|    DiscountedReturn  | 7.31     |
|    Success           | 0.925    |
| time/                |          |
|    iterations        | 147      |
|    fps               | 13.8     |
|    elapsed_time      | 1.9e+04  |
|    elapsed_steps     | 376320   |
-----------------------------------
 38%|‚ñà‚ñà‚ñà‚ñä      | 378880/1000000 [5:17:43<12:22:23, 13.94steps/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 381440/1000000 [5:19:17<10:30:43, 16.35steps/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 381440/1000000 [5:19:30<10:30:43, 16.35steps/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 384000/1000000 [5:20:51<9:13:27, 18.55steps/s]                                                                 38%|‚ñà‚ñà‚ñà‚ñä      | 384000/1000000 [5:20:51<9:13:27, 18.55steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 48.2     |
|    Return            | 20.4     |
|    NonzeroRewards    | 48.2     |
|    DiscountedReturn  | 20.4     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 1.72     |
|    mean_entropy      | -1.42    |
|    mean_ent_bonus    | -0.0303  |
|    max_target_q      | 21.8     |
|    min_target_q      | -4.82    |
|    max_reward        | 16.4     |
|    min_reward        | -1.14    |
|    encoder_grad_norm | 13.2     |
|    q1_grad_norm      | 3.37     |
|    q2_grad_norm      | 3.42     |
|    actor_loss        | -2.55    |
|    ent_coeff         | 0.0213   |
|    ent_coeff_loss    | -10      |
|    pi_grad_norm      | 0.154    |
|    n_updates         | 23520    |
| time/                |          |
|    iterations        | 150      |
|    fps               | 27.1     |
|    elapsed_time      | 1.93e+04 |
|    elapsed_steps     | 384000   |
-----------------------------------
 38%|‚ñà‚ñà‚ñà‚ñä      | 384000/1000000 [5:21:10<9:13:27, 18.55steps/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 386560/1000000 [5:22:26<8:19:52, 20.45steps/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 386560/1000000 [5:22:40<8:19:52, 20.45steps/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 389120/1000000 [5:24:01<7:41:14, 22.07steps/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 389120/1000000 [5:24:20<7:41:14, 22.07steps/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 391680/1000000 [5:25:36<7:14:10, 23.35steps/s]                                                                39%|‚ñà‚ñà‚ñà‚ñâ      | 391680/1000000 [5:25:36<7:14:10, 23.35steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 47.3     |
|    Return            | 21.5     |
|    NonzeroRewards    | 47.3     |
|    DiscountedReturn  | 21.5     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 1.82     |
|    mean_entropy      | -1.66    |
|    mean_ent_bonus    | -0.0337  |
|    max_target_q      | 22.6     |
|    min_target_q      | -4.77    |
|    max_reward        | 16.6     |
|    min_reward        | -1.2     |
|    encoder_grad_norm | 14.1     |
|    q1_grad_norm      | 3.58     |
|    q2_grad_norm      | 3.63     |
|    actor_loss        | -2.68    |
|    ent_coeff         | 0.0204   |
|    ent_coeff_loss    | -9.18    |
|    pi_grad_norm      | 0.172    |
|    n_updates         | 24000    |
| time/                |          |
|    iterations        | 153      |
|    fps               | 27       |
|    elapsed_time      | 1.95e+04 |
|    elapsed_steps     | 391680   |
-----------------------------------
 39%|‚ñà‚ñà‚ñà‚ñâ      | 391680/1000000 [5:25:50<7:14:10, 23.35steps/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 394240/1000000 [5:27:11<6:55:51, 24.28steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_394240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 39%|‚ñà‚ñà‚ñà‚ñâ      | 394240/1000000 [5:27:30<6:55:51, 24.28steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 40%|‚ñà‚ñà‚ñà‚ñâ      | 396800/1000000 [5:33:19<12:03:19, 13.90steps/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 399360/1000000 [5:34:54<10:15:05, 16.28steps/s]                                                                 40%|‚ñà‚ñà‚ñà‚ñâ      | 399360/1000000 [5:34:54<10:15:05, 16.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 47.9     |
|    Return            | 21.5     |
|    NonzeroRewards    | 47.9     |
|    DiscountedReturn  | 21.5     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 1.82     |
|    mean_entropy      | -1.8     |
|    mean_ent_bonus    | -0.0353  |
|    max_target_q      | 22.3     |
|    min_target_q      | -4.69    |
|    max_reward        | 16.6     |
|    min_reward        | -1.24    |
|    encoder_grad_norm | 13.5     |
|    q1_grad_norm      | 3.48     |
|    q2_grad_norm      | 3.51     |
|    actor_loss        | -2.82    |
|    ent_coeff         | 0.0196   |
|    ent_coeff_loss    | -8.68    |
|    pi_grad_norm      | 0.171    |
|    n_updates         | 24480    |
| eval/                |          |
|    Length            | 143      |
|    Return            | 4.33     |
|    NonzeroRewards    | 143      |
|    DiscountedReturn  | 4.33     |
|    Success           | 0.824    |
| time/                |          |
|    iterations        | 156      |
|    fps               | 13.8     |
|    elapsed_time      | 2.01e+04 |
|    elapsed_steps     | 399360   |
-----------------------------------
 40%|‚ñà‚ñà‚ñà‚ñâ      | 399360/1000000 [5:35:10<10:15:05, 16.28steps/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 401920/1000000 [5:36:28<8:58:19, 18.52steps/s]  40%|‚ñà‚ñà‚ñà‚ñà      | 401920/1000000 [5:36:40<8:58:19, 18.52steps/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 404480/1000000 [5:38:03<8:06:15, 20.41steps/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 404480/1000000 [5:38:20<8:06:15, 20.41steps/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 407040/1000000 [5:39:38<7:28:44, 22.02steps/s]                                                                41%|‚ñà‚ñà‚ñà‚ñà      | 407040/1000000 [5:39:38<7:28:44, 22.02steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 45.4     |
|    Return            | 22.6     |
|    NonzeroRewards    | 45.4     |
|    DiscountedReturn  | 22.6     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 1.99     |
|    mean_entropy      | -1.88    |
|    mean_ent_bonus    | -0.0352  |
|    max_target_q      | 23.2     |
|    min_target_q      | -4.69    |
|    max_reward        | 17.1     |
|    min_reward        | -1.1     |
|    encoder_grad_norm | 15       |
|    q1_grad_norm      | 3.7      |
|    q2_grad_norm      | 3.75     |
|    actor_loss        | -2.93    |
|    ent_coeff         | 0.0188   |
|    ent_coeff_loss    | -8.5     |
|    pi_grad_norm      | 0.175    |
|    n_updates         | 24960    |
| time/                |          |
|    iterations        | 159      |
|    fps               | 27       |
|    elapsed_time      | 2.04e+04 |
|    elapsed_steps     | 407040   |
-----------------------------------
 41%|‚ñà‚ñà‚ñà‚ñà      | 407040/1000000 [5:39:50<7:28:44, 22.02steps/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 409600/1000000 [5:41:13<7:02:27, 23.29steps/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 409600/1000000 [5:41:30<7:02:27, 23.29steps/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 412160/1000000 [5:42:49<6:44:40, 24.21steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 41%|‚ñà‚ñà‚ñà‚ñà      | 412160/1000000 [5:43:00<6:44:40, 24.21steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_412160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 414720/1000000 [5:48:55<11:40:07, 13.93steps/s]                                                                 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 414720/1000000 [5:48:55<11:40:07, 13.93steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 44.2     |
|    Return            | 21.7     |
|    NonzeroRewards    | 44.2     |
|    DiscountedReturn  | 21.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 1.97     |
|    mean_entropy      | -2.1     |
|    mean_ent_bonus    | -0.0378  |
|    max_target_q      | 23.5     |
|    min_target_q      | -4.71    |
|    max_reward        | 16.7     |
|    min_reward        | -1.16    |
|    encoder_grad_norm | 15.1     |
|    q1_grad_norm      | 3.77     |
|    q2_grad_norm      | 3.81     |
|    actor_loss        | -3.02    |
|    ent_coeff         | 0.018    |
|    ent_coeff_loss    | -7.7     |
|    pi_grad_norm      | 0.17     |
|    n_updates         | 25440    |
| eval/                |          |
|    Length            | 122      |
|    Return            | -0.126   |
|    NonzeroRewards    | 122      |
|    DiscountedReturn  | -0.126   |
|    Success           | 0.852    |
| time/                |          |
|    iterations        | 162      |
|    fps               | 13.8     |
|    elapsed_time      | 2.09e+04 |
|    elapsed_steps     | 414720   |
-----------------------------------
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 417280/1000000 [5:50:30<9:55:56, 16.30steps/s]  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 417280/1000000 [5:50:40<9:55:56, 16.30steps/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 419840/1000000 [5:52:04<8:41:53, 18.53steps/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 419840/1000000 [5:52:20<8:41:53, 18.53steps/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 422400/1000000 [5:53:38<7:50:34, 20.46steps/s]                                                                42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 422400/1000000 [5:53:38<7:50:34, 20.46steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 45.8     |
|    Return            | 21.9     |
|    NonzeroRewards    | 45.8     |
|    DiscountedReturn  | 21.9     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 2.02     |
|    mean_entropy      | -2.22    |
|    mean_ent_bonus    | -0.0385  |
|    max_target_q      | 23.2     |
|    min_target_q      | -4.65    |
|    max_reward        | 16.7     |
|    min_reward        | -1.22    |
|    encoder_grad_norm | 14.9     |
|    q1_grad_norm      | 3.74     |
|    q2_grad_norm      | 3.78     |
|    actor_loss        | -3.15    |
|    ent_coeff         | 0.0173   |
|    ent_coeff_loss    | -7.29    |
|    pi_grad_norm      | 0.167    |
|    n_updates         | 25920    |
| time/                |          |
|    iterations        | 165      |
|    fps               | 27.1     |
|    elapsed_time      | 2.12e+04 |
|    elapsed_steps     | 422400   |
-----------------------------------
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 422400/1000000 [5:53:50<7:50:34, 20.46steps/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 424960/1000000 [5:55:14<7:14:53, 22.04steps/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 424960/1000000 [5:55:30<7:14:53, 22.04steps/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 427520/1000000 [5:56:48<6:48:38, 23.35steps/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 427520/1000000 [5:57:00<6:48:38, 23.35steps/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 430080/1000000 [5:58:23<6:30:41, 24.31steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_430080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 430080/1000000 [5:58:40<6:30:41, 24.31steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 430080/1000000 [6:03:01<6:30:41, 24.31steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 50.1     |
|    Return            | 21       |
|    NonzeroRewards    | 50.1     |
|    DiscountedReturn  | 21       |
|    Success           | 0.978    |
| algo/                |          |
|    critic_loss       | 2.05     |
|    mean_entropy      | -2.37    |
|    mean_ent_bonus    | -0.0394  |
|    max_target_q      | 23.4     |
|    min_target_q      | -4.69    |
|    max_reward        | 17.3     |
|    min_reward        | -1.19    |
|    encoder_grad_norm | 15.2     |
|    q1_grad_norm      | 3.91     |
|    q2_grad_norm      | 3.97     |
|    actor_loss        | -3.23    |
|    ent_coeff         | 0.0166   |
|    ent_coeff_loss    | -6.71    |
|    pi_grad_norm      | 0.161    |
|    n_updates         | 26400    |
| eval/                |          |
|    Length            | 73.3     |
|    Return            | 15.8     |
|    NonzeroRewards    | 73.3     |
|    DiscountedReturn  | 15.8     |
|    Success           | 0.951    |
| time/                |          |
|    iterations        | 168      |
|    fps               | 13.7     |
|    elapsed_time      | 2.18e+04 |
|    elapsed_steps     | 430080   |
-----------------------------------
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 432640/1000000 [6:04:36<11:25:40, 13.79steps/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 435200/1000000 [6:06:11<9:41:48, 16.18steps/s]  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 435200/1000000 [6:06:30<9:41:48, 16.18steps/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 437760/1000000 [6:07:45<8:28:52, 18.41steps/s]                                                                44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 437760/1000000 [6:07:45<8:28:52, 18.41steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 54       |
|    Return            | 20.9     |
|    NonzeroRewards    | 54       |
|    DiscountedReturn  | 20.9     |
|    Success           | 0.987    |
| algo/                |          |
|    critic_loss       | 2.08     |
|    mean_entropy      | -2.62    |
|    mean_ent_bonus    | -0.0419  |
|    max_target_q      | 24       |
|    min_target_q      | -4.59    |
|    max_reward        | 17.1     |
|    min_reward        | -1.1     |
|    encoder_grad_norm | 15.5     |
|    q1_grad_norm      | 3.94     |
|    q2_grad_norm      | 3.98     |
|    actor_loss        | -3.36    |
|    ent_coeff         | 0.016    |
|    ent_coeff_loss    | -5.77    |
|    pi_grad_norm      | 0.156    |
|    n_updates         | 26880    |
| time/                |          |
|    iterations        | 171      |
|    fps               | 27       |
|    elapsed_time      | 2.21e+04 |
|    elapsed_steps     | 437760   |
-----------------------------------
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 437760/1000000 [6:08:00<8:28:52, 18.41steps/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 440320/1000000 [6:09:20<7:38:28, 20.35steps/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 440320/1000000 [6:09:30<7:38:28, 20.35steps/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 442880/1000000 [6:10:55<7:02:30, 21.98steps/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 442880/1000000 [6:11:10<7:02:30, 21.98steps/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 445440/1000000 [6:12:30<6:37:22, 23.26steps/s]                                                                45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 445440/1000000 [6:12:30<6:37:22, 23.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 51.1     |
|    Return            | 21.3     |
|    NonzeroRewards    | 51.1     |
|    DiscountedReturn  | 21.3     |
|    Success           | 0.987    |
| algo/                |          |
|    critic_loss       | 2.17     |
|    mean_entropy      | -2.72    |
|    mean_ent_bonus    | -0.0419  |
|    max_target_q      | 24.2     |
|    min_target_q      | -4.58    |
|    max_reward        | 17.4     |
|    min_reward        | -1.17    |
|    encoder_grad_norm | 16.1     |
|    q1_grad_norm      | 4.02     |
|    q2_grad_norm      | 4.06     |
|    actor_loss        | -3.48    |
|    ent_coeff         | 0.0154   |
|    ent_coeff_loss    | -5.44    |
|    pi_grad_norm      | 0.156    |
|    n_updates         | 27360    |
| time/                |          |
|    iterations        | 174      |
|    fps               | 27       |
|    elapsed_time      | 2.24e+04 |
|    elapsed_steps     | 445440   |
-----------------------------------
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 445440/1000000 [6:12:40<6:37:22, 23.26steps/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 448000/1000000 [6:14:05<6:19:42, 24.23steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 448000/1000000 [6:14:20<6:19:42, 24.23steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_448000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 450560/1000000 [6:20:19<11:06:08, 13.75steps/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 453120/1000000 [6:21:53<9:24:43, 16.14steps/s]                                                                 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 453120/1000000 [6:21:53<9:24:43, 16.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 44.8     |
|    Return            | 21.3     |
|    NonzeroRewards    | 44.8     |
|    DiscountedReturn  | 21.3     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 2.16     |
|    mean_entropy      | -2.95    |
|    mean_ent_bonus    | -0.0439  |
|    max_target_q      | 23.8     |
|    min_target_q      | -4.66    |
|    max_reward        | 17.3     |
|    min_reward        | -1.18    |
|    encoder_grad_norm | 15.5     |
|    q1_grad_norm      | 3.94     |
|    q2_grad_norm      | 3.99     |
|    actor_loss        | -3.54    |
|    ent_coeff         | 0.0149   |
|    ent_coeff_loss    | -4.52    |
|    pi_grad_norm      | 0.155    |
|    n_updates         | 27840    |
| eval/                |          |
|    Length            | 77.6     |
|    Return            | 11       |
|    NonzeroRewards    | 77.6     |
|    DiscountedReturn  | 11       |
|    Success           | 0.926    |
| time/                |          |
|    iterations        | 177      |
|    fps               | 13.6     |
|    elapsed_time      | 2.29e+04 |
|    elapsed_steps     | 453120   |
-----------------------------------
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 453120/1000000 [6:22:10<9:24:43, 16.14steps/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 455680/1000000 [6:23:28<8:14:08, 18.36steps/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 455680/1000000 [6:23:40<8:14:08, 18.36steps/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 458240/1000000 [6:25:03<7:24:53, 20.30steps/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 458240/1000000 [6:25:20<7:24:53, 20.30steps/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 460800/1000000 [6:26:38<6:49:38, 21.94steps/s]                                                                46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 460800/1000000 [6:26:38<6:49:38, 21.94steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 43.5     |
|    Return            | 22.7     |
|    NonzeroRewards    | 43.5     |
|    DiscountedReturn  | 22.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 2.24     |
|    mean_entropy      | -3.09    |
|    mean_ent_bonus    | -0.0444  |
|    max_target_q      | 24.6     |
|    min_target_q      | -4.7     |
|    max_reward        | 17.5     |
|    min_reward        | -1.16    |
|    encoder_grad_norm | 16.9     |
|    q1_grad_norm      | 4.13     |
|    q2_grad_norm      | 4.18     |
|    actor_loss        | -3.64    |
|    ent_coeff         | 0.0144   |
|    ent_coeff_loss    | -3.96    |
|    pi_grad_norm      | 0.157    |
|    n_updates         | 28320    |
| time/                |          |
|    iterations        | 180      |
|    fps               | 27       |
|    elapsed_time      | 2.32e+04 |
|    elapsed_steps     | 460800   |
-----------------------------------
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 460800/1000000 [6:26:50<6:49:38, 21.94steps/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 463360/1000000 [6:28:13<6:24:41, 23.25steps/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 463360/1000000 [6:28:30<6:24:41, 23.25steps/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 465920/1000000 [6:29:47<6:06:52, 24.26steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 465920/1000000 [6:30:00<6:06:52, 24.26steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_465920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 468480/1000000 [6:36:00<10:42:53, 13.78steps/s]                                                                 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 468480/1000000 [6:36:01<10:42:53, 13.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 44       |
|    Return            | 22.2     |
|    NonzeroRewards    | 44       |
|    DiscountedReturn  | 22.2     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 2.22     |
|    mean_entropy      | -3.29    |
|    mean_ent_bonus    | -0.0458  |
|    max_target_q      | 24.2     |
|    min_target_q      | -4.74    |
|    max_reward        | 17.7     |
|    min_reward        | -1.2     |
|    encoder_grad_norm | 16.3     |
|    q1_grad_norm      | 3.82     |
|    q2_grad_norm      | 3.86     |
|    actor_loss        | -3.72    |
|    ent_coeff         | 0.0139   |
|    ent_coeff_loss    | -3.1     |
|    pi_grad_norm      | 0.157    |
|    n_updates         | 28800    |
| eval/                |          |
|    Length            | 70       |
|    Return            | 14.8     |
|    NonzeroRewards    | 70       |
|    DiscountedReturn  | 14.8     |
|    Success           | 0.946    |
| time/                |          |
|    iterations        | 183      |
|    fps               | 13.7     |
|    elapsed_time      | 2.38e+04 |
|    elapsed_steps     | 468480   |
-----------------------------------
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 471040/1000000 [6:37:35<9:05:24, 16.16steps/s]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 471040/1000000 [6:37:50<9:05:24, 16.16steps/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 473600/1000000 [6:39:09<7:56:50, 18.40steps/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 473600/1000000 [6:39:20<7:56:50, 18.40steps/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 476160/1000000 [6:40:45<7:09:57, 20.31steps/s]                                                                48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 476160/1000000 [6:40:45<7:09:57, 20.31steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 42.6     |
|    Return            | 22.7     |
|    NonzeroRewards    | 42.6     |
|    DiscountedReturn  | 22.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 2.26     |
|    mean_entropy      | -3.27    |
|    mean_ent_bonus    | -0.0441  |
|    max_target_q      | 24.2     |
|    min_target_q      | -4.62    |
|    max_reward        | 17.8     |
|    min_reward        | -1.24    |
|    encoder_grad_norm | 16.8     |
|    q1_grad_norm      | 4.09     |
|    q2_grad_norm      | 4.13     |
|    actor_loss        | -3.78    |
|    ent_coeff         | 0.0135   |
|    ent_coeff_loss    | -3.27    |
|    pi_grad_norm      | 0.157    |
|    n_updates         | 29280    |
| time/                |          |
|    iterations        | 186      |
|    fps               | 27       |
|    elapsed_time      | 2.4e+04  |
|    elapsed_steps     | 476160   |
-----------------------------------
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 476160/1000000 [6:41:00<7:09:57, 20.31steps/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 478720/1000000 [6:42:20<6:36:08, 21.93steps/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 478720/1000000 [6:42:30<6:36:08, 21.93steps/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 481280/1000000 [6:43:54<6:11:56, 23.24steps/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 481280/1000000 [6:44:10<6:11:56, 23.24steps/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 483840/1000000 [6:45:30<5:54:55, 24.24steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 483840/1000000 [6:45:40<5:54:55, 24.24steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_483840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 483840/1000000 [6:50:07<5:54:55, 24.24steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 46.5     |
|    Return            | 22.5     |
|    NonzeroRewards    | 46.5     |
|    DiscountedReturn  | 22.5     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 2.27     |
|    mean_entropy      | -3.31    |
|    mean_ent_bonus    | -0.0429  |
|    max_target_q      | 24.6     |
|    min_target_q      | -4.6     |
|    max_reward        | 18.2     |
|    min_reward        | -1.2     |
|    encoder_grad_norm | 17.2     |
|    q1_grad_norm      | 4        |
|    q2_grad_norm      | 4.03     |
|    actor_loss        | -3.83    |
|    ent_coeff         | 0.013    |
|    ent_coeff_loss    | -3.1     |
|    pi_grad_norm      | 0.162    |
|    n_updates         | 29760    |
| eval/                |          |
|    Length            | 78.3     |
|    Return            | 13.4     |
|    NonzeroRewards    | 78.3     |
|    DiscountedReturn  | 13.4     |
|    Success           | 0.938    |
| time/                |          |
|    iterations        | 189      |
|    fps               | 13.7     |
|    elapsed_time      | 2.46e+04 |
|    elapsed_steps     | 483840   |
-----------------------------------
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 486400/1000000 [6:51:42<10:20:38, 13.79steps/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 488960/1000000 [6:53:16<8:46:30, 16.18steps/s]  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 488960/1000000 [6:53:30<8:46:30, 16.18steps/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 491520/1000000 [6:54:50<7:40:01, 18.42steps/s]                                                                49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 491520/1000000 [6:54:50<7:40:01, 18.42steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 52.2     |
|    Return            | 21.6     |
|    NonzeroRewards    | 52.2     |
|    DiscountedReturn  | 21.6     |
|    Success           | 0.988    |
| algo/                |          |
|    critic_loss       | 2.43     |
|    mean_entropy      | -3.52    |
|    mean_ent_bonus    | -0.0443  |
|    max_target_q      | 25.7     |
|    min_target_q      | -4.55    |
|    max_reward        | 18.2     |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 18.8     |
|    q1_grad_norm      | 4.57     |
|    q2_grad_norm      | 4.62     |
|    actor_loss        | -3.95    |
|    ent_coeff         | 0.0126   |
|    ent_coeff_loss    | -2.21    |
|    pi_grad_norm      | 0.166    |
|    n_updates         | 30240    |
| time/                |          |
|    iterations        | 192      |
|    fps               | 27.1     |
|    elapsed_time      | 2.49e+04 |
|    elapsed_steps     | 491520   |
-----------------------------------
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 491520/1000000 [6:55:00<7:40:01, 18.42steps/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 494080/1000000 [6:56:26<6:54:44, 20.33steps/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 494080/1000000 [6:56:40<6:54:44, 20.33steps/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 496640/1000000 [6:58:01<6:22:14, 21.95steps/s]ReplayBuffer: Replay buffer is now full. cursor=0.
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 496640/1000000 [6:58:20<6:22:14, 21.95steps/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 499200/1000000 [6:59:35<5:58:55, 23.25steps/s]                                                                50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 499200/1000000 [6:59:35<5:58:55, 23.25steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 41.5     |
|    Return            | 23.6     |
|    NonzeroRewards    | 41.5     |
|    DiscountedReturn  | 23.6     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 2.43     |
|    mean_entropy      | -3.69    |
|    mean_ent_bonus    | -0.0453  |
|    max_target_q      | 25       |
|    min_target_q      | -4.54    |
|    max_reward        | 17.9     |
|    min_reward        | -1.26    |
|    encoder_grad_norm | 18.3     |
|    q1_grad_norm      | 4.44     |
|    q2_grad_norm      | 4.47     |
|    actor_loss        | -4.01    |
|    ent_coeff         | 0.0123   |
|    ent_coeff_loss    | -1.55    |
|    pi_grad_norm      | 0.159    |
|    n_updates         | 30720    |
| time/                |          |
|    iterations        | 195      |
|    fps               | 26.9     |
|    elapsed_time      | 2.52e+04 |
|    elapsed_steps     | 499200   |
-----------------------------------
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 499200/1000000 [6:59:50<5:58:55, 23.25steps/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 501760/1000000 [7:01:10<5:42:29, 24.25steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_501760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 501760/1000000 [7:01:30<5:42:29, 24.25steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 504320/1000000 [7:07:23<9:58:47, 13.80steps/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 506880/1000000 [7:08:57<8:28:12, 16.17steps/s]                                                                51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 506880/1000000 [7:08:57<8:28:12, 16.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.3     |
|    Return            | 22.5     |
|    NonzeroRewards    | 39.3     |
|    DiscountedReturn  | 22.5     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 2.46     |
|    mean_entropy      | -3.76    |
|    mean_ent_bonus    | -0.045   |
|    max_target_q      | 25.5     |
|    min_target_q      | -4.53    |
|    max_reward        | 18.3     |
|    min_reward        | -1.22    |
|    encoder_grad_norm | 19.1     |
|    q1_grad_norm      | 4.6      |
|    q2_grad_norm      | 4.65     |
|    actor_loss        | -4.13    |
|    ent_coeff         | 0.012    |
|    ent_coeff_loss    | -1.16    |
|    pi_grad_norm      | 0.159    |
|    n_updates         | 31200    |
| eval/                |          |
|    Length            | 74.8     |
|    Return            | 13.6     |
|    NonzeroRewards    | 74.8     |
|    DiscountedReturn  | 13.6     |
|    Success           | 0.969    |
| time/                |          |
|    iterations        | 198      |
|    fps               | 13.7     |
|    elapsed_time      | 2.57e+04 |
|    elapsed_steps     | 506880   |
-----------------------------------
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 506880/1000000 [7:09:10<8:28:12, 16.17steps/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 509440/1000000 [7:10:32<7:24:09, 18.41steps/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 509440/1000000 [7:10:50<7:24:09, 18.41steps/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 512000/1000000 [7:12:06<6:39:18, 20.37steps/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 512000/1000000 [7:12:20<6:39:18, 20.37steps/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 514560/1000000 [7:13:40<6:06:51, 22.05steps/s]                                                                51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 514560/1000000 [7:13:40<6:06:51, 22.05steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 53.9     |
|    Return            | 21       |
|    NonzeroRewards    | 53.9     |
|    DiscountedReturn  | 21       |
|    Success           | 0.982    |
| algo/                |          |
|    critic_loss       | 2.57     |
|    mean_entropy      | -4.01    |
|    mean_ent_bonus    | -0.0476  |
|    max_target_q      | 25.5     |
|    min_target_q      | -4.56    |
|    max_reward        | 18.5     |
|    min_reward        | -1.24    |
|    encoder_grad_norm | 19.3     |
|    q1_grad_norm      | 4.6      |
|    q2_grad_norm      | 4.66     |
|    actor_loss        | -4.26    |
|    ent_coeff         | 0.0119   |
|    ent_coeff_loss    | -0.0486  |
|    pi_grad_norm      | 0.159    |
|    n_updates         | 31680    |
| time/                |          |
|    iterations        | 201      |
|    fps               | 27.2     |
|    elapsed_time      | 2.6e+04  |
|    elapsed_steps     | 514560   |
-----------------------------------
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 514560/1000000 [7:13:50<6:06:51, 22.05steps/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 517120/1000000 [7:15:15<5:45:11, 23.31steps/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 517120/1000000 [7:15:30<5:45:11, 23.31steps/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 519680/1000000 [7:16:50<5:29:19, 24.31steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 519680/1000000 [7:17:00<5:29:19, 24.31steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_519680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 522240/1000000 [7:23:05<9:39:53, 13.73steps/s]                                                                52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 522240/1000000 [7:23:05<9:39:53, 13.73steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 37.1     |
|    Return            | 24       |
|    NonzeroRewards    | 37.1     |
|    DiscountedReturn  | 24       |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 2.55     |
|    mean_entropy      | -4.11    |
|    mean_ent_bonus    | -0.049   |
|    max_target_q      | 25.6     |
|    min_target_q      | -4.51    |
|    max_reward        | 18.4     |
|    min_reward        | -1.41    |
|    encoder_grad_norm | 19.3     |
|    q1_grad_norm      | 4.52     |
|    q2_grad_norm      | 4.55     |
|    actor_loss        | -4.37    |
|    ent_coeff         | 0.0119   |
|    ent_coeff_loss    | 0.383    |
|    pi_grad_norm      | 0.168    |
|    n_updates         | 32160    |
| eval/                |          |
|    Length            | 68       |
|    Return            | 17.7     |
|    NonzeroRewards    | 68       |
|    DiscountedReturn  | 17.7     |
|    Success           | 0.949    |
| time/                |          |
|    iterations        | 204      |
|    fps               | 13.6     |
|    elapsed_time      | 2.66e+04 |
|    elapsed_steps     | 522240   |
-----------------------------------
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 524800/1000000 [7:24:40<8:11:33, 16.11steps/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 524800/1000000 [7:24:50<8:11:33, 16.11steps/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 527360/1000000 [7:26:14<7:09:25, 18.34steps/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 527360/1000000 [7:26:30<7:09:25, 18.34steps/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 529920/1000000 [7:27:49<6:25:35, 20.32steps/s]                                                                53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 529920/1000000 [7:27:49<6:25:35, 20.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 45.1     |
|    Return            | 22.3     |
|    NonzeroRewards    | 45.1     |
|    DiscountedReturn  | 22.3     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 2.55     |
|    mean_entropy      | -4.09    |
|    mean_ent_bonus    | -0.0492  |
|    max_target_q      | 25.8     |
|    min_target_q      | -4.47    |
|    max_reward        | 18.6     |
|    min_reward        | -1.23    |
|    encoder_grad_norm | 19.6     |
|    q1_grad_norm      | 4.64     |
|    q2_grad_norm      | 4.68     |
|    actor_loss        | -4.46    |
|    ent_coeff         | 0.012    |
|    ent_coeff_loss    | 0.267    |
|    pi_grad_norm      | 0.163    |
|    n_updates         | 32640    |
| time/                |          |
|    iterations        | 207      |
|    fps               | 27.1     |
|    elapsed_time      | 2.69e+04 |
|    elapsed_steps     | 529920   |
-----------------------------------
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 529920/1000000 [7:28:00<6:25:35, 20.32steps/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 532480/1000000 [7:29:25<5:55:59, 21.89steps/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 532480/1000000 [7:29:40<5:55:59, 21.89steps/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 535040/1000000 [7:31:00<5:34:35, 23.16steps/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 535040/1000000 [7:31:10<5:34:35, 23.16steps/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 537600/1000000 [7:32:36<5:19:17, 24.14steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 537600/1000000 [7:32:50<5:19:17, 24.14steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_537600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 537600/1000000 [7:37:12<5:19:17, 24.14steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 43.9     |
|    Return            | 22.9     |
|    NonzeroRewards    | 43.9     |
|    DiscountedReturn  | 22.9     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 2.65     |
|    mean_entropy      | -4.02    |
|    mean_ent_bonus    | -0.0484  |
|    max_target_q      | 26       |
|    min_target_q      | -4.55    |
|    max_reward        | 19.1     |
|    min_reward        | -1.32    |
|    encoder_grad_norm | 20.1     |
|    q1_grad_norm      | 4.57     |
|    q2_grad_norm      | 4.6      |
|    actor_loss        | -4.5     |
|    ent_coeff         | 0.012    |
|    ent_coeff_loss    | -0.0229  |
|    pi_grad_norm      | 0.158    |
|    n_updates         | 33120    |
| eval/                |          |
|    Length            | 90.8     |
|    Return            | 7.93     |
|    NonzeroRewards    | 90.8     |
|    DiscountedReturn  | 7.93     |
|    Success           | 0.901    |
| time/                |          |
|    iterations        | 210      |
|    fps               | 13.6     |
|    elapsed_time      | 2.74e+04 |
|    elapsed_steps     | 537600   |
-----------------------------------
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 540160/1000000 [7:38:49<9:17:38, 13.74steps/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 542720/1000000 [7:40:23<7:52:16, 16.14steps/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 542720/1000000 [7:40:40<7:52:16, 16.14steps/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 545280/1000000 [7:41:58<6:52:21, 18.38steps/s]                                                                55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 545280/1000000 [7:41:58<6:52:21, 18.38steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 41.4     |
|    Return            | 23.4     |
|    NonzeroRewards    | 41.4     |
|    DiscountedReturn  | 23.4     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 2.76     |
|    mean_entropy      | -4.05    |
|    mean_ent_bonus    | -0.049   |
|    max_target_q      | 26.1     |
|    min_target_q      | -4.62    |
|    max_reward        | 19.4     |
|    min_reward        | -1.25    |
|    encoder_grad_norm | 20.6     |
|    q1_grad_norm      | 4.53     |
|    q2_grad_norm      | 4.58     |
|    actor_loss        | -4.61    |
|    ent_coeff         | 0.0121   |
|    ent_coeff_loss    | 0.0787   |
|    pi_grad_norm      | 0.161    |
|    n_updates         | 33600    |
| time/                |          |
|    iterations        | 213      |
|    fps               | 26.9     |
|    elapsed_time      | 2.77e+04 |
|    elapsed_steps     | 545280   |
-----------------------------------
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 545280/1000000 [7:42:10<6:52:21, 18.38steps/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 547840/1000000 [7:43:32<6:10:19, 20.35steps/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 547840/1000000 [7:43:50<6:10:19, 20.35steps/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 550400/1000000 [7:45:07<5:40:58, 21.98steps/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 550400/1000000 [7:45:20<5:40:58, 21.98steps/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 552960/1000000 [7:46:42<5:20:32, 23.24steps/s]                                                                55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 552960/1000000 [7:46:42<5:20:32, 23.24steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 45.9     |
|    Return            | 20.9     |
|    NonzeroRewards    | 45.9     |
|    DiscountedReturn  | 20.9     |
|    Success           | 0.988    |
| algo/                |          |
|    critic_loss       | 2.82     |
|    mean_entropy      | -4.02    |
|    mean_ent_bonus    | -0.0488  |
|    max_target_q      | 25.8     |
|    min_target_q      | -4.95    |
|    max_reward        | 19.3     |
|    min_reward        | -1.26    |
|    encoder_grad_norm | 21.1     |
|    q1_grad_norm      | 4.79     |
|    q2_grad_norm      | 4.82     |
|    actor_loss        | -4.63    |
|    ent_coeff         | 0.0121   |
|    ent_coeff_loss    | 0.00233  |
|    pi_grad_norm      | 0.163    |
|    n_updates         | 34080    |
| time/                |          |
|    iterations        | 216      |
|    fps               | 27       |
|    elapsed_time      | 2.8e+04  |
|    elapsed_steps     | 552960   |
-----------------------------------
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 552960/1000000 [7:47:00<5:20:32, 23.24steps/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 555520/1000000 [7:48:17<5:05:50, 24.22steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 555520/1000000 [7:48:30<5:05:50, 24.22steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_555520.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 558080/1000000 [7:54:31<8:55:17, 13.76steps/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 560640/1000000 [7:56:05<7:33:32, 16.15steps/s]                                                                56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 560640/1000000 [7:56:05<7:33:32, 16.15steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 47.6     |
|    Return            | 22.1     |
|    NonzeroRewards    | 47.6     |
|    DiscountedReturn  | 22.1     |
|    Success           | 0.988    |
| algo/                |          |
|    critic_loss       | 2.86     |
|    mean_entropy      | -4.01    |
|    mean_ent_bonus    | -0.0482  |
|    max_target_q      | 26.3     |
|    min_target_q      | -5.26    |
|    max_reward        | 19.6     |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 21.8     |
|    q1_grad_norm      | 4.88     |
|    q2_grad_norm      | 4.91     |
|    actor_loss        | -4.68    |
|    ent_coeff         | 0.012    |
|    ent_coeff_loss    | -0.0892  |
|    pi_grad_norm      | 0.174    |
|    n_updates         | 34560    |
| eval/                |          |
|    Length            | 62.4     |
|    Return            | 12.2     |
|    NonzeroRewards    | 62.4     |
|    DiscountedReturn  | 12.2     |
|    Success           | 0.949    |
| time/                |          |
|    iterations        | 219      |
|    fps               | 13.6     |
|    elapsed_time      | 2.86e+04 |
|    elapsed_steps     | 560640   |
-----------------------------------
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 560640/1000000 [7:56:20<7:33:32, 16.15steps/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 563200/1000000 [7:57:39<6:36:02, 18.38steps/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 563200/1000000 [7:57:50<6:36:02, 18.38steps/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 565760/1000000 [7:59:14<5:55:27, 20.36steps/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 565760/1000000 [7:59:30<5:55:27, 20.36steps/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 568320/1000000 [8:00:48<5:27:12, 21.99steps/s]                                                                57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 568320/1000000 [8:00:48<5:27:12, 21.99steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.5     |
|    Return            | 23.5     |
|    NonzeroRewards    | 39.5     |
|    DiscountedReturn  | 23.5     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 2.97     |
|    mean_entropy      | -4.12    |
|    mean_ent_bonus    | -0.05    |
|    max_target_q      | 26.7     |
|    min_target_q      | -5.34    |
|    max_reward        | 19.6     |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 22.6     |
|    q1_grad_norm      | 5.07     |
|    q2_grad_norm      | 5.11     |
|    actor_loss        | -4.81    |
|    ent_coeff         | 0.0122   |
|    ent_coeff_loss    | 0.308    |
|    pi_grad_norm      | 0.159    |
|    n_updates         | 35040    |
| time/                |          |
|    iterations        | 222      |
|    fps               | 27.1     |
|    elapsed_time      | 2.88e+04 |
|    elapsed_steps     | 568320   |
-----------------------------------
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 568320/1000000 [8:01:00<5:27:12, 21.99steps/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 570880/1000000 [8:02:25<5:08:19, 23.20steps/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 570880/1000000 [8:02:40<5:08:19, 23.20steps/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 573440/1000000 [8:04:00<4:53:54, 24.19steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 573440/1000000 [8:04:10<4:53:54, 24.19steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_573440.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 576000/1000000 [8:10:12<8:32:17, 13.79steps/s]                                                                58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 576000/1000000 [8:10:12<8:32:17, 13.79steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 45.5     |
|    Return            | 22.3     |
|    NonzeroRewards    | 45.5     |
|    DiscountedReturn  | 22.3     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 2.97     |
|    mean_entropy      | -4.17    |
|    mean_ent_bonus    | -0.0518  |
|    max_target_q      | 27.1     |
|    min_target_q      | -5.45    |
|    max_reward        | 19.6     |
|    min_reward        | -1.33    |
|    encoder_grad_norm | 22.8     |
|    q1_grad_norm      | 5.34     |
|    q2_grad_norm      | 5.38     |
|    actor_loss        | -4.95    |
|    ent_coeff         | 0.0124   |
|    ent_coeff_loss    | 0.584    |
|    pi_grad_norm      | 0.169    |
|    n_updates         | 35520    |
| eval/                |          |
|    Length            | 74.6     |
|    Return            | 15.3     |
|    NonzeroRewards    | 74.6     |
|    DiscountedReturn  | 15.3     |
|    Success           | 0.943    |
| time/                |          |
|    iterations        | 225      |
|    fps               | 13.6     |
|    elapsed_time      | 2.94e+04 |
|    elapsed_steps     | 576000   |
-----------------------------------
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 578560/1000000 [8:11:45<7:13:39, 16.20steps/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 578560/1000000 [8:12:00<7:13:39, 16.20steps/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 581120/1000000 [8:13:20<6:18:46, 18.43steps/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 581120/1000000 [8:13:30<6:18:46, 18.43steps/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 583680/1000000 [8:14:54<5:40:06, 20.40steps/s]                                                                58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 583680/1000000 [8:14:54<5:40:06, 20.40steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 40.9     |
|    Return            | 24       |
|    NonzeroRewards    | 40.9     |
|    DiscountedReturn  | 24       |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.12     |
|    mean_entropy      | -4.01    |
|    mean_ent_bonus    | -0.0503  |
|    max_target_q      | 26.9     |
|    min_target_q      | -5.49    |
|    max_reward        | 19.7     |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 23.7     |
|    q1_grad_norm      | 4.99     |
|    q2_grad_norm      | 5        |
|    actor_loss        | -5.03    |
|    ent_coeff         | 0.0125   |
|    ent_coeff_loss    | -0.138   |
|    pi_grad_norm      | 0.154    |
|    n_updates         | 36000    |
| time/                |          |
|    iterations        | 228      |
|    fps               | 27.2     |
|    elapsed_time      | 2.97e+04 |
|    elapsed_steps     | 583680   |
-----------------------------------
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 583680/1000000 [8:15:10<5:40:06, 20.40steps/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 586240/1000000 [8:16:29<5:13:20, 22.01steps/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 586240/1000000 [8:16:40<5:13:20, 22.01steps/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 588800/1000000 [8:18:03<4:53:58, 23.31steps/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 588800/1000000 [8:18:20<4:53:58, 23.31steps/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 591360/1000000 [8:19:38<4:40:06, 24.31steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 591360/1000000 [8:19:50<4:40:06, 24.31steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_591360.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 591360/1000000 [8:24:15<4:40:06, 24.31steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 41.5     |
|    Return            | 22.7     |
|    NonzeroRewards    | 41.5     |
|    DiscountedReturn  | 22.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.04     |
|    mean_entropy      | -4.07    |
|    mean_ent_bonus    | -0.0509  |
|    max_target_q      | 26.8     |
|    min_target_q      | -5.51    |
|    max_reward        | 19.9     |
|    min_reward        | -1.38    |
|    encoder_grad_norm | 23.2     |
|    q1_grad_norm      | 5.06     |
|    q2_grad_norm      | 5.06     |
|    actor_loss        | -5.11    |
|    ent_coeff         | 0.0125   |
|    ent_coeff_loss    | 0.087    |
|    pi_grad_norm      | 0.154    |
|    n_updates         | 36480    |
| eval/                |          |
|    Length            | 64.5     |
|    Return            | 11.9     |
|    NonzeroRewards    | 64.5     |
|    DiscountedReturn  | 11.9     |
|    Success           | 0.953    |
| time/                |          |
|    iterations        | 231      |
|    fps               | 13.7     |
|    elapsed_time      | 3.03e+04 |
|    elapsed_steps     | 591360   |
-----------------------------------
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 593920/1000000 [8:25:52<8:11:36, 13.77steps/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 596480/1000000 [8:27:26<6:55:58, 16.17steps/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 596480/1000000 [8:27:40<6:55:58, 16.17steps/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 599040/1000000 [8:29:00<6:02:53, 18.42steps/s]                                                                60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 599040/1000000 [8:29:00<6:02:53, 18.42steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 49.8     |
|    Return            | 22.2     |
|    NonzeroRewards    | 49.8     |
|    DiscountedReturn  | 22.2     |
|    Success           | 0.987    |
| algo/                |          |
|    critic_loss       | 3.09     |
|    mean_entropy      | -4.05    |
|    mean_ent_bonus    | -0.0507  |
|    max_target_q      | 27.1     |
|    min_target_q      | -5.6     |
|    max_reward        | 20.2     |
|    min_reward        | -1.39    |
|    encoder_grad_norm | 24.5     |
|    q1_grad_norm      | 5.24     |
|    q2_grad_norm      | 5.27     |
|    actor_loss        | -5.12    |
|    ent_coeff         | 0.0125   |
|    ent_coeff_loss    | 0.0341   |
|    pi_grad_norm      | 0.161    |
|    n_updates         | 36960    |
| time/                |          |
|    iterations        | 234      |
|    fps               | 26.9     |
|    elapsed_time      | 3.05e+04 |
|    elapsed_steps     | 599040   |
-----------------------------------
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 599040/1000000 [8:29:10<6:02:53, 18.42steps/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 601600/1000000 [8:30:34<5:25:48, 20.38steps/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 601600/1000000 [8:30:50<5:25:48, 20.38steps/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 604160/1000000 [8:32:09<4:59:58, 21.99steps/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 604160/1000000 [8:32:20<4:59:58, 21.99steps/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 606720/1000000 [8:33:44<4:41:33, 23.28steps/s]                                                                61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 606720/1000000 [8:33:44<4:41:33, 23.28steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 51.8     |
|    Return            | 20.9     |
|    NonzeroRewards    | 51.8     |
|    DiscountedReturn  | 20.9     |
|    Success           | 0.976    |
| algo/                |          |
|    critic_loss       | 3.15     |
|    mean_entropy      | -3.94    |
|    mean_ent_bonus    | -0.0492  |
|    max_target_q      | 27.1     |
|    min_target_q      | -5.66    |
|    max_reward        | 20.1     |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 24.4     |
|    q1_grad_norm      | 5.09     |
|    q2_grad_norm      | 5.1      |
|    actor_loss        | -5.2     |
|    ent_coeff         | 0.0125   |
|    ent_coeff_loss    | -0.455   |
|    pi_grad_norm      | 0.175    |
|    n_updates         | 37440    |
| time/                |          |
|    iterations        | 237      |
|    fps               | 27       |
|    elapsed_time      | 3.08e+04 |
|    elapsed_steps     | 606720   |
-----------------------------------
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 606720/1000000 [8:34:00<4:41:33, 23.28steps/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 609280/1000000 [8:35:20<4:28:56, 24.21steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 609280/1000000 [8:35:30<4:28:56, 24.21steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_609280.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 611840/1000000 [8:41:33<7:49:27, 13.78steps/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 614400/1000000 [8:43:07<6:37:13, 16.18steps/s]                                                                61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 614400/1000000 [8:43:07<6:37:13, 16.18steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 41.6     |
|    Return            | 23       |
|    NonzeroRewards    | 41.6     |
|    DiscountedReturn  | 23       |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.19     |
|    mean_entropy      | -3.96    |
|    mean_ent_bonus    | -0.0479  |
|    max_target_q      | 27.3     |
|    min_target_q      | -5.78    |
|    max_reward        | 20.2     |
|    min_reward        | -1.42    |
|    encoder_grad_norm | 25       |
|    q1_grad_norm      | 5.31     |
|    q2_grad_norm      | 5.3      |
|    actor_loss        | -5.22    |
|    ent_coeff         | 0.0121   |
|    ent_coeff_loss    | -0.339   |
|    pi_grad_norm      | 0.182    |
|    n_updates         | 37920    |
| eval/                |          |
|    Length            | 63.7     |
|    Return            | 17.8     |
|    NonzeroRewards    | 63.7     |
|    DiscountedReturn  | 17.8     |
|    Success           | 0.978    |
| time/                |          |
|    iterations        | 240      |
|    fps               | 13.7     |
|    elapsed_time      | 3.14e+04 |
|    elapsed_steps     | 614400   |
-----------------------------------
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 614400/1000000 [8:43:20<6:37:13, 16.18steps/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 616960/1000000 [8:44:41<5:46:40, 18.41steps/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 616960/1000000 [8:45:00<5:46:40, 18.41steps/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 619520/1000000 [8:46:15<5:10:56, 20.39steps/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 619520/1000000 [8:46:30<5:10:56, 20.39steps/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 622080/1000000 [8:47:50<4:46:47, 21.96steps/s]                                                                62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 622080/1000000 [8:47:50<4:46:47, 21.96steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 47.3     |
|    Return            | 20.6     |
|    NonzeroRewards    | 47.3     |
|    DiscountedReturn  | 20.6     |
|    Success           | 0.983    |
| algo/                |          |
|    critic_loss       | 3.25     |
|    mean_entropy      | -4.08    |
|    mean_ent_bonus    | -0.0493  |
|    max_target_q      | 27.4     |
|    min_target_q      | -5.77    |
|    max_reward        | 20.8     |
|    min_reward        | -1.53    |
|    encoder_grad_norm | 25.4     |
|    q1_grad_norm      | 5.11     |
|    q2_grad_norm      | 5.14     |
|    actor_loss        | -5.32    |
|    ent_coeff         | 0.0121   |
|    ent_coeff_loss    | 0.177    |
|    pi_grad_norm      | 0.157    |
|    n_updates         | 38400    |
| time/                |          |
|    iterations        | 243      |
|    fps               | 27.1     |
|    elapsed_time      | 3.17e+04 |
|    elapsed_steps     | 622080   |
-----------------------------------
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 622080/1000000 [8:48:10<4:46:47, 21.96steps/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 624640/1000000 [8:49:26<4:29:43, 23.19steps/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 624640/1000000 [8:49:40<4:29:43, 23.19steps/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 627200/1000000 [8:51:01<4:16:42, 24.20steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_627200.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 627200/1000000 [8:51:20<4:16:42, 24.20steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 629760/1000000 [8:57:14<7:27:54, 13.78steps/s]                                                                63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 629760/1000000 [8:57:14<7:27:54, 13.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 40.8     |
|    Return            | 23.3     |
|    NonzeroRewards    | 40.8     |
|    DiscountedReturn  | 23.3     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.27     |
|    mean_entropy      | -4.05    |
|    mean_ent_bonus    | -0.0494  |
|    max_target_q      | 28.1     |
|    min_target_q      | -5.86    |
|    max_reward        | 21       |
|    min_reward        | -1.46    |
|    encoder_grad_norm | 26.2     |
|    q1_grad_norm      | 5.36     |
|    q2_grad_norm      | 5.38     |
|    actor_loss        | -5.38    |
|    ent_coeff         | 0.0122   |
|    ent_coeff_loss    | 0.0628   |
|    pi_grad_norm      | 0.171    |
|    n_updates         | 38880    |
| eval/                |          |
|    Length            | 62.2     |
|    Return            | 18.7     |
|    NonzeroRewards    | 62.2     |
|    DiscountedReturn  | 18.7     |
|    Success           | 0.977    |
| time/                |          |
|    iterations        | 246      |
|    fps               | 13.6     |
|    elapsed_time      | 3.22e+04 |
|    elapsed_steps     | 629760   |
-----------------------------------
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 632320/1000000 [8:58:49<6:19:33, 16.14steps/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 632320/1000000 [8:59:00<6:19:33, 16.14steps/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 634880/1000000 [9:00:23<5:30:57, 18.39steps/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 634880/1000000 [9:00:40<5:30:57, 18.39steps/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 637440/1000000 [9:01:57<4:56:41, 20.37steps/s]                                                                64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 637440/1000000 [9:01:57<4:56:41, 20.37steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.3     |
|    Return            | 23.7     |
|    NonzeroRewards    | 38.3     |
|    DiscountedReturn  | 23.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.21     |
|    mean_entropy      | -4.03    |
|    mean_ent_bonus    | -0.0493  |
|    max_target_q      | 27.4     |
|    min_target_q      | -6.09    |
|    max_reward        | 20.2     |
|    min_reward        | -1.48    |
|    encoder_grad_norm | 26.1     |
|    q1_grad_norm      | 5.8      |
|    q2_grad_norm      | 5.82     |
|    actor_loss        | -5.39    |
|    ent_coeff         | 0.0122   |
|    ent_coeff_loss    | -0.0113  |
|    pi_grad_norm      | 0.163    |
|    n_updates         | 39360    |
| time/                |          |
|    iterations        | 249      |
|    fps               | 27.1     |
|    elapsed_time      | 3.25e+04 |
|    elapsed_steps     | 637440   |
-----------------------------------
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 637440/1000000 [9:02:10<4:56:41, 20.37steps/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 640000/1000000 [9:03:33<4:33:17, 21.95steps/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 640000/1000000 [9:03:50<4:33:17, 21.95steps/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 642560/1000000 [9:05:07<4:16:08, 23.26steps/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 642560/1000000 [9:05:20<4:16:08, 23.26steps/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 645120/1000000 [9:06:43<4:04:05, 24.23steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_645120.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 645120/1000000 [9:07:00<4:04:05, 24.23steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 645120/1000000 [9:11:19<4:04:05, 24.23steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 49.2     |
|    Return            | 22.4     |
|    NonzeroRewards    | 49.2     |
|    DiscountedReturn  | 22.4     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 3.23     |
|    mean_entropy      | -4.03    |
|    mean_ent_bonus    | -0.049   |
|    max_target_q      | 27.5     |
|    min_target_q      | -6.01    |
|    max_reward        | 20.4     |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 26.1     |
|    q1_grad_norm      | 5.27     |
|    q2_grad_norm      | 5.28     |
|    actor_loss        | -5.43    |
|    ent_coeff         | 0.0122   |
|    ent_coeff_loss    | -0.103   |
|    pi_grad_norm      | 0.168    |
|    n_updates         | 39840    |
| eval/                |          |
|    Length            | 71.2     |
|    Return            | 13.3     |
|    NonzeroRewards    | 71.2     |
|    DiscountedReturn  | 13.3     |
|    Success           | 0.943    |
| time/                |          |
|    iterations        | 252      |
|    fps               | 13.7     |
|    elapsed_time      | 3.31e+04 |
|    elapsed_steps     | 645120   |
-----------------------------------
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 647680/1000000 [9:12:55<7:05:42, 13.79steps/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 650240/1000000 [9:14:29<5:59:57, 16.19steps/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 650240/1000000 [9:14:40<5:59:57, 16.19steps/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 652800/1000000 [9:16:03<5:14:17, 18.41steps/s]                                                                65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 652800/1000000 [9:16:03<5:14:17, 18.41steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 45.2     |
|    Return            | 22.5     |
|    NonzeroRewards    | 45.2     |
|    DiscountedReturn  | 22.5     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 3.24     |
|    mean_entropy      | -4.11    |
|    mean_ent_bonus    | -0.0502  |
|    max_target_q      | 27.5     |
|    min_target_q      | -5.75    |
|    max_reward        | 20.4     |
|    min_reward        | -1.47    |
|    encoder_grad_norm | 26.5     |
|    q1_grad_norm      | 5.48     |
|    q2_grad_norm      | 5.52     |
|    actor_loss        | -5.49    |
|    ent_coeff         | 0.0122   |
|    ent_coeff_loss    | 0.286    |
|    pi_grad_norm      | 0.161    |
|    n_updates         | 40320    |
| time/                |          |
|    iterations        | 255      |
|    fps               | 27       |
|    elapsed_time      | 3.34e+04 |
|    elapsed_steps     | 652800   |
-----------------------------------
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 652800/1000000 [9:16:20<5:14:17, 18.41steps/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 655360/1000000 [9:17:38<4:42:14, 20.35steps/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 655360/1000000 [9:17:50<4:42:14, 20.35steps/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 657920/1000000 [9:19:13<4:19:28, 21.97steps/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 657920/1000000 [9:19:30<4:19:28, 21.97steps/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 660480/1000000 [9:20:48<4:03:11, 23.27steps/s]                                                                66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 660480/1000000 [9:20:48<4:03:11, 23.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.1     |
|    Return            | 23.7     |
|    NonzeroRewards    | 38.1     |
|    DiscountedReturn  | 23.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.42     |
|    mean_entropy      | -4.04    |
|    mean_ent_bonus    | -0.0499  |
|    max_target_q      | 27.6     |
|    min_target_q      | -5.68    |
|    max_reward        | 21.1     |
|    min_reward        | -1.35    |
|    encoder_grad_norm | 27.7     |
|    q1_grad_norm      | 6.24     |
|    q2_grad_norm      | 6.28     |
|    actor_loss        | -5.53    |
|    ent_coeff         | 0.0123   |
|    ent_coeff_loss    | -0.047   |
|    pi_grad_norm      | 0.172    |
|    n_updates         | 40800    |
| time/                |          |
|    iterations        | 258      |
|    fps               | 27       |
|    elapsed_time      | 3.36e+04 |
|    elapsed_steps     | 660480   |
-----------------------------------
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 660480/1000000 [9:21:00<4:03:11, 23.27steps/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 663040/1000000 [9:22:23<3:51:30, 24.26steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_663040.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 663040/1000000 [9:22:40<3:51:30, 24.26steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 665600/1000000 [9:28:40<6:46:44, 13.70steps/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 668160/1000000 [9:30:14<5:43:49, 16.09steps/s]                                                                67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 668160/1000000 [9:30:14<5:43:49, 16.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 45.7     |
|    Return            | 23       |
|    NonzeroRewards    | 45.7     |
|    DiscountedReturn  | 23       |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.46     |
|    mean_entropy      | -4.08    |
|    mean_ent_bonus    | -0.0503  |
|    max_target_q      | 28       |
|    min_target_q      | -5.73    |
|    max_reward        | 20.3     |
|    min_reward        | -1.36    |
|    encoder_grad_norm | 28.2     |
|    q1_grad_norm      | 5.39     |
|    q2_grad_norm      | 5.39     |
|    actor_loss        | -5.59    |
|    ent_coeff         | 0.0123   |
|    ent_coeff_loss    | 0.0676   |
|    pi_grad_norm      | 0.184    |
|    n_updates         | 41280    |
| eval/                |          |
|    Length            | 61.8     |
|    Return            | 16.7     |
|    NonzeroRewards    | 61.8     |
|    DiscountedReturn  | 16.7     |
|    Success           | 0.962    |
| time/                |          |
|    iterations        | 261      |
|    fps               | 13.6     |
|    elapsed_time      | 3.42e+04 |
|    elapsed_steps     | 668160   |
-----------------------------------
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 668160/1000000 [9:30:30<5:43:49, 16.09steps/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 670720/1000000 [9:31:48<4:59:28, 18.32steps/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 670720/1000000 [9:32:00<4:59:28, 18.32steps/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 673280/1000000 [9:33:23<4:28:19, 20.29steps/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 673280/1000000 [9:33:40<4:28:19, 20.29steps/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 675840/1000000 [9:34:59<4:06:55, 21.88steps/s]                                                                68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 675840/1000000 [9:34:59<4:06:55, 21.88steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 42       |
|    Return            | 23.2     |
|    NonzeroRewards    | 42       |
|    DiscountedReturn  | 23.2     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.48     |
|    mean_entropy      | -3.89    |
|    mean_ent_bonus    | -0.0472  |
|    max_target_q      | 27.9     |
|    min_target_q      | -5.74    |
|    max_reward        | 21.3     |
|    min_reward        | -1.44    |
|    encoder_grad_norm | 28.8     |
|    q1_grad_norm      | 5.76     |
|    q2_grad_norm      | 5.76     |
|    actor_loss        | -5.62    |
|    ent_coeff         | 0.0121   |
|    ent_coeff_loss    | -0.739   |
|    pi_grad_norm      | 0.193    |
|    n_updates         | 41760    |
| time/                |          |
|    iterations        | 264      |
|    fps               | 27       |
|    elapsed_time      | 3.45e+04 |
|    elapsed_steps     | 675840   |
-----------------------------------
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 675840/1000000 [9:35:10<4:06:55, 21.88steps/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 678400/1000000 [9:36:34<3:51:38, 23.14steps/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 678400/1000000 [9:36:50<3:51:38, 23.14steps/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 680960/1000000 [9:38:09<3:39:46, 24.19steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 680960/1000000 [9:38:20<3:39:46, 24.19steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_680960.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 683520/1000000 [9:44:23<6:23:55, 13.74steps/s]                                                                68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 683520/1000000 [9:44:23<6:23:55, 13.74steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.2     |
|    Return            | 23.5     |
|    NonzeroRewards    | 39.2     |
|    DiscountedReturn  | 23.5     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.41     |
|    mean_entropy      | -3.98    |
|    mean_ent_bonus    | -0.0469  |
|    max_target_q      | 28       |
|    min_target_q      | -5.84    |
|    max_reward        | 21.3     |
|    min_reward        | -1.59    |
|    encoder_grad_norm | 29.1     |
|    q1_grad_norm      | 5.6      |
|    q2_grad_norm      | 5.59     |
|    actor_loss        | -5.72    |
|    ent_coeff         | 0.0118   |
|    ent_coeff_loss    | -0.267   |
|    pi_grad_norm      | 0.179    |
|    n_updates         | 42240    |
| eval/                |          |
|    Length            | 81.3     |
|    Return            | 8.42     |
|    NonzeroRewards    | 81.3     |
|    DiscountedReturn  | 8.42     |
|    Success           | 0.914    |
| time/                |          |
|    iterations        | 267      |
|    fps               | 13.6     |
|    elapsed_time      | 3.51e+04 |
|    elapsed_steps     | 683520   |
-----------------------------------
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 686080/1000000 [9:45:59<5:25:09, 16.09steps/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 686080/1000000 [9:46:11<5:25:09, 16.09steps/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 688640/1000000 [9:47:33<4:42:58, 18.34steps/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 688640/1000000 [9:47:51<4:42:58, 18.34steps/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 691200/1000000 [9:49:07<4:13:26, 20.31steps/s]                                                                69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 691200/1000000 [9:49:07<4:13:26, 20.31steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.5     |
|    Return            | 24       |
|    NonzeroRewards    | 39.5     |
|    DiscountedReturn  | 24       |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.55     |
|    mean_entropy      | -4       |
|    mean_ent_bonus    | -0.0467  |
|    max_target_q      | 29       |
|    min_target_q      | -5.57    |
|    max_reward        | 21.7     |
|    min_reward        | -1.59    |
|    encoder_grad_norm | 29.5     |
|    q1_grad_norm      | 6.2      |
|    q2_grad_norm      | 6.23     |
|    actor_loss        | -5.77    |
|    ent_coeff         | 0.0117   |
|    ent_coeff_loss    | -0.225   |
|    pi_grad_norm      | 0.181    |
|    n_updates         | 42720    |
| time/                |          |
|    iterations        | 270      |
|    fps               | 27       |
|    elapsed_time      | 3.53e+04 |
|    elapsed_steps     | 691200   |
-----------------------------------
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 691200/1000000 [9:49:21<4:13:26, 20.31steps/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 693760/1000000 [9:50:42<3:52:34, 21.95steps/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 693760/1000000 [9:51:01<3:52:34, 21.95steps/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 696320/1000000 [9:52:16<3:37:16, 23.29steps/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 696320/1000000 [9:52:31<3:37:16, 23.29steps/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 698880/1000000 [9:53:51<3:26:20, 24.32steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_698880.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 698880/1000000 [9:54:11<3:26:20, 24.32steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 698880/1000000 [9:58:26<3:26:20, 24.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 36.9     |
|    Return            | 24.1     |
|    NonzeroRewards    | 36.9     |
|    DiscountedReturn  | 24.1     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.48     |
|    mean_entropy      | -4.19    |
|    mean_ent_bonus    | -0.0493  |
|    max_target_q      | 29       |
|    min_target_q      | -5.13    |
|    max_reward        | 21.8     |
|    min_reward        | -1.55    |
|    encoder_grad_norm | 29.3     |
|    q1_grad_norm      | 5.92     |
|    q2_grad_norm      | 5.95     |
|    actor_loss        | -5.77    |
|    ent_coeff         | 0.0118   |
|    ent_coeff_loss    | 0.609    |
|    pi_grad_norm      | 0.171    |
|    n_updates         | 43200    |
| eval/                |          |
|    Length            | 67.1     |
|    Return            | 16.6     |
|    NonzeroRewards    | 67.1     |
|    DiscountedReturn  | 16.6     |
|    Success           | 0.953    |
| time/                |          |
|    iterations        | 273      |
|    fps               | 13.7     |
|    elapsed_time      | 3.59e+04 |
|    elapsed_steps     | 698880   |
-----------------------------------
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 701440/1000000 [10:00:03<6:00:30, 13.80steps/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 704000/1000000 [10:01:39<5:05:27, 16.15steps/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 704000/1000000 [10:01:51<5:05:27, 16.15steps/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 706560/1000000 [10:03:12<4:25:36, 18.41steps/s]                                                                 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 706560/1000000 [10:03:12<4:25:36, 18.41steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.5     |
|    Return            | 22.8     |
|    NonzeroRewards    | 39.5     |
|    DiscountedReturn  | 22.8     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.53     |
|    mean_entropy      | -4.11    |
|    mean_ent_bonus    | -0.0496  |
|    max_target_q      | 28.8     |
|    min_target_q      | -5.19    |
|    max_reward        | 21.7     |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 29.8     |
|    q1_grad_norm      | 5.55     |
|    q2_grad_norm      | 5.55     |
|    actor_loss        | -5.84    |
|    ent_coeff         | 0.0121   |
|    ent_coeff_loss    | 0.228    |
|    pi_grad_norm      | 0.174    |
|    n_updates         | 43680    |
| time/                |          |
|    iterations        | 276      |
|    fps               | 26.9     |
|    elapsed_time      | 3.62e+04 |
|    elapsed_steps     | 706560   |
-----------------------------------
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 706560/1000000 [10:03:31<4:25:36, 18.41steps/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 709120/1000000 [10:04:47<3:58:12, 20.35steps/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 709120/1000000 [10:05:01<3:58:12, 20.35steps/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 711680/1000000 [10:06:22<3:38:46, 21.96steps/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 711680/1000000 [10:06:41<3:38:46, 21.96steps/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 714240/1000000 [10:07:57<3:24:42, 23.27steps/s]                                                                 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 714240/1000000 [10:07:57<3:24:42, 23.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 41.2     |
|    Return            | 22.5     |
|    NonzeroRewards    | 41.2     |
|    DiscountedReturn  | 22.5     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.59     |
|    mean_entropy      | -4.12    |
|    mean_ent_bonus    | -0.0501  |
|    max_target_q      | 29.2     |
|    min_target_q      | -5.02    |
|    max_reward        | 22       |
|    min_reward        | -1.78    |
|    encoder_grad_norm | 31       |
|    q1_grad_norm      | 5.69     |
|    q2_grad_norm      | 5.7      |
|    actor_loss        | -5.9     |
|    ent_coeff         | 0.0122   |
|    ent_coeff_loss    | 0.174    |
|    pi_grad_norm      | 0.184    |
|    n_updates         | 44160    |
| time/                |          |
|    iterations        | 279      |
|    fps               | 27       |
|    elapsed_time      | 3.65e+04 |
|    elapsed_steps     | 714240   |
-----------------------------------
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 714240/1000000 [10:08:11<3:24:42, 23.27steps/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 716800/1000000 [10:09:33<3:15:05, 24.19steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_716800.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 716800/1000000 [10:09:51<3:15:05, 24.19steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 719360/1000000 [10:15:48<5:40:36, 13.73steps/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 721920/1000000 [10:17:23<4:48:07, 16.09steps/s]                                                                 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 721920/1000000 [10:17:23<4:48:07, 16.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 44.5     |
|    Return            | 23.8     |
|    NonzeroRewards    | 44.5     |
|    DiscountedReturn  | 23.8     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.6      |
|    mean_entropy      | -4.07    |
|    mean_ent_bonus    | -0.0502  |
|    max_target_q      | 29.3     |
|    min_target_q      | -5.13    |
|    max_reward        | 22.2     |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 31       |
|    q1_grad_norm      | 5.71     |
|    q2_grad_norm      | 5.72     |
|    actor_loss        | -5.93    |
|    ent_coeff         | 0.0123   |
|    ent_coeff_loss    | 0.0107   |
|    pi_grad_norm      | 0.185    |
|    n_updates         | 44640    |
| eval/                |          |
|    Length            | 57.1     |
|    Return            | 17.8     |
|    NonzeroRewards    | 57.1     |
|    DiscountedReturn  | 17.8     |
|    Success           | 0.974    |
| time/                |          |
|    iterations        | 282      |
|    fps               | 13.6     |
|    elapsed_time      | 3.7e+04  |
|    elapsed_steps     | 721920   |
-----------------------------------
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 721920/1000000 [10:17:41<4:48:07, 16.09steps/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 724480/1000000 [10:18:57<4:10:23, 18.34steps/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 724480/1000000 [10:19:11<4:10:23, 18.34steps/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 727040/1000000 [10:20:31<3:43:43, 20.33steps/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 727040/1000000 [10:20:51<3:43:43, 20.33steps/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 729600/1000000 [10:22:05<3:25:03, 21.98steps/s]                                                                 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 729600/1000000 [10:22:05<3:25:03, 21.98steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.9     |
|    Return            | 23.3     |
|    NonzeroRewards    | 39.9     |
|    DiscountedReturn  | 23.3     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.62     |
|    mean_entropy      | -3.95    |
|    mean_ent_bonus    | -0.0476  |
|    max_target_q      | 29.2     |
|    min_target_q      | -5.2     |
|    max_reward        | 21.8     |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 31.6     |
|    q1_grad_norm      | 6.48     |
|    q2_grad_norm      | 6.48     |
|    actor_loss        | -5.95    |
|    ent_coeff         | 0.0121   |
|    ent_coeff_loss    | -0.593   |
|    pi_grad_norm      | 0.186    |
|    n_updates         | 45120    |
| time/                |          |
|    iterations        | 285      |
|    fps               | 27.2     |
|    elapsed_time      | 3.73e+04 |
|    elapsed_steps     | 729600   |
-----------------------------------
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 729600/1000000 [10:22:21<3:25:03, 21.98steps/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 732160/1000000 [10:23:41<3:12:00, 23.25steps/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 732160/1000000 [10:24:01<3:12:00, 23.25steps/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 734720/1000000 [10:25:16<3:02:37, 24.21steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 734720/1000000 [10:25:31<3:02:37, 24.21steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_734720.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 737280/1000000 [10:31:32<5:19:13, 13.72steps/s]                                                                 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 737280/1000000 [10:31:32<5:19:13, 13.72steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.6     |
|    Return            | 23.4     |
|    NonzeroRewards    | 39.6     |
|    DiscountedReturn  | 23.4     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.63     |
|    mean_entropy      | -4.05    |
|    mean_ent_bonus    | -0.0482  |
|    max_target_q      | 29.7     |
|    min_target_q      | -5.23    |
|    max_reward        | 22.4     |
|    min_reward        | -1.61    |
|    encoder_grad_norm | 32       |
|    q1_grad_norm      | 6.11     |
|    q2_grad_norm      | 6.1      |
|    actor_loss        | -6.01    |
|    ent_coeff         | 0.0119   |
|    ent_coeff_loss    | -0.126   |
|    pi_grad_norm      | 0.18     |
|    n_updates         | 45600    |
| eval/                |          |
|    Length            | 58.4     |
|    Return            | 14.4     |
|    NonzeroRewards    | 58.4     |
|    DiscountedReturn  | 14.4     |
|    Success           | 0.964    |
| time/                |          |
|    iterations        | 288      |
|    fps               | 13.6     |
|    elapsed_time      | 3.79e+04 |
|    elapsed_steps     | 737280   |
-----------------------------------
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 739840/1000000 [10:33:07<4:29:40, 16.08steps/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 739840/1000000 [10:33:21<4:29:40, 16.08steps/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 742400/1000000 [10:34:41<3:54:06, 18.34steps/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 742400/1000000 [10:35:01<3:54:06, 18.34steps/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 744960/1000000 [10:36:15<3:29:14, 20.31steps/s]                                                                 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 744960/1000000 [10:36:15<3:29:14, 20.31steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 40.7     |
|    Return            | 23.2     |
|    NonzeroRewards    | 40.7     |
|    DiscountedReturn  | 23.2     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.59     |
|    mean_entropy      | -4.1     |
|    mean_ent_bonus    | -0.0486  |
|    max_target_q      | 29.4     |
|    min_target_q      | -5.33    |
|    max_reward        | 22       |
|    min_reward        | -1.68    |
|    encoder_grad_norm | 31.2     |
|    q1_grad_norm      | 5.88     |
|    q2_grad_norm      | 5.86     |
|    actor_loss        | -6.07    |
|    ent_coeff         | 0.0119   |
|    ent_coeff_loss    | 0.0359   |
|    pi_grad_norm      | 0.185    |
|    n_updates         | 46080    |
| time/                |          |
|    iterations        | 291      |
|    fps               | 27.1     |
|    elapsed_time      | 3.82e+04 |
|    elapsed_steps     | 744960   |
-----------------------------------
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 744960/1000000 [10:36:31<3:29:14, 20.31steps/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 747520/1000000 [10:37:49<3:11:22, 21.99steps/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 747520/1000000 [10:38:01<3:11:22, 21.99steps/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 750080/1000000 [10:39:24<2:58:55, 23.28steps/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 750080/1000000 [10:39:41<2:58:55, 23.28steps/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 752640/1000000 [10:40:59<2:49:50, 24.27steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 752640/1000000 [10:41:11<2:49:50, 24.27steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_752640.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 752640/1000000 [10:45:37<2:49:50, 24.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 42       |
|    Return            | 21.9     |
|    NonzeroRewards    | 42       |
|    DiscountedReturn  | 21.9     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 3.58     |
|    mean_entropy      | -3.97    |
|    mean_ent_bonus    | -0.0465  |
|    max_target_q      | 29.3     |
|    min_target_q      | -5.41    |
|    max_reward        | 22.6     |
|    min_reward        | -1.55    |
|    encoder_grad_norm | 31.3     |
|    q1_grad_norm      | 6.08     |
|    q2_grad_norm      | 6.06     |
|    actor_loss        | -6.08    |
|    ent_coeff         | 0.0117   |
|    ent_coeff_loss    | -0.481   |
|    pi_grad_norm      | 0.185    |
|    n_updates         | 46560    |
| eval/                |          |
|    Length            | 56.6     |
|    Return            | 16.8     |
|    NonzeroRewards    | 56.6     |
|    DiscountedReturn  | 16.8     |
|    Success           | 0.963    |
| time/                |          |
|    iterations        | 294      |
|    fps               | 13.7     |
|    elapsed_time      | 3.87e+04 |
|    elapsed_steps     | 752640   |
-----------------------------------
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 755200/1000000 [10:47:14<4:56:56, 13.74steps/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 757760/1000000 [10:48:49<4:10:43, 16.10steps/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 757760/1000000 [10:49:01<4:10:43, 16.10steps/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 760320/1000000 [10:50:24<3:38:05, 18.32steps/s]                                                                 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 760320/1000000 [10:50:24<3:38:05, 18.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 45.8     |
|    Return            | 23       |
|    NonzeroRewards    | 45.8     |
|    DiscountedReturn  | 23       |
|    Success           | 0.989    |
| algo/                |          |
|    critic_loss       | 3.6      |
|    mean_entropy      | -3.98    |
|    mean_ent_bonus    | -0.0454  |
|    max_target_q      | 29       |
|    min_target_q      | -5.5     |
|    max_reward        | 22.2     |
|    min_reward        | -1.74    |
|    encoder_grad_norm | 31.7     |
|    q1_grad_norm      | 5.87     |
|    q2_grad_norm      | 5.86     |
|    actor_loss        | -6.1     |
|    ent_coeff         | 0.0114   |
|    ent_coeff_loss    | -0.371   |
|    pi_grad_norm      | 0.19     |
|    n_updates         | 47040    |
| time/                |          |
|    iterations        | 297      |
|    fps               | 26.8     |
|    elapsed_time      | 3.9e+04  |
|    elapsed_steps     | 760320   |
-----------------------------------
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 760320/1000000 [10:50:41<3:38:05, 18.32steps/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 762880/1000000 [10:51:59<3:14:50, 20.28steps/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 762880/1000000 [10:52:11<3:14:50, 20.28steps/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 765440/1000000 [10:53:32<2:57:53, 21.98steps/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 765440/1000000 [10:53:51<2:57:53, 21.98steps/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 768000/1000000 [10:55:07<2:46:08, 23.27steps/s]                                                                 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 768000/1000000 [10:55:07<2:46:08, 23.27steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.7     |
|    Return            | 23.2     |
|    NonzeroRewards    | 38.7     |
|    DiscountedReturn  | 23.2     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.54     |
|    mean_entropy      | -4.05    |
|    mean_ent_bonus    | -0.0462  |
|    max_target_q      | 28.9     |
|    min_target_q      | -5.52    |
|    max_reward        | 21.9     |
|    min_reward        | -1.53    |
|    encoder_grad_norm | 32.3     |
|    q1_grad_norm      | 6.05     |
|    q2_grad_norm      | 6.03     |
|    actor_loss        | -6.1     |
|    ent_coeff         | 0.0114   |
|    ent_coeff_loss    | -0.0956  |
|    pi_grad_norm      | 0.182    |
|    n_updates         | 47520    |
| time/                |          |
|    iterations        | 300      |
|    fps               | 27.1     |
|    elapsed_time      | 3.93e+04 |
|    elapsed_steps     | 768000   |
-----------------------------------
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 768000/1000000 [10:55:21<2:46:08, 23.27steps/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 770560/1000000 [10:56:43<2:37:44, 24.24steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_770560.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 770560/1000000 [10:57:01<2:37:44, 24.24steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 773120/1000000 [11:02:55<4:34:14, 13.79steps/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 775680/1000000 [11:04:31<3:51:43, 16.13steps/s]                                                                 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 775680/1000000 [11:04:31<3:51:43, 16.13steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 40.9     |
|    Return            | 22.3     |
|    NonzeroRewards    | 40.9     |
|    DiscountedReturn  | 22.3     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.63     |
|    mean_entropy      | -3.91    |
|    mean_ent_bonus    | -0.0434  |
|    max_target_q      | 29.5     |
|    min_target_q      | -5.41    |
|    max_reward        | 22.5     |
|    min_reward        | -1.61    |
|    encoder_grad_norm | 33.1     |
|    q1_grad_norm      | 6        |
|    q2_grad_norm      | 5.98     |
|    actor_loss        | -6.16    |
|    ent_coeff         | 0.0111   |
|    ent_coeff_loss    | -0.72    |
|    pi_grad_norm      | 0.173    |
|    n_updates         | 48000    |
| eval/                |          |
|    Length            | 76       |
|    Return            | 11.7     |
|    NonzeroRewards    | 76       |
|    DiscountedReturn  | 11.7     |
|    Success           | 0.938    |
| time/                |          |
|    iterations        | 303      |
|    fps               | 13.6     |
|    elapsed_time      | 3.99e+04 |
|    elapsed_steps     | 775680   |
-----------------------------------
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 775680/1000000 [11:04:51<3:51:43, 16.13steps/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 778240/1000000 [11:06:04<3:20:51, 18.40steps/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 778240/1000000 [11:06:21<3:20:51, 18.40steps/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 780800/1000000 [11:07:39<2:59:20, 20.37steps/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 780800/1000000 [11:07:51<2:59:20, 20.37steps/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 783360/1000000 [11:09:12<2:43:46, 22.05steps/s]                                                                 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 783360/1000000 [11:09:12<2:43:46, 22.05steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 43.3     |
|    Return            | 23.6     |
|    NonzeroRewards    | 43.3     |
|    DiscountedReturn  | 23.6     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 3.57     |
|    mean_entropy      | -3.95    |
|    mean_ent_bonus    | -0.0423  |
|    max_target_q      | 29.5     |
|    min_target_q      | -5.4     |
|    max_reward        | 21.9     |
|    min_reward        | -1.5     |
|    encoder_grad_norm | 33.1     |
|    q1_grad_norm      | 6.06     |
|    q2_grad_norm      | 6.05     |
|    actor_loss        | -6.15    |
|    ent_coeff         | 0.0107   |
|    ent_coeff_loss    | -0.568   |
|    pi_grad_norm      | 0.18     |
|    n_updates         | 48480    |
| time/                |          |
|    iterations        | 306      |
|    fps               | 27.3     |
|    elapsed_time      | 4.02e+04 |
|    elapsed_steps     | 783360   |
-----------------------------------
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 783360/1000000 [11:09:31<2:43:46, 22.05steps/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 785920/1000000 [11:10:47<2:33:02, 23.31steps/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 785920/1000000 [11:11:01<2:33:02, 23.31steps/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 788480/1000000 [11:12:23<2:25:13, 24.28steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_788480.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 788480/1000000 [11:12:41<2:25:13, 24.28steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 791040/1000000 [11:18:36<4:12:45, 13.78steps/s]                                                                 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 791040/1000000 [11:18:36<4:12:45, 13.78steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 50.1     |
|    Return            | 20.3     |
|    NonzeroRewards    | 50.1     |
|    DiscountedReturn  | 20.3     |
|    Success           | 0.989    |
| algo/                |          |
|    critic_loss       | 3.57     |
|    mean_entropy      | -3.95    |
|    mean_ent_bonus    | -0.0416  |
|    max_target_q      | 29.9     |
|    min_target_q      | -5.23    |
|    max_reward        | 22.8     |
|    min_reward        | -1.81    |
|    encoder_grad_norm | 32.9     |
|    q1_grad_norm      | 6.07     |
|    q2_grad_norm      | 6.02     |
|    actor_loss        | -6.16    |
|    ent_coeff         | 0.0105   |
|    ent_coeff_loss    | -0.523   |
|    pi_grad_norm      | 0.17     |
|    n_updates         | 48960    |
| eval/                |          |
|    Length            | 58.9     |
|    Return            | 18       |
|    NonzeroRewards    | 58.9     |
|    DiscountedReturn  | 18       |
|    Success           | 0.972    |
| time/                |          |
|    iterations        | 309      |
|    fps               | 13.6     |
|    elapsed_time      | 4.07e+04 |
|    elapsed_steps     | 791040   |
-----------------------------------
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 793600/1000000 [11:20:12<3:33:26, 16.12steps/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 793600/1000000 [11:20:31<3:33:26, 16.12steps/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 796160/1000000 [11:21:46<3:05:08, 18.35steps/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 796160/1000000 [11:22:01<3:05:08, 18.35steps/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 798720/1000000 [11:23:20<2:44:55, 20.34steps/s]                                                                 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 798720/1000000 [11:23:20<2:44:55, 20.34steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 42.7     |
|    Return            | 22.5     |
|    NonzeroRewards    | 42.7     |
|    DiscountedReturn  | 22.5     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.56     |
|    mean_entropy      | -4.08    |
|    mean_ent_bonus    | -0.042   |
|    max_target_q      | 29.1     |
|    min_target_q      | -5.34    |
|    max_reward        | 22       |
|    min_reward        | -1.96    |
|    encoder_grad_norm | 33       |
|    q1_grad_norm      | 5.94     |
|    q2_grad_norm      | 5.92     |
|    actor_loss        | -6.15    |
|    ent_coeff         | 0.0103   |
|    ent_coeff_loss    | 0.0296   |
|    pi_grad_norm      | 0.174    |
|    n_updates         | 49440    |
| time/                |          |
|    iterations        | 312      |
|    fps               | 27       |
|    elapsed_time      | 4.1e+04  |
|    elapsed_steps     | 798720   |
-----------------------------------
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 798720/1000000 [11:23:31<2:44:55, 20.34steps/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 801280/1000000 [11:24:54<2:30:27, 22.01steps/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 801280/1000000 [11:25:11<2:30:27, 22.01steps/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 803840/1000000 [11:26:30<2:20:28, 23.27steps/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 803840/1000000 [11:26:41<2:20:28, 23.27steps/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 806400/1000000 [11:28:05<2:13:01, 24.26steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_806400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 806400/1000000 [11:28:21<2:13:01, 24.26steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 806400/1000000 [11:32:43<2:13:01, 24.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 42.2     |
|    Return            | 23.5     |
|    NonzeroRewards    | 42.2     |
|    DiscountedReturn  | 23.5     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.56     |
|    mean_entropy      | -4.19    |
|    mean_ent_bonus    | -0.0438  |
|    max_target_q      | 29.9     |
|    min_target_q      | -5.39    |
|    max_reward        | 22.9     |
|    min_reward        | -1.69    |
|    encoder_grad_norm | 33.1     |
|    q1_grad_norm      | 5.9      |
|    q2_grad_norm      | 5.88     |
|    actor_loss        | -6.22    |
|    ent_coeff         | 0.0105   |
|    ent_coeff_loss    | 0.51     |
|    pi_grad_norm      | 0.178    |
|    n_updates         | 49920    |
| eval/                |          |
|    Length            | 64.6     |
|    Return            | 11.9     |
|    NonzeroRewards    | 64.6     |
|    DiscountedReturn  | 11.9     |
|    Success           | 0.96     |
| time/                |          |
|    iterations        | 315      |
|    fps               | 13.6     |
|    elapsed_time      | 4.16e+04 |
|    elapsed_steps     | 806400   |
-----------------------------------
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 808960/1000000 [11:34:20<3:51:44, 13.74steps/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 811520/1000000 [11:35:55<3:15:03, 16.10steps/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 811520/1000000 [11:36:11<3:15:03, 16.10steps/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 814080/1000000 [11:37:30<2:49:06, 18.32steps/s]                                                                 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 814080/1000000 [11:37:30<2:49:06, 18.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 40.3     |
|    Return            | 23.2     |
|    NonzeroRewards    | 40.3     |
|    DiscountedReturn  | 23.2     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.57     |
|    mean_entropy      | -4.08    |
|    mean_ent_bonus    | -0.0433  |
|    max_target_q      | 30       |
|    min_target_q      | -5.45    |
|    max_reward        | 23.4     |
|    min_reward        | -1.68    |
|    encoder_grad_norm | 33.2     |
|    q1_grad_norm      | 6.18     |
|    q2_grad_norm      | 6.15     |
|    actor_loss        | -6.23    |
|    ent_coeff         | 0.0106   |
|    ent_coeff_loss    | 0.00382  |
|    pi_grad_norm      | 0.175    |
|    n_updates         | 50400    |
| time/                |          |
|    iterations        | 318      |
|    fps               | 26.8     |
|    elapsed_time      | 4.19e+04 |
|    elapsed_steps     | 814080   |
-----------------------------------
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 814080/1000000 [11:37:41<2:49:06, 18.32steps/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 816640/1000000 [11:39:05<2:30:46, 20.27steps/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 816640/1000000 [11:39:21<2:30:46, 20.27steps/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 819200/1000000 [11:40:39<2:17:20, 21.94steps/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 819200/1000000 [11:40:51<2:17:20, 21.94steps/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 821760/1000000 [11:42:14<2:07:54, 23.23steps/s]                                                                 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 821760/1000000 [11:42:14<2:07:54, 23.23steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 42.1     |
|    Return            | 23.1     |
|    NonzeroRewards    | 42.1     |
|    DiscountedReturn  | 23.1     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.58     |
|    mean_entropy      | -4.01    |
|    mean_ent_bonus    | -0.0423  |
|    max_target_q      | 29.5     |
|    min_target_q      | -5.69    |
|    max_reward        | 22.5     |
|    min_reward        | -1.9     |
|    encoder_grad_norm | 33.4     |
|    q1_grad_norm      | 6.04     |
|    q2_grad_norm      | 6.03     |
|    actor_loss        | -6.27    |
|    ent_coeff         | 0.0105   |
|    ent_coeff_loss    | -0.351   |
|    pi_grad_norm      | 0.175    |
|    n_updates         | 50880    |
| time/                |          |
|    iterations        | 321      |
|    fps               | 27       |
|    elapsed_time      | 4.21e+04 |
|    elapsed_steps     | 821760   |
-----------------------------------
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 821760/1000000 [11:42:31<2:07:54, 23.23steps/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 824320/1000000 [11:43:49<2:00:53, 24.22steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 824320/1000000 [11:44:01<2:00:53, 24.22steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_824320.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 826880/1000000 [11:50:03<3:29:50, 13.75steps/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 829440/1000000 [11:51:38<2:56:10, 16.13steps/s]                                                                 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 829440/1000000 [11:51:38<2:56:10, 16.13steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 40.9     |
|    Return            | 22.1     |
|    NonzeroRewards    | 40.9     |
|    DiscountedReturn  | 22.1     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 3.54     |
|    mean_entropy      | -4.05    |
|    mean_ent_bonus    | -0.0418  |
|    max_target_q      | 29.8     |
|    min_target_q      | -5.76    |
|    max_reward        | 22.9     |
|    min_reward        | -1.67    |
|    encoder_grad_norm | 34.5     |
|    q1_grad_norm      | 6.09     |
|    q2_grad_norm      | 6.07     |
|    actor_loss        | -6.23    |
|    ent_coeff         | 0.0103   |
|    ent_coeff_loss    | -0.155   |
|    pi_grad_norm      | 0.178    |
|    n_updates         | 51360    |
| eval/                |          |
|    Length            | 62.2     |
|    Return            | 16.3     |
|    NonzeroRewards    | 62.2     |
|    DiscountedReturn  | 16.3     |
|    Success           | 0.97     |
| time/                |          |
|    iterations        | 324      |
|    fps               | 13.6     |
|    elapsed_time      | 4.27e+04 |
|    elapsed_steps     | 829440   |
-----------------------------------
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 829440/1000000 [11:51:51<2:56:10, 16.13steps/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 832000/1000000 [11:53:11<2:32:14, 18.39steps/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 832000/1000000 [11:53:31<2:32:14, 18.39steps/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 834560/1000000 [11:54:45<2:15:22, 20.37steps/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 834560/1000000 [11:55:01<2:15:22, 20.37steps/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 837120/1000000 [11:56:19<2:03:03, 22.06steps/s]                                                                 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 837120/1000000 [11:56:19<2:03:03, 22.06steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 42.1     |
|    Return            | 22.9     |
|    NonzeroRewards    | 42.1     |
|    DiscountedReturn  | 22.9     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 3.61     |
|    mean_entropy      | -4.16    |
|    mean_ent_bonus    | -0.0435  |
|    max_target_q      | 30.2     |
|    min_target_q      | -5.83    |
|    max_reward        | 23.9     |
|    min_reward        | -1.49    |
|    encoder_grad_norm | 34.6     |
|    q1_grad_norm      | 6.09     |
|    q2_grad_norm      | 6.07     |
|    actor_loss        | -6.27    |
|    ent_coeff         | 0.0104   |
|    ent_coeff_loss    | 0.375    |
|    pi_grad_norm      | 0.173    |
|    n_updates         | 51840    |
| time/                |          |
|    iterations        | 327      |
|    fps               | 27.3     |
|    elapsed_time      | 4.3e+04  |
|    elapsed_steps     | 837120   |
-----------------------------------
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 837120/1000000 [11:56:31<2:03:03, 22.06steps/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 839680/1000000 [11:57:54<1:54:33, 23.32steps/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 839680/1000000 [11:58:11<1:54:33, 23.32steps/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 842240/1000000 [11:59:29<1:48:10, 24.31steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 842240/1000000 [11:59:41<1:48:10, 24.31steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_842240.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 844800/1000000 [12:05:45<3:08:20, 13.73steps/s]                                                                 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 844800/1000000 [12:05:45<3:08:20, 13.73steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 44.9     |
|    Return            | 22.1     |
|    NonzeroRewards    | 44.9     |
|    DiscountedReturn  | 22.1     |
|    Success           | 0.988    |
| algo/                |          |
|    critic_loss       | 3.51     |
|    mean_entropy      | -4.19    |
|    mean_ent_bonus    | -0.0447  |
|    max_target_q      | 30.4     |
|    min_target_q      | -5.89    |
|    max_reward        | 23.2     |
|    min_reward        | -1.64    |
|    encoder_grad_norm | 34       |
|    q1_grad_norm      | 5.95     |
|    q2_grad_norm      | 5.94     |
|    actor_loss        | -6.28    |
|    ent_coeff         | 0.0107   |
|    ent_coeff_loss    | 0.523    |
|    pi_grad_norm      | 0.17     |
|    n_updates         | 52320    |
| eval/                |          |
|    Length            | 36.6     |
|    Return            | 22.9     |
|    NonzeroRewards    | 36.6     |
|    DiscountedReturn  | 22.9     |
|    Success           | 1        |
| time/                |          |
|    iterations        | 330      |
|    fps               | 13.6     |
|    elapsed_time      | 4.35e+04 |
|    elapsed_steps     | 844800   |
-----------------------------------
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 847360/1000000 [12:07:19<2:37:53, 16.11steps/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 847360/1000000 [12:07:31<2:37:53, 16.11steps/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 849920/1000000 [12:08:54<2:16:22, 18.34steps/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 849920/1000000 [12:09:11<2:16:22, 18.34steps/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 852480/1000000 [12:10:28<2:01:00, 20.32steps/s]                                                                 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 852480/1000000 [12:10:28<2:01:00, 20.32steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 46.4     |
|    Return            | 23.6     |
|    NonzeroRewards    | 46.4     |
|    DiscountedReturn  | 23.6     |
|    Success           | 0.994    |
| algo/                |          |
|    critic_loss       | 3.59     |
|    mean_entropy      | -4.08    |
|    mean_ent_bonus    | -0.0441  |
|    max_target_q      | 30.5     |
|    min_target_q      | -5.9     |
|    max_reward        | 23.6     |
|    min_reward        | -1.68    |
|    encoder_grad_norm | 34.7     |
|    q1_grad_norm      | 6.27     |
|    q2_grad_norm      | 6.25     |
|    actor_loss        | -6.32    |
|    ent_coeff         | 0.0108   |
|    ent_coeff_loss    | -0.00224 |
|    pi_grad_norm      | 0.18     |
|    n_updates         | 52800    |
| time/                |          |
|    iterations        | 333      |
|    fps               | 27.1     |
|    elapsed_time      | 4.38e+04 |
|    elapsed_steps     | 852480   |
-----------------------------------
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 852480/1000000 [12:10:41<2:01:00, 20.32steps/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 855040/1000000 [12:12:03<1:49:57, 21.97steps/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 855040/1000000 [12:12:21<1:49:57, 21.97steps/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 857600/1000000 [12:13:38<1:42:09, 23.23steps/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 857600/1000000 [12:13:51<1:42:09, 23.23steps/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 860160/1000000 [12:15:13<1:36:04, 24.26steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_860160.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 860160/1000000 [12:15:31<1:36:04, 24.26steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                                 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 860160/1000000 [12:19:51<1:36:04, 24.26steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 40.5     |
|    Return            | 24       |
|    NonzeroRewards    | 40.5     |
|    DiscountedReturn  | 24       |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.52     |
|    mean_entropy      | -4.06    |
|    mean_ent_bonus    | -0.044   |
|    max_target_q      | 29.9     |
|    min_target_q      | -6.06    |
|    max_reward        | 22.8     |
|    min_reward        | -1.74    |
|    encoder_grad_norm | 34.5     |
|    q1_grad_norm      | 6.4      |
|    q2_grad_norm      | 6.37     |
|    actor_loss        | -6.3     |
|    ent_coeff         | 0.0108   |
|    ent_coeff_loss    | -0.01    |
|    pi_grad_norm      | 0.18     |
|    n_updates         | 53280    |
| eval/                |          |
|    Length            | 59.4     |
|    Return            | 17.1     |
|    NonzeroRewards    | 59.4     |
|    DiscountedReturn  | 17.1     |
|    Success           | 0.98     |
| time/                |          |
|    iterations        | 336      |
|    fps               | 13.6     |
|    elapsed_time      | 4.44e+04 |
|    elapsed_steps     | 860160   |
-----------------------------------
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 862720/1000000 [12:21:29<2:47:01, 13.70steps/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 865280/1000000 [12:23:05<2:20:00, 16.04steps/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 865280/1000000 [12:23:21<2:20:00, 16.04steps/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 867840/1000000 [12:24:41<2:00:42, 18.25steps/s]                                                                 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 867840/1000000 [12:24:41<2:00:42, 18.25steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 35.5     |
|    Return            | 23.9     |
|    NonzeroRewards    | 35.5     |
|    DiscountedReturn  | 23.9     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.5      |
|    mean_entropy      | -3.94    |
|    mean_ent_bonus    | -0.0418  |
|    max_target_q      | 30.1     |
|    min_target_q      | -5.97    |
|    max_reward        | 23.5     |
|    min_reward        | -1.54    |
|    encoder_grad_norm | 34.9     |
|    q1_grad_norm      | 6.14     |
|    q2_grad_norm      | 6.1      |
|    actor_loss        | -6.35    |
|    ent_coeff         | 0.0106   |
|    ent_coeff_loss    | -0.662   |
|    pi_grad_norm      | 0.172    |
|    n_updates         | 53760    |
| time/                |          |
|    iterations        | 339      |
|    fps               | 26.5     |
|    elapsed_time      | 4.47e+04 |
|    elapsed_steps     | 867840   |
-----------------------------------
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 867840/1000000 [12:24:51<2:00:42, 18.25steps/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 870400/1000000 [12:26:15<1:46:48, 20.22steps/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 870400/1000000 [12:26:31<1:46:48, 20.22steps/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 872960/1000000 [12:27:50<1:36:44, 21.89steps/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 872960/1000000 [12:28:01<1:36:44, 21.89steps/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 875520/1000000 [12:29:24<1:29:21, 23.22steps/s]                                                                 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 875520/1000000 [12:29:24<1:29:21, 23.22steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 35.8     |
|    Return            | 23.8     |
|    NonzeroRewards    | 35.8     |
|    DiscountedReturn  | 23.8     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.54     |
|    mean_entropy      | -4.03    |
|    mean_ent_bonus    | -0.0419  |
|    max_target_q      | 30.6     |
|    min_target_q      | -6.08    |
|    max_reward        | 23.2     |
|    min_reward        | -2.17    |
|    encoder_grad_norm | 35       |
|    q1_grad_norm      | 5.85     |
|    q2_grad_norm      | 5.8      |
|    actor_loss        | -6.35    |
|    ent_coeff         | 0.0104   |
|    ent_coeff_loss    | -0.226   |
|    pi_grad_norm      | 0.171    |
|    n_updates         | 54240    |
| time/                |          |
|    iterations        | 342      |
|    fps               | 27.1     |
|    elapsed_time      | 4.5e+04  |
|    elapsed_steps     | 875520   |
-----------------------------------
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 875520/1000000 [12:29:41<1:29:21, 23.22steps/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 878080/1000000 [12:30:59<1:23:44, 24.26steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 878080/1000000 [12:31:11<1:23:44, 24.26steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_878080.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 880640/1000000 [12:37:13<2:24:43, 13.75steps/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 883200/1000000 [12:38:49<2:00:59, 16.09steps/s]                                                                 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 883200/1000000 [12:38:49<2:00:59, 16.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.5     |
|    Return            | 23.3     |
|    NonzeroRewards    | 38.5     |
|    DiscountedReturn  | 23.3     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.5      |
|    mean_entropy      | -3.98    |
|    mean_ent_bonus    | -0.0407  |
|    max_target_q      | 30.4     |
|    min_target_q      | -6.14    |
|    max_reward        | 23.6     |
|    min_reward        | -2.09    |
|    encoder_grad_norm | 34.7     |
|    q1_grad_norm      | 6.36     |
|    q2_grad_norm      | 6.36     |
|    actor_loss        | -6.39    |
|    ent_coeff         | 0.0102   |
|    ent_coeff_loss    | -0.431   |
|    pi_grad_norm      | 0.182    |
|    n_updates         | 54720    |
| eval/                |          |
|    Length            | 41.7     |
|    Return            | 23.3     |
|    NonzeroRewards    | 41.7     |
|    DiscountedReturn  | 23.3     |
|    Success           | 1        |
| time/                |          |
|    iterations        | 345      |
|    fps               | 13.6     |
|    elapsed_time      | 4.55e+04 |
|    elapsed_steps     | 883200   |
-----------------------------------
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 883200/1000000 [12:39:01<2:00:59, 16.09steps/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 885760/1000000 [12:40:25<1:44:11, 18.27steps/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 885760/1000000 [12:40:41<1:44:11, 18.27steps/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 888320/1000000 [12:41:59<1:31:46, 20.28steps/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 888320/1000000 [12:42:11<1:31:46, 20.28steps/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 890880/1000000 [12:43:33<1:22:49, 21.96steps/s]                                                                 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 890880/1000000 [12:43:33<1:22:49, 21.96steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 42.7     |
|    Return            | 21.9     |
|    NonzeroRewards    | 42.7     |
|    DiscountedReturn  | 21.9     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.53     |
|    mean_entropy      | -4.07    |
|    mean_ent_bonus    | -0.0413  |
|    max_target_q      | 30.6     |
|    min_target_q      | -6.26    |
|    max_reward        | 22.9     |
|    min_reward        | -1.78    |
|    encoder_grad_norm | 35.5     |
|    q1_grad_norm      | 6.21     |
|    q2_grad_norm      | 6.19     |
|    actor_loss        | -6.41    |
|    ent_coeff         | 0.0101   |
|    ent_coeff_loss    | -0.0775  |
|    pi_grad_norm      | 0.166    |
|    n_updates         | 55200    |
| time/                |          |
|    iterations        | 348      |
|    fps               | 27.1     |
|    elapsed_time      | 4.58e+04 |
|    elapsed_steps     | 890880   |
-----------------------------------
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 890880/1000000 [12:43:51<1:22:49, 21.96steps/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 893440/1000000 [12:45:08<1:16:24, 23.24steps/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 893440/1000000 [12:45:21<1:16:24, 23.24steps/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 896000/1000000 [12:46:43<1:11:36, 24.20steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_896000.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 896000/1000000 [12:47:01<1:11:36, 24.20steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 898560/1000000 [12:53:03<2:04:08, 13.62steps/s]                                                                 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 898560/1000000 [12:53:03<2:04:08, 13.62steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 37.8     |
|    Return            | 23.7     |
|    NonzeroRewards    | 37.8     |
|    DiscountedReturn  | 23.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.49     |
|    mean_entropy      | -4.03    |
|    mean_ent_bonus    | -0.0402  |
|    max_target_q      | 30.3     |
|    min_target_q      | -6.13    |
|    max_reward        | 24.1     |
|    min_reward        | -1.77    |
|    encoder_grad_norm | 35.2     |
|    q1_grad_norm      | 5.84     |
|    q2_grad_norm      | 5.81     |
|    actor_loss        | -6.42    |
|    ent_coeff         | 0.00998  |
|    ent_coeff_loss    | -0.233   |
|    pi_grad_norm      | 0.169    |
|    n_updates         | 55680    |
| eval/                |          |
|    Length            | 50.7     |
|    Return            | 19.7     |
|    NonzeroRewards    | 50.7     |
|    DiscountedReturn  | 19.7     |
|    Success           | 0.985    |
| time/                |          |
|    iterations        | 351      |
|    fps               | 13.5     |
|    elapsed_time      | 4.64e+04 |
|    elapsed_steps     | 898560   |
-----------------------------------
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 901120/1000000 [12:54:39<1:43:07, 15.98steps/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 901120/1000000 [12:54:51<1:43:07, 15.98steps/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 903680/1000000 [12:56:13<1:28:08, 18.21steps/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 903680/1000000 [12:56:31<1:28:08, 18.21steps/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 906240/1000000 [12:57:48<1:17:19, 20.21steps/s]                                                                 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 906240/1000000 [12:57:48<1:17:19, 20.21steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 40.3     |
|    Return            | 24       |
|    NonzeroRewards    | 40.3     |
|    DiscountedReturn  | 24       |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.42     |
|    mean_entropy      | -4.06    |
|    mean_ent_bonus    | -0.0404  |
|    max_target_q      | 30.1     |
|    min_target_q      | -6.03    |
|    max_reward        | 22.9     |
|    min_reward        | -1.82    |
|    encoder_grad_norm | 35.2     |
|    q1_grad_norm      | 6.31     |
|    q2_grad_norm      | 6.28     |
|    actor_loss        | -6.41    |
|    ent_coeff         | 0.00997  |
|    ent_coeff_loss    | -0.137   |
|    pi_grad_norm      | 0.172    |
|    n_updates         | 56160    |
| time/                |          |
|    iterations        | 354      |
|    fps               | 27       |
|    elapsed_time      | 4.67e+04 |
|    elapsed_steps     | 906240   |
-----------------------------------
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 906240/1000000 [12:58:01<1:17:19, 20.21steps/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 908800/1000000 [12:59:22<1:09:31, 21.86steps/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 908800/1000000 [12:59:41<1:09:31, 21.86steps/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 911360/1000000 [13:00:57<1:03:38, 23.22steps/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 911360/1000000 [13:01:11<1:03:38, 23.22steps/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 913920/1000000 [13:02:32<59:19, 24.18steps/s]  RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_913920.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 913920/1000000 [13:02:51<59:19, 24.18steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 913920/1000000 [13:07:10<59:19, 24.18steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.1     |
|    Return            | 23.5     |
|    NonzeroRewards    | 39.1     |
|    DiscountedReturn  | 23.5     |
|    Success           | 0.995    |
| algo/                |          |
|    critic_loss       | 3.48     |
|    mean_entropy      | -4.14    |
|    mean_ent_bonus    | -0.0411  |
|    max_target_q      | 29.7     |
|    min_target_q      | -6.11    |
|    max_reward        | 23       |
|    min_reward        | -1.91    |
|    encoder_grad_norm | 35       |
|    q1_grad_norm      | 6.07     |
|    q2_grad_norm      | 6.06     |
|    actor_loss        | -6.43    |
|    ent_coeff         | 0.00992  |
|    ent_coeff_loss    | 0.258    |
|    pi_grad_norm      | 0.176    |
|    n_updates         | 56640    |
| eval/                |          |
|    Length            | 63.9     |
|    Return            | 15.7     |
|    NonzeroRewards    | 63.9     |
|    DiscountedReturn  | 15.7     |
|    Success           | 0.96     |
| time/                |          |
|    iterations        | 357      |
|    fps               | 13.6     |
|    elapsed_time      | 4.72e+04 |
|    elapsed_steps     | 913920   |
-----------------------------------
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 916480/1000000 [13:08:49<1:41:41, 13.69steps/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 919040/1000000 [13:10:25<1:24:11, 16.03steps/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 919040/1000000 [13:10:41<1:24:11, 16.03steps/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 921600/1000000 [13:12:00<1:11:40, 18.23steps/s]                                                                 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 921600/1000000 [13:12:00<1:11:40, 18.23steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.1     |
|    Return            | 24.1     |
|    NonzeroRewards    | 38.1     |
|    DiscountedReturn  | 24.1     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.48     |
|    mean_entropy      | -4.26    |
|    mean_ent_bonus    | -0.0435  |
|    max_target_q      | 30.4     |
|    min_target_q      | -6.07    |
|    max_reward        | 23.9     |
|    min_reward        | -1.71    |
|    encoder_grad_norm | 35.4     |
|    q1_grad_norm      | 5.76     |
|    q2_grad_norm      | 5.74     |
|    actor_loss        | -6.45    |
|    ent_coeff         | 0.0102   |
|    ent_coeff_loss    | 0.806    |
|    pi_grad_norm      | 0.176    |
|    n_updates         | 57120    |
| time/                |          |
|    iterations        | 360      |
|    fps               | 26.5     |
|    elapsed_time      | 4.75e+04 |
|    elapsed_steps     | 921600   |
-----------------------------------
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 921600/1000000 [13:12:11<1:11:40, 18.23steps/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 924160/1000000 [13:13:35<1:02:32, 20.21steps/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 924160/1000000 [13:13:51<1:02:32, 20.21steps/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 926720/1000000 [13:15:09<55:47, 21.89steps/s]   93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 926720/1000000 [13:15:21<55:47, 21.89steps/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 929280/1000000 [13:16:44<50:50, 23.18steps/s]                                                               93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 929280/1000000 [13:16:44<50:50, 23.18steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 37       |
|    Return            | 23.8     |
|    NonzeroRewards    | 37       |
|    DiscountedReturn  | 23.8     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.47     |
|    mean_entropy      | -4.26    |
|    mean_ent_bonus    | -0.0451  |
|    max_target_q      | 30.2     |
|    min_target_q      | -6.13    |
|    max_reward        | 23.6     |
|    min_reward        | -1.56    |
|    encoder_grad_norm | 35.9     |
|    q1_grad_norm      | 6.25     |
|    q2_grad_norm      | 6.21     |
|    actor_loss        | -6.48    |
|    ent_coeff         | 0.0106   |
|    ent_coeff_loss    | 0.732    |
|    pi_grad_norm      | 0.181    |
|    n_updates         | 57600    |
| time/                |          |
|    iterations        | 363      |
|    fps               | 27       |
|    elapsed_time      | 4.78e+04 |
|    elapsed_steps     | 929280   |
-----------------------------------
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 929280/1000000 [13:17:01<50:50, 23.18steps/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 931840/1000000 [13:18:20<47:03, 24.14steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 931840/1000000 [13:18:31<47:03, 24.14steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_931840.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 934400/1000000 [13:24:40<1:20:27, 13.59steps/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 936960/1000000 [13:26:17<1:05:57, 15.93steps/s]                                                                 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 936960/1000000 [13:26:17<1:05:57, 15.93steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.1     |
|    Return            | 24.1     |
|    NonzeroRewards    | 38.1     |
|    DiscountedReturn  | 24.1     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.53     |
|    mean_entropy      | -4.07    |
|    mean_ent_bonus    | -0.0438  |
|    max_target_q      | 30.3     |
|    min_target_q      | -6.24    |
|    max_reward        | 23.6     |
|    min_reward        | -1.83    |
|    encoder_grad_norm | 36.9     |
|    q1_grad_norm      | 6.12     |
|    q2_grad_norm      | 6.07     |
|    actor_loss        | -6.5     |
|    ent_coeff         | 0.0107   |
|    ent_coeff_loss    | -0.159   |
|    pi_grad_norm      | 0.175    |
|    n_updates         | 58080    |
| eval/                |          |
|    Length            | 55.8     |
|    Return            | 18.3     |
|    NonzeroRewards    | 55.8     |
|    DiscountedReturn  | 18.3     |
|    Success           | 0.975    |
| time/                |          |
|    iterations        | 366      |
|    fps               | 13.4     |
|    elapsed_time      | 4.84e+04 |
|    elapsed_steps     | 936960   |
-----------------------------------
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 936960/1000000 [13:26:31<1:05:57, 15.93steps/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 939520/1000000 [13:27:53<55:38, 18.12steps/s]   94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 939520/1000000 [13:28:11<55:38, 18.12steps/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 942080/1000000 [13:29:27<47:55, 20.14steps/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 942080/1000000 [13:29:41<47:55, 20.14steps/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 944640/1000000 [13:31:01<42:16, 21.82steps/s]                                                               94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 944640/1000000 [13:31:01<42:16, 21.82steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.6     |
|    Return            | 23.8     |
|    NonzeroRewards    | 39.6     |
|    DiscountedReturn  | 23.8     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.48     |
|    mean_entropy      | -4.1     |
|    mean_ent_bonus    | -0.0439  |
|    max_target_q      | 30.6     |
|    min_target_q      | -6.23    |
|    max_reward        | 23.3     |
|    min_reward        | -1.81    |
|    encoder_grad_norm | 36.1     |
|    q1_grad_norm      | 6.12     |
|    q2_grad_norm      | 6.08     |
|    actor_loss        | -6.52    |
|    ent_coeff         | 0.0107   |
|    ent_coeff_loss    | 0.00878  |
|    pi_grad_norm      | 0.181    |
|    n_updates         | 58560    |
| time/                |          |
|    iterations        | 369      |
|    fps               | 27       |
|    elapsed_time      | 4.87e+04 |
|    elapsed_steps     | 944640   |
-----------------------------------
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 944640/1000000 [13:31:21<42:16, 21.82steps/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 947200/1000000 [13:32:36<37:59, 23.16steps/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 947200/1000000 [13:32:51<37:59, 23.16steps/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 949760/1000000 [13:34:11<34:41, 24.14steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_949760.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 949760/1000000 [13:34:31<34:41, 24.14steps/s]EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 952320/1000000 [13:40:26<57:57, 13.71steps/s]                                                               95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 952320/1000000 [13:40:26<57:57, 13.71steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.3     |
|    Return            | 23.6     |
|    NonzeroRewards    | 38.3     |
|    DiscountedReturn  | 23.6     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.46     |
|    mean_entropy      | -4.05    |
|    mean_ent_bonus    | -0.0433  |
|    max_target_q      | 30.8     |
|    min_target_q      | -6.07    |
|    max_reward        | 23.2     |
|    min_reward        | -1.64    |
|    encoder_grad_norm | 36.2     |
|    q1_grad_norm      | 5.78     |
|    q2_grad_norm      | 5.75     |
|    actor_loss        | -6.49    |
|    ent_coeff         | 0.0107   |
|    ent_coeff_loss    | -0.214   |
|    pi_grad_norm      | 0.186    |
|    n_updates         | 59040    |
| eval/                |          |
|    Length            | 61.2     |
|    Return            | 16.1     |
|    NonzeroRewards    | 61.2     |
|    DiscountedReturn  | 16.1     |
|    Success           | 0.963    |
| time/                |          |
|    iterations        | 372      |
|    fps               | 13.6     |
|    elapsed_time      | 4.92e+04 |
|    elapsed_steps     | 952320   |
-----------------------------------
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 954880/1000000 [13:42:03<46:56, 16.02steps/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 954880/1000000 [13:42:21<46:56, 16.02steps/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 957440/1000000 [13:43:39<38:58, 18.20steps/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 957440/1000000 [13:43:51<38:58, 18.20steps/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 960000/1000000 [13:45:14<33:00, 20.20steps/s]                                                               96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 960000/1000000 [13:45:14<33:00, 20.20steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 39.4     |
|    Return            | 22.3     |
|    NonzeroRewards    | 39.4     |
|    DiscountedReturn  | 22.3     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.38     |
|    mean_entropy      | -4.14    |
|    mean_ent_bonus    | -0.044   |
|    max_target_q      | 30.7     |
|    min_target_q      | -6.08    |
|    max_reward        | 23.5     |
|    min_reward        | -1.72    |
|    encoder_grad_norm | 35.5     |
|    q1_grad_norm      | 6.11     |
|    q2_grad_norm      | 6.09     |
|    actor_loss        | -6.54    |
|    ent_coeff         | 0.0106   |
|    ent_coeff_loss    | 0.162    |
|    pi_grad_norm      | 0.177    |
|    n_updates         | 59520    |
| time/                |          |
|    iterations        | 375      |
|    fps               | 26.7     |
|    elapsed_time      | 4.95e+04 |
|    elapsed_steps     | 960000   |
-----------------------------------
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 960000/1000000 [13:45:31<33:00, 20.20steps/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 962560/1000000 [13:46:48<28:33, 21.85steps/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 962560/1000000 [13:47:01<28:33, 21.85steps/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 965120/1000000 [13:48:23<25:04, 23.18steps/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 965120/1000000 [13:48:41<25:04, 23.18steps/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 967680/1000000 [13:50:00<22:21, 24.09steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 967680/1000000 [13:50:11<22:21, 24.09steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_967680.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                               97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 967680/1000000 [13:54:37<22:21, 24.09steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.4     |
|    Return            | 23.4     |
|    NonzeroRewards    | 38.4     |
|    DiscountedReturn  | 23.4     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.33     |
|    mean_entropy      | -4.01    |
|    mean_ent_bonus    | -0.0424  |
|    max_target_q      | 30.9     |
|    min_target_q      | -6.01    |
|    max_reward        | 23.8     |
|    min_reward        | -1.55    |
|    encoder_grad_norm | 35.5     |
|    q1_grad_norm      | 6        |
|    q2_grad_norm      | 5.98     |
|    actor_loss        | -6.53    |
|    ent_coeff         | 0.0106   |
|    ent_coeff_loss    | -0.391   |
|    pi_grad_norm      | 0.179    |
|    n_updates         | 60000    |
| eval/                |          |
|    Length            | 57.4     |
|    Return            | 17.3     |
|    NonzeroRewards    | 57.4     |
|    DiscountedReturn  | 17.3     |
|    Success           | 0.969    |
| time/                |          |
|    iterations        | 378      |
|    fps               | 13.6     |
|    elapsed_time      | 5.01e+04 |
|    elapsed_steps     | 967680   |
-----------------------------------
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 970240/1000000 [13:56:19<36:26, 13.61steps/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 972800/1000000 [13:57:55<28:24, 15.96steps/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 972800/1000000 [13:58:11<28:24, 15.96steps/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 975360/1000000 [13:59:30<22:36, 18.17steps/s]                                                               98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 975360/1000000 [13:59:30<22:36, 18.17steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 37.7     |
|    Return            | 23.7     |
|    NonzeroRewards    | 37.7     |
|    DiscountedReturn  | 23.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.43     |
|    mean_entropy      | -4.12    |
|    mean_ent_bonus    | -0.0432  |
|    max_target_q      | 30.5     |
|    min_target_q      | -5.95    |
|    max_reward        | 23.4     |
|    min_reward        | -1.6     |
|    encoder_grad_norm | 36.7     |
|    q1_grad_norm      | 5.97     |
|    q2_grad_norm      | 5.93     |
|    actor_loss        | -6.56    |
|    ent_coeff         | 0.0105   |
|    ent_coeff_loss    | 0.11     |
|    pi_grad_norm      | 0.185    |
|    n_updates         | 60480    |
| time/                |          |
|    iterations        | 381      |
|    fps               | 26.2     |
|    elapsed_time      | 5.04e+04 |
|    elapsed_steps     | 975360   |
-----------------------------------
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 975360/1000000 [13:59:41<22:36, 18.17steps/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 977920/1000000 [14:01:05<18:16, 20.13steps/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 977920/1000000 [14:01:21<18:16, 20.13steps/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 980480/1000000 [14:02:40<14:56, 21.78steps/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 980480/1000000 [14:02:51<14:56, 21.78steps/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 983040/1000000 [14:04:15<12:13, 23.12steps/s]                                                               98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 983040/1000000 [14:04:15<12:13, 23.12steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.8     |
|    Return            | 23.7     |
|    NonzeroRewards    | 38.8     |
|    DiscountedReturn  | 23.7     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.4      |
|    mean_entropy      | -4.1     |
|    mean_ent_bonus    | -0.043   |
|    max_target_q      | 29.9     |
|    min_target_q      | -5.93    |
|    max_reward        | 23.7     |
|    min_reward        | -1.74    |
|    encoder_grad_norm | 36.7     |
|    q1_grad_norm      | 6.43     |
|    q2_grad_norm      | 6.4      |
|    actor_loss        | -6.57    |
|    ent_coeff         | 0.0105   |
|    ent_coeff_loss    | -0.00228 |
|    pi_grad_norm      | 0.172    |
|    n_updates         | 60960    |
| time/                |          |
|    iterations        | 384      |
|    fps               | 27       |
|    elapsed_time      | 5.07e+04 |
|    elapsed_steps     | 983040   |
-----------------------------------
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 983040/1000000 [14:04:31<12:13, 23.12steps/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 985600/1000000 [14:05:51<09:57, 24.08steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 985600/1000000 [14:06:01<09:57, 24.08steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_985600.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 988160/1000000 [14:12:08<14:27, 13.65steps/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 990720/1000000 [14:13:44<09:40, 15.99steps/s]                                                               99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 990720/1000000 [14:13:44<09:40, 15.99steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.1     |
|    Return            | 23.6     |
|    NonzeroRewards    | 38.1     |
|    DiscountedReturn  | 23.6     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.34     |
|    mean_entropy      | -4.13    |
|    mean_ent_bonus    | -0.0437  |
|    max_target_q      | 30.5     |
|    min_target_q      | -6.1     |
|    max_reward        | 23.7     |
|    min_reward        | -1.8     |
|    encoder_grad_norm | 36.2     |
|    q1_grad_norm      | 6.24     |
|    q2_grad_norm      | 6.19     |
|    actor_loss        | -6.59    |
|    ent_coeff         | 0.0106   |
|    ent_coeff_loss    | 0.157    |
|    pi_grad_norm      | 0.171    |
|    n_updates         | 61440    |
| eval/                |          |
|    Length            | 62.5     |
|    Return            | 17.1     |
|    NonzeroRewards    | 62.5     |
|    DiscountedReturn  | 17.1     |
|    Success           | 0.968    |
| time/                |          |
|    iterations        | 387      |
|    fps               | 13.5     |
|    elapsed_time      | 5.12e+04 |
|    elapsed_steps     | 990720   |
-----------------------------------
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 990720/1000000 [14:14:01<09:40, 15.99steps/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 993280/1000000 [14:15:20<06:09, 18.18steps/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 993280/1000000 [14:15:31<06:09, 18.18steps/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 995840/1000000 [14:16:54<03:26, 20.19steps/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 995840/1000000 [14:17:11<03:26, 20.19steps/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 998400/1000000 [14:18:29<01:13, 21.85steps/s]RLRunner: Evaluating agent...
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 998400/1000000 [14:18:41<01:13, 21.85steps/s]Saved video of policy to videos/2025-09-03/clx77it2/nominal/policy_step_998400.mp4.
wandb: WARNING `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
EvalSampler: Resetting all environments.
EvalSampler: Resetting agent.
RLRunner: Finished evaluating agent.
                                                              100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 998400/1000000 [14:23:04<01:13, 21.85steps/s]-----------------------------------
| rollout/             |          |
|    Length            | 38.4     |
|    Return            | 23.5     |
|    NonzeroRewards    | 38.4     |
|    DiscountedReturn  | 23.5     |
|    Success           | 1        |
| algo/                |          |
|    critic_loss       | 3.28     |
|    mean_entropy      | -4.06    |
|    mean_ent_bonus    | -0.043   |
|    max_target_q      | 31.1     |
|    min_target_q      | -6.02    |
|    max_reward        | 23.6     |
|    min_reward        | -1.93    |
|    encoder_grad_norm | 35.6     |
|    q1_grad_norm      | 6.07     |
|    q2_grad_norm      | 6.06     |
|    actor_loss        | -6.58    |
|    ent_coeff         | 0.0106   |
|    ent_coeff_loss    | -0.112   |
|    pi_grad_norm      | 0.175    |
|    n_updates         | 61920    |
| eval/                |          |
|    Length            | 52.1     |
|    Return            | 18.1     |
|    NonzeroRewards    | 52.1     |
|    DiscountedReturn  | 18.1     |
|    Success           | 0.984    |
| time/                |          |
|    iterations        | 390      |
|    fps               | 13.7     |
|    elapsed_time      | 5.18e+04 |
|    elapsed_steps     | 998400   |
-----------------------------------
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 998400/1000000 [14:23:04<01:22, 19.28steps/s]
RLRunner: Finished training.
RLRunner: Log files saved to /home/michaelbezick/Repos/pprlPCA/wandb/run-20250903_101920-clx77it2/files
Error executing job with overrides: ['parallel=True', 'wandb.group_name=PCA_DS_r4', 'env=deflect_spheres', 'model=ppt', 'env.image_shape=[128, 128]']
Traceback (most recent call last):
  File "/home/michaelbezick/Repos/pprlPCA/scripts/original_train_sac.py", line 515, in main
    with build(config) as runner:
  File "/home/michaelbezick/.conda/envs/pprl/lib/python3.10/contextlib.py", line 142, in __exit__
    next(self.gen)
  File "/home/michaelbezick/Repos/pprlPCA/scripts/original_train_sac.py", line 468, in build
    sampler.closer()
AttributeError: 'BasicSampler' object has no attribute 'closer'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33msoft-elevator-901[0m at: [34mhttps://wandb.ai/michael-bezick-purdue-university/pprl/runs/clx77it2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250903_101920-clx77it2/logs[0m



########## SIG ########## SIG 

########## SIG 1515

########## SIG 
########## SIG 15 - 
 - ########## SIG ########## SIG 
15
########## SIG 15 - SIGTERM: a termination request was sent to the program
########## SIG SIGTERM: a termination request was sent to the program1515########## SIG  - ########## SIG 15 - SIGTERM: a termination request was sent to the program #################### SIG 15 ########## -  - 15SIGTERM: a termination request was sent to the program15 - SIGTERM: a termination request was sent to the program ##########
15 - 
SIGTERM: a termination request was sent to the programSIGTERM: a termination request was sent to the program -  ########## - SIGTERM: a termination request was sent to the program ##########
 - SIGTERM: a termination request was sent to the program ########## ##########SIGTERM: a termination request was sent to the program
SIGTERM: a termination request was sent to the program ##########
SIGTERM: a termination request was sent to the program ##########

 ########## ##########
 ##########



  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
    _PyFunction_Vectorcall  sofa::helper::BackTrace::sig(int)
sofa::helper::BackTrace::sig(int)
  
  _PyEval_EvalFrameDefault  read
read  
    
sofa::helper::BackTrace::sig(int)  sofa::helper::BackTrace::sig(int)_PyFunction_Vectorcall    
_Py_read  
  
sofa::helper::BackTrace::sig(int)_Py_read    
  sofa::helper::BackTrace::sig(int)    sofa::helper::BackTrace::sig(int)    

sofa::helper::BackTrace::sig(int)read  sofa::helper::BackTrace::sig(int)
readsofa::helper::BackTrace::sig(int)
sofa::helper::BackTrace::sig(int)_PyEval_EvalFrameDefault    

_PyEval_EvalFrameDefault
  

  

read_PyEval_EvalFrameDefault    
  read    read    

read_Py_read  read
_Py_readread
read_PyFunction_Vectorcall    

_PyFunction_Vectorcall
  

  

_Py_read_PyFunction_Vectorcall    
  _Py_read    _Py_read    

_Py_read_PyEval_EvalFrameDefault  _Py_read
_PyEval_EvalFrameDefault_Py_read
_Py_read_PyEval_EvalFrameDefault    

_PyEval_EvalFrameDefault
  

  

_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault    
  _PyEval_EvalFrameDefault    _PyEval_EvalFrameDefault    

_PyEval_EvalFrameDefault_PyFunction_Vectorcall  _PyEval_EvalFrameDefault
_PyFunction_Vectorcall_PyEval_EvalFrameDefault
_PyEval_EvalFrameDefault_PyFunction_Vectorcall    

_PyFunction_Vectorcall
  

  

_PyFunction_Vectorcall_PyFunction_Vectorcall    
  _PyFunction_Vectorcall    _PyFunction_Vectorcall    

_PyFunction_Vectorcall_PyEval_EvalFrameDefault  _PyFunction_Vectorcall
_PyEval_EvalFrameDefault_PyFunction_Vectorcall
_PyFunction_Vectorcall_PyEval_EvalFrameDefault    

_PyEval_EvalFrameDefault
  

  

_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault    
  _PyEval_EvalFrameDefault    _PyEval_EvalFrameDefault    

_PyEval_EvalFrameDefault_PyFunction_Vectorcall  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall_PyFunction_Vectorcall_PyEval_EvalFrameDefault
_PyEval_EvalFrameDefault_PyFunction_Vectorcall    

_PyFunction_Vectorcall



  

_PyFunction_Vectorcall_PyFunction_Vectorcall    
        _PyFunction_Vectorcall    

_PyFunction_Vectorcall_PyEval_EvalFrameDefault  _PyFunction_Vectorcall_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault_PyFunction_Vectorcall
_PyFunction_Vectorcall_PyEval_EvalFrameDefault    

_PyEval_EvalFrameDefault



  

_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault    
        _PyEval_EvalFrameDefault    

_PyEval_EvalFrameDefault_PyFunction_Vectorcall  _PyEval_EvalFrameDefault_PyFunction_Vectorcall_PyFunction_Vectorcall_PyEval_EvalFrameDefault
_PyEval_EvalFrameDefault_PyFunction_Vectorcall    

_PyFunction_Vectorcall



  

_PyFunction_Vectorcall_PyFunction_Vectorcall    
        _PyFunction_Vectorcall    

_PyFunction_Vectorcall_PyEval_EvalFrameDefault  _PyFunction_Vectorcall_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault_PyFunction_Vectorcall
_PyFunction_Vectorcall_PyEval_EvalFrameDefault    

_PyEval_EvalFrameDefault



  
    _PyEval_EvalFrameDefault
_PyEval_EvalFrameDefault  
_PyFunction_Vectorcall  
_PyFunction_Vectorcall  
_PyEval_EvalFrameDefault  
_PyEval_EvalFrameDefault  
_PyFunction_Vectorcall  
_PyFunction_Vectorcall  
_PyEval_EvalFrameDefault  
_PyEval_EvalFrameDefault  
_PyFunction_Vectorcall    
_PyFunction_Vectorcall  
  _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault  

_PyFunction_Vectorcall_PyEval_EvalFrameDefault    
_PyFunction_Vectorcall_PyFunction_Vectorcall  

_PyFunction_Vectorcall    
_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault  

_PyEval_EvalFrameDefault    
PyEval_EvalCode_PyFunction_Vectorcall  

PyEval_EvalCode    
PyRun_StringFlags  
PyRun_StringFlags  
PyRun_SimpleStringFlags  
  Py_RunMain
  Py_BytesMain
  __libc_start_main
PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main


########## SIG 15########## SIG  - 15SIGTERM: a termination request was sent to the program -  ##########SIGTERM: a termination request was sent to the program
 ##########
_PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main

  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
    _PyEval_EvalFrameDefaultsofa::helper::BackTrace::sig(int)

    _PyFunction_Vectorcallread

    _PyEval_EvalFrameDefault_Py_read

    _PyFunction_Vectorcall_PyEval_EvalFrameDefault

    _PyEval_EvalFrameDefault_PyFunction_Vectorcall

    PyEval_EvalCode_PyEval_EvalFrameDefault

    PyRun_StringFlags_PyFunction_Vectorcall

    PyRun_SimpleStringFlags_PyEval_EvalFrameDefault

    Py_RunMain_PyFunction_Vectorcall

    Py_BytesMain_PyEval_EvalFrameDefault

    __libc_start_main_PyFunction_Vectorcall

  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main

########## SIG   15 - SIGTERM: a termination request was sent to the program ##########
_PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main

########## SIG 15 - SIGTERM: a termination request was sent to the program ##########
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main


########## SIG 
15   - _PyFunction_VectorcallSIGTERM: a termination request was sent to the program########## SIG 
 ##########  15
_PyEval_EvalFrameDefault - 
SIGTERM: a termination request was sent to the program   ##########_PyFunction_Vectorcall

  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main

########## SIG 15 - SIGTERM: a termination request was sent to the program ##########
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall  
sofa::helper::BackTrace::sig(int)  
_PyEval_EvalFrameDefault  
read  
_PyFunction_Vectorcall  
_Py_read  
_PyEval_EvalFrameDefault  

_PyEval_EvalFrameDefault  
_PyFunction_Vectorcall    ########## SIG 

_PyFunction_Vectorcall  15  
_PyEval_EvalFrameDefault - 
########## SIG 
########## SIG 15 - _PyEval_EvalFrameDefault15_PyEval_EvalFrameDefault_PyEval_EvalFrameDefaultSIGTERM: a termination request was sent to the program########## SIG  - 


 ##########15
SIGTERM: a termination request was sent to the program    
 -      ##########_PyFunction_Vectorcall_PyFunction_VectorcallSIGTERM: a termination request was sent to the programPyEval_EvalCode


 ##########
    
  _PyEval_EvalFrameDefault_PyEval_EvalFrameDefaultPyRun_StringFlags


      _PyFunction_Vectorcall_PyFunction_VectorcallPyRun_SimpleStringFlags


      _PyEval_EvalFrameDefault_PyEval_EvalFrameDefaultPy_RunMain


      _PyFunction_Vectorcall_PyFunction_VectorcallPy_BytesMain



      ########## SIG _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault__libc_start_main15


 -     SIGTERM: a termination request was sent to the program_PyFunction_Vectorcall_PyFunction_Vectorcall ##########


    _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault

    PyEval_EvalCodePyEval_EvalCode

    PyRun_StringFlagsPyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main
_PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
    PyRun_StringFlagssofa::helper::BackTrace::sig(int)

    PyRun_SimpleStringFlagsread

    Py_RunMain_Py_read

      sofa::helper::BackTrace::sig(int)Py_BytesMain_PyEval_EvalFrameDefault


      read__libc_start_main_PyFunction_Vectorcall


      sofa::helper::BackTrace::sig(int)_Py_read_PyEval_EvalFrameDefault


      read_PyEval_EvalFrameDefault_PyFunction_Vectorcall


      _Py_read_PyFunction_Vectorcall_PyEval_EvalFrameDefault


        _PyEval_EvalFrameDefault_PyEval_EvalFrameDefaultsofa::helper::BackTrace::sig(int)_PyFunction_Vectorcall



        _PyFunction_Vectorcall_PyFunction_Vectorcallread_PyEval_EvalFrameDefault



        _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault_Py_read_PyFunction_Vectorcall



        _PyFunction_Vectorcall_PyFunction_Vectorcall_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault



        _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault_PyFunction_Vectorcall_PyFunction_Vectorcall



        _PyFunction_Vectorcall_PyFunction_Vectorcall_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault



        _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault_PyFunction_Vectorcall_PyFunction_Vectorcall



        _PyFunction_Vectorcall_PyFunction_Vectorcall_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault



        _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault_PyFunction_Vectorcall_PyFunction_Vectorcall



        _PyFunction_Vectorcall_PyFunction_Vectorcall_PyEval_EvalFrameDefault_PyEval_EvalFrameDefault



        _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault_PyFunction_VectorcallPyEval_EvalCode



        _PyFunction_Vectorcall_PyFunction_Vectorcall_PyEval_EvalFrameDefaultPyRun_StringFlags



        _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault_PyFunction_VectorcallPyRun_SimpleStringFlags



        _PyFunction_VectorcallPyEval_EvalCode_PyEval_EvalFrameDefaultPy_RunMain



        _PyEval_EvalFrameDefaultPyRun_StringFlags_PyFunction_VectorcallPy_BytesMain



  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain

  Py_BytesMain########## SIG 
  15__libc_start_main - 
SIGTERM: a termination request was sent to the program ##########
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main

########## SIG 15 - SIGTERM: a termination request was sent to the program ##########

  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main

########## SIG 15 - SIGTERM: a termination request was sent to the program ##########
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main
_PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main

SIGTERM: a termination request was sent to the program  _PyFunction_Vectorcall_PyFunction_Vectorcall
 ##########  
_PyEval_EvalFrameDefault

    PyEval_EvalCode_PyEval_EvalFrameDefault

    PyRun_StringFlags_PyFunction_Vectorcall

    PyRun_SimpleStringFlags_PyEval_EvalFrameDefault

    Py_RunMain_PyFunction_Vectorcall

    Py_BytesMain_PyEval_EvalFrameDefault

    __libc_start_main_PyFunction_Vectorcall

  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main  
  PyRun_SimpleStringFlags
  Py_RunMain
_PyEval_EvalFrameDefault  
Py_BytesMain  
_PyFunction_Vectorcall  
__libc_start_main  
_PyEval_EvalFrameDefault
  PyEval_EvalCode
    PyRun_StringFlags
  PyRun_SimpleStringFlags
  __libc_start_mainPy_RunMain

  Py_BytesMain
  __libc_start_main

########## SIG 15 - SIGTERM: a termination request was sent to the program ##########
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
    _PyFunction_Vectorcallsofa::helper::BackTrace::sig(int)

    _PyEval_EvalFrameDefaultread

    _PyFunction_Vectorcall_Py_read

    _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault

    _PyFunction_Vectorcall_PyFunction_Vectorcall

    _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault

    _PyFunction_Vectorcall_PyFunction_Vectorcall

    _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault

    _PyFunction_Vectorcall_PyFunction_Vectorcall

    _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault

    _PyFunction_Vectorcall_PyFunction_Vectorcall

    _PyEval_EvalFrameDefault_PyEval_EvalFrameDefault

    PyEval_EvalCode_PyFunction_Vectorcall

    PyRun_StringFlags_PyEval_EvalFrameDefault

    PyRun_SimpleStringFlags_PyFunction_Vectorcall

    Py_RunMain_PyEval_EvalFrameDefault

    Py_BytesMain_PyFunction_Vectorcall

    __libc_start_main_PyEval_EvalFrameDefault

  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main

########## SIG 15 - SIGTERM: a termination request was sent to the program ##########
  sofa::helper::BackTrace::sig(int)
  read
  _Py_read
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  _PyFunction_Vectorcall
  _PyEval_EvalFrameDefault
  PyEval_EvalCode
  PyRun_StringFlags
  PyRun_SimpleStringFlags
  Py_RunMain
  Py_BytesMain
  __libc_start_main
